{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KLbGpqWyztt",
        "outputId": "dcb8b060-2a8c-4de3-ffa5-b76077d6438c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        behavior description  gender    age  \\\n",
            "0  Mental Health   excellent    Male  18-24   \n",
            "1  Mental Health   excellent  Female  25-34   \n",
            "2  Mental Health   excellent  Female  35-44   \n",
            "3  Mental Health   excellent  Female  45-54   \n",
            "4  Mental Health   excellent  Female  55-64   \n",
            "\n",
            "                                    location  sample_size  likelihood_percent  \n",
            "0                             East Melbourne          761                41.6  \n",
            "1                  South Wharf and Southbank          573                50.3  \n",
            "2                  Kensington and Flemington          274                35.6  \n",
            "3  South Yarra, Melbourne and St Kilda Road           421                43.3  \n",
            "4                                  Docklands          229                47.5  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 80 entries, 0 to 79\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   behavior            80 non-null     object \n",
            " 1   description         80 non-null     object \n",
            " 2   gender              80 non-null     object \n",
            " 3   age                 80 non-null     object \n",
            " 4   location            80 non-null     object \n",
            " 5   sample_size         80 non-null     int64  \n",
            " 6   likelihood_percent  80 non-null     float64\n",
            "dtypes: float64(1), int64(1), object(5)\n",
            "memory usage: 4.5+ KB\n",
            "None\n",
            "\n",
            "Training Random Forest...\n",
            "Best parameters: {'max_depth': None, 'n_estimators': 100}\n",
            "Accuracy: 0.375\n",
            "Cross-validation scores: [0.53333333 0.4        0.71428571 0.5        0.71428571]\n",
            "Mean CV score: 0.5723809523809524\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "          Carlton       0.33      0.20      0.25         5\n",
            "         Carlton        0.50      0.67      0.57         6\n",
            "City of Melbourne       0.00      0.00      0.00         3\n",
            "        Docklands       0.25      0.50      0.33         2\n",
            "\n",
            "         accuracy                           0.38        16\n",
            "        macro avg       0.27      0.34      0.29        16\n",
            "     weighted avg       0.32      0.38      0.33        16\n",
            "\n",
            "\n",
            "Feature Importance:\n",
            "              feature  importance\n",
            "6  likelihood_percent    0.374738\n",
            "3            location    0.171073\n",
            "4         sample_size    0.127386\n",
            "5     sample_size_log    0.126773\n",
            "1         age_numeric    0.092470\n",
            "2           age_group    0.075373\n",
            "0              gender    0.032187\n",
            "\n",
            "Training SVM...\n",
            "Best parameters: {'C': 10, 'kernel': 'rbf'}\n",
            "Accuracy: 0.3125\n",
            "Cross-validation scores: [0.6        0.53333333 0.71428571 0.35714286 0.78571429]\n",
            "Mean CV score: 0.5980952380952381\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "          Carlton       0.25      0.20      0.22         5\n",
            "         Carlton        0.43      0.50      0.46         6\n",
            "City of Melbourne       0.00      0.00      0.00         3\n",
            "        Docklands       0.25      0.50      0.33         2\n",
            "\n",
            "         accuracy                           0.31        16\n",
            "        macro avg       0.23      0.30      0.25        16\n",
            "     weighted avg       0.27      0.31      0.28        16\n",
            "\n",
            "\n",
            "Training Logistic Regression...\n",
            "Best parameters: {'C': 1, 'solver': 'lbfgs'}\n",
            "Accuracy: 0.5\n",
            "Cross-validation scores: [0.46666667 0.53333333 0.57142857 0.5        0.71428571]\n",
            "Mean CV score: 0.5571428571428572\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "          Carlton       0.40      0.40      0.40         5\n",
            "         Carlton        0.50      0.50      0.50         6\n",
            "City of Melbourne       0.67      0.67      0.67         3\n",
            "        Docklands       0.50      0.50      0.50         2\n",
            "\n",
            "         accuracy                           0.50        16\n",
            "        macro avg       0.52      0.52      0.52        16\n",
            "     weighted avg       0.50      0.50      0.50        16\n",
            "\n",
            "\n",
            "Behavior Mapping:\n",
            "Carlton: 0\n",
            "Carlton : 1\n",
            "City of Melbourne: 2\n",
            "Docklands: 3\n",
            "Docklands : 4\n",
            "East Melbourne: 5\n",
            "East Melbourne : 6\n",
            "Kensington  and Flemington: 7\n",
            "Kensington  and Flemington : 8\n",
            "Kensington and Flemington: 9\n",
            "Kensington and Flemington : 10\n",
            "Melbourne CBD: 11\n",
            "North Melbourne  and  West Melbourne : 12\n",
            "North Melbourne and  West Melbourne: 13\n",
            "North Melbourne and  West Melbourne : 14\n",
            "North Melbourne and West Melbourne : 15\n",
            "North Melbourne, and  West Melbourne: 16\n",
            "Parkville: 17\n",
            "Parkville : 18\n",
            "South Wharf  and Southbank : 19\n",
            "South Wharf / Southbank : 20\n",
            "South Wharf and Southbank: 21\n",
            "South Wharf and Southbank : 22\n",
            "South Yarra,  Melbourne and St Kilda Road: 23\n",
            "South Yarra,  Melbourne and St Kilda Road : 24\n",
            "South Yarra, Melbourne and St Kilda Road: 25\n",
            "South Yarra, Melbourne and St Kilda Road : 26\n",
            "\n",
            "Number of unique classes: 4\n",
            "Unique classes:\n",
            "Carlton\n",
            "Carlton \n",
            "City of Melbourne\n",
            "Docklands\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/HB1.csv')\n",
        "\n",
        "# Display the first few rows and data info\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "\n",
        "# Preprocess the data\n",
        "le = LabelEncoder()\n",
        "data['behavior'] = le.fit_transform(data['behavior'])\n",
        "data['gender'] = le.fit_transform(data['gender'])\n",
        "data['location'] = le.fit_transform(data['location'])\n",
        "\n",
        "# Handle age ranges\n",
        "def age_to_numeric(age_range):\n",
        "    if isinstance(age_range, str):\n",
        "        if '+' in age_range:\n",
        "            return int(age_range.replace('+', ''))\n",
        "        else:\n",
        "            return int(age_range.split('-')[0])\n",
        "    return age_range\n",
        "\n",
        "data['age_numeric'] = data['age'].apply(age_to_numeric)\n",
        "\n",
        "# Feature engineering\n",
        "data['age_group'] = pd.cut(data['age_numeric'], bins=[0, 25, 35, 45, 55, 65, 100], labels=[0, 1, 2, 3, 4, 5])\n",
        "data['sample_size_log'] = np.log1p(data['sample_size'])\n",
        "\n",
        "# Split features and target\n",
        "X = data[['gender', 'age_numeric', 'age_group', 'location', 'sample_size', 'sample_size_log', 'likelihood_percent']]\n",
        "y = data['behavior']\n",
        "\n",
        "# Get unique classes\n",
        "unique_classes = np.unique(y)\n",
        "class_names = le.inverse_transform(unique_classes)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42),\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, multi_class='ovr', max_iter=1000)\n",
        "}\n",
        "\n",
        "# Define parameter grids for GridSearchCV\n",
        "param_grids = {\n",
        "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]},\n",
        "    'SVM': {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear']},\n",
        "    'Logistic Regression': {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']}\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "    # Perform GridSearchCV\n",
        "    grid_search = GridSearchCV(model, param_grids[name], cv=5, n_jobs=-1)\n",
        "    grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "    # Get best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "    # Perform cross-validation\n",
        "    cv_scores = cross_val_score(best_model, X_train_resampled, y_train_resampled, cv=5)\n",
        "    print(f\"Cross-validation scores: {cv_scores}\")\n",
        "    print(f\"Mean CV score: {np.mean(cv_scores)}\")\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "    # Feature importance (only for Random Forest)\n",
        "    if name == 'Random Forest':\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': X.columns,\n",
        "            'importance': best_model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        print(\"\\nFeature Importance:\")\n",
        "        print(feature_importance)\n",
        "\n",
        "# Print unique behaviors and their encoded values\n",
        "behavior_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(\"\\nBehavior Mapping:\")\n",
        "for behavior, code in behavior_mapping.items():\n",
        "    print(f\"{behavior}: {code}\")\n",
        "\n",
        "# Print number of unique classes\n",
        "print(f\"\\nNumber of unique classes: {len(unique_classes)}\")\n",
        "print(\"Unique classes:\")\n",
        "for class_name in class_names:\n",
        "    print(class_name)"
      ]
    }
  ]
}