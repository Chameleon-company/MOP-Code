{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 94658,
     "status": "ok",
     "timestamp": 1747471394521,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "HDYaYgnUtRFj",
    "outputId": "a2c89675-fc6b-4ac2-ea55-82a38e3394dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m129.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
      "Collecting trl\n",
      "  Downloading trl-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.3)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.17.0-py3-none-any.whl (348 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, datasets, accelerate, trl\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.4\n",
      "    Uninstalling datasets-2.14.4:\n",
      "      Successfully uninstalled datasets-2.14.4\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.6.0\n",
      "    Uninstalling accelerate-1.6.0:\n",
      "      Successfully uninstalled accelerate-1.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.7.0 datasets-3.6.0 fsspec-2025.3.0 trl-0.17.0\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.31.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.4.26)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=13e2095cc0d73ef285e4f2a04d5485386f317a1f6c023c2f15db1fe8f508ad15\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m139.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes\n",
    "!pip install -U transformers\n",
    "!pip install -U accelerate datasets peft trl\n",
    "!pip install -U huggingface_hub\n",
    "!pip install -q evaluate bert-score\n",
    "!pip install rouge_score\n",
    "!pip install -q streamlit pyngrok\n",
    "!pip install -q flask flask-ngrok flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qw4Oj_qwp-2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "7b9b3cc897184f0a87417bb3d380621b",
      "cafc1bb1203842d68b8f8db45e6b4687",
      "5e97cf0464334668bea3d0ec0ec1b7e7",
      "694ede7ebebc4c92a6d8363c81d2b69c",
      "07e542ecd0e6457888e4ebdc68bb18f7",
      "a608daf23ea547aa84f19bb5ec057aed",
      "0bbb3b154bd940d88464e587fb545509",
      "353d7f5d665a4c39ae5f013054932dad",
      "8697e4059bc54eeb8298d2383006e148",
      "df9382b9bc344ee3879c733e75452707",
      "195b8c7fc35e45e9a5e54c6c3746b874",
      "1cdc45b52c8d486e8cf415c0d8992793",
      "00d47cb7fbbf45b6a9109dc1bdedb4bb",
      "621b958b3a2c42898026f5851c14f6db",
      "58405072f99e46b59fd540e86c096b8a",
      "58e2303960d1488ba2919453127f7009",
      "0d5200684e834eb6bd7009b52d73eadd",
      "5211b35f85d44a3b941b2a211b2590ab",
      "df61d723a30c46e488f7a91e1713d0c8",
      "5f70971f1c744e4b91138644bd4217cb"
     ]
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1747472501814,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "R0x0ttG1wszF",
    "outputId": "9656d96d-4005-42ef-a081-ceb48a223e12"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2372,
     "status": "ok",
     "timestamp": 1747473333802,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "ggbDC6T8gCC6",
    "outputId": "e0f37888-1cec-4da0-9cc9-e789ed6dca6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
      ".env file created at /content/drive/MyDrive/secrets/.env\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path(\"/content/drive/MyDrive/secrets/.env\")\n",
    "env_content = \"HF_TOKEN=ACTUAL_NGROK_TOKEN\"\n",
    "env_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "env_path.write_text(env_content)\n",
    "\n",
    "print(f\".env file created at {env_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iZWzKrAguBn"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Epq98bfm0IMk"
   },
   "source": [
    "# Dataset Counsel Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    },
    "executionInfo": {
     "elapsed": 3978,
     "status": "ok",
     "timestamp": 1745011877068,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "k8HwilSzwyQt",
    "outputId": "cf1ed0ca-cdc1-43d1-a45c-a69bdd7cd4d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "ğŸ§¾ Columns: Index(['Unnamed: 0', 'questionID', 'questionTitle', 'questionText',\n",
      "       'questionLink', 'topic', 'therapistInfo', 'therapistURL', 'answerText',\n",
      "       'upvotes', 'views', 'split'],\n",
      "      dtype='object')\n",
      "\n",
      "ğŸ“Œ Sample rows:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"print(df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questionID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questionTitle\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Can I change my feeling of being worthless to everyone?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questionText\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questionLink\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"depression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"therapistInfo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Sherry Katz, LCSWCouples and Family Therapist, LCSW\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"therapistURL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"https://counselchat.com/therapists/sherry-katz-lcsw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answerText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media. \\u00a0Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living. \\u00a0They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible. \\u00a0 Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upvotes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"views\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1873,\n        \"min\": 5,\n        \"max\": 3514,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2899\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a7c760d9-1696-42d0-b647-1d3756336624\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>questionID</th>\n",
       "      <th>questionTitle</th>\n",
       "      <th>questionText</th>\n",
       "      <th>questionLink</th>\n",
       "      <th>topic</th>\n",
       "      <th>therapistInfo</th>\n",
       "      <th>therapistURL</th>\n",
       "      <th>answerText</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>views</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Can I change my feeling of being worthless to ...</td>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>https://counselchat.com/questions/can-i-change...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Sherry Katz, LCSWCouples and Family Therapist,...</td>\n",
       "      <td>https://counselchat.com/therapists/sherry-katz...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "      <td>1</td>\n",
       "      <td>2899</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Can I change my feeling of being worthless to ...</td>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>https://counselchat.com/questions/can-i-change...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Robin Landwehr, DBH, LPCC, NCCMental Health in...</td>\n",
       "      <td>https://counselchat.com/therapists/robin-landw...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "      <td>1</td>\n",
       "      <td>3514</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Can I change my feeling of being worthless to ...</td>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>https://counselchat.com/questions/can-i-change...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Lee KingI use an integrative approach to treat...</td>\n",
       "      <td>https://counselchat.com/therapists/lee-king</td>\n",
       "      <td>First thing I'd suggest is getting the sleep y...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7c760d9-1696-42d0-b647-1d3756336624')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a7c760d9-1696-42d0-b647-1d3756336624 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a7c760d9-1696-42d0-b647-1d3756336624');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-76b75aed-73fb-46a0-aaca-bb6741aa18e3\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76b75aed-73fb-46a0-aaca-bb6741aa18e3')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-76b75aed-73fb-46a0-aaca-bb6741aa18e3 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Unnamed: 0  questionID                                      questionTitle  \\\n",
       "0           0           0  Can I change my feeling of being worthless to ...   \n",
       "1           1           0  Can I change my feeling of being worthless to ...   \n",
       "2           2           0  Can I change my feeling of being worthless to ...   \n",
       "\n",
       "                                        questionText  \\\n",
       "0  I'm going through some things with my feelings...   \n",
       "1  I'm going through some things with my feelings...   \n",
       "2  I'm going through some things with my feelings...   \n",
       "\n",
       "                                        questionLink       topic  \\\n",
       "0  https://counselchat.com/questions/can-i-change...  depression   \n",
       "1  https://counselchat.com/questions/can-i-change...  depression   \n",
       "2  https://counselchat.com/questions/can-i-change...  depression   \n",
       "\n",
       "                                       therapistInfo  \\\n",
       "0  Sherry Katz, LCSWCouples and Family Therapist,...   \n",
       "1  Robin Landwehr, DBH, LPCC, NCCMental Health in...   \n",
       "2  Lee KingI use an integrative approach to treat...   \n",
       "\n",
       "                                        therapistURL  \\\n",
       "0  https://counselchat.com/therapists/sherry-katz...   \n",
       "1  https://counselchat.com/therapists/robin-landw...   \n",
       "2        https://counselchat.com/therapists/lee-king   \n",
       "\n",
       "                                          answerText  upvotes  views  split  \n",
       "0  If everyone thinks you're worthless, then mayb...        1   2899  train  \n",
       "1  Hello, and thank you for your question and see...        1   3514  train  \n",
       "2  First thing I'd suggest is getting the sleep y...        0      5  train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§¼ Missing values per column:\n",
      "Unnamed: 0       0\n",
      "questionID       0\n",
      "questionTitle    0\n",
      "questionText     0\n",
      "questionLink     0\n",
      "topic            0\n",
      "therapistInfo    0\n",
      "therapistURL     0\n",
      "answerText       0\n",
      "upvotes          0\n",
      "views            0\n",
      "split            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#Load dataset\n",
    "file_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/20200325_counsel_chat.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#Preview dataset\n",
    "print(\"ğŸ§¾ Columns:\", df.columns)\n",
    "print(\"\\nğŸ“Œ Sample rows:\")\n",
    "display(df.head(3))\n",
    "\n",
    "#Check for missing values\n",
    "print(\"\\nğŸ§¼ Missing values per column:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPyEtvqo0Tf1"
   },
   "source": [
    "# Step 2: Extract Best Q&A Pairs to JSONL (for LoRA Fine-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1745011970886,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "KoYkbj-t0UuE",
    "outputId": "f345144e-93b9-4a96-d95b-b0fb80d2d531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 815 cleaned Q&A pairs to: /content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#Group by questionID and select top upvoted answer\n",
    "top_answers_df = (\n",
    "    df.sort_values(\"upvotes\", ascending=False)\n",
    "      .groupby(\"questionID\", as_index=False)\n",
    "      .first()\n",
    ")\n",
    "\n",
    "#Format into JSONL format for instruction-output fine-tuning\n",
    "jsonl_data = []\n",
    "for _, row in top_answers_df.iterrows():\n",
    "    instruction = row[\"questionText\"].strip()\n",
    "    output = row[\"answerText\"].strip()\n",
    "\n",
    "    #Optional: Skip if too short\n",
    "    if len(instruction.split()) < 4 or len(output.split()) < 4:\n",
    "        continue\n",
    "\n",
    "    jsonl_data.append({\"instruction\": instruction, \"output\": output})\n",
    "\n",
    "#Save to JSONL file\n",
    "output_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    for entry in jsonl_data:\n",
    "        json.dump(entry, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"âœ… Saved {len(jsonl_data)} cleaned Q&A pairs to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAhstEVv0ZIL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gKWui2D1Nvr"
   },
   "source": [
    "# Testing with Mistral + Counsel Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "addf197679684cce971353fa4e7a6ad6",
      "85b36571373b43b9a6eed7e094102440",
      "ac4e5f083276498eb3211bc1b814412a",
      "f1d48812c3dd46c1bb8bb2dbe807be08",
      "e07ba80b6b6a4f6b80268f05bd76daee",
      "677f490d842947448fdaa51f26ca9694",
      "9e560c36f5a24bed809704004aa5b067",
      "3ae50d61e8fe46a6b31ff5e60526029f",
      "70d31d63f77a45408ae0a461cbeaff81",
      "edb3cb4f9296426aa5c390eb79ce0b8b",
      "6a1596e0ec50487dadb07d81468c06ec",
      "2a737ac421b0440c8b5ff4b97546d96d",
      "aa0dca670e244040a0eee066e37e1a09",
      "24fbeed3f25a4fe49484692055b8c891",
      "182350f8ba9440959676db9aceb438a8",
      "156173c591304c0faafefc2171322314",
      "72f6d5121d164985b924208868a65b61",
      "481d22becbc44e85844cfa20e9687fd1",
      "1b90f01c187842a1a950619941f9aa01",
      "a362b9ae2b10416582701ee0a7ebf77a",
      "d84d4d8ceeaf49bfae94454810727f9f",
      "05868d30e75244bab83f0a19c649cc64",
      "4734d476d74f435a8ffd39f21233e146",
      "7a760f935e1049acb43eeeeefc5d2b2e",
      "8701451a3fe44b13b6499f2cfd49bd2f",
      "fe299507d39b414999df96ceaf0f9049",
      "1f2b3aba51734a9f938e752369d7f58e",
      "832b1b199ba44db885293b625798964c",
      "3af8fd016aae436f93750bd789ccfbc7",
      "ed564092f9334d0598a9b608492336d2",
      "8349731910f04c71ad002b8d5dd4cabf",
      "3d07f93db0ce4d8695fe19178c7ee89d",
      "ffa78e67d4ee4169badb95c0d9aa8630",
      "d7a8825947e34f45a92129ac564c7e1a",
      "8cfc1bad974745c6878e75df1f1e928c",
      "9625c56fa28248bca8a8250e67d1800d",
      "e4b1dc19b21445d1a76a7643a7d9d555",
      "0c913930433141d887a2ce6ac780eeaf",
      "3ca6a11dac544281be19d99f457dcd33",
      "eb384ea1ea2540409591e29906cb9aa7",
      "02f77ba8ef504bcf88c47df0492856aa",
      "c119ec45b34c4faeaad8c366e603ce18",
      "c8c0ced0bc394c02b5896b8423f2a8d7",
      "3853e0483fc34e879957e4befaa09c48",
      "3001bfcdec424f2f80a69d084ebfb316",
      "46101e79224e4e948f1c147c6abe33fd",
      "34381f5184a64bc7a78c40374cd960b7",
      "1f28f6eca576404d91afa7e4ce746eff",
      "01288d24bf8c43aea9ca8f84c558df80",
      "6025b31361074595b69249cb181eb25c",
      "454d2ad014ad4cc781b55a3599cb30e6",
      "0c6047e75c3a4d28b7ed11c624801f21",
      "14893385c5e64c5c863f1039f72b3b66",
      "806c42c3a64f44e8bf87bd829dab0a72",
      "c8da6c62a0274071870d6a8db6dd53d5",
      "fa61b8b075874b2fb516f25ba55ee2b1",
      "5cd84ce027484791aa3027744954bb18",
      "2ce2d1fa49954bc7a0d489fcdbf72a7a",
      "5032052c73284d5ba10d14a29691e011",
      "cbc6ebe17b9b475f96cb5f2bd2a409aa",
      "1de42330747f4df5b7247827428d3cc6",
      "8c9c46219b24452aac2e6bdf60961734",
      "1642d7234d944b4a872e88c03cbcc0f3",
      "066b9e188a5342178611d78bb8658215",
      "30fcab15c933446492128ea10da0abe2",
      "515a1c2d85194c4f94f12238d99f78bb",
      "bee51dc3675344fc8d1044020382d7a3",
      "1c342b7d2e6944cf9e765e4b2ff5f468",
      "43057d01ae944859b53e44c7ce357326",
      "6730335a0ba74b9d965afbe989ef926e",
      "a7e2e24e595f45c8a56e5110a0cb8c1e",
      "992be9bf85254f4db434dc6179a581b3",
      "1137f0a659e04320a3372240ca2c97bd",
      "c96903e980fe45e4b679ef16dab1f170",
      "56f39caf5a384966b6993bf2158b8eaa",
      "f5d2d10492a048db8f0791aba411e915",
      "9522a24fd2f04c4e9a9c34dd82f999b0",
      "9d34263a146c4acea58ce0d5d095d39d",
      "2dd0fa669ca045ebada0eb9838e35216",
      "18009e9947a94704b06107d48eca6fac",
      "2b0684f537a44769a3104d234ef010f3",
      "33c26f0d7d584a149da261296357521e",
      "39b50fb25ea441eb8a321d5f6c06911f",
      "6724e48fe1ec4a0785040e5b90088488",
      "43f22475f45743aebb076dae09396dea",
      "657b119fdfd545d5be8de963e9a17ad5",
      "10c3843925d5434b87c651234db4460e",
      "a2002445788f4da8b6c1240d4a60b2e7",
      "c74c2a920ab8489fa5235595a52b8b88",
      "df62a723c62648aa8d36b55d1380bb70",
      "052e7c9d614a42e1b8c4284a95e08159",
      "3a3cb5f680ab429aa5b76166d525ea67",
      "7cb87c8ff390433d89688d2996f88ad4",
      "070fb241286b4dda9f21e63d2cea939a",
      "b3571d08d48a465db79c3a1375bbcc20",
      "318f84a6d66e4e57b7d037ba91347a79",
      "8355cf61136c439383bc22063d9d1c41",
      "506224f726d14c298a7d107f669eaf66",
      "498dbbdc0e504ea9a372d62148157fc5",
      "c06d285e85764d0c84422f41cfd03d0a",
      "60e7ca516f4547d1b22e749a9f07735b",
      "949bfbfc43f2436790bb4a6e9e1fbd14",
      "0feb65b4cd134f0884442f017cddb94f",
      "ae4c8902cf0e4c3e8dacfd158d51147b",
      "10f06b82721647dca29a4eb0f9a5eca7",
      "a0337a1bbf0842adbcf55f835024af6a",
      "259633cd52da4ac4ba792f383af286b9",
      "86645c0ae2e74fc6a026699b16b462ec",
      "0c13a1eecccf4d27bc14b1dfd12cf850",
      "b2563a215c3347a284e23d6ebc207b2a",
      "6525836528c942f8b96ce2db93ebb715",
      "cf473f3d36b24a578ec47a618d6d8aa8",
      "1c4ec6b403e64e218366382eae16d936",
      "4b106ac55ccb4d06a3d72a8d9c3608ef",
      "db672945614c47c6971aaf0409ac749b",
      "f534bdf0a3c141af93ef1a5c40dceafc",
      "bb7bdc2f812943b5911b84f225995e69",
      "5426982a19a645ccb8e5e36fadd5035f",
      "6ce8ae47acb445da994a333f37af50fe",
      "6ba6560500f244128e39382039fe46df",
      "875e75a97be14178a8d699da40944906",
      "3ae90da961c74089a89e4cd76cd3522c",
      "db0e2c74afb54aef8d6abb0f63f91451",
      "946f8deda3e24a85a684c4cef4921504",
      "262e9ff850e241bbaec98b49e930c346",
      "9a2fa98baf654ce7bce85d40bcca2a46",
      "fd87b098c72d4ace955450d08cdb3a2a",
      "d2cb4496f19d434593ce1f260ba07e34",
      "53f0e5c9a54e4bf3be5940cbfcd93530",
      "4dc202cb1f4743d3960041d166016b3f",
      "5bd8d4964638480795e7d7b0e10e7750",
      "dd76dd767b8645d2b4a86ff92bb2feb7"
     ]
    },
    "executionInfo": {
     "elapsed": 87495,
     "status": "ok",
     "timestamp": 1745012435263,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "ru6fE__O1Sdr",
    "outputId": "346de0cc-e682-4c26-e821-a9cb2f378497"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addf197679684cce971353fa4e7a6ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a737ac421b0440c8b5ff4b97546d96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4734d476d74f435a8ffd39f21233e146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a8825947e34f45a92129ac564c7e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3001bfcdec424f2f80a69d084ebfb316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa61b8b075874b2fb516f25ba55ee2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee51dc3675344fc8d1044020382d7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d34263a146c4acea58ce0d5d095d39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74c2a920ab8489fa5235595a52b8b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06d285e85764d0c84422f41cfd03d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6525836528c942f8b96ce2db93ebb715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae90da961c74089a89e4cd76cd3522c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ Prompt: I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n",
      "   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n",
      "   How can I change my feeling of being worthless to everyone?\n",
      "ğŸ”¹ Expected: Hello, and thank you for your question and seeking advice on this. Feelings of worthlessness is unfortunately common. In fact, most people, if not all, have felt this to some degree at some point in their life. You are not alone.Â Changing our feelings is like changing our thoughts - it's hard to do. Our minds are so amazing that the minute you change your thought another one can be right there to take it's place. Without your permission, another thought can just pop in there. The new thought may feel worse than the last one! My guess is that you have tried several things to improve this on your own even before reaching out on here. People often try thinking positive thoughts, debating with their thoughts, or simply telling themselves that they need to \"snap out of it\" - which is also a thought that carries some self-criticism.Â Some people try a different approach, and there are counselors out there that can help you with this. The idea is that instead of trying to change the thoughts, you change how you respond to them. You learn skills that allow you to manage difficult thoughts and feelings differently so they don't have the same impact on you that they do right now. For some people, they actually DO begin to experience less hurtful thoughts once they learn how to manage the ones they have differently. Acceptance and Commitment Therapy may be a good choice for you.Â There is information online and even self-help books that you can use to teach you the skills that I mentioned. Because they are skills, they require practice, but many people have found great relief and an enriched life by learning them.Â As for suicidal thoughts, I am very glad to read that this has not happened to you. Still, you should watch out for this because it can be a sign of a worsening depression. If you begin to think about this, it is important to reach out to a support system right away. The National Suicide Prevention Lifeline is 1-800-273-8255. The text line is #741741.Â I hope some other colleagues will provide you more suggestions.Â Be well...Robin Landwehr, DBH, LPCC\n",
      "ğŸ¤– Model: [INST] You are a supportive mental health assistant. Provide thoughtful guidance.\n",
      "\n",
      "User: I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n",
      "   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n",
      "   How can I change my feeling of being worthless to everyone?\n",
      "\n",
      "Respond with empathy and practical steps. [/INST] I'm really sorry that you're feeling this way, and I want you to know that it's important to reach out for help when you're struggling. Feeling worthless can be a very heavy burden to carry, and it's not uncommon for people to experience these feelings from time to time. However, it's important to remember that your worth is not determined by what you do or don't accomplish, but rather by your inherent value as a human being.\n",
      "\n",
      "Here are some practical steps that might help you start to shift your thinking and improve your self-worth:\n",
      "\n",
      "1. Practice self-compassion: Be kind and understanding with yourself, just as you would be with a good friend. Instead of criticizing yourself, try to speak to yourself with kindness and understanding.\n",
      "2. Identify your strengths: Make a list of things that you're good at and that you're proud of. Focusing on your strengths\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ Prompt: I self-harm, and I stop for awhile. Then when I see something sad or depressing, I automatically want to self-harm.\n",
      "ğŸ”¹ Expected: In a way, self-harm can present somewhat like an addiction. Â According to new research within the field of neuroscience there is a valid explanation for this. Â When a person cuts or uses other forms of self harm, the body produces endorphins to help make a person feel better. Â If a person was dealing with depression or high anxiety, that might be misinterpreted by the brain as a way to help oneself feel better and a new neural network or map might form (addiction) that would utilize this new behavior. Â Another way to look at it would be thru a behavioral lens, a positive reward for a behavior, even though the behavior has other long term negative consequences. Â Consider working with someone who can both have you work on and address those items that trigger your behavior and the root causes, in this case sadness or depression, and second find someone who can help give you alternatives that take into account the neurological requirement by replacing the behavior with another behavior (such as snapping a rubber band on the wrist) and working to extinguish the unwanted behavior. Â  Someone who is trained in Dialectic Behavior Therapy and/or Interpersonal Neurobiology would most likely have the skills and means available to address this with you.\n",
      "ğŸ¤– Model: [INST] You are a supportive mental health assistant. Provide thoughtful guidance.\n",
      "\n",
      "User: I self-harm, and I stop for awhile. Then when I see something sad or depressing, I automatically want to self-harm.\n",
      "\n",
      "Respond with empathy and practical steps. [/INST] I'm really sorry that you're feeling this way, and it's important to remember that I'm an AI and can't provide the same level of understanding and support as a human mental health professional. However, I can offer some suggestions that might help you when you're feeling the urge to self-harm.\n",
      "\n",
      "First and foremost, it's important to reach out for help. Reach out to a trusted friend or family member, or consider contacting a mental health professional. They can provide you with the support and guidance you need to manage your feelings and find healthier ways to cope.\n",
      "\n",
      "When you're feeling the urge to self-harm, try the following steps:\n",
      "\n",
      "1. Reach out for support: Call a trusted friend or family member, or contact a mental health professional.\n",
      "2. Practice deep breathing: Take deep breaths in through your nose, hold for a few seconds, and exhale slowly through your\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Œ Prompt: After he got home from the hospital he was angry, then for a time wonderful. Now he is depressed and hopeless again.\n",
      "ğŸ”¹ Expected: This is actually more common then we often realize, and actually understandable, as he has gone through a trauma, an unresolved existential crisis. Â He was taken care of by others and now is again left alone with his own internal, and rather horrific inner struggle.In my work with CCT, or Contextual Conceptual Therapy, (see www.suicidetherapy.com) I have learned how trapped suicidalÂ people are in their own isolation, also called a \"mysterious isolation,\" a form of self protection which cuts the off from their Self, or spirit. Â And unless they address this message from their soul, accompany a guide on a journey to discover their own missing information, that is to recognize how their own uncomforted emotionalÂ pain has resulted in a coping stategy which has effectively cut themselves off from their own beauty, their Self, and their ability to receive love from themselves and others.Â Their attempt to kill themselves is a cry from their soul or spirit that they cannot live the life they are living any longer. Â They take this literally and try to end their life, when in fact what their soul or spirit is saying is they need to begin to live the life they came here to live.\n",
      "ğŸ¤– Model: [INST] You are a supportive mental health assistant. Provide thoughtful guidance.\n",
      "\n",
      "User: After he got home from the hospital he was angry, then for a time wonderful. Now he is depressed and hopeless again.\n",
      "\n",
      "Respond with empathy and practical steps. [/INST] I'm really sorry to hear that your loved one is experiencing depression and hopelessness again after a hospitalization. It's important to remember that mental health can be unpredictable and recovery can be a rollercoaster ride with ups and downs. It's normal to feel angry, wonderful, and depressed at different times.\n",
      "\n",
      "First, I want to validate your feelings and let you know that it's okay to feel frustrated and concerned. It's important to remember that mental health recovery is a process and setbacks are a part of it.\n",
      "\n",
      "Here are some practical steps that may help:\n",
      "\n",
      "1. Encourage professional help: Encourage your loved one to continue with their treatment plan, which may include therapy, medication, or support groups. Remind them that it's important to stay consistent with their treatment to see improvement.\n",
      "2. Encourage self-care: Encourage your loved one to engage in\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "#Load base model (or your fine-tuned model path)\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "#Load your CounselChat cleaned JSONL\n",
    "jsonl_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\"\n",
    "samples = []\n",
    "\n",
    "with open(jsonl_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        samples.append(data)\n",
    "\n",
    "#Test first 3 prompts\n",
    "for i in range(3):\n",
    "    user_question = samples[i]['instruction']\n",
    "    expected_answer = samples[i]['output']\n",
    "\n",
    "    #Prompt style to guide model\n",
    "    prompt = f\"\"\"<s>[INST] You are a supportive mental health assistant. Provide thoughtful guidance.\n",
    "\n",
    "User: {user_question}\n",
    "\n",
    "Respond with empathy and practical steps. [/INST]\"\"\"\n",
    "\n",
    "    #Generate\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=200)\n",
    "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\nğŸ“Œ Prompt: {user_question}\\nğŸ”¹ Expected: {expected_answer}\\nğŸ¤– Model: {response}\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYy9lDcc11K6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lQIuZhc30Qf"
   },
   "source": [
    "# Tuning -Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d4e5ec717b164a86992ee47e40368ae3",
      "d72e6d94e19f491380e8f0e5e3ddfd36",
      "bcebfc5b9b66467186e2f115eecfac56",
      "f4c924e329d2434f8ad8590f0224cf9d",
      "890bc707230348afb5cdc6da1a6fe126",
      "d25e968e041f4aa191cadcadc8ccb588",
      "6e9a5f429a57400fb56ae98384243f6a",
      "d4825c1ff6164dec9bfb23f0bdd3c1e2",
      "0783f1e77b0143748286ecddaa833904",
      "b9e3cbade94449409805ba2a55e81824",
      "20d79abe25d34139a3ed1b428e9ada0a",
      "fada0d75ba214f4c8cd4956dc820ae98",
      "191367cb9c4a4b7b959c451e938ee9fe",
      "66c1c38f6f014ebf83439d714ff13706",
      "1daf2d2359374fc5a26a1e34e8fb0431",
      "954363e9e76c4064986af270e9889a9b",
      "04d18bac0300468995fc6c2ac3e437dc",
      "a0a01d71a5584633ad2c97dbda8d93e9",
      "dabc2c3ca9ed46a181ec927dd9ddd85c",
      "e8aa5ed4487b49479cb5134aba09ecb5",
      "e202206c7d174f229b4e942de3e79b02",
      "c76d6bab6526486a84d5e73ee168c6f6"
     ]
    },
    "executionInfo": {
     "elapsed": 305677,
     "status": "ok",
     "timestamp": 1745014056543,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "RwTh9NvJ32ul",
    "outputId": "c53db966-fdb1-4b9e-ebe5-093d323c66b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e5ec717b164a86992ee47e40368ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fada0d75ba214f4c8cd4956dc820ae98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='612' max='612' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [612/612 04:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>12.829200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.938700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.618200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.235300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.349400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.701100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.456600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.925600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.346300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.419900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.498300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.368400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.337400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.234000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.469800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.493000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.389400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.615600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.287400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.466800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trial 1 fine-tuning complete and saved to Drive!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "\n",
    "#Load dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\", split=\"train\")\n",
    "\n",
    "#Load tokenizer + Fix padding\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Fix padding token issue\n",
    "\n",
    "#Tokenization function\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{example['instruction']} [/INST]\"\n",
    "    result = tokenizer(prompt, text_target=example[\"output\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    return result\n",
    "\n",
    "#Tokenize dataset\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "#Load base model + apply LoRA\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "#Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial1\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    warmup_steps=10,\n",
    "    logging_steps=20,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset\n",
    ")\n",
    "\n",
    "#Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "#Save model\n",
    "model.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial1\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial1\")\n",
    "\n",
    "print(\"âœ… Trial 1 fine-tuning complete and saved to Drive!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLFsGyBI8nXq"
   },
   "source": [
    "# Trial 1 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573,
     "referenced_widgets": [
      "abf89e855a6945148ff5c9e449257333",
      "c6fb5c7d38d640ea9e340729996ffa14",
      "e4552f53c2e840a1a74cd32bfd1fb1e1",
      "ac02f15b7a0b4875ae25ca8e8388085a",
      "ee8795f87549423ab063f894b1d8d23a",
      "c37b9a18f3d34aa9876fbe834575cc49",
      "86c5c07075bf4c8cb184ec75106ca321",
      "17e29de9db4c4b61aa5ae2b19aa57faa",
      "7f37a5ba05994a7391a300888e708d11",
      "24bf1c4bd77048fa819fdfa202a55b9a",
      "45df035a41514b4da34b9e58966a4193",
      "ff0120a4af5c46d7b893ebbdb8b717a8",
      "5b2e59eaa75c4fd5b41db474e3e3e5ef",
      "3989928de7714a60b2e9d9ede327821f",
      "65854e88592c4e6d9ef2a7aabd5e644e",
      "4f4ef9b0a62d4c22a1e9f36d3122bc71",
      "90781949380f4d9f8b7cff21e9a6ae13",
      "02452c52e68645c6bdf4f2bfccc30a81",
      "ce120c6549424152bf5ae24e5949ea64",
      "73e042da16be4732ac52ffa6128bbb7d",
      "9f4ce2828b644fa4953e544ccfe7c419",
      "e2d3a93b191148a0a042da2db6ccbeba",
      "a0577376fb35426d98c88a88d48a6464",
      "e41c94e059884af1a77665189aa91164",
      "9a0ba704d0644782839fd97c5370c752",
      "e3254cb6a64743e98f3867af9538de1d",
      "622dff5ad84b4234b440b846b5872677",
      "3235e80245c4471682268518c4f47d17",
      "2a7a2445cd4645e29be0a10e3d558c55",
      "74b8e63eac5b4f9ea29aa6bc40c39776",
      "17f933e195ba48ffb4ac30e79eca9239",
      "fc35d2bc947043b899b4f0e516f5dee4",
      "2d139044a30249dcb9c4d98687b4a1c4",
      "425c4a46016940f8a888ee09db56328a",
      "3c1cd5a7d2e6477ba20b9852eabaad92",
      "7b7b9b07352e44e583478662741fdb3e",
      "304e6d73ce0441348255663b06a0e33a",
      "ed6b83d1cf3e4cf8b8dcb5cbe2951c95",
      "d714c141cb2a495bb668627a69453710",
      "b7df5b5a79034898acdf26be647846c2",
      "a8edb922ea98432c99da20e66bda6abd",
      "10b98478f895487abb8fd7f48159665e",
      "24d58296be7b4781b2cc0dd5be53efcd",
      "ed2bf83fce724f1dbbb77bbb67e2a53d",
      "ec1f8796005a44e0a42792d24245664b",
      "90458becb0f345998598a8de7d7d5b3a",
      "1c9ad1cc7863445ba16f8d12f91c720b",
      "febca3bc3154493dae93c702ccd16c5d",
      "753e08cdf3de4077be172cc370637c2e",
      "b913b6f951a94503853b7101070d39c8",
      "ca842d84658c4623b660085db337a828",
      "0cfdba52e510428f974e798f32567fad",
      "eaf4986d615f4cb18b56c1e9f7d218ea",
      "93044f68ddc141d79f98973d52cf2c7e",
      "91fda82437714deba9def9bfe0755f1f",
      "b9b228bd032848719306e0ebb386339f",
      "7deed4209bdb4e2a954345fb06c28db3",
      "a5e9d7af886c478ea7d93ea2db75a2a5",
      "259ca3cdb8cf4b35868354c6cb43d141",
      "948fc1f843024cb7aa340dd08c5e1976",
      "44874c15c4364ed8b0e4d3ae7b2381c2",
      "5dc3926031d0421d9bb8a44c3916d1ef",
      "9438700304474c0c8de17aec771045d2",
      "f8db1f4ceaef4d73a80f9fd1de8006eb",
      "468944ae249b46daafaee8d6f527ef3c",
      "2f35a291efc5413d97dbef817692f0a7",
      "4528b0882435446c9c8131a052a38342",
      "352280db44d049a8912ec924c80bfef2",
      "943ba03a5ccc4f4a83ad0bf340bae5f2",
      "d677a23049aa452d9baa97d53ecabdf4",
      "ff13a4e53a03406082cf7b52fdfe93d0",
      "1e8b428e4b3d41209be1263862067573",
      "c2559f092d9f4201a3b2e2dca0c01803",
      "e2d05337b2c14923b5c9a62cb5a5a60c",
      "806386b90e1e45d5b4c430d1c002906f",
      "01249bd465e44c8891512ded3e5fe388",
      "e1cd5f1c86f341fc8d47e9406f7a75ca"
     ]
    },
    "executionInfo": {
     "elapsed": 1626496,
     "status": "ok",
     "timestamp": 1745017706183,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "fSqCKfcb6hLV",
    "outputId": "3216b03a-6539-473f-cdb4-880e64a86a7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf89e855a6945148ff5c9e449257333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating Trial 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [26:18<00:00,  5.26s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0120a4af5c46d7b893ebbdb8b717a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0577376fb35426d98c88a88d48a6464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425c4a46016940f8a888ee09db56328a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1f8796005a44e0a42792d24245664b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b228bd032848719306e0ebb386339f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4528b0882435446c9c8131a052a38342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Trial 1 Evaluation Results (1000 samples):\n",
      "BLEU: 0.0203\n",
      "ROUGE-1: 0.2888\n",
      "ROUGE-2: 0.0429\n",
      "ROUGE-L: 0.1349\n",
      "BERTScore (F1): 0.8311\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "\n",
    "#Load the evaluation dataset (1000 samples)\n",
    "eval_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\",\n",
    "    split=\"train[:300]\"\n",
    ")\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial1\"\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_path, local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, local_files_only=True)\n",
    "\n",
    "\n",
    "#Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "#Inference loop\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"ğŸ” Evaluating Trial 1\"):\n",
    "    prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "#Compute metrics\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "#Print results\n",
    "print(\"\\nğŸ“Š Trial 1 Evaluation Results (1000 samples):\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRvXJdDy83n8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2N-Fe8D6D6Ma"
   },
   "source": [
    "# Tuning trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9588b1d768f343499ab1dee21e9cad1f",
      "972237eae63f4aab869c173139a2ed7a",
      "ee75d2fa75324dbe8aefd064e2e92bef",
      "27607310cd3e4e34aa2eb396890c2424",
      "7b701d237fc349fca4664d49e7726b5f",
      "e5f270aa6cf74063bb11f6987ff4f9bb",
      "dc33108d089949be9013490ecb1a3d57",
      "0d8b1a8d0149405d8188ae6eb406597c",
      "cc6dc7e979214cb785edbb2ea63aa4f5",
      "6f8a2ad6fb8f4b5493ad0bf323946a01",
      "975efab37a3c4ddea26ee72451365627",
      "cb2805df7eaa40de8d1c6359870a0a4a",
      "ad4e7606fb604c57b9f4fa1d0c6e4980",
      "2413addb220845e59c356649b6f7a3ae",
      "88946a86714841f4bb61773f02e0a477",
      "6bcf2d8096c844fcb7808f58e23c3097",
      "79717ede60fc4d3da77dc38b70081f36",
      "70d11d269e6945e8b4063dfbba93d9e9",
      "00bac6d6beee4da9a78fe358a2f5da2b",
      "0cddc2a074b142c5a511bbcc33fc14b2",
      "60042e9d8a0343a1a6b281f5c38a8372",
      "81bae87b5a7d4f0395daa5901ba70da5"
     ]
    },
    "executionInfo": {
     "elapsed": 299699,
     "status": "ok",
     "timestamp": 1745084651131,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "lSNbU5tkD8UM",
    "outputId": "c831fc33-3358-40b8-c215-df4c4065d3d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9588b1d768f343499ab1dee21e9cad1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2805df7eaa40de8d1c6359870a0a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-1523726af268>:68: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='408' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [408/408 04:38, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>17.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>13.626400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>11.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>9.039500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>7.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.140400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.231900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.870600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.182300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.612800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.774100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.943600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.813400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.855700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.512600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.731700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.844300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.615300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.878300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.787100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.280200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.834500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.228200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.388900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.676400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.442900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.544900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.812600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.637800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.014300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trial 2 fine-tuning complete and saved to Drive!\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import gc\n",
    "\n",
    "#Clear GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#Load dataset (~890 samples)\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "#Load model + tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "#Tokenization function\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, padding=\"max_length\", truncation=True, max_length=384)\n",
    "    result[\"labels\"] = tokenizer(output, padding=\"max_length\", truncation=True, max_length=384)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "#Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "#LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "#Training args (tested in Trial 9)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial2\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#Train\n",
    "trainer.train()\n",
    "\n",
    "#Save model + tokenizer\n",
    "model.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial2\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial2\")\n",
    "\n",
    "print(\"âœ… Trial 2 fine-tuning complete and saved to Drive!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mi7rvAjMF9mv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe-bAMDYJ0JN"
   },
   "source": [
    "# Trial 2 - evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751,
     "referenced_widgets": [
      "623210a816c64c94806ee5f2df567d1b",
      "f2131aa0d3c847d6a381a6501b854370",
      "9a7c350e207d4118bafded94b0006ec4",
      "2aefe1a193064dd4bcccb1f4d33e7f5b",
      "364b7d237f614ddeb86c2329c15cc194",
      "df5e82e6f13e4417bf2e0d5139a7f416",
      "3fb736ef82804611b0f1803751b91a3d",
      "b93dc920ddb4495aa2a824b3b1a3bc41",
      "080b64fcd22942ef9d00fc350fa3f0c5",
      "be8bae799dfc434296ce8dd9e4bdbdee",
      "1d37e3d69ee1430a9d031bdfdc3709c7",
      "78c9ff8caff54df2aa480c2dc68f447e",
      "5c1d36c0395c40d3a93732274213d131",
      "0b19dbc2d1d243ffbeda2e99eac0a3eb",
      "a73396b5013d4c9686940c6f4587c4ae",
      "75b3fc272c6443e98f5c0c9cce783d2d",
      "fa8ff647d90d44448028a0e29eabef9a",
      "f5adfdf29b124881a75dca02b8aaca1c",
      "782ef820d53a40c2805c13ff8acc2084",
      "ca72988cb56d4a72b21a6fe076a435d8",
      "f1945e090fa44b30969535817de34c61",
      "dd1f6e16ebd04d348c84f828e47a1ac9",
      "b605741134634eb394a2230e011c9387",
      "4301e046040e4feeb622e9f3a1591771",
      "56bac3ba38994480a4e01ce4edfdf691",
      "6b15d7c9c68943b49624c8d5f9fb76d5",
      "4929fd2a07724790ba60bbd6fd7ad0e3",
      "2faeee364c7a4f089aa013e1f185ad80",
      "2fd617692392469dae6f7d5d5b4d513d",
      "b0c03ff9a2994ef7b24376c78df69f1c",
      "2f1a40805507434fba7b0542cd3d425b",
      "abcc8392e2d040748942b1caacb7e69b",
      "54b98e772bea4c5cbeeb6cb8443cb5f5",
      "de0fe05ad25b42b3816c7c7ac7557ee7",
      "79b328cb7bf74c51b4af2b1e3271215d",
      "35352e23f7d34db38b2bc0fdd74147cf",
      "8b6f44d03c6c4d3996bf7839c7705e35",
      "e52904578e0841ef8d8dbc8c409186e1",
      "341623e60f294ccca4991d869bf3f104",
      "65dbe88764944c488b2f02f121009746",
      "0f4d1f06bb4b481cb99eb065eee0e761",
      "1b70e99020f74787b57cc0450a07ca4f",
      "00f1418dab3e4b09b56ac6181b3c8f45",
      "7559e7c4cc7240ee9b52bb92a3d0d19d",
      "f53940d4a9a84e598b66df0e11216603",
      "601e6bb8f79d4cc7a2555effe43de504",
      "71e1586deffc4713b1bc31265140fa9f",
      "8d3f099e6f8b4cffa59270b9078d68b5",
      "bc7d4e0200c44b70aab7ce57910308d7",
      "dc6e7f074b254275975bdde6fd5e9889",
      "692eccc9697342548e96524c918f9d38",
      "5437e7e4889b485592de5162e8c97d7a",
      "19e51d9c4701413eaab4298ca4ebc40a",
      "6a9f5246daaa4300b120c14ca676d7c5",
      "0ff360ab13bd4bff984883cb29c47a11",
      "b5cd005e35564b86b727e3983a7298c6",
      "758c3fe98455438eae6fdd8f52f92a1f",
      "e5caa7aa50314ec2a2f977a66b633432",
      "d24f73f28cf74d1e88a942b448632e2f",
      "93aea883eba040439d95beec28d6e65f",
      "f38f472d7997471ab3718a95dfffa5d3",
      "9834a18d7a8f491da2e40479ba6cda29",
      "78d69ff63b5545ac87adbb6d5cf46902",
      "167721d4bd244efab1591f483f528080",
      "c7b523d65ac84ed3ac1efa6ecd6e2d6b",
      "552928b1caf64003a7a0267ef7d22a35",
      "a2382ddb58e643e9a20241cd40eafc9e",
      "b2497d55c4474c08a87c29d52524d9b8",
      "528124779b6443bb8504d6e2f7bf3f82",
      "d69b3789f563410c86880d0e3d413647",
      "92b429ea95514a8e9742836fa76dc244",
      "0e98f7083b634ac59a9df3a67dc7fb55",
      "3c0da1a6ef20493587bd25e525197d6c",
      "875a1d181dbb4ef1b9bfc01ea99226e2",
      "b426257210d84f83a38bb7acf83c1a3e",
      "549410a0dc054689bed859b3090e2dba",
      "ada19710ff82485093665ecf21f342fc",
      "83c25f137dac4363b82ff3b3c91769b4",
      "7579688ef964495dab05566f884c74b0",
      "87acdc887b2f46928c0cc1e473279503",
      "9c0c5e1bccd64076aa92523e68244e97",
      "96dd2ef905ea491bb2d29bf9b4f6d318",
      "a73494ce338a4ed69146c2055a04fa30",
      "71e15be2924243498864206eb4053e79",
      "0cdebdf2b40e4b8ca520fca5bd8869ff",
      "013d1733417d46d684e7d42c1dff13a0",
      "33ae36ab31194b63ab18b00913aa1133",
      "c35c4f6492e641e5b77d4b1a49859d1d",
      "876742fc3dc14ce78128f22be83a9197",
      "27beb960d91f4099835e9f7a9dd52aae",
      "c8024d1c9334411d959d8e87a290ac13",
      "43420d2c93984e4ead64f1adb21f5dca",
      "855242a9dc3e43adad61ef6361111691",
      "a9c977a275ce454686edeba4aace9bc3",
      "8f6edfe6e0264445880b5f375936f84e",
      "5a141597374d4e64848b078fc90106d4",
      "8ff158a6bd6540ff96b0e96fc7267093",
      "2da69b1b28f74bc2a3c8d1334f3f2abd",
      "38963bd330544c8fa3c2dd5b0c9b942e",
      "a318c972d5a84e2593d0e295791fae64",
      "738b9cd3d6a74df38bf5e820dcb0702e",
      "717f04b2b13c4747a50185e6167ac0ee",
      "ad640011632542b58e1e916ec87e64e9",
      "edc6aea95373458fb6dd60e71e9347f7",
      "b90ed2a59df6405db4c49155f766151a",
      "da6ef19c8ecb4866b94ce58188e65aba",
      "41ab33ee6a804b1e9a93d5f9fbc5d20d",
      "d2fdf1880ec64e8285cd1cdf7e1fb477",
      "dd20b19e422c4e859b0220227fc7c596",
      "3e4ae329d6a946f3a1201491a31f5423",
      "cd70c418332145338fe10323c67d9132",
      "181daee61b9b47af9d350ddf07c8ef90",
      "ced1ed1a503b428f84b5b2e3042955e0",
      "b6bb3871bc124c66a5dfcd9e21aa8042",
      "6fd294fc8c494f7abf0cc1b18d459ba0",
      "15279e68566d4dfca2567a745eb0240e",
      "6f546953cfa74c8cb6903535b047fe11",
      "007f28b188b94245bff8dc8767048f26",
      "dfc8762cfa5343cd8f73a72f42c329ed",
      "a473d10023f842f9a7c32ba2addd9a1e",
      "9ead24a492c7424bb152644af56ac18d",
      "63d17cea7a14406ea382e7d4653fe14f",
      "25eaa6c49cd94f599764b64b68502090",
      "1482079b41304235affcfb1635ccd197",
      "1fe9cf87337d433ca2af78365e75614d",
      "e043cfbc65bc4e78af0b234f4eb6d1cf",
      "1196dd51833b4052a6381f4627db6882",
      "49197e1abff747bc9779392c2b6746ce",
      "bced946a2b474b0e80fbc057b62ebc73",
      "bf832c442ee34eec82f3efcc91f9b2c6",
      "2cbf8761b3f3493794fe3f0bdc6690d3",
      "61e49d4f27d84170b92aa93cf837110b"
     ]
    },
    "executionInfo": {
     "elapsed": 3057617,
     "status": "ok",
     "timestamp": 1745087831153,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "eraZ3CQpJ0sF",
    "outputId": "eb7728cd-c751-4715-a2a5-6339a7810fd6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623210a816c64c94806ee5f2df567d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c9ff8caff54df2aa480c2dc68f447e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b605741134634eb394a2230e011c9387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0fe05ad25b42b3816c7c7ac7557ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53940d4a9a84e598b66df0e11216603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cd005e35564b86b727e3983a7298c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating Trial 2:   0%|          | 0/300 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "ğŸ” Evaluating Trial 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [50:07<00:00, 10.02s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2382ddb58e643e9a20241cd40eafc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c25f137dac4363b82ff3b3c91769b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876742fc3dc14ce78128f22be83a9197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a318c972d5a84e2593d0e295791fae64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd70c418332145338fe10323c67d9132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d17cea7a14406ea382e7d4653fe14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Trial 2 Evaluation Results (300 samples):\n",
      "BLEU: 0.0173\n",
      "ROUGE-1: 0.2315\n",
      "ROUGE-2: 0.0334\n",
      "ROUGE-L: 0.122\n",
      "BERTScore (F1): 0.8076\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Load evaluation dataset (300 or 1000 samples)\n",
    "eval_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\",\n",
    "    split=\"train[:300]\"\n",
    ")\n",
    "\n",
    "#Load the PEFT config + base model\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial2\"  # ğŸ‘ˆ Change here\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "\n",
    "#Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "#Load LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_model, model_path, local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, local_files_only=True)\n",
    "\n",
    "#Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "#Inference loop\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"ğŸ” Evaluating Trial 2\"):\n",
    "    prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "#Evaluation\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "#Print results\n",
    "print(\"\\nğŸ“Š Trial 2 Evaluation Results (300 samples):\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQFK5gwjKHOQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHVquUAuWul8"
   },
   "source": [
    "# creating synthetic GPT samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NJD2f1XXYbu"
   },
   "source": [
    "ğŸ” Synthetic Sample Generation â€“ CounselChat Augmentation (Trial 3)\n",
    "To enhance the performance of our Mistral 7B fine-tuning for the mental health chatbot, we generate 200 high-quality synthetic Q&A samples. These samples are designed to:\n",
    "\n",
    "Match the tone, format, and structure of the original CounselChat dataset\n",
    "\n",
    "Improve generalization and bigram-level coherence (ROUGE-2)\n",
    "\n",
    "Stay lightweight to avoid exhausting Colab Pro A100 resources\n",
    "\n",
    "Each synthetic entry consists of:\n",
    "\n",
    "A realistic user query about anxiety, depression, or emotional distress (instruction)\n",
    "\n",
    "A thoughtful, structured, empathetic multi-step response (output) based on known therapeutic practices (e.g., CBT, DBT)\n",
    "\n",
    "These 200 samples will be merged with ~890 real samples to create a new training set (counselchat_augmented_1090.jsonl) for Trial 3 fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1745088509306,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "Dd96pEXtWz2y",
    "outputId": "96387a0b-f216-45b3-9ce6-bc286daad373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 200 synthetic samples saved to: /content/drive/MyDrive/chatbot/counsel/datasets/counselchat_synthetic_200.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "#Expanded set of ~60 varied emotional/mental health prompts\n",
    "user_issues = [\n",
    "    \"I feel anxious about everyday situations, even simple ones like sending emails.\",\n",
    "    \"I can't stop overanalyzing conversations after they happen.\",\n",
    "    \"I'm always expecting the worst-case scenario, even when things seem fine.\",\n",
    "    \"My heart races whenever I have to speak in front of others.\",\n",
    "    \"I feel guilty when I try to take time for myself.\",\n",
    "    \"Iâ€™m scared to share how I feel with my family because they might judge me.\",\n",
    "    \"Sometimes I just feel numb, like Iâ€™m not really here.\",\n",
    "    \"I constantly compare myself to others and feel like Iâ€™m falling behind.\",\n",
    "    \"I feel overwhelmed by my responsibilities and don't know where to start.\",\n",
    "    \"I'm always trying to please others and end up neglecting myself.\",\n",
    "    \"Even when I achieve something, I feel like it's not good enough.\",\n",
    "    \"I canâ€™t stop thinking about things I did wrong years ago.\",\n",
    "    \"Iâ€™m scared Iâ€™ll never feel truly happy again.\",\n",
    "    \"Sometimes I cry for no reason and I don't know how to explain it.\",\n",
    "    \"I get upset with myself when Iâ€™m not productive enough.\",\n",
    "    \"I feel like a burden to the people around me.\",\n",
    "    \"I hate asking for help because I don't want to seem weak.\",\n",
    "    \"I isolate myself even though I donâ€™t want to be alone.\",\n",
    "    \"It feels like my mind is always racing and I can't shut it off.\",\n",
    "    \"Iâ€™ve been eating less lately because I feel stressed and anxious.\",\n",
    "    \"I feel like my life lacks purpose or direction.\",\n",
    "    \"I try to sleep but my brain keeps bringing up bad memories.\",\n",
    "    \"I always feel like Iâ€™m being judged, even when no one is around.\",\n",
    "    \"Sometimes I fake being okay because I donâ€™t want others to worry.\",\n",
    "    \"I struggle to get out of bed in the mornings lately.\",\n",
    "    \"I donâ€™t know how to express my emotions without feeling ashamed.\",\n",
    "    \"I keep doubting my self-worth, even when others praise me.\",\n",
    "    \"I feel stuck in a loop of negative thinking.\",\n",
    "    \"Itâ€™s hard for me to enjoy things I used to love.\",\n",
    "    \"I feel afraid of failing, so I avoid trying new things.\",\n",
    "    \"Iâ€™ve lost interest in socializing with others.\",\n",
    "    \"I get nervous even before small meetings or group calls.\",\n",
    "    \"I overthink everything I say and do.\",\n",
    "    \"I feel like Iâ€™m pretending to be okay all the time.\",\n",
    "    \"It feels like no one really understands me.\",\n",
    "    \"I panic when plans change unexpectedly.\",\n",
    "    \"I feel like I'm falling apart on the inside.\",\n",
    "    \"I worry a lot about things I canâ€™t control.\",\n",
    "    \"I feel disconnected from my own life.\",\n",
    "    \"Iâ€™m trying to heal, but progress feels painfully slow.\",\n",
    "    \"I question if therapy is even helping me.\",\n",
    "    \"I want to trust people but I'm afraid of being hurt.\",\n",
    "    \"I avoid eye contact because I feel ashamed.\",\n",
    "    \"I feel anxious when someone compliments me.\",\n",
    "    \"I'm afraid people are pretending to like me.\",\n",
    "    \"I get angry at myself for feeling this way.\",\n",
    "    \"I often feel like an imposter, even with my accomplishments.\",\n",
    "    \"Iâ€™m overwhelmed and donâ€™t know where to begin.\",\n",
    "    \"I worry that people secretly dislike me.\",\n",
    "    \"I sometimes wish I could just disappear for a while.\",\n",
    "    \"I get drained by social events, even short ones.\",\n",
    "    \"I feel like I can't be myself around others.\",\n",
    "    \"I donâ€™t feel motivated to do anything lately.\",\n",
    "    \"I try to look strong, but inside Iâ€™m falling apart.\",\n",
    "    \"Iâ€™m scared of being vulnerable with people.\",\n",
    "    \"I feel emotionally exhausted by my own thoughts.\",\n",
    "    \"I want to feel better, but I donâ€™t know how.\",\n",
    "    \"I get scared of being alone but also fear getting close to people.\"\n",
    "]\n",
    "\n",
    "# Same response components from earlier\n",
    "responses_intro = [\n",
    "    \"Thank you for being open and sharing this. You're not alone in feeling this way.\",\n",
    "    \"I hear you, and I want you to know that your feelings are valid.\",\n",
    "    \"What you're experiencing is difficult, and it's good that you're reaching out.\",\n",
    "    \"It takes courage to speak up about this â€” you're already taking a positive step.\",\n",
    "    \"I'm really glad you asked this. Many people go through similar emotions.\"\n",
    "]\n",
    "\n",
    "responses_body = [\n",
    "    \"Anxiety can often lead to overthinking and self-doubt. It helps to practice grounding techniques like focused breathing or mindful journaling.\",\n",
    "    \"Cognitive Behavioral Therapy (CBT) has proven effective in managing negative thought loops. You might consider exploring CBT worksheets or speaking with a therapist trained in it.\",\n",
    "    \"Try to notice when these thoughts come up and gently challenge them by asking yourself if they're based on facts or assumptions.\",\n",
    "    \"Consider keeping a self-compassion journal where you write down moments you were kind to yourself or others.\",\n",
    "    \"Sometimes, talking to a counselor or even joining a peer support group can provide relief and perspective.\"\n",
    "]\n",
    "\n",
    "responses_close = [\n",
    "    \"Remember, healing is not linear. Small steps matter.\",\n",
    "    \"Be patient with yourself. You deserve support and care.\",\n",
    "    \"You are worthy of kindness â€” from others and from yourself.\",\n",
    "    \"Donâ€™t hesitate to seek professional help when needed. Youâ€™re not alone.\",\n",
    "    \"Keep going. You're doing better than you think.\"\n",
    "]\n",
    "\n",
    "# Generate and save 200 synthetic Q&A pairs\n",
    "synthetic_samples = []\n",
    "for _ in range(200):\n",
    "    instruction = random.choice(user_issues)\n",
    "    output = \"\\n\\n\".join([\n",
    "        random.choice(responses_intro),\n",
    "        random.choice(responses_body),\n",
    "        random.choice(responses_close)\n",
    "    ])\n",
    "    synthetic_samples.append({\n",
    "        \"instruction\": instruction,\n",
    "        \"output\": output\n",
    "    })\n",
    "\n",
    "# Save as JSONL\n",
    "output_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_synthetic_200.jsonl\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    for item in synthetic_samples:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… 200 synthetic samples saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrHblaKRXq3I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlqN7WsuX7Y8"
   },
   "source": [
    "# Creating new augmented dataset - synthetic200 + counsel chat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1745088526714,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "bIx7D2XzYEZX",
    "outputId": "418ddae4-ff04-4058-9f77-86e801c213b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged dataset saved to: /content/drive/MyDrive/chatbot/counsel/datasets/counselchat_augmented_1090.jsonl\n",
      "ğŸ“Š Total samples: 1015\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "#File paths\n",
    "real_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\"\n",
    "synthetic_path = \"/content/dtasets/counselchat_augmented_1090.jsonl\"rive/MyDrive/chatbot/counsel/datasets/counselchat_synthetic_200.jsonl\"\n",
    "output_path = \"/content/drive/MyDrive/chatbot/counsel/da\n",
    "\n",
    "#Load real CounselChat data\n",
    "with open(real_path, \"r\") as f:\n",
    "    real_data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "#Load synthetic samples\n",
    "with open(synthetic_path, \"r\") as f:\n",
    "    synthetic_data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "#Combine and shuffle\n",
    "combined_data = real_data + synthetic_data\n",
    "random.shuffle(combined_data)\n",
    "\n",
    "#Save merged dataset as JSONL\n",
    "with open(output_path, \"w\") as f:\n",
    "    for item in combined_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Merged dataset saved to: {output_path}\")\n",
    "print(f\"ğŸ“Š Total samples: {len(combined_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShAuC8aqYHWp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LjBtIYTYf4T"
   },
   "source": [
    "# Trial 3 with augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fff433869c1a4aed84e3e69e5fd62664",
      "870b7293670244de808548ca2759179b",
      "c3882118635945ecb6189d01453434b2",
      "06a56350a67941d7a010f31dd8209cc3",
      "48aeb8c837b8494e8fe906c15912cca5",
      "675c6047daf94c028408a1dfcb4c4066",
      "fb1497d8d38a40a0bc9e779785eef1b0",
      "9e9b3c32781c48af8b1ea87cac3dfa22",
      "672b75f308bc46119c234ef5708e8c5d",
      "ad6a7ab305d94732a2309c658b209106",
      "09b5706c204241dcaf1a16f05e3819e5"
     ]
    },
    "executionInfo": {
     "elapsed": 365048,
     "status": "ok",
     "timestamp": 1745088979489,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "Tjxwg2OyYkYH",
    "outputId": "799b57a2-adef-45f2-e147-cf00f0e3ed90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff433869c1a4aed84e3e69e5fd62664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f6edb7a7795b>:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='508' max='508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [508/508 05:46, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>17.418500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>12.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>10.916100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>7.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.653400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.596200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.061300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.700300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.890600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.363200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.564100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.468500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.708300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.319400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.689100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.458400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.040400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.321900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.380100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.704400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.734200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.166400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.888800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.497900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.439400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.255600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.357400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.175400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.205600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.718100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.229800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.427400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.852300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trial 3 fine-tuning complete and saved to Drive!\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import gc\n",
    "\n",
    "#Clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#Load merged dataset (Counsel + 200 synthetic)\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_augmented_1090.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "#Load model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "#Tokenize\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, padding=\"max_length\", truncation=True, max_length=384)\n",
    "    result[\"labels\"] = tokenizer(output, padding=\"max_length\", truncation=True, max_length=384)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "#LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "#Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial3\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "#Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#Train the model\n",
    "trainer.train()\n",
    "\n",
    "#Save model and tokenizer\n",
    "model.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial3\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial3\")\n",
    "\n",
    "print(\"âœ… Trial 3 fine-tuning complete and saved to Drive!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbqlO9z1Ymjc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggm_iDdeaO7c"
   },
   "source": [
    "# Trial 3 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMPysrNooULS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364,
     "referenced_widgets": [
      "f76dfeeea6894e3bb5f47c683fb52cd9",
      "66a8673d457f4c93bfef5ef49840bfd5",
      "f63d66db3bc0438b976f710ebd7323af",
      "52b50ff44dd74353a6702c652344d99c",
      "45971b84508447e1916687ba1d20fdd5",
      "656d57fe45d94bf7995e49e720c55afc",
      "3652808436784f9ba677c01f5433ea56",
      "f484cecbbaa34c318f1032ea6e807ef9",
      "7b648bcb15df41a89025b0b1d1efe64d",
      "ab5c5c6586ce4378ac49f0503495f1e6",
      "d4173dfb9f4a4b7f9355215f606b9923"
     ]
    },
    "executionInfo": {
     "elapsed": 2897401,
     "status": "ok",
     "timestamp": 1745091974966,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "WrOxFh6qaUv5",
    "outputId": "69cc0f89-32d8-4473-b3a1-7f957a2f161b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76dfeeea6894e3bb5f47c683fb52cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating Trial 3:   0%|          | 0/300 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "ğŸ” Evaluating Trial 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [47:45<00:00,  9.55s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Trial 3 Evaluation Results (300 samples):\n",
      "BLEU: 0.016\n",
      "ROUGE-1: 0.2163\n",
      "ROUGE-2: 0.0291\n",
      "ROUGE-L: 0.1134\n",
      "BERTScore (F1): 0.8058\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Load evaluation dataset\n",
    "eval_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\",\n",
    "    split=\"train[:300]\"  # Adjust to 1000 if needed\n",
    ")\n",
    "\n",
    "#Load the PEFT model and config\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial3\"\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "\n",
    "#Load base model and LoRA adapter\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, model_path, local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, local_files_only=True)\n",
    "\n",
    "#Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "#Run generation\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"ğŸ” Evaluating Trial 3\"):\n",
    "    prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "#Compute metrics\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "#Print results\n",
    "print(\"\\nğŸ“Š Trial 3 Evaluation Results (300 samples):\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdpW_y12ad0n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUDCnfTzGrNv"
   },
   "source": [
    "# Dataset Cleaning Updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA06ISrMVaTX"
   },
   "source": [
    "## ğŸ§¹ Smart Filtering of CounselChat Dataset (Explained)\n",
    "\n",
    "This dataset cleaning script was applied to the original CSV file `20200325_counsel_chat.csv` from CounselChat.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Step-by-Step Actions\n",
    "\n",
    "#### 1. **Loaded the original raw CSV**\n",
    "- File: `20200325_counsel_chat.csv`\n",
    "- Contains therapist responses to mental health questions.\n",
    "- Columns included: `questionText`, `answerText`, `topic`, `therapistInfo`, etc.\n",
    "\n",
    "#### 2. **Extracted Key Fields**\n",
    "Only two fields were kept to train the model:\n",
    "\n",
    "| CSV Field       | Transformed Field |\n",
    "|----------------|-------------------|\n",
    "| `questionText` | `instruction`     |\n",
    "| `answerText`   | `output`          |\n",
    "\n",
    "Example format:\n",
    "```json\n",
    "{\n",
    "  \"instruction\": \"Iâ€™ve been feeling anxious a lot lately. How can I manage it?\",\n",
    "  \"output\": \"Anxiety is common. You can begin with deep breathing and journaling...\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Applied Smart Filters**\n",
    "The goal was to remove low-quality or misleading samples.\n",
    "\n",
    "| Filter Rule                                      | Reason                                              |\n",
    "|--------------------------------------------------|-----------------------------------------------------|\n",
    "| `instruction` and `output` must not be empty     | Skips blank entries                                 |\n",
    "| `instruction` must have â‰¥ 5 words                | Too-short questions aren't useful                   |\n",
    "| `output` must have â‰¥ 15 words                    | Short answers donâ€™t help the model learn enough     |\n",
    "| No phrases like â€œI am an AIâ€, â€œI donâ€™t understandâ€ | Removes hallucinated or chatbot-like answers        |\n",
    "| `instruction` must not appear inside the `output`| Avoid parroting                                     |\n",
    "\n",
    "This ensures cleaner and more meaningful learning data.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Saved Cleaned Data**\n",
    "- Saved as JSONL to:\n",
    "  `/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_smartfiltered.jsonl`\n",
    "- Each line contains one valid instruction-output pair\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Why This Matters\n",
    "- Improves dataset quality for fine-tuning\n",
    "- Reduces junk samples and repetitive patterns\n",
    "- Leads to **better BLEU, ROUGE, and BERTScore results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2345,
     "status": "ok",
     "timestamp": 1745151576297,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "1mMhQy0hGsKf",
    "outputId": "ee82ecfc-a969-426b-835b-08918304511e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['Unnamed: 0', 'questionID', 'questionTitle', 'questionText',\n",
      "       'questionLink', 'topic', 'therapistInfo', 'therapistURL', 'answerText',\n",
      "       'upvotes', 'views', 'split'],\n",
      "      dtype='object')\n",
      "Total rows: 2129\n",
      "âœ… Total valid instruction-output pairs: 2116\n",
      "âœ… Cleaned JSONL saved to: /content/drive/MyDrive/chatbot/counsel/datasets/counselchat_smartfiltered.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "csv_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/20200325_counsel_chat.csv\"  # Update path if needed\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Total rows:\", len(df))\n",
    "\n",
    "def format_row(row):\n",
    "    instruction = row.get(\"questionText\", \"\").strip()\n",
    "    output = row.get(\"answerText\", \"\").strip()\n",
    "    return {\"instruction\": instruction, \"output\": output}\n",
    "\n",
    "def is_valid(example):\n",
    "    instr = example[\"instruction\"]\n",
    "    out = example[\"output\"]\n",
    "\n",
    "    # Basic checks\n",
    "    if not instr or not out:\n",
    "        return False\n",
    "    if len(instr.split()) < 5 or len(out.split()) < 15:\n",
    "        return False\n",
    "    if \"I am an AI\" in out or \"I don't understand\" in out:\n",
    "        return False\n",
    "    if instr.lower() in out.lower():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "filtered = []\n",
    "for _, row in df.iterrows():\n",
    "    formatted = format_row(row)\n",
    "    if is_valid(formatted):\n",
    "        filtered.append(formatted)\n",
    "\n",
    "print(f\"Total valid instruction-output pairs: {len(filtered)}\")\n",
    "\n",
    "output_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_smartfiltered.jsonl\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    for item in filtered:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(\"Cleaned JSONL saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTDsBrHZI73V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8oY57KlKQLl"
   },
   "source": [
    "# Tuning - Trial 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "195922bc1ff84f3c8a84d5e1929ca784",
      "8ff4bb54c73b4fe385800032dc5774de",
      "87aa0bd93b484c0cba68e04081b4d4a0",
      "cb89cf5d7033432dae32f463d18cc54e",
      "53fee68ac1724a65ade6409afa4d5e03",
      "b11c6d26b554493fa5db265c336cb05a",
      "d3b4f9ce3d3947419f5d301fb72774d8",
      "a2c83c20b30445ff80924b0da134d4d6",
      "a1018b01c2244cd2ac18457fc5f1d6dc",
      "ed1ed628d9c840cda67fd60d58edb1f2",
      "baa2fb0bfbbf4bc2836df8c429abdd8b",
      "7e4a564bf90e438b892582f03575aa7c",
      "7fca746a94164b8e909218d5c2151f84",
      "ec5b4b9945e34f42a245a10ae2998c6b",
      "1e21f26c85794f67b6c9a762bf4fe799",
      "aad64c6b6c5849ff8fef79a3813c8d4c",
      "f92e4d87d16946f4b67481e0d7527955",
      "6f27873ea9a841a9a2d80de178cec057",
      "13770966f27a4242abfe18d2eede6590",
      "f54ec45998ba4534b300b1cd6f8676eb",
      "57a1346d0882468abff9af5a2c9209c5",
      "db11d6ddb7594064be6ee9c978a00062",
      "a6da7956a6a342f7a6be104db827cd5a",
      "b541b046cce246b093b500b0b730e65d",
      "38551a7ec84f40b3bc1b3ea6953c57b7",
      "9f76850fd9a44bee940afa228a497b01",
      "ed779a2aed1a4cb3a4ce8088e4b02219",
      "6abd2cac34ec4a0a8d0b9e720b4c799e",
      "cdc0084b8aae438298569f17a95007b2",
      "a6999dab41f840f0af49addc07fde344",
      "c4c942a209f04b4c81979579529ef49b",
      "646d5c50ae554572bf4ed34752786935",
      "2ec5d09f21544697b53dcd50902e04a6",
      "d1d9a1901b1d4ed1afa1a6f38b9d6843",
      "7b08fd44cc3f42ba99340c2945595841",
      "a1153f1f5dab4ccca4e61a9b0b05cc1d",
      "3efe90190a6a4d6599a1cbcfe0155319",
      "f8062d6e7bd44108ae838e2cba8938ce",
      "7ead41968beb4b2b883e20ff839ac8fa",
      "6529de5bf18c47d1ada31eef8052d4c8",
      "137955e652414bbb890a586de8286aa1",
      "66edd8fc75dc497cbc863dfef9a1de0c",
      "9b426abbee35492b9b7a9e2d89cb14be",
      "3d503ba609214ec48f97da5e03fd7f8b",
      "649025c60a884f26a874ac68a9b259d3",
      "8cff70cac39e4c7c81308e74398d2e8c",
      "1390b72c8d9c45f684f0af87c887562f",
      "418468fb33464a5e84ead9ce624ca4e7",
      "60ebbe76986d4e489f18885410105dcd",
      "5a7bdc317a1e47d691022155c0bcc0a1",
      "0a6153c5642b49a1ae44702a9da83054",
      "a5c8ec24cb264d4189ba85c3620da71c",
      "1e6b2b16af734b1ca5befd1b167c2057",
      "aa561edaca954ae3843396f006b9a270",
      "dd1ebc62a49140108ee8a90bd481c4fd",
      "e0e63a4093944df3acd3ea154069e3d6",
      "3a2c14724a744b33be88bbb7cc611ba8",
      "10ec415009754519adec1243b5bb9c9a",
      "d0ca2f6fd0e242ad92aed4d1aafaf1bf",
      "58a45e5e4f584478870e73ee13968173",
      "bc0f47c42dff4c77abc75e12c4f2e95a",
      "c39c92a8a4ee436f8540a8165158c29c",
      "8fc60ad396c64793be5f27b27b66ef86",
      "6be8566e728140799d49ceebdc964f8f",
      "d3059a71156d4b03859f449f3e8e492c",
      "7c7d02a68c6f4e7f916a92aa29e5eb3d",
      "5edc65da65804aa4af0f54415045488e",
      "1604f91eeaa741879fd7f67e07f2e9ea",
      "56bec2551fe8426f8e182d05bd2e5850",
      "fc404c77dc684d838b1c2198fed5a5b0",
      "a85930e746d046c183aef02442c8cf77",
      "1bb7d715930b4d82acb063a0da1c85e6",
      "1bb134d25e9749f49a661bf4b8f0475a",
      "ce8ea69259634dfcb9ee7d9e024b3a49",
      "2caa5efc76ef4e13b04cd2d1b150f5f8",
      "ff293c7427924d1894fb56c43cee4fa9",
      "b918e22a98134957a08a2993a75698f4",
      "1ed9bac1843a4cebba3157a56fb419ff",
      "4ed67dfdcd0c43009dcfb84a086415f5",
      "c2c9d9956336431ebecfc172c3044045",
      "7aa2f915a0474cab8412c390ad324fd5",
      "bd50afe036e34581b5fbc30fd47480e0",
      "f9b76440324a48dbbe9392781c612c16",
      "d63bafa200d241ce9700e9a1b7193897",
      "dee769639eeb46789526a46025f66b66",
      "c233aab549af40a0860d0467c5027ba1",
      "14fe0648f03b42e5befbb5ff59554fb7",
      "e8fe9e2740bd441caec9962856dbb1e4",
      "0e0b69f5c4624b2b8ab6811dcf26f6f1",
      "4e2efedc48a843e48a2bd91c6ea394ee",
      "5d94cf7e8e97495898a24810a18301cd",
      "146f48f0109c4fd289276d02c7eccb94",
      "3bfb1afa04394ea6ac96c52f35f0158d",
      "656cdf0c601745de85db08a9792e950c",
      "81dc8fd83c9245deb604ffd841e88296",
      "f27a7ad1a6ad4f4bb429a214fb009f8c",
      "44516f9b902846269dce69965f658122",
      "0d7068f9bbe746a09e21667bbb47efb8",
      "36b2da25e33840f994e9eedd7cfee289",
      "f6d084217e6c42f3a87f942f5fc07fb7",
      "03d2e3bfdac248469a163323a7979e0a",
      "7b247d74d80e4023b5e65679e8ca9f1c",
      "5c2a0a0aeadb49328d1b3de2b96b43e6",
      "b09cb828635649e59b2a0d7a58b2fba3",
      "5df0e76f0b2148789c74afaba7151017",
      "c92f7d06d2f94ec4b539cc5692a19230",
      "2dc8977b08aa4051930d7ea24af93d34",
      "c34dab34ac2c4b3fa19b5322b5ac3744",
      "0fd315fda94543b290f1e0024160f976",
      "ca9d04e3be3a473b990b080be523a0fe",
      "e2edc0e16eb34b7ea6e9517015e438f6",
      "530190b62edf411db7eeea5d60f3e004",
      "b45d3be019bb4aa68f787ebfe7db0f9a",
      "d2b46985e0874970ad127578c38594a7",
      "3f68b0e209524824bfa79b116d940763",
      "d7e79ba5efc1460db88e755a39cb0410",
      "7e7581c4bc2a4d8cb5a0aed72723e4df",
      "2871cad8d0764e5b9ca0fb775d0c0640",
      "c4c17e78635b439ca263323d798c9abc",
      "c5ba66dab4a9486fbafba54480fa42fb",
      "506ccb471149466aada3d87f8984c435",
      "16a70df60f294e53886da63a66bb3fa0",
      "8a7d72c6d2584c37977ab71d6265464f",
      "e479bc77ee934b08ab6b31b4e4b038c5",
      "7bf522a3e7f4407ab63a514988a9a5db",
      "4b03191506724a59b8a331ea02fd3be3",
      "fbd6dbc1873a493dab86d07c3d688030",
      "fcde4696e7cf4ba4aebbab5dce21281b",
      "316e4ddc06dd4cb9b9fa19e7830d9bbd",
      "cd9b58d042484da9900a4c6e70dd4182",
      "2dbff328a3ce4328be6c50e47b23ae6a",
      "97f67e5ef6964c8a9f9d3d53525262b4",
      "e5e73754dc8d49afb0c406da800ce7db",
      "be8943ca805c47f18b73ffc5de80c3e4",
      "2a427e57c0ae42a19c3875823109c577",
      "ea513eceb27e41f0b15893717aa09ea4",
      "656376f9b52b42f6bc0569167b2361cb",
      "632e5bb7cfcb4c5f97f81a0c38174a28",
      "2fac4588f1124edb938b5bf691ae7280",
      "2e9c1ced2eeb434d92ac47a7e44f0717",
      "81021d9fc41948b1afbb9636673c36ce",
      "71089af0bb174e91b14644e96f6316e1",
      "2ee1a4d1b40a497babfe97e646ac6bd1",
      "4ebdceb12e434b69a23b303d64200e1d",
      "97920490814a4d33b4b4b7a15a6e325e",
      "48f7692917d34c768515b2291a250236",
      "88fba25773a84cb990497515b6d88099",
      "16f2eec38dcc428f93a5f2f24d3ab80d",
      "6013c003844e4eca92bc701b3fda4bb4",
      "6e408e3bda234808badaeddde2b72956",
      "f6b39bcc4d154a75a9584f403c1928b6",
      "4570b72474614ec09650856cb509ee0d",
      "015b6ce3653544abaa96e1f6b3868593",
      "01b7eaf5fac044a0978a054646f9a8ad"
     ]
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 983514,
     "status": "ok",
     "timestamp": 1745152950155,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "k04Wps7YKUT2",
    "outputId": "a1a349a1-14ee-4180-dbfb-0755ff3b1c56"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195922bc1ff84f3c8a84d5e1929ca784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4a564bf90e438b892582f03575aa7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6da7956a6a342f7a6be104db827cd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d9a1901b1d4ed1afa1a6f38b9d6843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649025c60a884f26a874ac68a9b259d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e63a4093944df3acd3ea154069e3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edc65da65804aa4af0f54415045488e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed9bac1843a4cebba3157a56fb419ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0b69f5c4624b2b8ab6811dcf26f6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d084217e6c42f3a87f942f5fc07fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df0e76f0b2148789c74afaba7151017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a70df60f294e53886da63a66bb3fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e73754dc8d49afb0c406da800ce7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebdceb12e434b69a23b303d64200e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-608caa9e6f9e>:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1320' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1320/1320 15:08, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>17.176900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>12.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>10.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>8.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.551900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.540200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.852400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.774700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.588100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.860400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.943100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.681100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.834100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.602900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.326700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.964200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.198700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.951100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.545300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.247100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.481300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.471700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.632700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.532800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.589100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.187200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.755900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.910100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.586900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.752300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.571900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.949100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.637300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.848400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.303300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.358300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.808200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.216900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.260500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.568900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.867000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.631600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.584200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.905800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.865400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.732400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.727400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.640200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.384900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.934600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.459400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.648600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.359300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.551600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.099400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.205700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.601500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.384300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.542900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.431400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.514800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.738900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>2.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>2.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>1.991400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>2.911800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.542800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>2.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>2.642800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>2.445200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.951800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>2.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>2.419500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>3.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>2.514800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.527400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>2.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>2.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>3.200400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>2.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.157800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>2.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>2.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>2.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>2.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>2.573200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>2.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>2.270400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>2.454900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.412900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>2.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>2.306100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trial 4 complete! Model saved to Drive.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import gc\n",
    "\n",
    "#Clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#Load filtered dataset (2,116 samples)\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_smartfiltered.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "#Load model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "#Tokenization function\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, padding=\"max_length\", truncation=True, max_length=384)\n",
    "    result[\"labels\"] = tokenizer(output, padding=\"max_length\", truncation=True, max_length=384)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "#LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "#Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial4\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#Train!\n",
    "trainer.train()\n",
    "\n",
    "#Save model and tokenizer\n",
    "model.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial4\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial4\")\n",
    "\n",
    "print(\"âœ… Trial 4 complete! Model saved to Drive.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65PXSARyKbyT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzn6bNOaO_2b"
   },
   "source": [
    "# Trial 4 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643,
     "referenced_widgets": [
      "3df70da3748742d6a19db0364de3b41b",
      "622ecf6c757b44ae9fcd9a490af1ba16",
      "a8febc5e874d405e9f408802ace5f5d5",
      "9c06cd8dcd0043a5b761f96be3bfda24",
      "21aab5245e0546c1aec8078fd5520efd",
      "ef225f377fa645649e441bc674b0acae",
      "a0942ac47ec547929341c46153a37622",
      "123a2d390d7242aeae556ccc5fa6db9e",
      "466af2c5b8154b609364df4e53f4e0e1",
      "56ae99e926e04a5db413fa57ed6bf53d",
      "ebb1e4094f8d4d5cafa5673e8889f09c",
      "13b06eef6035404da3cc1e86999bf5de",
      "aa21c1549b4840299b6e358e85bc60e1",
      "ab80583840554eb5be1c6c9c77d76c5c",
      "54382934d8424d7f8e1ecd1acc6859f9",
      "35399f4d5d054716812314fa108e228a",
      "4a0cad0e9c434657be20ff384c262023",
      "3739022ee2a248d992aed5ab574c7977",
      "849f220b9faa402f949b785b6408365f",
      "b4a93d94d1bc4849a13df490e355c130",
      "0274bdbadf6442e58fa8c34a7c9f3ec4",
      "9761ba4f76e842a9bd310faf3bbb2db1",
      "6eff84c5f00943689d8b06c2311a913c",
      "4434aa4db63447729aadb7932dccbbc1",
      "cdb96b19922d414a832c8f283646d39c",
      "797da3741aca42bd8f6a5e16866b8021",
      "1401976a82bf44499cfe92cd14fd328b",
      "7a675faa9d5547b7b47c041977019356",
      "c689d3adb9c943e397b80f97222e66db",
      "f47155849a99498ea6a2506bbe67cc46",
      "b2a06a4694bb4dfc9918c4943ee11290",
      "6ab4f8058d5e49538a102b0dd59e6c87",
      "2e3b02e1bfb84c60b0baf9d5139d08c6",
      "d1acfe83c6ec4c62a53188a33e661f47",
      "206491a2d5c942c4b834e812d9739836",
      "cf2a318eea6e488ea557716278042e61",
      "f94c13b0869d4a9aa0b91c337e30c531",
      "9eda41e9b5644f8ab2035f64e7b1f96a",
      "e3e9485f0c9f4c0292cae75c25ba82a0",
      "d6013f8fc1414fbb96c97ac35ed446b0",
      "a5af0642f186456c905a1facbe62285f",
      "be8ff92a1c5240dbb6b5d52516e800c1",
      "302c19e7d25e475799a16f339749429f",
      "9b5f24d61f304ff3b95295ff66fab0ce",
      "364eab465bee46b7bb7b97249a2755f7",
      "45f6263e3c16427686811fd50f240f87",
      "bd15d0dcf8e344b8b767619b222f5b68",
      "a53490d1d4ea4f75af8712ec2b727345",
      "121c8c64ac2341aba50c9c3c4ef5904a",
      "f1aaf39252bf4cd9a3e4234f1c1c0604",
      "1919cd662ed840a2808729b891f1c2e0",
      "d919680545e94d9a80fe98723f99d303",
      "03988fcbab5d4957b6cee536d7611df2",
      "88bcd0da1d1e4c93a6181efbde2f8e15",
      "b7dc4d23e1b549cf88db3d1cdc1692e1",
      "9527cf39863c4cd2a1c5c301fda4efc6",
      "b401b3444b85458eb51aa37291feeb98",
      "f17f33236c2a40fa89f942dc3be3df15",
      "62d64bdb05dd43519514206c3ab656bc",
      "52a59306283b4f548afaecc5b89faa9d",
      "c3b5558f2a5b4e5b8b27f53173c799b7",
      "a8484ebf98bc44718faa5e26ef809968",
      "0cc251d15ba945848f0f22c32d51a9a5",
      "fd1331e5608348a8b0702f17670f238e",
      "ac678dc013fc405c9062049a6bb39ad4",
      "0e47b92d90b44887a28b0471533fc54a",
      "c8e58e90b45a4a348fe40e6eb3a52b5e",
      "f4972edeb138494dbb5af8b34aeb1e70",
      "09ee4aa2a47f47a2aefd7b6b0ed34427",
      "2152bb6f00da4dbbbb42a08e055d8fff",
      "dc39696339f846f39d2f65c81c219bd0",
      "c716788f9fad431797441b279b0b236a",
      "91ac4b625f8e4081b5a904bab97f6e66",
      "d8da455fb9a440198b6ac65ea8282e31",
      "b95522c71cac48a0bf16f9af336eedbe",
      "7bba6ab596204440ae45976cdddf2de5",
      "077005af52ae4eb681ccb7a2ceaa1e3c"
     ]
    },
    "executionInfo": {
     "elapsed": 2414804,
     "status": "ok",
     "timestamp": 1745156677341,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "KQbzLHc2PDRw",
    "outputId": "5f0a0bac-90e2-4bff-fb58-0772c30b0bca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df70da3748742d6a19db0364de3b41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating Trial 4 (500 samples, fast mode):   0%|          | 0/300 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "ğŸ” Evaluating Trial 4 (500 samples, fast mode): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [39:36<00:00,  7.92s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b06eef6035404da3cc1e86999bf5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eff84c5f00943689d8b06c2311a913c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1acfe83c6ec4c62a53188a33e661f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364eab465bee46b7bb7b97249a2755f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9527cf39863c4cd2a1c5c301fda4efc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e58e90b45a4a348fe40e6eb3a52b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Trial 4 Evaluation Results (500 samples, Fast Mode):\n",
      "BLEU: 0.0222\n",
      "ROUGE-1: 0.2384\n",
      "ROUGE-2: 0.0387\n",
      "ROUGE-L: 0.1225\n",
      "BERTScore (F1): 0.8144\n",
      "\n",
      "â±ï¸ Avg generation time per sample: 7.92 seconds\n",
      "ğŸ§  Avg token length of output: 251.76 tokens\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Enable TF32 for faster matrix operations\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "#Load smaller eval set (500 samples for quick test)\n",
    "eval_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_smartfiltered.jsonl\",\n",
    "    split=\"train[:300]\"\n",
    ")\n",
    "\n",
    "#Load PEFT config and model\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial4\"\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, model_path, local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, local_files_only=True)\n",
    "\n",
    "#Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "#Inference loop with timing\n",
    "predictions = []\n",
    "references = []\n",
    "token_lengths = []\n",
    "start_time = time.time()\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"ğŸ” Evaluating Trial 4 (500 samples, fast mode)\"):\n",
    "    prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=150,  # âœ… Reduced from 200\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "    token_lengths.append(len(tokenizer.tokenize(pred)))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "#Evaluation metrics\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "#Performance logs\n",
    "avg_gen_time = round((end_time - start_time) / len(eval_dataset), 2)\n",
    "avg_token_len = round(sum(token_lengths) / len(token_lengths), 2)\n",
    "\n",
    "print(\"\\nğŸ“Š Trial 4 Evaluation Results (500 samples, Fast Mode):\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n",
    "\n",
    "print(f\"\\nâ±ï¸ Avg generation time per sample: {avg_gen_time} seconds\")\n",
    "print(f\"ğŸ§  Avg token length of output: {avg_token_len} tokens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUkommnVdr0e"
   },
   "source": [
    "## ğŸ“Š Mistral-7B + CounselChat Hyperparameter Tuning Tracker\n",
    "\n",
    "### âœ… Trial Summary Table\n",
    "\n",
    "| Trial | Dataset Size                  | LoRA `r` | Alpha | Dropout | Epochs | LR     | Prompt Style                                    | BLEU   | ROUGE-1 | ROUGE-2 | ROUGE-L | BERTScore | Notes            |\n",
    "|-------|-------------------------------|----------|--------|----------|--------|--------|------------------------------------------------|--------|----------|----------|----------|------------|------------------|\n",
    "| 1     | 890 real                      | 8        | 16     | 0.05     | 3      | 2e-5   | Friendly therapist tone                         | 0.0203 | 0.2888   | 0.0429   | 0.1349   | 0.8311     | Baseline         |\n",
    "| 2     | 890 real                      | 16       | 32     | 0.05     | 4      | 2e-5   | Same prompt as Trial 1                          | 0.0173 | 0.2315   | 0.0334   | 0.1220   | 0.8076     | More stable LoRA |\n",
    "| 3     | 1,015 (real + 200 synthetic)  | 16       | 32     | 0.05     | 4      | 2e-5   | Same prompt as Trial 1                          | 0.0160 | 0.2163   | 0.0291   | 0.1134   | 0.8058     | With GPT samples |\n",
    "| âœ… 4  | 2,116 smart-filtered (real)   | 16       | 32     | 0.05     | 5      | 2e-5   | Same prompt, full cleaned dataset               | **0.0222** | 0.2384   | **0.0387** | 0.1225   | **0.8144** | Best so far ğŸ”¥   |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ Notes:\n",
    "- **BLEU** = n-gram overlap\n",
    "- **ROUGE-1/2/L** = word, bigram, sequence overlap\n",
    "- **BERTScore** = semantic similarity using RoBERTa\n",
    "- All trials used the same system prompt:  \n",
    "  `\"You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\"`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TF8t_OuPEVP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-Ab1XpVfGAW"
   },
   "source": [
    "# Trial 4 Model (Chatbot Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELSW7UYEfnrn"
   },
   "source": [
    "Bulk message testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1745157698655,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "DZPCRYgsfml4",
    "outputId": "93c31a31-c519-43c2-a7a6-667897f35957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Files saved to Colab:\n",
      "- test_prompts_counselchat.txt\n",
      "- test_prompts_counselchat.jsonl\n",
      "- test_prompts_counselchat.csv\n"
     ]
    }
   ],
   "source": [
    "#Test prompts for Mistral-7B + CounselChat model\n",
    "test_prompts = [\n",
    "    \"I feel like I'm constantly overthinking every little thing. How do I make it stop?\",\n",
    "    \"Why do I get so anxious when I have to talk to people, even my friends?\",\n",
    "    \"I wake up with a knot in my stomach every day. What can I do about it?\",\n",
    "    \"Lately Iâ€™ve lost interest in everything. Nothing makes me happy anymore.\",\n",
    "    \"Is it normal to feel tired all the time even when Iâ€™m not physically active?\",\n",
    "    \"I feel numb, like nothing really matters. What should I do?\",\n",
    "    \"I had a panic attack at work and now Iâ€™m afraid itâ€™ll happen again. How do I cope?\",\n",
    "    \"My heart races for no reason and I feel like I can't breathe. Am I losing control?\",\n",
    "    \"How can I calm down quickly when I feel overwhelmed in public?\",\n",
    "    \"No matter what I do, I always feel like Iâ€™m not good enough.\",\n",
    "    \"I compare myself to everyone and feel like Iâ€™m constantly failing.\",\n",
    "    \"Why do I always blame myself when something goes wrong?\",\n",
    "    \"I always say yes to people even when Iâ€™m exhausted. How do I set boundaries?\",\n",
    "    \"My partner doesnâ€™t understand my anxiety. Itâ€™s hurting our relationship. What should I do?\",\n",
    "    \"I feel guilty for putting myself first. Is that selfish?\"\n",
    "]\n",
    "\n",
    "#Save to TXT\n",
    "with open(\"/content/drive/MyDrive/chatbot/counsel/datasets/test_prompts_counselchat.txt\", \"w\") as txt_file:\n",
    "    txt_file.write(\"\\n\".join(test_prompts))\n",
    "\n",
    "#Save to JSONL\n",
    "with open(\"/content/drive/MyDrive/chatbot/counsel/datasets/test_prompts_counselchat.jsonl\", \"w\") as jsonl_file:\n",
    "    for prompt in test_prompts:\n",
    "        jsonl_file.write(f'{{\"instruction\": \"{prompt}\"}}\\n')\n",
    "\n",
    "#Save to CSV\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"user_prompt\": test_prompts})\n",
    "df.to_csv(\"/content/drive/MyDrive/chatbot/counsel/datasets/test_prompts_counselchat.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Files saved to Colab:\")\n",
    "print(\"- test_prompts_counselchat.txt\")\n",
    "print(\"- test_prompts_counselchat.jsonl\")\n",
    "print(\"- test_prompts_counselchat.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0603d916a0774ba8940586ab8226a280",
      "e5449bc1176c48b1969d2eb7cdf3e508",
      "9e5a4d768d4b49c88416bf2a18516764",
      "101b2974926d4cf18bb090fbbfeaf5b6",
      "9efac499547b4340abdee2a548acacd6",
      "3683ce889d7b4020b1684aeec3918c09",
      "2b159cc73f574d9ebe6aef2091e50f82",
      "4034422e32ef4588b49c7713d151ebcd",
      "0036b74c62584ec6ae822ef1649117e3",
      "99fb6069bf374dab959cc06b9c1da776",
      "b8c651680b8e4049b7d0b6eb899cef49"
     ]
    },
    "executionInfo": {
     "elapsed": 126122,
     "status": "ok",
     "timestamp": 1745158070174,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "GzHVmOSIfIDw",
    "outputId": "8f29eaf0-cba6-408a-b425-87861b3b6058"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0603d916a0774ba8940586ab8226a280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§  Prompt 1: I feel like I'm constantly overthinking every little thing. How do I make it stop?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "I feel like I'm constantly overthinking every little thing. How do I make it stop? [/INST] I'm a therapist and I''m. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm. I'm a therapist and I'm\n",
      "\n",
      "ğŸ§  Prompt 2: Why do I get so anxious when I have to talk to people, even my friends?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "Why do I get so anxious when I have to talk to people, even my friends? [/INST] It's not uncommon for people to feel anxious about talking to others.\n",
      "\n",
      "ğŸ§  Prompt 3: I wake up with a knot in my stomach every day. What can I do about it?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "I wake up with a knot in my stomach every day. What can I do about it? [/INST] I'd recommend that you start by keeping a journal of your thoughts and feelings.\n",
      "\n",
      "ğŸ§  Prompt 4: Lately Iâ€™ve lost interest in everything. Nothing makes me happy anymore.\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "Lately Iâ€™ve lost interest in everything. Nothing makes me happy anymore. [/INST] I'm sorry to hear that you're feeling this way. It's important to remember that you're not alone in feeling this way. I'm sure you've heard that before, but it's true. I'm sure you've heard that before, but it's true. I'm sure you've heard that before, but it's true. I'm sure you've heard that before, but it's true. I'm sure you'.\n",
      "\n",
      "ğŸ§  Prompt 5: Is it normal to feel tired all the time even when Iâ€™m not physically active?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "Is it normal to feel tired all the time even when Iâ€™m not physically active? [/INST] It is not normal to feel tired all the time. Â There are many reasons why you might feel tired. Â It is important to rule out medical causes. Â If you are not physically active, you should be able to get enough energy from your diet. Â If you are not getting enough energy from your diet, you should feel tired. Â If you are getting enough energy from your diet, you should not feel tired. Â If you are feeling tired all the time, you should talk to your doctor.\n",
      "\n",
      "ğŸ§  Prompt 6: I feel numb, like nothing really matters. What should I do?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "I feel numb, like nothing really matters. What should I do? [/INST] I'm sorry to hear that you're feeling numb.\n",
      "\n",
      "ğŸ§  Prompt 7: I had a panic attack at work and now Iâ€™m afraid itâ€™ll happen again. How do I cope?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "I had a panic attack at work and now Iâ€™m afraid itâ€™ll happen again. How do I cope? [/INST] I'm glad you're seeking help.\n",
      "\n",
      "ğŸ§  Prompt 8: My heart races for no reason and I feel like I can't breathe. Am I losing control?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "My heart races for no reason and I feel like I can't breathe. Am I losing control? [/INST] It sounds like you are experiencing a panic attack.\n",
      "\n",
      "ğŸ§  Prompt 9: How can I calm down quickly when I feel overwhelmed in public?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "How can I calm down quickly when I feel overwhelmed in public? [/INST] I'd recommend taking a few deep breaths, and then try to find a quiet place to sit down for a few minutes. Â If you're in a public place, you might be able to find a quiet corner, or a bench in a park. Â If you're in a crowded area, you might be able to find a quiet spot in a store or mall. Â If you're in a busy office, you might be able to find a quiet room or closet. Â Once you've found a quiet place, try to focus on your breathing, and let yourself relax. Â If you're feeling overwhelmed, it's important to give yourself a break, and to take\n",
      "\n",
      "ğŸ§  Prompt 10: No matter what I do, I always feel like Iâ€™m not good enough.\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "No matter what I do, I always feel like Iâ€™m not good enough. [/INST] I'm not sure what you mean by \"I'm not good enough\" but I'll try to answer your question.I'm not sure what you mean by \"I'm not good enough\" but I'll try to answer your question.I'm not sure what you mean by \"I'm not good enough\" but I'll try to answer your question.I'm not sure what you mean by \"I'm not good enough\" but I'll try to answer your question.I'm not sure what you mean by \"I'm not good enough\" but I'll try to answer your question.I'm not sure what you mean by \"I'm not good\n",
      "\n",
      "ğŸ§  Prompt 11: I compare myself to everyone and feel like Iâ€™m constantly failing.\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "I compare myself to everyone and feel like Iâ€™m constantly failing. [/INST] It's important to remember that everyone is different and that we all have our own unique strengths and weaknesses. Comparing yourself to others is not helpful and can lead to feelings of inadequacy. Instead of comparing yourself to others, focus on your own personal growth and development. Remember that everyone has their own struggles and challenges, and that it's okay to not be perfect. You are enough just the way you are.\n",
      "\n",
      "ğŸ§  Prompt 12: Why do I always blame myself when something goes wrong?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "Why do I always blame myself when something goes wrong? [/INST] It is not uncommon for people to blame themselves when something goes wrong. It is a way of taking responsibility for the situation and trying to find a solution. However, it is important to remember that sometimes things go wrong because of circumstances beyond our control. It is also important to remember that we are not perfect and that we make mistakes. Blaming yourself for everything that goes wrong can be a way of avoiding taking responsibility for your actions and can lead to feelings of guilt and shame. It can also be a way of avoiding taking responsibility for your actions and can lead to feelings of guilt and shame. It can also be a way of avoiding taking responsibility for your actions and can lead to feelings of guilt and shame. It can also be a way of\n",
      "\n",
      "ğŸ§  Prompt 13: I always say yes to people even when Iâ€™m exhausted. How do I set boundaries?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "I always say yes to people even when Iâ€™m exhausted. How do I set boundaries? [/INST] I'm a professional therapist and I'm. I'm a. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a professional therapist and I'. I'm a\n",
      "\n",
      "ğŸ§  Prompt 14: My partner doesnâ€™t understand my anxiety. Itâ€™s hurting our relationship. What should I do?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "My partner doesnâ€™t understand my anxiety. Itâ€™s hurting our relationship. What should I do? [/INST] I'm sorry to hear that you're struggling with your partner not understanding your anxiety. Â It's important to remember that your partner may not be able to understand your anxiety because they don't have the same experience. Â It's not that they don't care about you, but that they don't understand what you're going through. Â It's important to try to help them understand what you're going through. Â You can do this by explaining to them what you're feeling and what you need from them. Â It's also important to remember that you can't make them understand, but you can help them understand. Â If you're having\n",
      "\n",
      "ğŸ§  Prompt 15: I feel guilty for putting myself first. Is that selfish?\n",
      "ğŸ¤– Response:\n",
      " [INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\n",
      "I feel guilty for putting myself first. Is that selfish? [/INST] It is not selfish to put yourself first.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import json\n",
    "\n",
    "#Load the fine-tuned model (Trial 4)\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial4\"\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, model_path, local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, local_files_only=True)\n",
    "\n",
    "#Load test prompts from JSONL\n",
    "test_file_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/test_prompts_counselchat.jsonl\"\n",
    "prompts = []\n",
    "with open(test_file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        entry = json.loads(line)\n",
    "        prompts.append(entry[\"instruction\"])\n",
    "\n",
    "#Define the response function\n",
    "def generate_response(prompt, max_tokens=150):\n",
    "    full_prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{prompt} [/INST]\"\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "#Generate and print responses\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"\\nğŸ§  Prompt {i}: {prompt}\")\n",
    "    print(\"ğŸ¤– Response:\\n\", generate_response(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FP3YliQfKoX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdHO1TkZl-WF"
   },
   "source": [
    "# Tuning - Trial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1dc930a4f9b04774ad24dce1d5396bc4",
      "02a4f487317f4115808592f9cca7a985",
      "65965cc47e5d48a9aff26fa798807e28",
      "2e71cf1500dd4db39cbcfc707c831986",
      "00926aef990045a8bc4d487f99941bd4",
      "eeb1ab4c60bb45f0bdbe37fe9409917f",
      "6eca788922c046ff8b4f7a3659b175f3",
      "07fdfc9761304bf6ab501a33597e680f",
      "8a33081c55674dcdbb0dd930423c8a68",
      "dca8acd95c844b97bcbc60302679b6c1",
      "0b9c56b0e6814ea6b70abf8f41a4cace",
      "81c7fdad5f2148fcb960ad6f338c25c7",
      "022819265af4417ba82e897055d00036",
      "5148caf3acfa4b3c923a5df58fa306bd",
      "f6462487cb044d8d9814f827878d2e0e",
      "572e741d53144284a4d14eaacb261a49",
      "f445eff0ca094006a115138fa2eedf73",
      "45b3417beb0b4d42b269b489f17ed287",
      "9ee43215a0b54f83b87f1fd19a346ee4",
      "20c056dcfd87401f9e13a81dd5289855",
      "468288d853ed40e3b05c0449a678b1c3",
      "4a868ff3972d4d9a9bb26c1b186652cc"
     ]
    },
    "executionInfo": {
     "elapsed": 1238673,
     "status": "ok",
     "timestamp": 1745161129648,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "nNIXH9igmCfE",
    "outputId": "b5966e1f-e3c2-4497-ab02-c62ea2165f75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc930a4f9b04774ad24dce1d5396bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c7fdad5f2148fcb960ad6f338c25c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-3a2b407a4a68>:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1320' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1320/1320 20:17, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>17.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>12.119700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>9.575500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>7.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.501400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>6.536400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.985400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.608700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.713500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.919900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.809200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.963200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.965100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.801300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.415300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.567500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.721200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.497600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.897900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.779300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.507500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.313900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.871900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.462800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.579700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.479600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.973400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.754800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.257300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.804700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.493600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.296300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.958900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.806300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.386900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.595300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.191700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.843400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.824500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.609600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.816300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.750500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.837900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.707700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.418200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.528300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.786200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.608200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.068700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.583600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.946100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.112300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.559200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.239900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.405100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.685100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.611700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.507800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.328300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.328300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.532100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.659600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.725800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.739200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.640300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.712200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.381300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.737700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>1.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.787400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.666300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1.777600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.772600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.286500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.600100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>2.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>1.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.696300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.322200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>1.604900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>2.172100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>1.536100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>1.948900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>1.657200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.720800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.553600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>1.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.368200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.732400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>1.423800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>1.772000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trial 5 complete! Model saved to Drive.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import gc\n",
    "\n",
    "#Clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#Load filtered dataset (2,116 samples)\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_smartfiltered.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "#Load model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "#Trial 5 Prompt Style: Updated for variety and tone\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] As a helpful mental health assistant, how would you support someone who says:\\n\\\"{example['instruction']}\\\" [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    result[\"labels\"] = tokenizer(output, padding=\"max_length\", truncation=True, max_length=512)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "#LoRA Config â€” same structure as Trial 4\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "#Training arguments (Trial 5 updates applied)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial5\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=1e-5,  # lower learning rate\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#Train!\n",
    "trainer.train()\n",
    "\n",
    "#Save model and tokenizer\n",
    "model.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial5\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial5\")\n",
    "\n",
    "print(\"âœ… Trial 5 complete! Model saved to Drive.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pO-eRBo6mVSZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1R7gaMy1tvG8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WriMhs7ItulA"
   },
   "source": [
    "# Trial 5 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381,
     "referenced_widgets": [
      "54f605dc65ff47ddabbd17e918ff64c3",
      "9c71e52b701c4d9a93d7ddeda95fbeb3",
      "33af28649e054ab8b1402042963f7016",
      "59f4b68cd14c43e5935185a5d7bf39fc",
      "760fdb8b5cf34456a2722dbd01de024b",
      "25e1919dcb834006b2b3c8cce7e550d6",
      "d120f22163d14db38e7a21e7a80f9d43",
      "5959688790dd47589688ec55609b0d16",
      "4a99017b553b4509875fe99363ffb0bf",
      "b11129c4bed3474e81aea8bd1ab28877",
      "73334ea4cf1e4b0cabad2635c7a4ccf1"
     ]
    },
    "executionInfo": {
     "elapsed": 1935347,
     "status": "ok",
     "timestamp": 1745163183489,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "rJshrX73tyWk",
    "outputId": "cf822e4f-08e5-43cf-aae5-e7a74dc6c03b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f605dc65ff47ddabbd17e918ff64c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating Trial 5 (300 samples):   0%|          | 0/300 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "ğŸ” Evaluating Trial 5 (300 samples): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [31:45<00:00,  6.35s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Trial 5 Evaluation Results (300 samples):\n",
      "BLEU: 0.0243\n",
      "ROUGE-1: 0.3071\n",
      "ROUGE-2: 0.0416\n",
      "ROUGE-L: 0.1307\n",
      "BERTScore (F1): 0.8344\n",
      "â±ï¸ Avg generation time/sample: 6.4s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "#Load 300-sample evaluation set\n",
    "eval_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_smartfiltered.jsonl\",\n",
    "    split=\"train[:300]\"\n",
    ")\n",
    "\n",
    "#Load fine-tuned Trial 5 model + PEFT config\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial5\"\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, model_path, local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, local_files_only=True)\n",
    "\n",
    "#Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "#Inference loop\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"ğŸ” Evaluating Trial 5 (300 samples)\"):\n",
    "    prompt = f\"<s>[INST] As a helpful mental health assistant, how would you support someone who says:\\n\\\"{example['instruction']}\\\" [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=150,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            repetition_penalty=1.2\n",
    "        )\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "#Compute metrics\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "end = time.time()\n",
    "avg_gen_time = round((end - start) / len(predictions), 2)\n",
    "\n",
    "#Print results\n",
    "print(\"\\nğŸ“Š Trial 5 Evaluation Results (300 samples):\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n",
    "print(f\"â±ï¸ Avg generation time/sample: {avg_gen_time}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QB5heZWUt1x9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwICqZkK6boJ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-S0CD2aN6b9V"
   },
   "source": [
    "# Merging - CounselChat + Augmented EmpatheticDialogues For Trial 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1745164777966,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "964gDO0268rF",
    "outputId": "816adecc-9b85-4506-bb25-d3935788c663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged dataset saved to: /content/drive/MyDrive/chatbot/counsel/datasets/merged_counsel_empathetic.jsonl\n",
      "ğŸ“Š Total samples after deduplication: 3793\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_smartfiltered.jsonl\", \"r\") as f:\n",
    "    counsel_data = [json.loads(line) for line in f]\n",
    "\n",
    "with open(\"/content/drive/MyDrive/SIT782/datasets/empdiag_augmented_4100.jsonl\", \"r\") as f:\n",
    "    empathetic_data = [json.loads(line) for line in f]\n",
    "\n",
    "assert \"instruction\" in counsel_data[0] and \"output\" in counsel_data[0], \"âŒ CounselChat format issue\"\n",
    "assert \"instruction\" in empathetic_data[0] and \"output\" in empathetic_data[0], \"âŒ Empathetic format issue\"\n",
    "\n",
    "merged_data = counsel_data + empathetic_data\n",
    "unique_jsons = list({json.dumps(entry, sort_keys=True) for entry in merged_data})\n",
    "merged_cleaned = [json.loads(j) for j in unique_jsons]\n",
    "\n",
    "output_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/merged_counsel_empathetic.jsonl\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    for sample in merged_cleaned:\n",
    "        json.dump(sample, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "#final report\n",
    "print(f\"Merged dataset saved to: {output_path}\")\n",
    "print(f\"Total samples after deduplication: {len(merged_cleaned)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQiJ60t_8h6P"
   },
   "source": [
    "dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1745165120150,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "KAGO2Vk97HC0",
    "outputId": "dca17587-d3ef-45e0-b4f0-23eeba1546a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total Samples': 3793,\n",
       " 'Avg Instruction Length (words)': 34.73,\n",
       " 'Avg Output Length (words)': 97.18,\n",
       " 'Min Instruction Length': 1,\n",
       " 'Max Instruction Length': 552,\n",
       " 'Min Output Length': 1,\n",
       " 'Max Output Length': 939,\n",
       " 'Samples with Output < 20 words': 1516}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load merged dataset\n",
    "with open(\"/content/drive/MyDrive/chatbot/counsel/datasets/merged_counsel_empathetic.jsonl\", \"r\") as f:\n",
    "    merged_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Basic stats\n",
    "total_samples = len(merged_data)\n",
    "instruction_lengths = [len(entry[\"instruction\"].split()) for entry in merged_data]\n",
    "output_lengths = [len(entry[\"output\"].split()) for entry in merged_data]\n",
    "\n",
    "# Token length distributions\n",
    "avg_instruction_len = sum(instruction_lengths) / total_samples\n",
    "avg_output_len = sum(output_lengths) / total_samples\n",
    "\n",
    "min_instruction_len = min(instruction_lengths)\n",
    "max_instruction_len = max(instruction_lengths)\n",
    "\n",
    "min_output_len = min(output_lengths)\n",
    "max_output_len = max(output_lengths)\n",
    "\n",
    "# Extremely short responses\n",
    "short_outputs = sum(1 for length in output_lengths if length < 20)\n",
    "\n",
    "# Summary\n",
    "dataset_stats = {\n",
    "    \"Total Samples\": total_samples,\n",
    "    \"Avg Instruction Length (words)\": round(avg_instruction_len, 2),\n",
    "    \"Avg Output Length (words)\": round(avg_output_len, 2),\n",
    "    \"Min Instruction Length\": min_instruction_len,\n",
    "    \"Max Instruction Length\": max_instruction_len,\n",
    "    \"Min Output Length\": min_output_len,\n",
    "    \"Max Output Length\": max_output_len,\n",
    "    \"Samples with Output < 20 words\": short_outputs\n",
    "}\n",
    "\n",
    "dataset_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky0ccuca8qrF"
   },
   "source": [
    "Why We Removed Outputs with Fewer Than 20 Words (Trial 6 Dataset)\n",
    "\n",
    "In our merged dataset (counselchat + empathetic_dialogues), many samples had very short responses, often under 20 words. While these samples may be realistic, they:\n",
    "\n",
    "    Lack informative content or emotional depth\n",
    "\n",
    "    Hurt phrase overlap metrics like ROUGE-2 and BLEU\n",
    "\n",
    "    Introduce noise or overly generic replies into training\n",
    "\n",
    "To improve model quality, especially for long-form conversational replies, we created a cleaned dataset where each response (output) has at least 20 words.\n",
    "\n",
    "This refined dataset (Trial 6) will help:\n",
    "\n",
    "    Boost evaluation scores (ROUGE, BLEU, BERTScore)\n",
    "\n",
    "    Encourage more complete, helpful responses\n",
    "\n",
    "    Train the model to match empathetic, multi-step advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1745165208673,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "9XXQdtHh8nE1",
    "outputId": "06e049d4-b9ab-435b-dc3f-c51f8a19887a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trial 6 dataset saved!\n",
      "Total samples (after filter): 2277\n",
      "Samples removed (< 20 words): 1516\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "merged_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/merged_counsel_empathetic.jsonl\"\n",
    "with open(merged_path, \"r\") as f:\n",
    "    merged_data = [json.loads(line) for line in f]\n",
    "\n",
    "#Filter: Keep only samples with output â‰¥ 20 words\n",
    "filtered_data = [sample for sample in merged_data if len(sample[\"output\"].split()) >= 20]\n",
    "\n",
    "trial6_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/merged_counsel_empathetic_cleaned_trial6.jsonl\"\n",
    "with open(trial6_path, \"w\") as f:\n",
    "    for sample in filtered_data:\n",
    "        json.dump(sample, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"Trial 6 dataset saved!\")\n",
    "print(f\"Total samples (after filter): {len(filtered_data)}\")\n",
    "print(f\"Samples removed (< 20 words): {len(merged_data) - len(filtered_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qn17EGd988rl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf40swfAtidV"
   },
   "source": [
    "# Trial 6 Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CKq8D-B9xr-"
   },
   "source": [
    "ğŸ” Trial 6 Fine-Tuning Script (merged_counsel_empathetic_cleaned_trial6.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8dbcbf7b6ea7420dbea1f2a8e7012eb7",
      "266ab8b3ad954db58eab03494deacbfa",
      "9a19054c78ee4426a0e32399662259b4",
      "e754d262adde41d58d3ac3f15b117921",
      "8ab394b9d41247238764017edbb08306",
      "44d4317d24804e178f43ce4410298fca",
      "9da8eb3f647c42e2b6106b238df0695a",
      "5038990d0b7d44f0a5cd897050d04f8f",
      "bf5daf3f9ff7442c8bbf768191e30624",
      "51c00470505c4500bbcfe53ea8a123ae",
      "642a25bc1604450181b67770938b76a7",
      "831b91ecfecb4ff3aec5c249f02f5a92",
      "c0f38c26f8d6451a8709c7001f5d5b07",
      "b089adae9d5c48bdacbece7de524cba0",
      "1cf5016eed3541efb3099dd15c4cebe8",
      "fa6c8a0681f04da48187dbf903846e1f",
      "845b0e0207bf446a9d60c77e6a221f70",
      "213f19a6e87742c59fda26e5c45fa9da",
      "f486b8b0f98b49a596a8a7e17bcbfede",
      "0992e2ca49d641b581c35f26c3d90beb",
      "41c94410ef214297a9af3165ef04756a",
      "465f26f8c8894cc79af434a9dd16a175"
     ]
    },
    "executionInfo": {
     "elapsed": 1239078,
     "status": "ok",
     "timestamp": 1745167903778,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "aKw6ZLc_9yjK",
    "outputId": "f44f0d3a-a305-4baa-b0df-98d25f39c734"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbcbf7b6ea7420dbea1f2a8e7012eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831b91ecfecb4ff3aec5c249f02f5a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-b778cb5bd9e7>:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 14,155,776 || all params: 7,255,887,872 || trainable%: 0.1951\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1136' max='1136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1136/1136 20:18, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.098800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.536900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.415900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.452400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.459800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.406700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.473100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.392700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.393300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.380100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.514300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.367300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.383800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.333600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.420600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.482400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.384200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.362800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.408200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.383200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.314400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.347400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.409500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.375900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.337900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.264400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.350700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.364300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.483800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.316000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.278100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.363700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.266900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.479700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.358700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.323500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.347800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.383400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.293300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.344300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.316200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.338400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trial 6 complete and saved!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "#Clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#Load dataset (Trial 6)\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/merged_counsel_empathetic_cleaned_trial6.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "#Load model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.use_cache = False  # Prevent rotary crash\n",
    "\n",
    "#Preprocessing function (batched-safe)\n",
    "def preprocess(batch):\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for instruction, output in zip(batch[\"instruction\"], batch[\"output\"]):\n",
    "        prompt = f\"You are a helpful mental health assistant. Respond empathetically and with clarity:\\n{instruction}\"\n",
    "\n",
    "        prompt_tokens = tokenizer(prompt, truncation=True, max_length=256, padding=\"max_length\")\n",
    "        output_tokens = tokenizer(output, truncation=True, max_length=256, padding=\"max_length\")\n",
    "\n",
    "        input_ids = prompt_tokens[\"input_ids\"] + output_tokens[\"input_ids\"]\n",
    "        attention_mask = prompt_tokens[\"attention_mask\"] + output_tokens[\"attention_mask\"]\n",
    "        labels = [-100] * len(prompt_tokens[\"input_ids\"]) + output_tokens[\"input_ids\"]\n",
    "\n",
    "        # Ensure total length is 512 tokens\n",
    "        input_ids_list.append(input_ids[:512])\n",
    "        attention_mask_list.append(attention_mask[:512])\n",
    "        labels_list.append(labels[:512])\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"attention_mask\": attention_mask_list,\n",
    "        \"labels\": labels_list\n",
    "    }\n",
    "\n",
    "#Apply preprocessing\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names\n",
    ")\n",
    "\n",
    "#LoRA Config (rotary-safe)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "#Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial6\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=1e-5,\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=[],\n",
    "    run_name=\"mistral_trial6\"\n",
    ")\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#Train\n",
    "trainer.train()\n",
    "\n",
    "#Save\n",
    "model.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial6\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial6\")\n",
    "\n",
    "print(\"âœ… Trial 6 complete and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPrGsJuH96WD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQCaJjEGHsoY"
   },
   "source": [
    "# Trial 6 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329,
     "referenced_widgets": [
      "563c359dcedb4170bf6529682c86d888",
      "370596338b354555891332b2e8f0b9ce",
      "0a1b79ed7f444a67bca21a8f32ff5836",
      "e39284f6357f4f758d4e7fe8e7b6f723",
      "5fcd8d483be544dfbd58f6ec42ef7f9f",
      "57f217e5dda748b9acf798c742c37bc2",
      "bbad778460a34ac8979aa7d20e46edb8",
      "77557fe45a7446e9a873c733432f1aee",
      "6d1af056362a4baa8b5c90d34eaf1a9b",
      "40c7cb88692c464d9f3f28326dc18ba0",
      "19114ab1f8134b249bb228f96ad9d8c9"
     ]
    },
    "executionInfo": {
     "elapsed": 3029648,
     "status": "ok",
     "timestamp": 1745171095650,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "8w8FxhgMHvzV",
    "outputId": "9ef7c808-bf8a-413b-bf19-7a112004afc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563c359dcedb4170bf6529682c86d888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating Trial 6 (300 samples):   0%|          | 0/300 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "ğŸ” Evaluating Trial 6 (300 samples): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [49:58<00:00, 10.00s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': 0.028,\n",
       " 'ROUGE-1': np.float64(0.2967),\n",
       " 'ROUGE-2': np.float64(0.054),\n",
       " 'ROUGE-L': np.float64(0.1442),\n",
       " 'BERTScore (F1)': 0.8328}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial6\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "#Load evaluation dataset (300 samples for speed)\n",
    "eval_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/merged_counsel_empathetic_cleaned_trial6.jsonl\",\n",
    "    split=\"train[:300]\"\n",
    ")\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"ğŸ” Evaluating Trial 6 (300 samples)\"):\n",
    "    input_text = f\"<s>[INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "{\n",
    "    \"BLEU\": round(bleu_result[\"bleu\"], 4),\n",
    "    \"ROUGE-1\": round(rouge_result[\"rouge1\"], 4),\n",
    "    \"ROUGE-2\": round(rouge_result[\"rouge2\"], 4),\n",
    "    \"ROUGE-L\": round(rouge_result[\"rougeL\"], 4),\n",
    "    \"BERTScore (F1)\": round(sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"]), 4)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch0ORDR0WeiR"
   },
   "source": [
    "ğŸ“Š Trial 6 Evaluation Comparison: Mistral + CounselChat Trials\n",
    "\n",
    "| Trial   | Dataset                        | Samples | LoRA Params (r/Î±) | Epochs | BLEU   | ROUGE-1 | ROUGE-2 | ROUGE-L | BERTScore (F1) |\n",
    "|---------|--------------------------------|---------|-------------------|--------|--------|----------|----------|----------|----------------|\n",
    "| Trial 1 | counselchat_cleaned.jsonl    | ~890    | 8 / 16            | 3      | 0.0173 | 0.2315   | 0.0334   | 0.1220   | 0.8076         |\n",
    "| Trial 2 | Same as Trial 1                | ~890    | 16 / 32           | 4      | 0.0160 | 0.2163   | 0.0291   | 0.1134   | 0.8058         |\n",
    "| Trial 3 | Real + 200 Synthetic           | ~1,015  | 16 / 32           | 4      | 0.0160 | 0.2163   | 0.0291   | 0.1134   | 0.8058         |\n",
    "| Trial 4 | Smart-filtered CounselChat     | ~2,116  | 16 / 32           | 5      | 0.0222 | 0.2384   | 0.0387   | 0.1225   | 0.8144         |\n",
    "| Trial 5 | Same dataset, prompt tweaks    | ~2,116  | 16 / 32           | 5      | 0.0243 | 0.3071   | 0.0416   | 0.1307   | 0.8344         |\n",
    "| **Trial 6** | Merged (filtered counsel) + Empathetic (augmented) | 2,277 | 8 / 16            | 4      | **0.0280** | **0.2967** | **0.0540** | **0.1442** | **0.8328**       |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6bbf93331d944277a2fc94d3084b42e8",
      "8265a2b4bed7438db9fb02c5afa4d776",
      "d057f2182a7844b3ab0df7d299844544",
      "4f9c1d19323d4e64b17e475b3349b677",
      "0c703b4e8a7a450aaaf965dc0fe5967c",
      "b5f2adcab8a44c7f97c568fea1f1d8cf",
      "146bed7f5fe64d958cae9dc804ae0996",
      "4d7461576c674441969bc7ca4d8c7908",
      "2a376c02237047ad91996606a17096c7",
      "509dd4b3af0042fca49ebf45c1984e00",
      "c83c2630d4d348659e95c45a3fb592e8",
      "a0bca6da590b454a84429cf2767ec2c2",
      "c9c993bfd15c459abcbe30e46cb6ac98",
      "42ac57db2b584582b00783697e2269bb",
      "30ffc207c327402f91eb2db9a1a96c77",
      "0486290b86ac4b48a694326adbf5fb40",
      "6cbe0005f35b4aa1a3f4fe6832f5d2aa",
      "3b18472dda52491dbb5dc4339623cd41",
      "269ba3e2e88a459e8bd9421d4a135d0e",
      "39ceba00427640e4b71dc4d0cd0a4f9d",
      "dc38f404db044b4e9f2e1c6e36189102",
      "714e9471f54f4cb189ea602593fb7696",
      "136860285d6047a8865416d0f1d9087b",
      "79103051571e40fc97094353ad4070ae",
      "fad5ed1b26ec4bba87ee5e900a436456",
      "34fb94f0eb94461287576920b6d9f841",
      "9311d33c516d41318e3ace4656aa2986",
      "47284e9362fa4857bca4137e95e13997",
      "0b0f06e9ffa740329cfd5d64d64c3fd0",
      "cc37877b3de84168874ad3eafdc54043",
      "a5e02226974a42d78b464ecfca9861a9",
      "3955afa5bd834a639e26f9e577b48b50",
      "4f5d92b900044a2a84b1b666be48cec6",
      "05a8611638784cebad717eefb451a091",
      "415f2302514240d2b8778100d6c3857c",
      "2a2d950e78894348986ac8a6f34a02d9",
      "7e61d48e6abf44f4be8dc4d625a6a461",
      "da267829284a4fadb8a066635a7ff3c8",
      "b5d5e9fee270459183bb18379653f5f0",
      "e00ae3f31f7940e5b756c18cf54a5280",
      "4e55188b2ebb446c8c28c060d1e2f0d3",
      "f3f0caef0bef41288f2f8f037268621c",
      "59d9ca44c3dc45c28d6ff8133af636bb",
      "54850f993bdf48629b5dabfd9f09ec6d",
      "3f53c64c801648a59d6d4e27138669c9",
      "214316d705134299bf93f16e12f00adc",
      "912e090b52574fd987e276493bfbb7e4",
      "4b297a20b2e44e34a262ef5c28212192",
      "e83ee1e5f96a47319869277ffb2677ad",
      "369c0c1968364c639c02cd3593402ecc",
      "3e17300b10a347af80adda78a6874fc8",
      "280e2fe3645a46079983005709331ec7",
      "7ef7c28fc0fa4691911082cd6b191114",
      "96e9fd6166d34da08b9b8a4b66c8ecce",
      "04636755d256481da5e6a0f412fe396c",
      "3a65bdcec9d3416da66b0b63eb7ffd92",
      "9986795018cd482c89dcfeee04d16342",
      "fd4b61376274411e8030800a8e5c4849",
      "36465e4e9f784730822a9584dd195f10",
      "01a20a1304bc48cf8f0d388e0dd6a79c",
      "db0b0d15a87c48ef8882b0510a96f38f",
      "27584386b4b44346984f34183167f45f",
      "792374b7f78c4e13b5ed261db75f9cde",
      "c672fa709a5d48f795bd99615fe0f846",
      "e46182a308474129909e2df66d8e12f0",
      "ee68768681b44d44b45a617388fe0277",
      "e97cedc4ca6c48edb88e3e9274d3126b",
      "6f32257244944e33816dd4ebcc49221b",
      "dfa63e5c33dc4c47b0c5273f3986c0a8",
      "ef24a59f60434d70bfdc396cf7ee089f",
      "e65b7284c4db49c8a87655311dd18bba",
      "cc2ad073a5384cc785763f7cdb6c4549",
      "09fe0100388c428eb4696950a49efccc",
      "9c92ffca5d50474c86986e8b220deb4b",
      "8015f8a14a84482d857360c9dbcc04af",
      "7a3ea5b08d754548a1fd8545b1ccdbe3",
      "a1708395879148d08eb1a06ef46d3f7d",
      "9b7be10eaa4d432bbc076c3d5f1f8879",
      "d4100a77bcd34870b3f8a17b4e40b962",
      "4ee56c2dde3c481ab10500356e3e2e69",
      "3a211532e0bb4cbdbe5b8924cc7e4ed4",
      "d209a80060c246c39c9822c0966ba0fa",
      "76f39526e84540c891d0dac7f790ed7f",
      "6fd2f028d60b404fbff9a76f3e33aebf",
      "7b3d73a605dd4296b71dfe1a57faf57b",
      "b7c7af729d724aaf99fea3e40fcc2844",
      "bb2aca2e00a246958fce8b0abdcc397f",
      "49a226f487cc41c0ba2380794b41ff2d",
      "fc178648c7874dd19eea2109d140483d",
      "912ee36c16d24906b4d14dfd5055f612",
      "56c3cbb392ed46c0810640eaeae13c18",
      "f6cf0e5576324cb1b9030d89903683d7",
      "cc126003bd0b4362a72e00fc4f5602a6",
      "31adfb9468c24689b4e928887dba37c6",
      "3e280b22da7a4f7cbfeb23e766ba2361",
      "8c484c8689c142ccaea47f5b86645d52",
      "90bb695934884055af1b495a4175946d",
      "f057af485d0a491f85ab26482af86405",
      "d3e302853e774009bc4d3c45a610aff9",
      "1f9371ac40fe4d3b9b175fc093202bc1",
      "d9dc9366707149919b0c4d3fbe2fb109",
      "ed12322dc03e4f8bbd99591ecabb840c",
      "671dc7fde4114b209ab05604840bbd86",
      "1bc98d4a05534ea69e78f4d44ce47492",
      "bdea7a8013104c67adb971d7b39b18ff",
      "9c29318fcac543c6802724de75fb284b",
      "5bb1d149583044a7b1fce0cb925c01b7",
      "3ba7a71e640c4ca28ba6a24321a2b33e",
      "34c912c45563485794568e99f7c06281",
      "ccab396b41ab4d2a8190224cc686b9fb",
      "aa56f07743104805bc0fff140c841415",
      "cfd749689c984e03b69820ba63bd50a5",
      "0dc94414eb6e4ddfb096b32136c2dadd",
      "56bb6e75d2744188ab205ef06bca5f6e",
      "c9c0366704b94313a758f068ba74b4b5",
      "9a8162bed6984b378f7a400ca2629547",
      "b0bd3c2ae47042ccb3247bc2ae5cad4f",
      "0b64415613044a8ca2992ae63cd4ad9a",
      "fd6ca70f8e0d4fc3874100161991f8e0",
      "f4e57c0f3f724a49a5ec8e8d09f370af",
      "0e57ffdca08748419e94feb2bf95d2e0",
      "fae1450ca8b74fc2b1afe087eef83390",
      "5cd26ee0fce1465093bd6cc751e3b77e",
      "356473b6b82442c2a66e56167b5ab170",
      "fadba50f9a7d4aafae5609f6e5cef05b",
      "91a63129dbfa4bacb4b25d812c92f51d",
      "2a7d64f4747a469ea35be64b2c84f97c",
      "5d0fef555aa049b1bcf8e0a666d64ef7",
      "a97c89637bd6432c91226ed72b2a8815",
      "8a7b3feee6bf4d18b280b69b5d808108",
      "d658bf3278c0409ba098c66adbb1827f",
      "543bc62ece4e4de6b3eb8932e847e8da",
      "6fc4d2a44aae4117982e1b289cb227e6",
      "8523f914db2248bea13b4f4ee8ca1c5d",
      "41fc3ad2731b4a6bb792a47f8235a057",
      "9708562a4a7447a2b3cdc6c8c86689d4",
      "9f3292e15f0f4215b5bf9d032cf9fe8a",
      "d878cd85cddf41bfbf587ac97ef3af73",
      "422b2836ab2c405ab487d2634595243b",
      "524e1fa19cea46839db6ed8518096d40",
      "5a6ac655b3064dc197676fa3e3d5a11a",
      "7701b7d917dd4ff5be468933557b94f8",
      "147b9b40f5044fed9bed68fd76ebd4b2",
      "76a233afcaeb45ba82f08785c53f65f4",
      "c45c1c895e2549c7b594c90d1c05c916",
      "dc0ef5c59cbd4ba1b4b55dce3bb80e04",
      "c80c0a3f6fee4401a80648bcb2fc0b34",
      "27c03637c10f4235b6f05137e260a75d",
      "7dc1c812c4a74444ae510eaaf976fc6a",
      "2d3f0b1f19e9402e99664bce06815242",
      "fa017ce076cd49a2a691b24fbc471619",
      "cbaf45670251426d90045f29a28bd231",
      "d4e1aa935a4d469ead5eb6a8807055a7",
      "f5a7e4e7bb5e458590837f2f6f14a281",
      "42607851ade048d695a799bc564cb19c",
      "dcd714c1b7214305a405f39581f530f4",
      "c31a606363a941e2bb5119b7ee46f7d8",
      "21cfffea47464fbab32c582fa13cfdb6",
      "71c775e43b8b4f2eb0f913ff49f10a59",
      "b02ac3f5f4d848aaa1f2f1c3355f9b29",
      "d31996e2a61a4464a3fb0ff0ab74f7bb",
      "249cec789e5b4dd9adc19a1f16edf2c6",
      "81d15d01b73749628841ee57b4d5e58f",
      "e0d675bb4b7841e381d92d8c00e129e3",
      "14276779d998470c9583fb66b306676c",
      "c1a7b8b39a77430c8b38cbf13964559e",
      "555983f0b8604f168efff550a2e13f06",
      "21e3bd187c404afeb7a0516ee5a651c1",
      "cf2cd5a4a55c417bbec6bafec8e2cd7a",
      "6f8b8ea039e74988817f56dd9129858c",
      "7adb1f13233e436698fd82ced854d835",
      "50e61ea9fb0b4c60a9152af553769914",
      "c7ba18d2e826422bb24b41b5a9dcd855",
      "a6daf428088448e3a4f8c962da4af722",
      "c0ddcc8e04014a3da8e4978f72958351",
      "a7b114a1cd9444d8a4d31090726c2ce8",
      "73dc81484c6d49898c7e101c8a488e08",
      "a063a5ae32dd46149c237c5a6d997eb4",
      "097b29ea00fd48ff9659541bf4e1c738",
      "96e7b06bb10349a58b9b3c899284b2a6",
      "d2ebb4877f594434a31acc30b3eab771",
      "0c516b7476cb4086820980b9cb940be5",
      "1df51a538f334245893a9411611f1a97",
      "ac01259ec9294bbcab2f4a2df7fbde71",
      "cdc44ab4acd444cba4dfa4b7a0117fcb",
      "0bde77b4e33144188e9c93023e41c29d",
      "358d61018f8f4395b01e4486ef356d5c",
      "849104c31293461da629e2a8594a0c72",
      "98ad5fe670c5405fbf8fef2dd94fcc61",
      "0b0da7a5e5f44e31be4eb7cc19f31d0e",
      "de06f999fcdf4fb9920fb7b376d1ff11",
      "8e03d9c6765d4717aece0a95324ce419",
      "629019e506c244e2b4d06cfbf3026322",
      "c062ebf50d374d2db1924c4741db5d58",
      "04677e975c0e468eaba58eb3b41aa24e",
      "c09f19a648114f749ddca4e4d6bd7b86",
      "4ef68d9577594f95a110a89644558165",
      "2519e008680b4b149d91fe3f56e1135c",
      "19081ce6ed7d46a88daae5b534d87f4f",
      "84a287d321a940aab4ef0360321cc21b",
      "d5557d03fbea4135a79d6e652dfb4437",
      "bef9491d4ec04016acb7a3664ddaeda1",
      "8be7473b97c24fb69aa08ac902f1c7db",
      "cce633c9629f4eb48fc1dc0dee67478b",
      "bb1aa21e5ab243798389782160aeff16",
      "b53ef43305654763b21b55ec544f8777",
      "99ce9df10f034d61865b45e4e5f551ee",
      "7d464b2960e744e1b1656735c7e6e01a",
      "103326abd02943a18846e45679c5cb37",
      "ff7b9cb169ff4a8a9d93abce1e261220",
      "1c069581c7d04489a2b5b7e5af333516",
      "7f3780ec6b604304b2913936e209cc95",
      "dacfd5faad9b47dd800561ec74b5a314",
      "e2cdab0ac8f846548390b8c5050729a6",
      "6d61ac4dd92545a0b5e06b3a251a2168",
      "3df50ea2f80f433dbb08e6562646b7cf",
      "0ffdb4b5034b4f41a942bd27fb8b37b8",
      "c99f64dbeba0448c899f0d2ccc96f771",
      "563c988838d949498ee6d38df74e8071",
      "c580d40248244149a2296f420f30bf6b",
      "d55c471b57394e89aec990fd7a024650",
      "d255856c88ca4eccace44910eefd0b5a",
      "395ebc85dccc47d9b42259bafce3089c",
      "869000e0685c4362ab6901d9c45bab52",
      "dd3b5beb45ca49a69ac21aab5103890b",
      "eafebb13964b4cc0afd155cff4e0f918",
      "8da982aac6bf499baafd8fba4cdfadee",
      "2825b8b2c4ad446dae61929967b1f02d",
      "97ae4a7b07ed4a0c9d2ba010e142cf09",
      "ccd742ba30f04967a035d0c962787fb5",
      "b7257c22c76747f3b0baae3da04e2f1f",
      "e110cfa6bbd8473b8ff1b02fba20b2a6",
      "238be2d725a945b1a13b00dd53f9bfda",
      "4c45662e8112445a9decb13a4c71bf87",
      "f6eae26e56a140bb982c05c5b6746e25",
      "91ccade2e07f449a9ed0dd36a1120ab4",
      "1917a49c841a4a66abfcd8227c3460f4",
      "109ff7bcd9614f2dbd90ec26d5000c04",
      "05cfee82941f467582db654d923b0c67",
      "9ce8ad6be2e443ed9453dd5c814d355c",
      "43d503d07ad64683920c2c0f9845522a",
      "d19e70a4ab47467294dc55785428de17",
      "a01931f414534d748f5e0d6c4c896494",
      "4bce8b9ed29648a19b151d5de9154d8b",
      "cad8882eba0e469cad2358aceccd7d82",
      "3dea890f53674c1b8c0642fa1ef2a365",
      "64e963086bfd4f039cf56f104f7f3fde",
      "b9f16e028e94465d933107ce3fca9837",
      "f8694caa954546c3899308a979674e36",
      "12b03f9c47d34a369cf1023bb5451452",
      "9327242ab27e4e3ca4329a38afd3ce78",
      "484463d5478641449d11834c28eff2cc",
      "6e3685717630456aa7bd5afa7fefd0e2"
     ]
    },
    "executionInfo": {
     "elapsed": 5010771,
     "status": "ok",
     "timestamp": 1746340057510,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "4dW7SssOVAJV",
    "outputId": "ce1d1d41-82fb-478a-c7f3-d1ff22711f29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbf93331d944277a2fc94d3084b42e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bca6da590b454a84429cf2767ec2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Interview_Data_6K.csv:   0%|          | 0.00/13.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136860285d6047a8865416d0f1d9087b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Synthetic_Data_10K.csv:   0%|          | 0.00/32.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a8611638784cebad717eefb451a091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f53c64c801648a59d6d4e27138669c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a65bdcec9d3416da66b0b63eb7ffd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97cedc4ca6c48edb88e3e9274d3126b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7be10eaa4d432bbc076c3d5f1f8879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc178648c7874dd19eea2109d140483d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9371ac40fe4d3b9b175fc093202bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa56f07743104805bc0fff140c841415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae1450ca8b74fc2b1afe087eef83390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Generating responses on 500 MentalChat16K samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [1:21:35<00:00,  9.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Running BLEU, ROUGE, and BERTScore evaluations...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc4d2a44aae4117982e1b289cb227e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a233afcaeb45ba82f08785c53f65f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42607851ade048d695a799bc564cb19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a7b8b39a77430c8b38cbf13964559e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dc81484c6d49898c7e101c8a488e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”µ BLEU: 1.905935401808183\n",
      "ğŸŸ¥ ROUGE-1: 31.896644231716277\n",
      "ğŸŸ¥ ROUGE-2: 5.002930566136682\n",
      "ğŸŸ¥ ROUGE-L: 13.574478216532698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849104c31293461da629e2a8594a0c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19081ce6ed7d46a88daae5b534d87f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b9cb169ff4a8a9d93abce1e261220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55c471b57394e89aec990fd7a024650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e110cfa6bbd8473b8ff1b02fba20b2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01931f414534d748f5e0d6c4c896494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ© BERTScore (F1): 83.32848395109177\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q transformers datasets evaluate bert_score tqdm\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Load 500 evaluation samples from MentalChat16K\n",
    "eval_data = load_dataset(\"ShenLab/MentalChat16K\", split=\"train\")\n",
    "eval_subset = eval_data.shuffle(seed=42).select(range(500))\n",
    "\n",
    "#Load fine-tuned model from Trial 12\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial6\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "#Response generator\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=350).to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=180,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "#Generate predictions with live progress\n",
    "preds, refs = [], []\n",
    "\n",
    "print(\"ğŸ§  Generating responses on 500 MentalChat16K samples...\")\n",
    "for sample in tqdm(eval_subset, desc=\"Evaluating\"):\n",
    "    user_msg = sample[\"instruction\"]\n",
    "    ref_response = sample[\"output\"]\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{user_msg} [/INST]\"\n",
    "    gen_response = generate_response(prompt)\n",
    "    preds.append(gen_response)\n",
    "    refs.append(ref_response)\n",
    "\n",
    "#Run evaluation metrics\n",
    "print(\"\\nğŸ“Š Running BLEU, ROUGE, and BERTScore evaluations...\\n\")\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "print(\"ğŸ”µ BLEU:\", bleu.compute(predictions=preds, references=refs)[\"bleu\"] * 100)\n",
    "\n",
    "rouge_scores = rouge.compute(predictions=preds, references=refs)\n",
    "print(\"ğŸŸ¥ ROUGE-1:\", rouge_scores[\"rouge1\"] * 100)\n",
    "print(\"ğŸŸ¥ ROUGE-2:\", rouge_scores[\"rouge2\"] * 100)\n",
    "print(\"ğŸŸ¥ ROUGE-L:\", rouge_scores[\"rougeL\"] * 100)\n",
    "\n",
    "bert_result = bertscore.compute(predictions=preds, references=refs, lang=\"en\")\n",
    "print(\"ğŸŸ© BERTScore (F1):\", sum(bert_result[\"f1\"]) / len(bert_result[\"f1\"]) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746,
     "referenced_widgets": [
      "1e131157c1b44ce3a8822bef43e321e3",
      "8480f472410f45bf843181eb92ec1a56",
      "75452d2eec5d4bbbb9db56476ca7095c",
      "92a48bcb193841158cbc69252ab15d85",
      "8d4c525de1b141d6a41112916dbda861",
      "48c173a7aac14a1693b509ba6c606d84",
      "2b35eb3728ec44d789ebcc5895e77dce",
      "35e9e5824c8b403cb3580a514139f607",
      "310d80599c25460a85a2c8063113b3e9",
      "4da68bba0b6d43c390e4f2a8063cf0b8",
      "d151b367303a43a7aef270f9b218f077"
     ]
    },
    "executionInfo": {
     "elapsed": 61174,
     "status": "ok",
     "timestamp": 1746340817285,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "Xr4Fuv5wA3YX",
    "outputId": "4dc8ff9c-bdc1-4965-f6bf-3b9e67da7bef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e131157c1b44ce3a8822bef43e321e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Prompt 1: I feel like I'm constantly overthinking every little thing. How do I make it stop?\n",
      "ğŸ¤– Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel like I'm constantly overthinking every little thing. How do I make it stop? [/INST] I'm sorry to hear that you are experiencing so much overthinking. It's very common for people to have racing thoughts and it can be overwhelming at times. Here are some things that may help:\n",
      "\n",
      "1. Mindfulness: This is a technique that can help you stay present in the moment. Try focusing on your breath, and whenever your mind wanders, gently bring your focus back to your breath. This can be a great way to calm your mind and help you focus on the present moment instead of the past or future.\n",
      "\n",
      "2. Exercise: Physical activity can be a great way to release tension and stress. Try going for a walk, doing yoga, or any other activity that you enjoy.\n",
      "\n",
      "3. Journaling: Writing down your thoughts and feelings can be a great way to process them and gain some perspective. Try writing about what's on your mind and see if you notice any patterns or themes.\n",
      "\n",
      "4. Practice self-\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ§  Prompt 2: Why do I get so anxious when I have to talk to people, even my friends?\n",
      "ğŸ¤– Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Why do I get so anxious when I have to talk to people, even my friends? [/INST] I'm glad you reached out for support. Anxiety can be really uncomfortable and frustrating. It can be helpful to explore the reasons behind your anxiety when talking to people. Sometimes, anxiety can be a result of past experiences where we felt judged or criticized by others. Other times, it could be that we are worried about what others think of us or we are concerned about saying the wrong thing. It can also be helpful to explore your thoughts and feelings about the people you are anxious about talking to. Do you feel like you are not good enough? Do you feel like you don't belong in their group? These are just a few questions that may help you understand your anxiety a bit better. If you find that your anxiety is impacting your daily life, it may be helpful to seek out a therapist who can help you explore these questions and help you develop tools to manage your anxiety. I hope this helps. Let me know if you have any questions. Best of\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ§  Prompt 3: I wake up with a knot in my stomach every day. What can I do about it?\n",
      "ğŸ¤– Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I wake up with a knot in my stomach every day. What can I do about it? [/INST] I'm sorry to hear that you're experiencing this symptom. There are a few things that might be helpful. First, I would recommend that you see a medical doctor to rule out any medical issues that could be causing this. If it turns out that there's nothing physically wrong, then it might be a good idea to explore some of the emotional causes. A few things that might be helpful are:\n",
      "\n",
      "1. Reflecting on what you're thinking about when you wake up. Are you worried about something? Are you anxious about your day? Are you thinking about something that's bothering you?\n",
      "2. Reflecting on what you're feeling when you wake up. Are you feeling anxious? Are you feeling sad? Are you feeling stressed? Are you feeling overwhelmed?\n",
      "3. Reflecting on what's going on in your life that might be contributing to your symptoms. Is there something that you're worried about? Is there\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ§  Prompt 4: im being bullied in my college no one to talk\n",
      "ğŸ¤– Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "im being bullied in my college no one to talk [/INST] I'm really sorry to hear that you're being bullied in college. Bullying can be a really difficult experience and it can be hard to know what to do or who to talk to. I'm here to listen and support you. Do you feel safe at all on campus? Is there a specific person or group of people who are bullying you? It might be helpful to try to identify what specifically is happening and who you feel safe talking to about it. Sometimes talking to a teacher or professor about what's going on can be helpful. If you don't feel comfortable talking to someone on campus, there are also other resources you can contact such as a local mental health clinic, a counselor at a community center, or even a local hotline. I'm here to support you and help you figure out what to do. It can be really hard to ask for help, but it's the first step in getting through a difficult situation. You'\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ§  Prompt 5: i like to dance and sing\n",
      "ğŸ¤– Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "i like to dance and sing [/INST] That's wonderful! Dancing and singing are such great ways to express ourselves and let go of stress and emotions. What type of music do you like to dance and sing to? Is there a particular artist or genre that you connect with? I'm here to support you and your interests. Keep dancing and singing! :)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# ğŸ”¹ Load your fine-tuned model from a specific trial\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial6\"  # change as needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# ğŸ”¹ List of saved user questions (manually added or loaded from file)\n",
    "prompts = [\n",
    "    \"I feel like I'm constantly overthinking every little thing. How do I make it stop?\",\n",
    "    \"Why do I get so anxious when I have to talk to people, even my friends?\",\n",
    "    \"I wake up with a knot in my stomach every day. What can I do about it?\",\n",
    "    \"im being bullied in my college no one to talk\",\n",
    "    \"i like to dance and sing\"\n",
    "    # ...add more prompts as needed\n",
    "]\n",
    "\n",
    "# ğŸ”¹ Generate and print responses (no saving)\n",
    "for i, question in enumerate(prompts, 1):\n",
    "    full_prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{question} [/INST]\"\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", truncation=True, padding=True).to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.6, top_p=0.9, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"ğŸ§  Prompt {i}: {question}\\nğŸ¤– Response: {response}\\n{'-'*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0ehtQNrAwSF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGhOWmjxWnIx"
   },
   "source": [
    "Trial 6 Model (Chatbot Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1666,
     "referenced_widgets": [
      "d3ee40d350f34b3ea88ec846664aed47",
      "a931840f8fe64e528c1675c75b725568",
      "7c892c2c83814e7fb4965b767818004d",
      "cb61033f167f4149a14aab9e8c5e5186",
      "ce962a4bfc6542e58a63bfcf9ddf78a7",
      "31b36275e45e4990ae4e081038c92e1f",
      "048700fb6e8d4f92a1d4281fd6923b7b",
      "0fa7ec2c756d4a79a7abb608fea3d76f",
      "5421971ae25d4a7c9f4ba8d3822ab163",
      "038887cd2e6f4dccb61f790fd3f1d8ff",
      "a650506f02a64b3c949dc9b392dec346"
     ]
    },
    "executionInfo": {
     "elapsed": 181621,
     "status": "ok",
     "timestamp": 1747478162025,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "blX2zQphU_DT",
    "outputId": "96786b9c-b3e3-4dfb-877e-2310967995cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ee40d350f34b3ea88ec846664aed47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Running Trial 6 Inference:   0%|          | 0/15 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "ğŸ§  Running Trial 6 Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [02:47<00:00, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§  Prompt 1: I feel like I'm constantly overthinking every little thing. How do I make it stop?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "I feel like I'm constantly overthinking every little thing. How do I make it stop? [/INST] Overthinking can be exhausting and overwhelming. It can also be a sign of anxiety. Anxiety is a normal response to stress, but when it becomes excessive and interferes with your daily life, it can be a problem. Here are some things you can try to help reduce your overthinking:\n",
      "\n",
      "1. Practice mindfulness. Mindfulness is being fully present in the moment. It can help you to focus on the present and reduce your overthinking. You can practice mindfulness through meditation, deep breathing, or simply focusing on your senses.\n",
      "\n",
      "2. Identify your triggers. What is causing you to overthink? Is it a particular situation or person? Once you identify your triggers, you can start to develop strategies to manage them.\n",
      "\n",
      "3. Challenge your thoughts. Overthinking often involves negative or irrational thoughts. Try to challenge these thoughts by asking yourself if they are true and if there is evidence to support them.\n",
      "\n",
      "ğŸ§  Prompt 2: Why do I get so anxious when I have to talk to people, even my friends?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "Why do I get so anxious when I have to talk to people, even my friends? [/INST] It sounds like you are experiencing social anxiety. Social anxiety is a common condition that affects many people. It can be very distressing and can make it difficult to do things that you would like to do. Social anxiety can be caused by many different things. Some people have social anxiety because of something that happened to them in the past. Others have social anxiety because of the way they were raised. Still others have social anxiety because of the way they were taught to think about themselves. Social anxiety can be treated. There are many different ways to treat social anxiety. One way is to talk to a therapist. A therapist can help you understand why you have social anxiety and can help you learn ways to manage it. Another way to treat social anxiety is to practice doing the things that make you anxious. This is called exposure therapy. Exposure therapy can be very effective in helping people with social anxiety. It is important to remember that you are not alone. Many people have social anxiety and there are many\n",
      "\n",
      "ğŸ§  Prompt 3: I wake up with a knot in my stomach every day. What can I do about it?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "I wake up with a knot in my stomach every day. What can I do about it? [/INST] I'm sorry to hear that you're experiencing this. It sounds like you're having some anxiety. Anxiety can be caused by many different things. It could be related to a specific situation or it could be related to a general feeling of unease. It's important to figure out what is causing your anxiety. Once you know what is causing it, you can start to work on ways to manage it. If you're not sure what is causing your anxiety, you may want to consider talking to a therapist. They can help you figure out what is causing your anxiety and help you develop strategies to manage it. If you're not ready to talk to a therapist, there are some things you can do on your own. For example, you can try deep breathing exercises. You can also try progressive muscle relaxation. This involves tensing and then releasing different muscle groups in your body. You can also try to distract yourself from your anxiety. For example, you can\n",
      "\n",
      "ğŸ§  Prompt 4: Lately Iâ€™ve lost interest in everything. Nothing makes me happy anymore.\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "Lately Iâ€™ve lost interest in everything. Nothing makes me happy anymore. [/INST] I'm sorry to hear that you're feeling this way. It sounds like you're going through a tough time. It's important to remember that you're not alone in this. Many people go through periods of time where they feel like they've lost interest in things. It's also important to remember that you're not defined by your feelings. You're a complex person with many different parts to you. It's possible to feel this way and still be a happy person. I would encourage you to reach out to a therapist. They can help you to explore what's going on and help you to find ways to cope with your feelings. It's also important to remember that you don't have to go through this alone. You can reach out to friends and family for support. They may be able to offer you some insight into what's going on. I hope this helps. I wish you the best of luck.\n",
      "\n",
      "ğŸ§  Prompt 5: Is it normal to feel tired all the time even when Iâ€™m not physically active?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "Is it normal to feel tired all the time even when Iâ€™m not physically active? [/INST] Yes, it is normal to feel tired all the time. There are many reasons why someone might feel tired. Some common reasons include stress, anxiety, depression, lack of sleep, poor diet, and lack of exercise. It is important to rule out any medical conditions that may be contributing to your fatigue. If you are concerned about your energy levels, I would recommend speaking with your primary care physician. They can help you determine if there is a medical reason for your fatigue. If there is not a medical reason, then I would recommend speaking with a therapist. They can help you explore the reasons why you might be feeling tired and help you develop strategies to increase your energy levels. I hope this helps! Let me know if you have any other questions.\n",
      "\n",
      "ğŸ§  Prompt 6: I feel numb, like nothing really matters. What should I do?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "I feel numb, like nothing really matters. What should I do? [/INST] I'm sorry to hear that you're feeling this way. It sounds like you're going through a tough time. Feeling numb and like nothing matters can be a sign of depression. It's important to talk to someone about how you're feeling. A therapist can help you to understand what's going on and to find ways to cope. You don't have to go through this alone. I'm here for you.Â If you're not ready to talk to a therapist, you can also try talking to someone you trust. Sometimes just talking to someone about how you're feeling can help. You can also try to do things that you enjoy. Sometimes when we're feeling down, we don't want to do anything. But doing things that you enjoy can help to lift your mood. Try to find something that you like to do and do it. Even if it's just for a little while.Â I hope this helps\n",
      "\n",
      "ğŸ§  Prompt 7: I had a panic attack at work and now Iâ€™m afraid itâ€™ll happen again. How do I cope?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "I had a panic attack at work and now Iâ€™m afraid itâ€™ll happen again. How do I cope? [/INST] I'm sorry to hear that you had a panic attack at work. It can be very scary and overwhelming to have a panic attack, especially if it happens in a place where you feel like you should be able to control your emotions. It's completely normal to feel afraid that it will happen again. Panic attacks can be very distressing and it's important to take care of yourself after having one. Here are some things that may help you cope:\n",
      "\n",
      "1. Take care of yourself. Make sure you are getting enough rest, eating well, and exercising. These things can help you feel better overall and may help reduce the likelihood of having another panic attack.\n",
      "\n",
      "2. Practice relaxation techniques. Deep breathing, progressive muscle relaxation, and mindfulness meditation are all techniques that can help you relax and reduce anxiety. You can find many resources online to help you learn these techniques.\n",
      "\n",
      "3. Identify your triggers. If you know what is causing your panic\n",
      "\n",
      "ğŸ§  Prompt 8: My heart races for no reason and I feel like I can't breathe. Am I losing control?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "My heart races for no reason and I feel like I can't breathe. Am I losing control? [/INST] It sounds like you are experiencing symptoms of anxiety. Anxiety can present itself in many different ways, and it is common for people to feel like they are losing control when they are experiencing symptoms. Anxiety can also make it feel like you can't breathe, and your heart may race. It is important to remember that anxiety is a normal response to stress, and it is not a sign that you are losing control. If you are feeling anxious, it may be helpful to try some relaxation techniques such as deep breathing, progressive muscle relaxation, or meditation. It may also be helpful to talk to a therapist about your anxiety and to develop a plan to manage it. If you are feeling like you are unable to manage your anxiety on your own, it may be helpful to talk to your doctor about your symptoms. They may be able to help you determine if there is an underlying medical condition that is contributing to your symptoms. If you are experiencing symptoms of anxiety, it is important to remember\n",
      "\n",
      "ğŸ§  Prompt 9: How can I calm down quickly when I feel overwhelmed in public?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "How can I calm down quickly when I feel overwhelmed in public? [/INST] It can be very difficult to calm down quickly when we feel overwhelmed in public. Here are some suggestions that may help:\n",
      "\n",
      "1. Take a few deep breaths. This can help to slow down your heart rate and calm your mind.\n",
      "2. Find a quiet place to go. If you are able to step away from the situation for a few minutes, this can help to reduce your stress level.\n",
      "3. Use positive self-talk. Tell yourself that you are capable of handling the situation and that you will get through it.\n",
      "4. Use grounding techniques. This can help to bring your focus back to the present moment. For example, you could focus on your feet and the feeling of the ground beneath them, or you could focus on your breath and the sensation of the air moving in and out of your lungs.\n",
      "5. Use progressive muscle relaxation. This involves tensing and then releasing each muscle group in your body, starting at your toes and working your way\n",
      "\n",
      "ğŸ§  Prompt 10: No matter what I do, I always feel like Iâ€™m not good enough.\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "No matter what I do, I always feel like Iâ€™m not good enough. [/INST] I'm sorry to hear that you're feeling this way. It sounds like you're struggling with self-worth. It's important to remember that everyone has worth and value, and that you are no exception. It's also important to remember that everyone has strengths and weaknesses. It's okay to not be perfect at everything. It's okay to make mistakes. It's okay to not be good at something. It's okay to not be good enough at something. It's okay to not be good enough for someone. It's okay to not be good enough for yourself. It's okay to not be good enough for your family. It's okay to not be good enough for your friends. It's okay to not be good enough for your boss. It's okay to not be good enough for your coworkers. It's okay to not be good enough for your significant other. It's okay to\n",
      "\n",
      "ğŸ§  Prompt 11: I compare myself to everyone and feel like Iâ€™m constantly failing.\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "I compare myself to everyone and feel like Iâ€™m constantly failing. [/INST] It sounds like you are really hard on yourself. Comparing yourself to others can be a difficult thing to do. It can be helpful to remember that everyone has their own unique strengths and weaknesses. It is also important to remember that everyone has their own journey and path in life. It is okay to have goals and to strive to be the best version of yourself, but it is also important to be kind to yourself and to remember that you are enough just as you are. It may be helpful to talk with a therapist about your feelings of self-doubt and to work on building your self-esteem. A therapist can help you to identify your strengths and to work on building your confidence. It may also be helpful to talk with a therapist about your feelings of comparison and to work on developing a more positive self-image. I wish you the best of luck on your journey to self-discovery and self-love. You are not alone and there are people who care about\n",
      "\n",
      "ğŸ§  Prompt 12: Why do I always blame myself when something goes wrong?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "Why do I always blame myself when something goes wrong? [/INST] It sounds like you are struggling with self-blame. Self-blame is a common issue that many people face. It can be a result of many different things. Some people blame themselves because they feel like they are in control of their lives and they want to take responsibility for what happens. Others blame themselves because they feel like they are not good enough. Still others blame themselves because they feel like they are the only ones who can fix the problem. It is important to remember that we are not always in control of what happens to us. Sometimes things go wrong because of things that are outside of our control. It is also important to remember that we are not always the only ones who can fix the problem. Sometimes we need help from others. It is also important to remember that we are not always the cause of the problem. Sometimes things go wrong because of things that are outside of our control. It is important to remember that we are not always the cause of the problem. Sometimes things\n",
      "\n",
      "ğŸ§  Prompt 13: I always say yes to people even when Iâ€™m exhausted. How do I set boundaries?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "I always say yes to people even when Iâ€™m exhausted. How do I set boundaries? [/INST] It sounds like you are feeling overwhelmed and need some space. Setting boundaries can be difficult, but it is important to take care of yourself. Start by identifying what you are able to say yes to and what you are not. Once you have identified your limits, communicate them to others. You can say something like \"I would love to help you out, but I am feeling overwhelmed right now and need some time for myself.\" It is important to remember that setting boundaries is not selfish, it is necessary for your own well-being. Good luck!\n",
      "\n",
      "ğŸ§  Prompt 14: My partner doesnâ€™t understand my anxiety. Itâ€™s hurting our relationship. What should I do?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "My partner doesnâ€™t understand my anxiety. Itâ€™s hurting our relationship. What should I do? [/INST] I'm sorry to hear that your partner doesn't understand your anxiety. It can be very difficult to be in a relationship with someone who doesn't understand what you're going through. It's important to remember that everyone has their own way of dealing with things and that your partner may not have the same way of dealing with anxiety as you do. It's also important to remember that your partner may not be able to understand your anxiety because they may not have experienced it before. I would suggest talking to your partner about how you feel and what you need from them. It's important to remember that you can't change how your partner feels or thinks, but you can change how you communicate with them. I would also suggest looking into therapy for yourself. A therapist can help you learn ways to manage your anxiety and also help you learn how to communicate with your partner about your anxiety. I hope this helps! Let me know if you have any other questions.\n",
      "\n",
      "ğŸ§  Prompt 15: I feel guilty for putting myself first. Is that selfish?\n",
      "ğŸ¤– Response: [INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\n",
      "I feel guilty for putting myself first. Is that selfish? [/INST] It's natural to feel guilty when we put ourselves first. We've been taught that putting others first is the right thing to do. However, it's important to remember that we can't pour from an empty cup. We need to take care of ourselves first so that we can be there for others. It's not selfish to put yourself first. It's necessary.Â \n",
      "\n",
      "If you're feeling guilty about putting yourself first, it may be helpful to explore where this guilt is coming from. Are you feeling guilty because you've been taught that putting others first is the right thing to do? Or are you feeling guilty because you're worried about how others will react if you put yourself first?Â \n",
      "\n",
      "It's important to remember that we can't control how others react to our decisions. We can only control our own actions and reactions. If you're feeling guilty about putting yourself first, it may be helpful to explore these feelings\n",
      "\n",
      "âœ… Responses saved to trial6_test_outputs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Trial 6 model path\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial6\"\n",
    "\n",
    "#Load model + tokenizer\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "#Load test prompts\n",
    "test_file_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/test_prompts_counselchat.jsonl\"\n",
    "with open(test_file_path, \"r\") as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "#Run inference\n",
    "results = []\n",
    "for i, sample in enumerate(tqdm(test_data, desc=\"ğŸ§  Running Trial 6 Inference\")):\n",
    "    prompt = f\"<s>[INST] You are a helpful mental health assistant. Respond empathetically and with clarity:\\n{sample['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    results.append({\n",
    "        \"user_prompt\": sample[\"instruction\"],\n",
    "        \"model_response\": decoded.strip()\n",
    "    })\n",
    "\n",
    "#Display responses\n",
    "for idx, r in enumerate(results, 1):\n",
    "    print(f\"\\nğŸ§  Prompt {idx}: {r['user_prompt']}\\nğŸ¤– Response: {r['model_response']}\")\n",
    "\n",
    "#Save to CSV\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"/content/trial6_test_outputs.csv\", index=False)\n",
    "print(\"\\nâœ… Responses saved to trial6_test_outputs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQyO070zZo48"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S3Vy-rYZHQP"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHZbot9cZtXw"
   },
   "source": [
    "# FINAL ANDROID APP BACKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "e71915bf3fa44c57853bd74fb1d7ac60",
      "cf77c54f547f4c4fb586184869d8e973",
      "24c8e5d3684040e6a450274ce8c4c20d",
      "d269383c61a941b7944b466777892523",
      "f5dae873e4e0467eab824b57f791ef9d",
      "400e2d0203e847b78437dd64d55af191",
      "77fcfe6ef2754ff4a44bfcc13db525a5",
      "02c2a6370cdc4e4b96889b95121a98fa",
      "c7c036cceeda42498da88f0e8369ccbd",
      "793b0749b86b484ba36af60595ef65fb",
      "6a4f47cf767e44e5b2e35a1802f24f30"
     ]
    },
    "executionInfo": {
     "elapsed": 18204,
     "status": "ok",
     "timestamp": 1747473648077,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "HlL97JHca_a6",
    "outputId": "b5a5090c-bd31-4875-8692-9275c067c8b0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71915bf3fa44c57853bd74fb1d7ac60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL to access chatbot API: NgrokTunnel: \"https://97d3-34-60-24-47.ngrok-free.app\" -> \"http://localhost:5000\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "import os, threading\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial6\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "SAFETY_KEYWORDS = [\n",
    "    \"kill myself\", \"end my life\", \"suicide\", \"hurt myself\", \"self-harm\",\n",
    "    \"i want to die\", \"not worth living\", \"give up on life\"\n",
    "]\n",
    "\n",
    "SAFETY_RESPONSE = (\n",
    "    \"ğŸ’™ I'm really sorry you're feeling this way. You're not alone. \"\n",
    "    \"Please seek help from a professional. You can contact Lifeline Australia at 13 11 14, \"\n",
    "    \"available 24/7 for support.\"\n",
    ")\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/chat\", methods=[\"POST\"])\n",
    "def chat():\n",
    "    data = request.json\n",
    "    user_input = data.get(\"message\", \"\")\n",
    "    mode = data.get(\"mode\", \"long\")  # 'short' or 'long'\n",
    "\n",
    "    if any(keyword in user_input.lower() for keyword in SAFETY_KEYWORDS):\n",
    "        return jsonify({\"response\": SAFETY_RESPONSE})\n",
    "\n",
    "    style_instruction = {\n",
    "        \"short\": \"Keep it brief, supportive, and to the point (under 100 words).\",\n",
    "        \"long\": \"Give a detailed and compassionate response with examples and encouragement (around 200 words).\"\n",
    "    }.get(mode, \"Give a helpful and supportive response.\")\n",
    "\n",
    "    prompt = (\n",
    "        f\"<s>[INST] You are a kind and supportive mental health assistant.\\n\"\n",
    "        f\"{style_instruction}\\nUser: {user_input}\\n[/INST]\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(model.device)\n",
    "\n",
    "    max_tokens = 400 if mode == \"long\" else 120\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = decoded.split(\"[/INST]\")[-1].strip() if \"[/INST]\" in decoded else decoded.strip()\n",
    "\n",
    "    return jsonify({\"response\": response})\n",
    "\n",
    "\n",
    "ngrok.set_auth_token(os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "def run_flask():\n",
    "    app.run()\n",
    "\n",
    "threading.Thread(target=run_flask).start()\n",
    "public_url = ngrok.connect(5000)\n",
    "print(f\"Public URL to access chatbot API: {public_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwq9MXLUdttx"
   },
   "outputs": [],
   "source": [
    "!pkill -f uvicorn\n",
    "!pkill -f streamlit\n",
    "ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CI_gyax9bFcu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgtmgEkerxNX"
   },
   "source": [
    "# Final Web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q98Qz1jZqpmt"
   },
   "outputs": [],
   "source": [
    "code = '''\n",
    "\n",
    "import streamlit as st\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# --- Page Config ---\n",
    "st.set_page_config(page_title=\"ğŸ§  CounselChat\", page_icon=\"ğŸ’¬\", layout=\"centered\")\n",
    "\n",
    "# --- Model Path ---\n",
    "model_path = \"/content/drive/MyDrive/chatbot/counsel/checkpoints/trial6\"\n",
    "\n",
    "# --- Bits & Bytes Config ---\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# --- Load Model & Tokenizer ---\n",
    "@st.cache_resource(show_spinner=True)\n",
    "def load_model():\n",
    "    config = PeftConfig.from_pretrained(model_path)\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        config.base_model_name_or_path,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(base_model, model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "with st.spinner(\"ğŸ”„ Loading model...\"):\n",
    "    model, tokenizer = load_model()\n",
    "\n",
    "# --- Safety Filter ---\n",
    "SAFETY_KEYWORDS = [\n",
    "    \"kill myself\", \"end my life\", \"suicide\", \"hurt myself\", \"self-harm\",\n",
    "    \"i want to die\", \"not worth living\", \"give up on life\"\n",
    "]\n",
    "\n",
    "SAFETY_RESPONSE = (\n",
    "    \"ğŸ’™ I'm really sorry you're feeling this way. You're not alone. \"\n",
    "    \"Please seek help from a professional. You can contact Lifeline Australia at 13 11 14, \"\n",
    "    \"available 24/7 for support.\"\n",
    ")\n",
    "\n",
    "# --- Chat History Container (Scrollable & Styled) ---\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "        .chat-container {\n",
    "            max-height: 500px;\n",
    "            overflow-y: auto;\n",
    "            padding-right: 10px;\n",
    "            margin-bottom: 15px;\n",
    "        }\n",
    "        .user-bubble {\n",
    "            background-color: #DCF8C6;\n",
    "            color: #000000;\n",
    "            padding: 10px;\n",
    "            border-radius: 15px;\n",
    "            text-align: right;\n",
    "            width: fit-content;\n",
    "            margin-left: auto;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "        .bot-bubble {\n",
    "            background-color: #F0F0F0;\n",
    "            color: #000000;\n",
    "            padding: 10px;\n",
    "            border-radius: 15px;\n",
    "            text-align: left;\n",
    "            width: fit-content;\n",
    "            margin-right: auto;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# --- Header ---\n",
    "st.markdown(\"\"\"\n",
    "    <div style='text-align: center;'>\n",
    "        <h1>ğŸ§  CounselChat</h1>\n",
    "        <p>Your empathetic mental health assistant</p>\n",
    "    </div>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# --- Chat Form ---\n",
    "mode = st.radio(\"Select Response Style:\", options=[\"short\", \"long\"], horizontal=True)\n",
    "user_input = st.text_input(\"ğŸ’¬ Type your message:\")\n",
    "\n",
    "# --- Trigger Chat ---\n",
    "if st.button(\"Send\") and user_input:\n",
    "    with st.container():\n",
    "        st.markdown(\"<div class='chat-container'>\", unsafe_allow_html=True)\n",
    "\n",
    "        # Safety filter\n",
    "        if any(keyword in user_input.lower() for keyword in SAFETY_KEYWORDS):\n",
    "            st.markdown(f\"<div class='bot-bubble'>{SAFETY_RESPONSE}</div>\", unsafe_allow_html=True)\n",
    "        else:\n",
    "            with st.spinner(\"ğŸ¤– Thinking...\"):\n",
    "                style_instruction = {\n",
    "                    \"short\": \"Keep it brief, supportive, and to the point (under 100 words).\",\n",
    "                    \"long\": \"Give a detailed and compassionate response with examples and encouragement (around 200 words).\"\n",
    "                }.get(mode, \"Give a helpful and supportive response.\")\n",
    "\n",
    "                prompt = (\n",
    "                    f\"\"\"<s>[INST] You are a kind and supportive mental health assistant.\\n\"\"\"\n",
    "                    f\"\"\"{style_instruction}\\nUser: {user_input}\\n[/INST]\"\"\"\n",
    "                )\n",
    "\n",
    "                inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(model.device)\n",
    "                max_tokens = 400 if mode == \"long\" else 120\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=max_tokens,\n",
    "                        temperature=0.6,\n",
    "                        top_p=0.9,\n",
    "                        do_sample=True,\n",
    "                        pad_token_id=tokenizer.eos_token_id,\n",
    "                        eos_token_id=tokenizer.eos_token_id\n",
    "                    )\n",
    "\n",
    "                decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                response = decoded.split(\"[/INST]\")[-1].strip() if \"[/INST]\" in decoded else decoded.strip()\n",
    "\n",
    "                # Show conversation\n",
    "                st.markdown(f\"<div class='user-bubble'>{user_input}</div>\", unsafe_allow_html=True)\n",
    "                st.markdown(f\"<div class='bot-bubble'>ğŸ¤– {response}</div>\", unsafe_allow_html=True)\n",
    "\n",
    "        st.markdown(\"</div>\", unsafe_allow_html=True)\n",
    "\n",
    "'''\n",
    "#Save to app.py\n",
    "with open(\"app.py\", \"w\") as f:\n",
    "    f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 232775,
     "status": "ok",
     "timestamp": 1747475952842,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "VUO2XDp0o2dQ",
    "outputId": "38b130d8-639e-4bda-8889-beb8d5a90591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1G\u001b[0Kâ ™\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.60.24.47:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1G\u001b[0Kyour url is: https://funny-spies-cut.loca.lt\n",
      "2025-05-17 09:55:41.122720: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-17 09:55:41.142313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747475741.166927   20558 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747475741.174506   20558 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-17 09:55:41.198950: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100% 3/3 [00:17<00:00,  5.70s/it]\n",
      "2025-05-17 09:56:03.195 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSlKTLuio3ui"
   },
   "outputs": [],
   "source": [
    "!pkill -f streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1747477851466,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "mxPwmZlGy71Z",
    "outputId": "067bb154-1dd3-415f-e150-39ec548abe86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxvLAO3Ay-wL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxLJ-7qMAtjZ"
   },
   "source": [
    "# Evaluation Summary For Counsel Chat + Mistral 7b model trials\n",
    "\n",
    "\n",
    "###Evaluation Summary\n",
    "\n",
    "| Trial | Dataset Used                            | Synthetic Data | Prompt Style                                                | LoRA Config (r/Î±) | Epochs | BLEU   | ROUGE-1 | ROUGE-2 | ROUGE-L | BERTScore (F1) | Notes                          |\n",
    "|-------|------------------------------------------|----------------|--------------------------------------------------------------|-------------------|--------|--------|----------|----------|----------|----------------|---------------------------------|\n",
    "| 1     | CounselChat (890)                        | âŒ No          | \"You are a professional mental health assistant...\"         | r=8 / Î±=16        | 3      | 0.0203 | 0.2888   | 0.0429   | 0.1349   | 0.8311         | Baseline trial                 |\n",
    "| 2     | CounselChat (same)                       | âŒ No          | Same as Trial 1                                              | r=16 / Î±=32       | 4      | 0.0173 | 0.2315   | 0.0334   | 0.122    | 0.8076         | Slight drop in scores          |\n",
    "| 3     | CounselChat + 200 synthetic              | âœ… Yes         | Same as Trial 1                                              | r=16 / Î±=32       | 4      | 0.0228 | 0.2984   | 0.0461   | 0.1387   | 0.8331         | Better than Trial 1 & 2        |\n",
    "| 4     | Smart-filtered CounselChat (2,116)       | âŒ No          | Same as Trial 1                                              | r=16 / Î±=32       | 5      | 0.0222 | 0.2384   | 0.0387   | 0.1225   | 0.8144         | Fast mode, improved token len  |\n",
    "| 5     | Same as Trial 4                          | âŒ No          | \"How would you support someone who says...\" variation        | r=16 / Î±=32       | 5      | 0.0243 | 0.3071   | 0.0416   | 0.1307   | 0.8344         | Most human-like tone           |\n",
    "| 6     | Merged CounselChat + Empathetic (cleaned)| âœ… Yes (merged)| \"You are a helpful mental health assistant...\" (rotary-safe) | r=8 / Î±=16        | 4      | 0.028  | 0.2967   | 0.054    | 0.1442   | 0.8328         | âœ… Best overall on clean eval   |\n",
    "| 6â˜…    | Trial 6 on MentalChat16K (general test)  | âœ… Yes         | Same as above                                                | r=8 / Î±=16        | â€”      | 1.91   | 31.90    | 5.00     | 13.57    | 83.33%          | âœ… Best generalization ability  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4dNynhaA4_K"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avFjogHtkxXU"
   },
   "outputs": [],
   "source": [
    "from nbformat import read, write\n",
    "from nbformat import NO_CONVERT\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Colab Notebooks/counsel-mistral7b.ipynb\") as f:\n",
    "    nb = read(f, as_version=NO_CONVERT)\n",
    "\n",
    "# Remove invalid widget metadata\n",
    "if \"widgets\" in nb.metadata and \"state\" not in nb.metadata[\"widgets\"]:\n",
    "    del nb.metadata[\"widgets\"]\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Colab Notebooks/counsel-mistral7b-cleaned_notebook.ipynb\", \"w\") as f:\n",
    "    write(nb, f)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMM/Lbozx4GDcRdK2GbH+AI",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
