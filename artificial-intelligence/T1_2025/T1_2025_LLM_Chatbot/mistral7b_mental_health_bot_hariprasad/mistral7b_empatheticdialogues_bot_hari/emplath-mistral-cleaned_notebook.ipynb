{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 92535,
     "status": "ok",
     "timestamp": 1746278921825,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "XkKS7yVF3k2N",
    "outputId": "3dc3bc02-2029-47a8-eca3-f4b0d15683a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.4.26)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=6ebcf4691e965cd39cd894eb7b30fcf6e59c8adb5e82d1fe24b6da58df5c3fb7\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes\n",
    "!pip install -U transformers\n",
    "!pip install -U accelerate datasets peft bitsandbytes trl --quiet\n",
    "!pip install -U huggingface_hub\n",
    "!pip install -q evaluate transformers bert-score\n",
    "!pip install rouge_score\n",
    "!pip install -q streamlit pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3397,
     "status": "ok",
     "timestamp": 1745839983369,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "HsOsb-F_3fuf",
    "outputId": "443db3a5-bed0-4f92-d875-03d5138c0297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22kMGfwA4xAQ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359,
     "referenced_widgets": [
      "8c0989a7be2c462e9101f4b7267d25df",
      "0c55d2862a2048c6903a1fab53b57562",
      "d4e023f5447543bfa7210de4c1cb2438",
      "c50aa59dc0ee4f6a9a2824bcdc48a4a1",
      "6beb25ecaf71417fa41c7a33ac1f1dbb",
      "888fcc4d4eb346dc96cf21ffac8b9eb2",
      "829b8f1fb9754369a3fd767109499442",
      "a15bb20026d04afeac70f51fe5941e66",
      "7b024072e48c4950b83198c87919d35e",
      "e14ffbf64acf48599e1077c16d6186e8",
      "6131588caa3a4abeaa6e8e0bc1d6c54b",
      "a6a6f3df14db44a888789f8fbeadd75b",
      "b7c4194f10af4c2cb82798a2cfb97f6a",
      "75d036d18e934b61ae0a5a606e2ae20e",
      "3446ab2a3b584bfcb0537b6f3b68d6a3",
      "dcef656ae59f4f07b224f34d3654061c",
      "92d2918ead4e403e9caca41d3c306533"
     ]
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1746961413142,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "ZUHEMTy64zqI",
    "outputId": "aeecaa58-e6cc-4e1b-e386-58a7877eb781"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2027,
     "status": "ok",
     "timestamp": 1744208258115,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "spBNs8Tp45yK",
    "outputId": "23bc0d31-0365-4346-c104-363df43875c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned file saved with 79170 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the file\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/SIT782/datasets/train-conv.csv\")\n",
    "\n",
    "# Drop empty/junk columns\n",
    "df = df[[\"utterance\", \"context\", \"prompt\"]]\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna(subset=[\"utterance\", \"context\", \"prompt\"]).reset_index(drop=True)\n",
    "\n",
    "# Save cleaned version\n",
    "df.to_csv(\"/content/drive/MyDrive/SIT782/datasets/train-conv-cleaned.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Cleaned file saved with {len(df)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "431926e7f648479283f53098974ca865",
      "968feeab752e48b287749dadc77138bc",
      "859602dd308b4d87b4cac23b4527a977",
      "88edcc1b1e0e4a7d90149a2d65e78071",
      "d7f7225865b942d88ba9525318af1696",
      "07dd5cb9d8504bcf881312cece37606a",
      "bc7587ce80ba45eda0a168817f7070e6",
      "7e4cadeabc3b46e3a18b6d98c0c4b763",
      "3fc5a27742b2498f91d833a5810ed0e3",
      "d2bfad19c3854262a981350a26054079",
      "f1d95b8e2fed4f8296b79475e7464d19",
      "7e45cf7827154879994e7fc49d29bdba",
      "6ddf7d658ab944be9448dcf7a184c839",
      "49217dcd2457476ead1ab1de3c08d0b9",
      "227f5220734244328c488d288f260999",
      "f130455462d54f4ab9c71cfd0a0546b5",
      "eb4803885ef748a7bfb9f08361b272b6",
      "fedeb91fef6b4364b4d7a4b6f60b4467",
      "d02d395202ae4d5986debdaa4cc621ce",
      "39e2eec7dd8646eaa3c65595787d0a30",
      "bb2005749b3e49ef9445055b40dd074d",
      "f86b1e991833482ca97e0f76bcbb7219",
      "1e285f2cb22c4642ba53e7be2688d40e",
      "79a9ed4bdf53464a90ebb08d4361fe2d",
      "924f48ca91704fb4b737a3a16fb632b3",
      "56c8d7c1ca974afab1d42ad885bbeeb1",
      "09e80bc86ec84e7ebdf52705f07b566b",
      "36e84b6f4fca4cc480d166c0c0c06eb9",
      "0ac3045fbe94450082aa7d3720b5a0a7",
      "bc23c8aed74148ebb75f3beea25fd07d",
      "0852008d446e431998b81d8b890ccd4f",
      "cc23082d8d914de382fdf4b50ae1f840",
      "4b465ea4ea774baaafdf4f60ca9fc81e",
      "608f2843d5bd42ab8cfa20a34a7b4a3c",
      "a63d0ca07ca2491d920afa439a099305",
      "ef2bd4504e1e4b0396dd7749123564ca",
      "4de7865968964e7da25d21fd41b08fc0",
      "c21ef25fb6f54fd78858e9baa60eb9c6",
      "e21cd505264c4bd2bbaf603cc9346cc5",
      "3901d695da4d441498e5f564449f0730",
      "5a9e26ec0f754ef5b428cabd26a1a6a6",
      "b3f5164b7e25439494da3efa1dafb6e7",
      "e378bf357e4d4a54b25d0dac6d9f43b0",
      "2a79737613f5490a9d30719618ff806e",
      "06392c56f4ad46a486b607260605dd60",
      "8803755f26bf4c1d928530ac5c2d8ebf",
      "c278e6398a8f4d4584d2ce2c7239c839",
      "ba80ad5a5f964e749d2f20cbd1fc4bc3",
      "8ce4945757ef486abc8a057c2401df6d",
      "81656384d0524a7a8258029748e9ece9",
      "e2cdbdb3f6e24baab0b0de6b5c4c1d35",
      "cb03ec1188b543bc9f5e2c78fac13c5b",
      "bc06e8e5184049e1b68e9a0289fab40d",
      "1e5d8a726a884a95988a15f692de3027",
      "1b6981a9ab124e28857396fe06b94e58",
      "f9b4ac8deaa74a64b42b3ad925dba53a",
      "a265ecdbf4644444a74ff0cafdbdaf41",
      "60e5ace8d654493fb703e4e1e30d05aa",
      "834f2f517f644f5b847e71ca4c8a1ffe",
      "e51580bc28f6424ab06404408349dd56",
      "9be0977fb41a4143b431f568e67e9601",
      "aca31705589243c691215e7f51d476a3",
      "b67446204cfc40baa64c363a2f86aa65",
      "562181c7a8764a318dd6ff47194cdbfc",
      "77b168094d6a4134a87cd8fd81f106e6",
      "87b284142c8f4a32a6729ec856d1011b",
      "4b753a49d2124983bc9827d389827475",
      "d746b9b67d0a4b58a6fa02134f0b34fa",
      "740b472042d84395bcdddfc6a698aeed",
      "4d704eb8f63f4174bfffda1ebee8625d",
      "fc3d267dee8c4ba5bbdf276075954920",
      "64a6782db8354895ae7a0d1d361401ca",
      "dc517940c37c4bd8869eae6633a743d6",
      "36c2cfa3c4b447edaec4174835b50884",
      "c4101626b41642159f0ecfb3f0eef82d",
      "50d2912257c64bb986c0653b2a5e5be4",
      "734cd0eef62e4565a81a424dc74d6c9d",
      "29fb880c3d8b4e6bbcbaf97cb8898582",
      "488514a66f844c0aac5940dbc7fa0c3c",
      "cbe6ec26e2e849308c97c81558f91ebd",
      "e5a44e8c755e4b3790ed05751ac0deea",
      "8518767ac8664d49a5d1721fffef2d77",
      "c05cbdb89fa94a7db49f67d8c72c1c60",
      "31bd0bd52a7048ee8aa15aa58ff6b41e",
      "047530144fc143cb90fedb48e667a961",
      "e7b34b3e58c047a3aa5baedc11853831",
      "bdceceaefc9f47ebbbbc31efe924ecb5",
      "7f723564d738412d88a9d0889a400dbc",
      "62aead5d7caf4fa9b98d5022d1128872",
      "66c6292396d249b69a948316dda639b5",
      "223d6121380143afa31a5f5c08ff10eb",
      "e87262dd3824434ca2dea9a793216cf8",
      "d2a1a403e7cb4792901ff9f01fa155b2",
      "02061d91217b430e8f94671d9f8aa9e6",
      "b0cf74372cbe4eb2a925615005561c8f",
      "361a3b71125341e2a9b5b14110898a54",
      "52da9b46602740ac9dbfdb0802d810f4",
      "a32fd72e9ddb4ea0aad557c955fb6e9c",
      "d877360fd1a54653a1cd55b881bde31a",
      "695ba4f44fad485a9897a34ab66af270",
      "5a9ef3117f844ff28647eb9a8338d98a",
      "b54010085381489f896b010ca361abcf",
      "f75a82fd0a224624a9ddd794126a4a9d",
      "5f568565dc8144579c3f676fb0cf27aa",
      "469ef35a17d24db2ade20a92e5975b47",
      "a2dd9e58c4054518bbf05f193a2057ce",
      "fa71caecb0b841149d364ff82263acfa",
      "9c329835ec2e44e89668cc3a1f25f05d",
      "cf1b39559da04294ba1f7b684e50510b",
      "e90792c8128640b59daf7729306e58b5",
      "5048f386c3b442ae956ca836c3b9b5d0",
      "2eed497fc99441e68aba320fd5446d09",
      "333caf92c132475dbcb50b2bdfb149e8",
      "c1cbdf9ccabe4c9da6425ee3af2c3d51",
      "47593532f0e340d29e19094a78eb8a6e",
      "779f1f476cf94ef7bf849893f0dc930c",
      "13b89b3c6720487ba7326ee1d3fc8be6",
      "f0c51ea49a4d460a84baacf93f198ee3",
      "0b58d2df61c546adaacbe386a574bea6",
      "197999f2d8874982a334ee1509943cbe",
      "65c8cb2b22774f41a87581ad23a57bed",
      "7060f831705b4cf980c708f85254312b",
      "26b72d69ab4e4009a372d76aadd02112",
      "5b2b5d55079c4334ab7f1261d5bc3f71",
      "d246b4533a0241068cea08eba55df34b",
      "dca4ed788f234fef973ed09e7aa90368",
      "8350608868914563bc5db03cd5346606",
      "8e72650f7084437796f69f5d763f5f86",
      "1a191c8d820e4b4687e316f698531fc0",
      "bba4988a0c374eb4930185459e73a6a4",
      "aae20d43df534ebc8385e4138b6fd381",
      "0bd0e2dcb12842b1a539e121f890a53b"
     ]
    },
    "id": "bT0qIexr2oqm",
    "outputId": "2ac64054-c168-48d7-add8-3f4c353b5207"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431926e7f648479283f53098974ca865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e45cf7827154879994e7fc49d29bdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e285f2cb22c4642ba53e7be2688d40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608f2843d5bd42ab8cfa20a34a7b4a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06392c56f4ad46a486b607260605dd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b4ac8deaa74a64b42b3ad925dba53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b753a49d2124983bc9827d389827475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fb880c3d8b4e6bbcbaf97cb8898582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62aead5d7caf4fa9b98d5022d1128872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695ba4f44fad485a9897a34ab66af270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5048f386c3b442ae956ca836c3b9b5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7060f831705b4cf980c708f85254312b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌿 Welcome to the Mistral 7B Empathetic Chatbot\n",
      "Type your message or 'sample' to use a dataset example.\n",
      "Type 'exit' to quit.\n",
      "\n",
      "You: hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Mistral: [INST] You are a supportive mental health assistant.\n",
      "hi [/INST] Hello! I'm here to help and support you in any way I can. If you're feeling down or need someone to talk to, please don't hesitate to share what's on your mind. Remember, it's okay to not be okay sometimes, and I'm here to listen and offer guidance if you need it. Take care of yourself and know that you're not alone. How can I help you today?\n",
      "\n",
      "You: im feeling down today\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Mistral: [INST] You are a supportive mental health assistant.\n",
      "im feeling down today [/INST] I'm really sorry that you're feeling down today. I'm here to listen and offer support in any way I can. It's important to remember that it's okay to have bad days and it's okay to ask for help when you need it.\n",
      "\n",
      "If you'd like to talk about what's been on your mind, I'm here to listen without judgment. Sometimes just getting things out can help make things feel a little better. Or, if you prefer, we can focus on some things that might help improve your mood, like engaging in an activity you enjoy, reaching out to a friend, or practicing relaxation techniques.\n",
      "\n",
      "Remember, it's okay to take things one day at a time and to be kind to yourself. You're not alone and there are people who care about you and want to help. If you need someone to talk to, I'm here for you.\n",
      "\n",
      "You: Im being bullied in the college and I have no one to talk about that.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Mistral: [INST] You are a supportive mental health assistant.\n",
      "Im being bullied in the college and I have no one to talk about that. [/INST] I'm really sorry to hear that you're going through a difficult time and feeling bullied in college. I'm here to listen and offer support in any way that I can. Bullying can be a very isolating and painful experience, and it's important to remember that you're not alone.\n",
      "\n",
      "First and foremost, it's important to take care of yourself. This might include things like getting enough sleep, eating well, and engaging in activities that bring you joy and help you feel good about yourself. It can also be helpful to reach out to trusted adults, such as a teacher, counselor, or other school administrator, to let them know what's happening. They may be able to offer guidance or resources to help you deal with the situation.\n",
      "\n",
      "If you don't feel comfortable talking to an adult, there are other options as well. You might consider joining a club or organization where you can meet new people and make friends\n",
      "\n",
      "You: Im having suicidal thoughts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Mistral: [INST] You are a supportive mental health assistant.\n",
      "Im having suicidal thoughts. [/INST] I'm really sorry that you're feeling this way, but I'm unable to provide the help that you need. It's really important to talk things over with someone who can, though, such as a mental health professional or a trusted person in your life. If you're in immediate danger, please reach out to the National Suicide Prevention Lifeline in the US at 1-800-273-TALK (8255), or contact a crisis center or emergency services in your country. They're there to help you 24 hours a day.\n",
      "\n",
      "I know it can be hard to reach out, but talking about how you're feeling can help. It's also important to remember that there are people who care about you and want to help. You're not alone, and there are resources available to support you.\n",
      "\n",
      "In the meantime, try to focus on self-care activities that\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load your cleaned dataset (user + bot turns)\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/SIT782/datasets/train-conv-cleaned.csv\")\n",
    "\n",
    "# Load the Hugging Face Mistral model\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Response generator function\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Start interactive chatbot session\n",
    "print(\"\\n🌿 Welcome to the Mistral 7B Empathetic Chatbot\")\n",
    "print(\"Type your message or 'sample' to use a dataset example.\")\n",
    "print(\"Type 'exit' to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"👋 Goodbye!\")\n",
    "        break\n",
    "\n",
    "    if user_input.lower() == \"sample\":\n",
    "        sample = df.sample(1).iloc[0]\n",
    "        situation = sample[\"prompt\"]\n",
    "        emotion = sample[\"context\"]\n",
    "        user_msg = sample[\"utterance\"]\n",
    "\n",
    "        print(f\"\\n📌 Prompt: {situation}\")\n",
    "        print(f\"🧠 Emotion: {emotion}\")\n",
    "        print(f\"🗣️ User Message: {user_msg}\")\n",
    "\n",
    "        formatted_prompt = f\"<s>[INST] You are a supportive mental health assistant.\\nEmotion: {emotion}\\nSituation: {situation}\\nMessage: {user_msg} [/INST]\"\n",
    "    else:\n",
    "        formatted_prompt = f\"<s>[INST] You are a supportive mental health assistant.\\n{user_input} [/INST]\"\n",
    "\n",
    "    reply = generate_response(formatted_prompt)\n",
    "    print(f\"\\n🤖 Mistral: {reply}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hEe1D5U7QSk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1744210040439,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "ZKnBgIIw9ANI",
    "outputId": "b88aa86e-76aa-4b8a-b68b-7e50e1c27ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: empdiag_1000.jsonl\n",
      "✅ JSONL file copied to Google Drive!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Load your cleaned file\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/SIT782/datasets/train-conv-cleaned.csv\")\n",
    "\n",
    "# Drop NaNs and shuffle for randomness\n",
    "df = df.dropna().sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Limit to 1000 samples for fast training\n",
    "df_subset = df.iloc[:1000]\n",
    "\n",
    "# Convert to instruction-output format\n",
    "records = []\n",
    "for i in range(0, len(df_subset) - 1, 2):  # pair every 2 utterances\n",
    "    instruction = df_subset.iloc[i][\"utterance\"]\n",
    "    output = df_subset.iloc[i + 1][\"utterance\"]\n",
    "    records.append({\n",
    "        \"instruction\": instruction.strip(),\n",
    "        \"output\": output.strip()\n",
    "    })\n",
    "\n",
    "# Save to JSONL format\n",
    "with open(\"empdiag_1000.jsonl\", \"w\") as f:\n",
    "    for r in records:\n",
    "        json.dump(r, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Copy file to your Drive\n",
    "shutil.copy(\"empdiag_1000.jsonl\", \"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\")\n",
    "\n",
    "print(\"✅ Saved: empdiag_1000.jsonl\")\n",
    "print(\"✅ JSONL file copied to Google Drive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuZ5dhvS_oZg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPzkKEZtC2fJ"
   },
   "source": [
    "# **TUNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkMVv5ENC76R"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset from JSONL\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\", split=\"train\")\n",
    "\n",
    "# Load base Mistral model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] {example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"mistral-lora-chatbot\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Save\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-chatbot\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-chatbot\")\n",
    "\n",
    "print(\"✅ Fine-tuning complete. Model saved to Google Drive.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESStIZ4qGlby"
   },
   "source": [
    "# **🔧 Trial 1 – Baseline LoRA Fine-Tuning Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605,
     "referenced_widgets": [
      "1277b1fde20847c79a5322d94f25adc5",
      "9a02243db8a341d69e6358e96f572dee",
      "eccaf68b210f475e88395c0e1b8b7268",
      "2cc900b2c2ef4135ad3633e37629edae",
      "1508179857ae4c1585762cfd0089f9c8",
      "9dcccc406a9b43fdabcb65d8f7c204d0",
      "ea979b5a9f4a4f8982ff25d0ceec762f",
      "09431982e60f43ffa62e9528619541d5",
      "9dc459d05c554d6bab9e643e3dd9b989",
      "0f4466862db347bfae47cf1851fa8f92",
      "eb03f8b3721348bd9befe1f6930bd9a2",
      "55844654ab354b04ad87d2853ca78e53",
      "bab7db51901f460c9119155bd7cf15e6",
      "a7f4f371584442c2ba9e2db06ec46501",
      "38c60aa1266f4fb591714b414eaf882c",
      "683e14e02a7e4345a5138f753d425846",
      "c0555f0113174d019cf36596b4b4adb3",
      "9b9c06e0b08b444da0e97ce48d968c94",
      "25aaf51da97c42b8badc1af03f1559b1",
      "727591485a41499aa37dfd2503af1203",
      "20249579c040434ab6e0e93649429345",
      "d62d638abe3a4824b9acb46daf66d9ad"
     ]
    },
    "executionInfo": {
     "elapsed": 116876,
     "status": "ok",
     "timestamp": 1744211715490,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "Wl02blf_GqMK",
    "outputId": "58b965a6-a2a8-494c-bc7a-05aa2a851845"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1277b1fde20847c79a5322d94f25adc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55844654ab354b04ad87d2853ca78e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-30a7dc22872d>:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 01:44, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13.689900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.423200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.765600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.567500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.345300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.156700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.994500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.995400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 1 (Baseline) complete! Model saved to Drive.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset from JSONL\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/empdiag_1000.jsonl\", split=\"train\")\n",
    "\n",
    "# Load base Mistral model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # ← Add this line ✅\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] {example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA Configuration – Trial 1\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Training Arguments – Trial 1\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-baseline\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Save final checkpoint\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-baseline\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-baseline\")\n",
    "\n",
    "print(\"✅ Trial 1 (Baseline) complete! Model saved to Drive.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 58,
     "status": "error",
     "timestamp": 1744212181498,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "w7ke3ioVGtDn",
    "outputId": "3f912649-99f6-4b7b-eb25-2133e9485097"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1d69339dd352>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qLRL8-vJgFA"
   },
   "source": [
    "# **Trial 2: Lower Learning Rate + More Epochs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78yptOqFJmYK"
   },
   "source": [
    "Config\tValue\n",
    " - 🔢 Learning Rate\t1e-5 ✅ (slower, more stable)\n",
    " - 🔁 Epochs\t3 (more training passes)\n",
    " - 🔧 LoRA Rank\t8 (same as Trial 1)\n",
    " - 💾 Save Path\t/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr1e5_ep3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "56455a28cb214614944d2b3bbbb37371",
      "479cd4e2a46f4986bde0b643a0a01b43",
      "ba7aa3f76e28412d82286bc58a25d5ca",
      "8d1ddcb0adc5483faf6026b6f5ea8062",
      "af28d0c05bcc47ff944ee3299ae667f2",
      "3bba12bc41494b359f91f12db1c8b60c",
      "817c45b6a51a4bed9f1b6a2979a01b60",
      "c86997e0085a4c1b9206d50e5fcd3bb5",
      "dd742177df4347bb84a10de611e0f6a4",
      "0079b7e2ae494270a5703a50ba10711c",
      "448bbcd2f1b946d79b140f996509f721",
      "445cfbacdb6640bab00c8bfd6998a42e",
      "74f5d02dc8bb462983f87527ca3e7f5f",
      "fb7c44a263734552b9e16b3bf3187711",
      "8719bc0eec8e4afc8678f2185125703d",
      "cddb6a56c44b4d68af25967d85ea9b0c",
      "b2dea532bbcc436f96fac7a361839f2e",
      "6607b24d738448c68a94347010b489c8",
      "f3e0c15c808a4294a0ebdf1447affdc9",
      "0b366558775d4571ac71216e1608d33d",
      "da8a54e278324ab5912275913e671366",
      "5cb9dbceab8846ad912fa256a260b28d",
      "dccd569542e04fe7b85e605bd0065670",
      "9d6c4fd6960a423b83d24411c2e665c2",
      "53ab8d42896043e0ba20298d4ce1b916",
      "cf6ca1e0e23b4b17a42aabac9cf79b12",
      "f7055cbb5a3740249f024fc676c24e08",
      "fc2ca3e8c5e949b2bc799cf5dd28308a",
      "0103e702ac584c9682a92a708d69dcd4",
      "e090d9360283411b9a3257fae1f438f0",
      "694a27786f46495887b4f95753af5068",
      "ac769ec4d760443bb5b99fea30114582",
      "d2678e8cba0a45539e09da3a7b240b6a",
      "7e0eccee4e6a4cbca4323592220b1c32",
      "52dcfbfee4404d428b35aa1385c88c9f",
      "b0730bfcffe9412bad5d5cee587664be",
      "5f5e9a23d8644c728c47c88811b34bf1",
      "ea3132a2587c416b983fe890cb6510a8",
      "9e54f3bda855419eb24dda01e3d4fecf",
      "c0a488d5997f43f1a666acbb90b783a8",
      "27959b09afe947d581ec3cd31ffef98e",
      "e8aee09eff5b46baaa90feb019680c60",
      "1fd1fbc548a34e66afd503e5f3fe1363",
      "ce125c7029e34fb09dbccc95794aea4f",
      "b4105d238cad4258bc422ce02e60d037",
      "4d75f7db54f2463eb5020c2bff82184c",
      "e4f4048b3b9d4f668bfc376a8e6b0b9c",
      "56ac8c3fb5b24ed4ae73cd727674b338",
      "0895a4b773274e2b87292001b48ee16d",
      "612b3505666341659662a1a105d52bd2",
      "5543d6dbb92c480786001ea59919d49d",
      "6eccf1657a4e4444b91a787a75acb0a9",
      "0b6a03086b224cf492cda7b01be8854a",
      "7a3a11539bcb40bf98972148fbb05cc9",
      "6b3d7b2ef7ba4ce5afb656ba3ce023b1",
      "bc67f0c266ab4c08a24bbb58399a1e45",
      "d043485f966d4b8b910b4fe72d71fcb3",
      "3ea119f5c67f4df6bb6c69f9eb534b47",
      "35cd865eafc54806ac19e0cc796cd1e0",
      "21187aa541dc4868852ac9750706efb5",
      "8fffbf7315894c889f943e18aad4b0af",
      "c2efe687245b40d3847feb2c10755d22",
      "cb918502e5a94aa68acf1f6c0a39a82c",
      "16cda6fd2f814be4934993bc19e66aac",
      "424b5bcb68974a51a6c55e7dc9c56f97",
      "be9e6925135d4c8fb723b64ef509e0d5",
      "b5eb67427df14099ad43789a72d79e81",
      "e575ea0e7fb242ba9be6f7b102056333",
      "17709c1457954c3190dc2c4636474773",
      "5d36e66a78854f3286c3f333279d8cd5",
      "a5634cf2daff4947adf15fa592d46598",
      "c43f252d874f4b5faaab5fc2c60708c9",
      "9fac205b41e242588fa097fce4c91407",
      "496fe414c5634bbeb6a89820cd661b17",
      "32e26350f0bd46108fdb251813b313d1",
      "e7b809d0f2e042edaa79d1fe019af564",
      "6d9cbb5729104c0886d0cd6d0144d22e",
      "19c297dc8f464aa8a7f664cc2a97feff",
      "d6dc6dbcdfe54602b06c5f076ebb9ffb",
      "69cdbd9c95334da199ed9594fef607d7",
      "f8588d801b554e2285864627e059e4bb",
      "f7eeb76894e84a8faa9c53b93154d93b",
      "e3cce2c51c7646c5a2dd1210f7bc61ab",
      "1505ef53029640e9995a74be0546b45f",
      "116eecfdbf6546acaa32dcc8565b10fe",
      "ac7c145b0b374fecbce372e12efb6d19",
      "1f197531ac5548328650b5d25a5a6b37",
      "fc38e6e538b3422dbfb728b47ba1a4d9",
      "c0d5beb2383c4fd48875d6111127c244",
      "592214c24812471b897442b96fc46f9b",
      "05db099bf5834b4bb7150ca62c3af8b8",
      "05c5e6897eb447eeb5b81502f3d5748f",
      "fd35a51a2c8544e79e88f2c64d1cbcfd",
      "4c4b6762a62b45cf8547599105070689",
      "b8869e89fd0543ff85f59fcf27596036",
      "9887728f3c16420494abbff10f5b7aa4",
      "957c66f2e3a243f2be125714ae877249",
      "3c67ea254c2741d8a13fa1c480695860",
      "b6491d718e954c1b8fabe44eff1b03cd",
      "b9a6bda0efe2470d97a8cb0b7391cfe4",
      "01f9414af6e346668055becae16a7e28",
      "e1b75a3e75864ae7a86a520f16b891d2",
      "143c5831576c4847b0b81a5513557fd0",
      "d4b181df659147c2aa15e428bb26dc69",
      "7540b5556eab486da3a9806cde84eba6",
      "94a24563771b47a9a08d6441f776373d",
      "ffcacb17ebe74ec6b5b6694f0bec5b3c",
      "fc129fe76eea4096b6f5ccc9a70fbe14",
      "82c548bffc7b4c818a4fbe0ee075ba56",
      "3933cf79e6514268adcb6344232df694",
      "b32e657c5bb84cbd8f11de350140d3eb",
      "539da1d9793249d7b90a95bd44bc324b",
      "b3bd8f7a8507440faf43f52f8634b64b",
      "69a6d51598fd42d8811e5cc33357b9eb",
      "b1a656ee3afb411b9cc23f1d078a68fc",
      "867fb418c2b14278b0cf738425d298fa",
      "4425fedf3077418ca5c007c40d2c3944",
      "b4aff1cd71494ac08dbf4f37794574c0",
      "cd51b9285b27477fb14f7e7f12276715",
      "f5aa1e3c80204fbf9f4e32a67d70138a",
      "d8923eec29914e0887cff02a7ef1a31d",
      "cdceea93a28745b9919b56c9319ed3d0",
      "443821fb6abe4d3398f2256e22a5090a",
      "1df1aa582e3e4aea9df0fddcb3fc996c",
      "b0f377cd44d54e88bb51ec11b01f8d80",
      "472c2c27d31644c991fa27d6a17b4ba6",
      "584d75d8b6d6460399078d8b9291c705",
      "7f09a38a21a34968ac28db7f045c3925",
      "8cf7ce41459c4406b2cfc99829edec62",
      "5c7d825ce82946b29ca90879d0c507b4",
      "2d321c20f6bd4c99bd15d8349b2a5491",
      "5124091a6f114d9bb498410c87faa06b",
      "0e3e01ca412e4da3ba15446c989f5777",
      "f22a18e9990740dd98b8f8c0915a434b",
      "560ad651cf7f479384eed5b76d0b658a",
      "3683993c94d64204bc8b59c7a3141f08",
      "9894f67794d4400b8a931a7873179503",
      "6392fd2aff03494b942bf75bdd3a0d90",
      "1cbc64c3a06944fa8176ee92ae4ed0f0",
      "324227aeba124cf09c570ae43abdafce",
      "dca1a94ac00b4803b367d769f3ef98a8",
      "d646efb0dffd47cba67efe944f6077ff",
      "875b31ee11b646129a3624945078e6eb",
      "3f6c47222ebc415b88d0a438c70f52fe",
      "c5965da0e0134c8fa1617b025c010720",
      "17cbd0b663444d9aac750c7e55389234",
      "1034866d709a4e668ea19101360b4794",
      "c8a22a6de1a84e6eb41b35ba348e7beb",
      "be08f97a017b4a39bbd6f5e2c3a17fad",
      "03fab2b809184f8db02ae772b4a50be7",
      "6d2a0b0b7da649b9933864a4d3900492",
      "121ed487bd294387915b0cd1078f9e5d",
      "e223439fbf734d089bb7c6e36a2a8c72",
      "3c475d21e13049088881b0182bdb84e4"
     ]
    },
    "executionInfo": {
     "elapsed": 340827,
     "status": "ok",
     "timestamp": 1744213055861,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "OYj-Gb4HI-KG",
    "outputId": "0b9098cb-368d-4d3f-e5b6-5dacbcaf5703"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56455a28cb214614944d2b3bbbb37371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445cfbacdb6640bab00c8bfd6998a42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccd569542e04fe7b85e605bd0065670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0eccee4e6a4cbca4323592220b1c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4105d238cad4258bc422ce02e60d037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc67f0c266ab4c08a24bbb58399a1e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eb67427df14099ad43789a72d79e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c297dc8f464aa8a7f664cc2a97feff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d5beb2383c4fd48875d6111127c244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a6bda0efe2470d97a8cb0b7391cfe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32e657c5bb84cbd8f11de350140d3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdceea93a28745b9919b56c9319ed3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3e01ca412e4da3ba15446c989f5777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6c47222ebc415b88d0a438c70f52fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a9d1da2dac60>:66: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.0470\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 04:29, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>14.781200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>10.924100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.174200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.165700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.976800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.982500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.933200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.723400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.572300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.472700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.431400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.466500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.245200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.324700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 2 complete! Model saved to Drive.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "#Load dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\", split=\"train\")\n",
    "\n",
    "#Load model/tokenizer with 8-bit quantization & GPU pinning\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_enable_fp32_cpu_offload=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Fix padding error\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "#Tokenization\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] {example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "#LoRA config (Trial 2)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "#TrainingArguments (Trial 2)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr1e5_ep3\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train!\n",
    "trainer.train()\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr1e5_ep3\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr1e5_ep3\")\n",
    "\n",
    "print(\"✅ Trial 2 complete! Model saved to Drive.\")\n",
    "\n",
    "#Optional cleanup\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "error",
     "timestamp": 1744213076363,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "SMOP_CzBJzM7",
    "outputId": "01712d8d-447e-418e-9111-6ef28cab107e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1f94360eae0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 🧹 Optional cleanup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 🧹 Optional cleanup\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59YMleguM2ge"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TJrliMCNMq-"
   },
   "source": [
    "# 🔁 Trial 3: Fast Learning with Higher LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONrkqxoLNQfa"
   },
   "source": [
    "Parameter\tValue\n",
    " - learning_rate\t5e-5 ⚡ (aggressive)\n",
    " - epochs\t2 (to balance fast learning)\n",
    " - LoRA rank\t8 (same as previous)\n",
    " - Save path\t/checkpoints/mistral-lora-lr5e5_ep2/ ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573,
     "referenced_widgets": [
      "cb7800050b0b4aa9ba15011eb7e33f7f",
      "8dcc8dd6c8ac403eadd1373aed7f9572",
      "54605c004ccd49618c49e83332e035c4",
      "cb4aa7a030d04bde9061d085a033e4b6",
      "a37955f28f5c49a685cbf0156cfedd92",
      "03fb2e0bd99e4d22a01c75d9f0617d38",
      "113a46f7cc6540c89344708b38c5a12f",
      "68419ced16cb4395b69a7d3b588f5f72",
      "229c046663a84b1898699e0a0cd1b3d8",
      "b23ebf276e4f46c881115d86d4c8430d",
      "ff8e49fcc4cd435f806667c9360789f9"
     ]
    },
    "executionInfo": {
     "elapsed": 203091,
     "status": "ok",
     "timestamp": 1744213429389,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "mbGOwN-mNWin",
    "outputId": "eb294edf-8998-4636-eb9c-2c824d973112"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7800050b0b4aa9ba15011eb7e33f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-5e8a2ff77ba6>:65: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 02:57, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>12.916100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.771600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.475300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.333200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.198600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 3 complete! Model saved to Drive.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\", split=\"train\")\n",
    "\n",
    "# Load model/tokenizer with quant config\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_enable_fp32_cpu_offload=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] {example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA config (same as before)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# TrainingArguments – Trial 3\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr5e5_ep2\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr5e5_ep2\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr5e5_ep2\")\n",
    "\n",
    "print(\"✅ Trial 3 complete! Model saved to Drive.\")\n",
    "\n",
    "# Optional cleanup\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DIH5DdQNbIi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDnR7AiYPpet"
   },
   "source": [
    "# 🔁 Trial 4 – Lower LoRA Rank (r = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M398Goa-QKQH"
   },
   "source": [
    "Hyperparameter\tValue\n",
    " - Learning Rate\t2e-5 (balanced)\n",
    " - Epochs\t2\n",
    " - LoRA Rank\t4\n",
    " - Save Path\t/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-rank4_ep2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c313bab20c9f4403a54ca4432643acb3",
      "d2f00ec68c564a638d249722835feeef",
      "5f62816249b64d26a787af439d20d684",
      "28547a9a72ac46fd8172dd1bd23786e5",
      "a02279ad2cf3405eb7fab1adae8f2e53",
      "d37d569c05fc489b8fb995957066d260",
      "15acc60dd9e740ffaec5cc5a66ecc8cd",
      "625744c4d6a54356990f3dc5b718598f",
      "e7792c075d544639a36de91d3c7fd436",
      "01b6ac5ecdcc4038b868979bffdb7c89",
      "967e97dfdf21402ebe5d6d1311dbf9cf",
      "e518ba3ef3cd48e9acf923ac54da3413",
      "91318ee16e0a44938e5badfb8c22ebbd",
      "4c70605f8fa94ab7b654cd1ad164a28f",
      "c6dbe664fd77437b88bf29ce0d4774c6",
      "7c20ffde8c174ecca9b68f0f33000bd6",
      "522ad3e3ecd7492ab1c5f5ce68a1d35a",
      "e13f1d97719c4a46b97495990546b57d",
      "a83e1fa083ca4abb99cf89afe90ccd6f",
      "ceed4a159cec4c1184b64aa14a06ed1e",
      "29e49ceac4ca478c9e50e01a0f6101d2",
      "a64a3744fa314fbcbb4b6a903622e776",
      "7ece8b415c094ea0ad757fc1ad10147c",
      "f80fc499848b48a1a2996011a2010e36",
      "2a49199ee2684913b4ccb57d422dd689",
      "36f04be27a22447bbe48f28d7d1bea93",
      "a9e0f37034484a66ad6755654fd17fd5",
      "11fdcbf093cf4ac28e3b1e03b218988b",
      "c0679f6af48f4156bb9586513b7f0efc",
      "1ec53051e6f24186b43b8a780859d2b3",
      "80c56685828345c59a9630c8f0819489",
      "e871a4df7c9241a88ed9ce3a52dd235f",
      "6a8d9ccc292746dba9bf472b6f3d1d7b",
      "964936649fb04d29bdfac49f45268971",
      "bd006f98e90a4e268e04b38b43239300",
      "08430e194d094d47b8165bf0a12ac8fd",
      "9da6e8deac6a487e8154f7d792f98710",
      "18f09d063b51403f8d10a88935e238d3",
      "8971dd38325c4ddaa1ca5466465947fd",
      "4501f260766e4272bf4d33dc2f35227f",
      "1e44c85f32284e5bbc27d2171ca72667",
      "38e5c65279aa4495ad6d46dd0d001b74",
      "f9a9828579274231bf9d49413e3b911e",
      "adcc4b36843e432eb95f5495efc96de0",
      "7261d46398de4ef788cdea051a0ccb6a",
      "985830f04349464aa077a50645161ec5",
      "9eeb74d2a1064cb9bc1eb8e4a72fc137",
      "0a70a0a7ee2745efbd0632e8e570f533",
      "508d916c5c104ff7863bc8ba7dee2c3d",
      "a35906cc19b542dba5b4cd53be120a36",
      "342327ee66854e66b387c34676aaf950",
      "1d4b41bf85424bdba41765e81d5feca2",
      "249219d3d07c485d9ea8607c236fb9de",
      "5c7a289e5a024069b71f068210f180af",
      "6b5a87bf191b4e6496d32a7791320164",
      "daadb1ae94f74ef2a6e396f3c32f7213",
      "7957e796e57643cc8219b0f641366ef4",
      "22c1880afc7f42f0a396a36828eb2b56",
      "eb48aa19a9324a5095a9eeb03601d6db",
      "8fa43d5bdc6f49ff88b991cf225f9313",
      "37a281c704f34c9d923a8fc0419b1fcb",
      "079ec8d7e4b442f6bbcebcdc08db9162",
      "2aef399996ba48bc880525a1da1996d8",
      "e8a87ca1343b4b8492de9c6fc5459147",
      "18bea305c6964e41a3891b02c30bd99d",
      "3106296a6e35475a846be39d967f50ff",
      "f6f34f7a3d854c0d82db454ad7f856bc",
      "65bedc2aab1849ca8ac2bdc7d62f5e5c",
      "5720c6b815194913997e9d22f34150aa",
      "4f7e8296e3a74da883f64bf55790a321",
      "1cff20526b72469493ca57c11fb6a39d",
      "231a13c0073043178a5463dec6cf3d4e",
      "f598b3e7a175495bb7386b866eafd35f",
      "76ea2fc6b71a4e53b8b558e447522659",
      "b617430f85014e9fbb59251457a1e2c9",
      "b04edead66ae4945a5f3ac21b2088c2f",
      "e3645667e5aa46b9abaf73e1d6509c03",
      "2f6ca636da8a4601870de17f94645b84",
      "2fbec58f0d504c46932c5106dc5a24b0",
      "def3f3074e0d48fba754591c249087f4",
      "bbb170a3d3dc4878832fd188b3a289d0",
      "303683c97812449eb8e536d5fea0bdaa",
      "b7bf73a05fc54379b0123a924456abc1",
      "a082aa7f86124e6692fb6d3e2db67c36",
      "bdfd3ce2d7084ae99e79a6ce9ede1909",
      "9c1a885c4c3841e6ba772b4312872b07",
      "01324f66ecf342fbbeb9e2be1a73742d",
      "3d0dafc169154fde9c2053ae2f5ee2e7",
      "b8c104a51e3b49f7a1a50bc5c487e507",
      "a5b7bb8b659e40aaad320b36cc84e432",
      "88a6214db06443daa61d1f2a354debfc",
      "939e60a4d6ca4044bce4f74679c08ebe",
      "9df76ac4be7f4178940f186df30610c7",
      "cb01dc3c793a41ff97ccde2619a7a642",
      "597d4e520c4641e7ad1d2eeb87403a7b",
      "18c6bab519964647ab1e06276323bc96",
      "66cb0ce436bf4279a228624066582ed1",
      "0898adbaf0cb4058a1eab27ca3cf12ab",
      "0ef82be051b34e5f877167184db76a40",
      "8aed6d91a8914f07a08cb7b11939b192",
      "98dbd1f280cc4e02ad7c831bf099e2b3",
      "70dd279c5fef4a859866f1aa025eebbe",
      "b2b42b9a13d64d1ea42ee2403339ae73",
      "ce69b2cf7401481084d96f3b39a80620",
      "c87d74a022b441dea4c86950fcbd83be",
      "6ce7d82d78ab442e882ed21332687482",
      "ca845768202441f6a76855f0a055f110",
      "0095a7a0f3d14affbf7491940981798c",
      "1d9a104748dd4185b2ae95a899c0ab33",
      "412ba9c3691742e3b69d29e7299ddfc2",
      "f64ee55a01974cc6b57df8e244b4271c",
      "56ad10a4843d490380d03bec28c07012",
      "94109e01acd24c2da309fd65aaae68fc",
      "d41534419490425492d4dc7db88bc870",
      "258024ee64ac4eca802915c2c82476dc",
      "b270fb49fb234b45aae3ce691aad03a0",
      "cc3bb03b1f3346d9b6835d252c45e34b",
      "7efa37bb70cb4b49b75cdfb581ad71d0",
      "a9dd6b0393604f8a9d63d356ae99a9db",
      "56e7752ba91746a09340c9c49d76ce62",
      "6860959c76664e4ab62467e2d1808a5f",
      "8c98d5d13bd14c8684bc10279d464d1a",
      "52206714c1934003a3c6fafd14aa0cfe",
      "07625fa66eb14faa961be94e04fb830c",
      "ecf14dc3e33741d380a28a738638ce77",
      "cad5f187139343c4a98fcbd8db4155fd",
      "4b0a9e9a46f94b879374468fbd66e614",
      "f17dc58168e947d7be5aea3f1d7e4f38",
      "735b0472ae884587993f2645f8640496",
      "1d595b9a5e4c4b4a9b33663b1e129e1f",
      "9e8f6299c7a8485795326571a33e48b6",
      "88a7e26909694adaaa1d7f2a6ed4f035",
      "f0839ef2ab8b4a59923517f338cab507",
      "7139ffa72672424baba1365398f529fe",
      "078974df1df9449cbc869cb1dcbd84ba",
      "24036cacf38241c38e6d653595ff7233",
      "1da42745b97b4a0bb35a213884bfe9d2",
      "5486da15dc7c43ec8c68eea4d2483643",
      "4f81d9b373ba43509e56a884d9966206",
      "8195d166d0534017b221e9f6d397094e",
      "61c2a80a2c5d4bb3a512741611c09b03",
      "778bd8cbffe04b6fb0bcdd77d84f2ee7",
      "10b2ccd353f844d09eabc23cb1ec0985",
      "92315e4892a547029ae1e097c7433781",
      "67c2ae7e5c934a66b6d1a55080c59464",
      "d8041d7f53604c81b692cf035415842c",
      "0c9d64c46b21410d811af2c2fddd152c",
      "c6b68e93c1c64e43b91627d899bb79c7",
      "730b76b764824f53967260774baa1a91",
      "9cdf2aeccfa64a0992894ed663348348",
      "6b82b65aad734ea79b49b740c06ce2dc",
      "b60993e30fa744d0bdce6f550fac177b",
      "4fa385c2a47d41c8af3132b9347a35c7",
      "46753f3e77514620822e60e3df1580dd"
     ]
    },
    "executionInfo": {
     "elapsed": 265751,
     "status": "ok",
     "timestamp": 1744214221575,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "znScZfYtQKYf",
    "outputId": "242976be-4a92-4b02-8ea0-115d082116dd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c313bab20c9f4403a54ca4432643acb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e518ba3ef3cd48e9acf923ac54da3413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ece8b415c094ea0ad757fc1ad10147c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964936649fb04d29bdfac49f45268971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7261d46398de4ef788cdea051a0ccb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daadb1ae94f74ef2a6e396f3c32f7213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f34f7a3d854c0d82db454ad7f856bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6ca636da8a4601870de17f94645b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c104a51e3b49f7a1a50bc5c487e507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aed6d91a8914f07a08cb7b11939b192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64ee55a01974cc6b57df8e244b4271c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c98d5d13bd14c8684bc10279d464d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0839ef2ab8b4a59923517f338cab507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92315e4892a547029ae1e097c7433781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-8c0d072cd64e>:66: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 02:57, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>14.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7.172100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.859100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.968200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.542500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.198700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.134100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.014600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 4 complete! Model saved to Drive.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\", split=\"train\")\n",
    "\n",
    "# Load model/tokenizer with quant config\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_enable_fp32_cpu_offload=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] {example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA config – Trial 4\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# TrainingArguments – Trial 4\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-rank4_ep2\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Launch training\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-rank4_ep2\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-rank4_ep2\")\n",
    "\n",
    "print(\"✅ Trial 4 complete! Model saved to Drive.\")\n",
    "\n",
    "# Clean up\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eI-OWHwtQNQc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykjSz4lsR0f6"
   },
   "source": [
    "# 🔁 Trial 5 – Smooth + Low-Rank LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edcxzS_TR10s"
   },
   "source": [
    "Hyperparameter\tValue\n",
    " - Learning Rate\t1e-5\n",
    " - Epochs\t3\n",
    " - LoRA Rank\t4\n",
    " - Save Path\t/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr1e5_rank4_ep3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761,
     "referenced_widgets": [
      "c3ef6c73371c4fc3b7c977b1fe4b2ee7",
      "ad30b864dba0420e917d37fd38f79c44",
      "08d0169b0c8a49cc89795a8c81fde7c7",
      "60872a68de904419b0b105682ccf727b",
      "28488fa8be694426845845a5cf8809e7",
      "1bde80667cdc4fb2a482b83a6e18b534",
      "24be0041d0e446239fcaada76c915626",
      "65a15aadf71c4413a9e2f58876b18a08",
      "0abf426cec6f4d7ba2b986b9e740937d",
      "708792561ad34638be148f521decba1b",
      "ed56d5f39f6d45ca982f756182b23e56"
     ]
    },
    "executionInfo": {
     "elapsed": 292481,
     "status": "ok",
     "timestamp": 1744214724327,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "FFX1Jdp5R7YS",
    "outputId": "f1fc5647-eb68-4981-8318-585c9203b13f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ef6c73371c4fc3b7c977b1fe4b2ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-96d437494caa>:66: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 04:25, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>15.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>11.497400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.993500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.996400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.943400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.762800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.575900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.602900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.236300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.318100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 5 complete! Model saved to Drive.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\", split=\"train\")\n",
    "\n",
    "# Load model/tokenizer with quant config\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_enable_fp32_cpu_offload=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] {example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA config – Trial 5\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# TrainingArguments – Trial 5\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr1e5_rank4_ep3\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Launch training\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr1e5_rank4_ep3\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr1e5_rank4_ep3\")\n",
    "\n",
    "print(\"✅ Trial 5 complete! Model saved to Drive.\")\n",
    "\n",
    "# Cleanup\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iISMdcgNR9X4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o2fgKPwTLPW"
   },
   "source": [
    "# Trial 1 Evaluation Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFres_nrkMUL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2f7b4609163b416c939b584fb438a28a",
      "000e4e6b4fcc4249b0be78411a8dd1fa",
      "8684d1433b1240a992e1b72c68c80864",
      "fd0adc1abed94886828bd5f1955851f0",
      "62f84540358b4b5891f49f3afcd6585b",
      "63d046a4a9404fc5a177a73f818ad647",
      "a024661f10af4988ae596326db91169e",
      "ea56eed19c9e47b2b91e24a0145fe501",
      "08e9f55c5bd14164960de14f07b48fbe",
      "6f382720aa2247d69ff31bb8093e8be4",
      "c67c6d70b692426f967327908c9a30c4",
      "3b8056c886504c5292db8fdfaf72403a",
      "21577936a3fe449784c6042395c26265",
      "50946c30dfe04675989a9bbb188a222a",
      "cbd2e52cccf74537be56ef314358825d",
      "4229b94dda8f4a4bb4c89ae1954566a6",
      "5b9cc38cd4404688916d5dfe9496a511",
      "cc1df21002b04868aedfa377dee50d98",
      "a9fa4e5d495943d0b5cde888278eef09",
      "df3ce9209c7e45b89fabd1b036538916",
      "bc65723cf3b444d3abd38c5dad31f375",
      "6cf82954104a4e0b8ebb25dda8c9e10d",
      "84eb45598dea4e1a956e5d24fdec06d2",
      "34632136c8cd40cebfc4d550c266b34a",
      "857199f84e5546fe8c89b81572f10cfe",
      "b65e6b7bd8a143ab9ad7c30a6134b801",
      "7fa55fcfb1294fee94832081d37463f7",
      "4b61b05a9edc4ceba9d1fb4383c49a3b",
      "1ef653a87a5a437b97f1aab4be86b0b5",
      "9b037d423de84d36a52cb07e7aa17695",
      "34a946cb91d64eccb1d6445e5d3de499",
      "af1396675bfc4e9ea2aea13cd01cf799",
      "67157e1538104b3bac24cec0dbe1e130",
      "a111212e7096426d9d11c627f953d84d",
      "c78eafd61e44442c8a990e84b97a634a",
      "51ec0a295ced4a608c5e10cc485a0064",
      "6654f48efca2426fb42579b5b6773358",
      "7a25b9f3805a4bb981ad71a7522e6bc6",
      "c280afb477f34d3faab0662dcdb02c03",
      "d4272263ef1a4c0882116b7013643338",
      "15de3d1a264b444abb9149dde670d220",
      "85d03b7ac52445ea85ae217ad8d7c3bb",
      "6f73e56e032046c488bceffdfe67abf6",
      "9a9a9f18a7354474a15759b632a9e06f",
      "f4f8528c0c304ad3951b41b0848c33f0",
      "6566ae7a66444992b5c11a18f4526698",
      "5bffa757e51e45dd8ea016f65ec0cf75",
      "4934c1774ee94839a4a1574a7cd0aa5e",
      "2b0bec1d8e154249a4d3a66e0fcdf7dd",
      "ae94d282cd0b4436ba8f68deaa7717e7",
      "f2359fac4c28448d87b26a82ffe2008e",
      "8e5de8f53a3d4fe8a83e72d227cd470e",
      "3b04cc7580a2470bac23f07db3f84b2b",
      "ae3fc87e503744118fa4d1e57768f13f",
      "c2cdb9603369486cb8176db70d0b7f90",
      "bff4fcf3769a45bdb1ac077f4b5c8edf",
      "f2c545ab57d8489da2353d39f5b29861",
      "0f4175e87bd64bd6bb824350e42a3068",
      "b999bccabf5749e681c160e4019cf1e3",
      "4f4e4ed629c1407a872fc4c54ff380e4",
      "4a7610c4cb954657a36ac6cbf1606acb",
      "7d309c0077014bceb9c758380074efc0",
      "7990cd111d58403d82f93e1a2669ffd5",
      "4cf444bc1f8348d4bc602fc92578e543",
      "f585693311f749c985575de39b4ca5ca",
      "ac34b0a4eaa747e8a63320a41408b777",
      "5cab59c444614b25ae48c9f2123476b8",
      "5f9930eb40bd4a46a4d3adc2af772e72",
      "51d2d379696444039867516081b23988",
      "c423d0a3fa2146889d51c99c935f2a36",
      "59bd2d840b424defb96b2bb5c95ae449",
      "f45a4e29cc96445b9f009d43a49ca343",
      "8548efe112584ae2bde3712807a2f866",
      "a8e204e7d1974be3a70a8794becd01cf",
      "e906dc97433a4d00bf68c612146a984a",
      "6d7c70aeba434458af4671403a8fe121",
      "e0d719ddc28c4ab7b129b7857c85dc9b",
      "5a341916291f417a8c2c7812ec699674",
      "8ed66783381a4b8ab46345d89e42525c",
      "dca630b6b36b43648e6afb0cad573650",
      "f3f400cab1424b18b06398d435107bf9",
      "57c92daa7f2747bbb1aaa8653afb80c0",
      "5b36c5ae566b4471b941b480c3c07a0b",
      "ac888b5d15444ea09ed57f8ae1b551b2",
      "0b6914939ae446bdb339290067a1639a",
      "15d01dbf82e244ffa52fa5c4043909ab",
      "eab86e496a7f4be385d64095b29a4ff4",
      "663de89edba84451a19d1c4672583c9d",
      "2abe4da18af847d5ac50388e283bb67c",
      "0288079a748c42a19b43e0145e214c42",
      "bc39bce8993c491d8bc02397c2864aee",
      "03ffbb84f26a43338fd5e97dfe8060e1",
      "8de1c6aeac6a451db0a2db7bc6fb2383",
      "9e59bed639904a2685134cce7e3f363b",
      "1b7ea386e9bf4c2f998d48c023afc5a9",
      "35925e714b3a4f8eaa4cc23007b39c4e",
      "152de45d91214c229b8b83bcca340466",
      "1fd7aaa63fb44146b128b826f1f24246",
      "8c57c0eac48e406fbb3a26b688be9ae9",
      "6409452ece94411ebd7fdbc170af2355",
      "9d5b6226e7894a53bc0e7a9021d5622c",
      "1e00e7268e9a4c09b8269c68be5d1ce9",
      "8ad86244415d426a9a6edf3ee44febdd",
      "db76f91c5ddb456d8e6270e1e3401f7f",
      "c5451645f9ca4244b632240bb6263da3",
      "323e94e2b7e24eb186c068c3224a5aa4",
      "df56825b19d9463dbb8bd1e5f04cebc0",
      "37036468039d4c85b929303c9feaafe7",
      "62281329d1474ccf8cb257ba00354889",
      "6b42b968542842f384963e7481d1f4b2",
      "8273a26f93a74a49bdb9737ccaba7d2e",
      "1991e9f172b748f39d188bdb7c124473",
      "50701ce5741c4335b567ab22a4ef9232",
      "f7fc42e38457490d910788acd8f512f3",
      "2cdb8137bd4c422eba272252671e1447",
      "bcc920a8ebe548979c11fd23bcd26e02",
      "aad0c9cfcc654ad1a4348ebccb620516",
      "849818c47d0542a8af9808b46fa55174",
      "3464dae9c56742da9a08797c371dd1ef",
      "324207a315c74fad8a29b50c5d5de0ee",
      "a363d31588a44a6aafe123089655334f",
      "1ce51d3e434849b8b6e3294b1ecf8ac6",
      "0739db3bc83b4595b6d87b8ad9b0f125",
      "520c87c8ee4044f59c29b71d621fff7d",
      "3de890954d764fc29c9ee8914d95df1a",
      "ed5a5913399b4913b8e9c0ea185ab918",
      "2f1531d6c8ce42bdbdfea6dbe5d93e8d",
      "7acfcfd14c5643efb6e1372f2a0ca74b",
      "bf8b4b2da8b14e5bb4051f691c871591",
      "bfefe4ca544742b19db9159cad82cec0",
      "648ed2023b9d49889c86536b602faf89",
      "db63c680736b4e66bf8f17a4e883dd4f",
      "f1e7f33a1a9749a48190c39fc449921b",
      "22db90c137db45e883428eececc4b9cb",
      "326ac43551534043a007aa0fbb7939b7",
      "1a0b3927c79c458d98f5284be857f41c",
      "0ef17383172b4acd8042be7a61e34ef0",
      "e91a2c0aa0d04e6e8dba5f1010e5d5ee",
      "2dc7d5bc725c413da4c8d53203721e2e",
      "a24b725e31164570a21b330de9fa4608",
      "989dedab0994409c9776d35406055a42",
      "fb1de96981134b719ef6188376beb757",
      "b22f742898b9478ea0d14062371703e5",
      "468366921b36453e8e56f485e27a7cbc",
      "dd5fbc3cfffd42deadd828b61f993eb2",
      "c83919e48a3c4a38abceb8ee62fe2f6d",
      "bc2de85c03d44369ba9b96cc2b07dbf7",
      "b13188c2c6ca4f1aaf6b077d8b741ab1",
      "2e467e9f726c4098b4b6535b2c15876a",
      "6bacbd17be604d70b2578707c5154656",
      "aea0ecc4997b424da294ba4510d0c036",
      "63ccfad163224375af7d18786ec4597b",
      "d27e612bc7a54a86a2e094502a4773cb",
      "8b167039584f43b5a14e954122e9dad2",
      "875346c62185436d92bdfbeb439d1dbf",
      "de15e83740b0486197cb24039054c233",
      "df77d113f45146109d687af5b016ac72",
      "3f3cba8441724d18a8b3287736aebe6a",
      "723ebb8c2f654961a50bc12986fe3dc3",
      "dbee2b4f8c5a4d8580b6e2bef288387d",
      "06b93c8e4a094ec6b78ae8e65c34d857",
      "4350022417fb4dcbb55996f66f7ea0fe",
      "413598d2190f468caae76c8c07d47a22",
      "63081ea60e5944bf9771b3230b9ac4d5",
      "f03421a5b406464289da23de4a0781eb",
      "38a5a1a71fcd410aa85206f30c622233",
      "d764a2f893c343c1ab9da082a5443cbf",
      "7e327492faea456c9da0895f47be0103",
      "6615b191fc484f2daf861746bb5ccc03",
      "0f48aa006c374136a69a86a6d7f2b11c",
      "76745f760ded42cb9e964d832d6d78fe",
      "8621af0387ce4daab525b1fd16455a22",
      "e38c78fee06947179c28c863281f4e9e",
      "24603b9e2d4342378adfc290a0d8d779",
      "dd4f256f683c46adb8e85b0955f61f18",
      "5ee4c4fb5ffe4534b8ce65c8606a304d",
      "345472cc00de4183add9b89db26943d4",
      "765c518e0ed044b8b9092baaf8be5666",
      "e04b2a296f1d4ad5b3fcc0ea6d32ab6f",
      "699bd16aed4b4aaa83afadbeae853eef",
      "9e7d1bafabcc4be4960881a465ecea53",
      "a03cd9e3c3bc4b3ea697e866a82fc4c2",
      "7148b4a7f485408ea3e15e873e294855",
      "c1402b9fefc14328a9db9aae0c61940b",
      "7aa76c3504374534a8699a82ddafae49",
      "623f81d88fb04497b97c37c49f5c5699",
      "fe4cb514a7a540d2982a413b48859895",
      "bc689017a2cd46c793c5df0d8607410b",
      "9c08957ff782494ab288171533869358",
      "b008753dd62348bcb5709761b9e0e1a8",
      "1f2d388d17d34590ae94c281c92e501a",
      "06b5abb3a221407fa3641dce054ef396",
      "5a31d65c7ff24b6688dc30a207ef2194",
      "9df922119a4d49f9a4612b1a380573a8",
      "fabd9b9dadf64b80848d882bf2620896",
      "9809fb25c153444e8035a3e756b71ef5",
      "d6fb9630663e41f6aae978cabb4a130d",
      "68e3a2a8037e471aa0da2eebe4fd08c1",
      "f172e2ce191249938c611161267e353f",
      "8b02fd5a51ed47b08c2ad9d3a410384a",
      "a6953b91a6874653b38137b9a7642547",
      "fa7811ae31d14f9687d63fe674bb664a",
      "8813c8eab15f406ebdd2637e83c856d8",
      "bace3169820644d49062a9d109040175",
      "35fd347870b748fdbf9d1eebbe4b831b",
      "0eddc28eed6747f0811b263902cdcf04",
      "91263ebf40f3417d96b8f9c272378b3c",
      "a24ebca2ce4d4ce0b7c52e7d5f766796",
      "a8a6902d5d7943858994fec51a03a0de",
      "fe0ab9636f424be6a9659564bc534967",
      "018c03a31f3140e6bd67b494ebf32242",
      "d7e52259b24e458b973d8fe5c1b7aea9",
      "793482701f0a4cb189a72c3c0b8b6169",
      "1f8573d4cb0c46029974ad98740d505a",
      "2d3c736f9d984f03941ae38676114c99",
      "ceeb0bdfd2854a54aa2eab61b922739e",
      "d628c7b9ef7b4b4f9aca4d48be86c48e",
      "83a76d6054ea4013a563585a2584cbb6",
      "8f879471d9354b4cad0b7c4bd1f55263",
      "3677a17713714cfa8b41949c9e2a82d5",
      "f442f2ece79d4d239bd21d0171f825e7",
      "6fd2826ec2564dcd9e3ccd394d7f3aa8",
      "8ec9678ecdf94220828efd34ae8d9c07",
      "0f6a688959f54dae9f6573fef3a8e47c",
      "9d5f3143d6eb402ca4e2955393172a37",
      "7e9ce4b4ed8e48859b5e0be0d8848b69",
      "d4cd7850802d45af97a28d7f40059b23",
      "ed133851b31d447bb0c4044eef2b8a82",
      "0dfa3c69ca6542c3851f0f0b4ee03249",
      "9b8da44a4589411e936b005dcb515648",
      "360c950978424b9990cac4687b877be4",
      "405155803c0d498cbc6a674d58ca41eb",
      "de3dbf24cfa24bd9a81d62a26a76a784",
      "45570b4214754578bc198d56c9b744b9",
      "a7d27004527c44d984846a6460012a08",
      "7451b441ecba4472a1640070c4ea2e8b",
      "700ed520989644e28b6b73fea287b039",
      "d23f98791f4a4c7785d493f8413da977",
      "e8e36350099645e39470b9274075063d",
      "0f2e901a41ac48f5849e2aaea4ad8345",
      "bd44e365702c406fb17bb6dc4afcbe08",
      "73996e082531456ab6fa548ef7d93b08",
      "5c488e6b3d4d469e9b406b1e9bceeaca",
      "208942978dc74a3a86c346d01aa25b87",
      "c7f6ea4ccd5e4fdc9e0fa4924a9cbacc",
      "0333ad1640f041589fc10193d4804a4d",
      "5ac28995835f45f589dc672b5df18afa",
      "58a84b0e3f544072beb5b2d6193f8a6b",
      "7be6778fe5bf448ba8a92f3f506baf29",
      "090bdb3c45cd46a389c96b6c37bd52f6",
      "975d6e0ada2043868263c12201694199",
      "9166bf8ccdc54337bd13e59696c56eae",
      "6a402658cefa440695ce7258895027e6"
     ]
    },
    "executionInfo": {
     "elapsed": 1107930,
     "status": "ok",
     "timestamp": 1744219085203,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "iqEJVGw1VZJ_",
    "outputId": "66cdf1c4-fcc2-464e-dc39-7066c7031c06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7b4609163b416c939b584fb438a28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8056c886504c5292db8fdfaf72403a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84eb45598dea4e1a956e5d24fdec06d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a111212e7096426d9d11c627f953d84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f8528c0c304ad3951b41b0848c33f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff4fcf3769a45bdb1ac077f4b5c8edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cab59c444614b25ae48c9f2123476b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a341916291f417a8c2c7812ec699674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abe4da18af847d5ac50388e283bb67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6409452ece94411ebd7fdbc170af2355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8273a26f93a74a49bdb9737ccaba7d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce51d3e434849b8b6e3294b1ecf8ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e7f33a1a9749a48190c39fc449921b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468366921b36453e8e56f485e27a7cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875346c62185436d92bdfbeb439d1dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a5a1a71fcd410aa85206f30c622233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345472cc00de4183add9b89db26943d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating: Trial 1 — Baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 250/250 [17:02<00:00,  4.09s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc689017a2cd46c793c5df0d8607410b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f172e2ce191249938c611161267e353f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0ab9636f424be6a9659564bc534967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f442f2ece79d4d239bd21d0171f825e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405155803c0d498cbc6a674d58ca41eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c488e6b3d4d469e9b406b1e9bceeaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 1 Results:\n",
      "     BLEU  ROUGE-1  ROUGE-2  ROUGE-L  BERTScore (F1)\n",
      "0  0.0018   0.0824   0.0044   0.0666          0.8229\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# === Setup ===\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-baseline\"\n",
    "eval_data_path = \"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\"  # Replace with your actual path\n",
    "\n",
    "# Load evaluation data\n",
    "eval_data = []\n",
    "with open(eval_data_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        r = json.loads(line)\n",
    "        eval_data.append((r[\"instruction\"], r[\"output\"]))\n",
    "\n",
    "# Load base model and LoRA weights\n",
    "peft_config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(peft_config.base_model_name_or_path, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Inference\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "print(f\"🔍 Evaluating: Trial 1 — Baseline\")\n",
    "\n",
    "for instruction, expected in tqdm(eval_data[:250]):\n",
    "    prompt = f\"<s>[INST] {instruction} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "    pred = tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, \"\").strip()\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(expected)\n",
    "\n",
    "# Compute metrics\n",
    "bleu_score = bleu.compute(predictions=predictions, references=[[r] for r in references])\n",
    "rouge_score = rouge.compute(predictions=predictions, references=references)\n",
    "bert_score = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    \"BLEU\": round(bleu_score[\"bleu\"], 4),\n",
    "    \"ROUGE-1\": round(rouge_score[\"rouge1\"], 4),\n",
    "    \"ROUGE-2\": round(rouge_score[\"rouge2\"], 4),\n",
    "    \"ROUGE-L\": round(rouge_score[\"rougeL\"], 4),\n",
    "    \"BERTScore (F1)\": round(sum(bert_score[\"f1\"]) / len(bert_score[\"f1\"]), 4)\n",
    "}\n",
    "\n",
    "print(\"\\n📊 Trial 1 Results:\")\n",
    "print(pd.DataFrame([results]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjkfjbCKVqoQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYlUs02DkOV0"
   },
   "source": [
    "# Trial 2 Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225,
     "referenced_widgets": [
      "72f48a11fc654af98bc5fc4eba419e36",
      "1a3644723bfc4e6ea308d2b44d52ef82",
      "adcbf96f5b7d465aaf06dc4358641979",
      "5f219826c42d489eb99a0ca8f524c09b",
      "66623cb66958478bbc5bba1da2ba36ba",
      "47c35c98d5f146c090f519d5f391d3fd",
      "cfb9110eade74a6983389199040b39fa",
      "3b7bc1f61ea54656a20d1046a4d1c72e",
      "dfbb31b85497465b948d2fbd646ee710",
      "a1c15cf702de469d9094fe3a7d1f9b99",
      "4b9360c94ae941b7b4cc8a53f6fd0ac3"
     ]
    },
    "executionInfo": {
     "elapsed": 1170914,
     "status": "ok",
     "timestamp": 1744220422215,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "SrJBfDehkQtY",
    "outputId": "88294f36-be8e-436c-c6c5-84bebe558523"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f48a11fc654af98bc5fc4eba419e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating: Trial 2 — LR 1e-5, Epochs 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 250/250 [19:19<00:00,  4.64s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 2 Results:\n",
      "     BLEU  ROUGE-1  ROUGE-2  ROUGE-L  BERTScore (F1)\n",
      "0  0.0018   0.0788    0.004   0.0637          0.8212\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# === Setup ===\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr1e5_ep3\"\n",
    "eval_data_path = \"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\"  # Replace with your actual path\n",
    "\n",
    "# Load evaluation data\n",
    "eval_data = []\n",
    "with open(eval_data_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        r = json.loads(line)\n",
    "        eval_data.append((r[\"instruction\"], r[\"output\"]))\n",
    "\n",
    "# Load base model and LoRA weights\n",
    "peft_config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Inference\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "print(f\"🔍 Evaluating: Trial 2 — LR 1e-5, Epochs 3\")\n",
    "\n",
    "for instruction, expected in tqdm(eval_data[:250]):\n",
    "    prompt = f\"<s>[INST] {instruction} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "    pred = tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, \"\").strip()\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(expected)\n",
    "\n",
    "# Compute metrics\n",
    "bleu_score = bleu.compute(predictions=predictions, references=[[r] for r in references])\n",
    "rouge_score = rouge.compute(predictions=predictions, references=references)\n",
    "bert_score = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    \"BLEU\": round(bleu_score[\"bleu\"], 4),\n",
    "    \"ROUGE-1\": round(rouge_score[\"rouge1\"], 4),\n",
    "    \"ROUGE-2\": round(rouge_score[\"rouge2\"], 4),\n",
    "    \"ROUGE-L\": round(rouge_score[\"rougeL\"], 4),\n",
    "    \"BERTScore (F1)\": round(sum(bert_score[\"f1\"]) / len(bert_score[\"f1\"]), 4)\n",
    "}\n",
    "\n",
    "print(\"\\nTrial 2 Results:\")\n",
    "print(pd.DataFrame([results]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAvdukoepHuu"
   },
   "source": [
    "# Trial 3 Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "66d9e530aab74c1784da0d4718ca3d92",
      "d567478ba3cc490eaf06d1d16c17ab89",
      "803422011dc443faaa454c9acdd82317",
      "cfe9d30a2465400f95b05c3b79ddcff9",
      "1eba626e19404dfa92ceb788e794cc6c",
      "8f810cdbf417468a97ae8f4a86e65735",
      "c8a73c7fbc964937ac4d78bc0acc5288",
      "5a48148fc92645419919910a55320897",
      "a5a9fd28eac74306b4d9a4d4ab697664",
      "15a81a57bb574bc09ab44f79a3bde190",
      "36322f0341a74bae9dbb91fbee00ddec"
     ]
    },
    "id": "KYLEpPUjkaEa",
    "outputId": "fdf8b6ec-e92a-4f6a-e658-afef9c908991"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d9e530aab74c1784da0d4718ca3d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating: Trial 3 — LR 5e-5, Epochs 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 250/250 [1:16:39<00:00, 18.40s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 3 Results:\n",
      "    BLEU  ROUGE-1  ROUGE-2  ROUGE-L  BERTScore (F1)\n",
      "0  0.004   0.1021    0.007   0.0864          0.8294\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# === Setup ===\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-lr5e5_ep2\"\n",
    "eval_data_path = \"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\"  # Replace with your actual path\n",
    "\n",
    "# Load evaluation data\n",
    "eval_data = []\n",
    "with open(eval_data_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        r = json.loads(line)\n",
    "        eval_data.append((r[\"instruction\"], r[\"output\"]))\n",
    "\n",
    "# Load base model and LoRA weights\n",
    "peft_config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Inference\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "print(f\"🔍 Evaluating: Trial 3 — LR 5e-5, Epochs 2\")\n",
    "\n",
    "for instruction, expected in tqdm(eval_data[:250]):\n",
    "    prompt = f\"<s>[INST] {instruction} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "    pred = tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, \"\").strip()\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(expected)\n",
    "\n",
    "# Compute metrics\n",
    "bleu_score = bleu.compute(predictions=predictions, references=[[r] for r in references])\n",
    "rouge_score = rouge.compute(predictions=predictions, references=references)\n",
    "bert_score = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    \"BLEU\": round(bleu_score[\"bleu\"], 4),\n",
    "    \"ROUGE-1\": round(rouge_score[\"rouge1\"], 4),\n",
    "    \"ROUGE-2\": round(rouge_score[\"rouge2\"], 4),\n",
    "    \"ROUGE-L\": round(rouge_score[\"rougeL\"], 4),\n",
    "    \"BERTScore (F1)\": round(sum(bert_score[\"f1\"]) / len(bert_score[\"f1\"]), 4)\n",
    "}\n",
    "\n",
    "print(\"\\n📊 Trial 3 Results:\")\n",
    "print(pd.DataFrame([results]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVPJTRnIpS3C"
   },
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woD5H2J2SR6X"
   },
   "source": [
    "# New Finetuning with increased sample to 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkS0_vwdShpO"
   },
   "source": [
    "JSONL file for 3000 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6141,
     "status": "ok",
     "timestamp": 1744298501019,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "bHtYsvxaSgub",
    "outputId": "e3d89283-3fc5-410b-b4cd-b84eecfe72fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: empdiag_3000.jsonl\n",
      "✅ JSONL file copied to Google Drive!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/SIT782/datasets/train-conv-cleaned.csv\")\n",
    "\n",
    "# Drop NaNs and shuffle for randomness\n",
    "df = df.dropna().sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Limit to 3000 samples for fast training\n",
    "df_subset = df.iloc[:3000]\n",
    "\n",
    "# Convert to instruction-output format\n",
    "records = []\n",
    "for i in range(0, len(df_subset) - 1, 2):  # pair every 2 utterances\n",
    "    instruction = df_subset.iloc[i][\"utterance\"]\n",
    "    output = df_subset.iloc[i + 1][\"utterance\"]\n",
    "    records.append({\n",
    "        \"instruction\": instruction.strip(),\n",
    "        \"output\": output.strip()\n",
    "    })\n",
    "\n",
    "with open(\"empdiag_1000.jsonl\", \"w\") as f:\n",
    "    for r in records:\n",
    "        json.dump(r, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "shutil.copy(\"empdiag_1000.jsonl\", \"/content/drive/MyDrive/SIT782/datasets/empdiag_3000.jsonl\")\n",
    "print(\"Saved: empdiag_3000.jsonl\")\n",
    "print(\"JSONL file copied to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2ydNCujT_oX"
   },
   "source": [
    "# 🔁 Trial 6 High-Rank LoRA\n",
    " - Trial 6 – High-Rank LoRA with Extended Dataset (3000 samples)\n",
    " - This trial uses 3000 training samples with LoRA rank 16 and 3 epochs to help the model generalize better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c86e065d8908473d90838b72797c93f1",
      "e0a2365e285749f6b5111e7d29b17a57",
      "45f20d17913046fe825843a690ac23e6",
      "a52b2c15e3214d108aed3332238bf4e4",
      "3c1a48a4b2344e048cf476103995a0f9",
      "bec5dbb189fa45b8a01eaafe9f950fe1",
      "ed8450d1856c4d3cbf8de54dae75f62e",
      "43f89d5914974c518acea9a23d4e95b7",
      "534816c0e0e9443ea7ea9ee5cdd4c052",
      "d002c54eabac4719b9f79441a99b7e90",
      "75e9a53882014947acd92133b7969da8",
      "e0dfed3aa70448a092971ed69c93f1c2",
      "1a1a404c4d5448feb6c132d3c436e4ff",
      "2719bcb666274d4c9c6ef4df940d791c",
      "5a3786f921554c208e2e919a2879d68a",
      "d589e4efcf5643a4b87383e131c14224",
      "94a4968dda8c46d2987ec1cdccbb7b93",
      "5032af37d7d34718825ac8572885a13e",
      "7cc5fda9c0844727829ea7ab355928d7",
      "707e0d06fbc3414a9357f11cf11a55fa",
      "c77c11231417427babd2811034597117",
      "2fe294695ae24943a85fb2bd40301355"
     ]
    },
    "executionInfo": {
     "elapsed": 487136,
     "status": "ok",
     "timestamp": 1744299765500,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "pjhRwdA21V64",
    "outputId": "a9d36d28-b094-4fc4-9933-b31db017d0ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86e065d8908473d90838b72797c93f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0dfed3aa70448a092971ed69c93f1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-8130b41cca5b>:52: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='561' max='561' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [561/561 07:54, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>14.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>8.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.443200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.153300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.064700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.320300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.442400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.728600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.362100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.246300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.247600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.242200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.214900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.205900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.201100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.199500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.184500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.243100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.198800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.165200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.175400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.173600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.161200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.171800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.172400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.169300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.176300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.169800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.162600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.158900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.169400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.156800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.174300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.179200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.163200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.156700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 6 complete! Model saved to Drive.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "#Load dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_3000.jsonl\", split=\"train\")\n",
    "\n",
    "#Load tokenizer & base model\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Tokenization (no emotion field, role-based prompt)\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message.\\n{example['instruction']} [/INST]\"\n",
    "    output = f\"{example['output']}</s>\"\n",
    "\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA configuration (Trial 6)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "#Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"mistral-lora-3000-trial6\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "#  Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Save checkpoint to Drive\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-3000-trial6\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-3000-trial6\")\n",
    "\n",
    "print(\"✅ Trial 6 complete! Model saved to Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iywWZ75X52a"
   },
   "source": [
    "#🔁 Trial 7 Long Context Boost + Moderate LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "60ee73fbeda242208ae8f1140fd9eb73",
      "cccd13b2b4cf4e5fb97e245a8a38659e",
      "fec0758acac546e78b1c427971f6e0dc",
      "863fd4c0280c4f00b87758b0a0e82367",
      "cd6af6b6faa24583919c47a383914433",
      "41e3500846de4fc88e6d237acff1ef7b",
      "796a4cc2b94749f1a815b4e8090f5da0",
      "e1e8d288c72c42fcb5ec8d9f18a21d9e",
      "fd5f645b8ba747a9b385319703a618b9",
      "1bee1ace09e649c4bb824af901c8a633",
      "006a0a1fa82b4ae8b4faafe8d388f7c8",
      "d7204178af9b4198b656de495a640b0f",
      "ee87e30b3173461e9858c348e110ab7a",
      "34982289451447a7bbab924241b059fc",
      "13a26b7bc61f4fc4af3c2d12d0396f7c",
      "a0cf463b41764ef69a0c5c9b2b6cd2d3",
      "21f92805655447029ad73075e5f0a17c",
      "72603386750441c2b2f4267c4fbd547b",
      "3798ffed07534376b23759b33699de58",
      "e32d47edea7042bcb7d3604caddc0af8",
      "ce992fc69c9e4ccbb3a5313bf93d38a5",
      "9ba6d4b7f6574af0825cfbd8e872ffba"
     ]
    },
    "executionInfo": {
     "elapsed": 740218,
     "status": "ok",
     "timestamp": 1744301087462,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "yMRQ6N3GU8pc",
    "outputId": "7c0a1b50-182c-45b5-efc9-1560cf1067fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ee73fbeda242208ae8f1140fd9eb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7204178af9b4198b656de495a640b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-5b529b9a8f3f>:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,703,936 || all params: 7,243,436,032 || trainable%: 0.0235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='561' max='561' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [561/561 12:00, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13.350800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.933900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.777900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.981400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.267800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.119800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.124100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.112100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.133600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.094900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.087200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.087600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.080400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.092600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.081100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 7 complete! Model saved to Drive.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_3000.jsonl\", split=\"train\")\n",
    "\n",
    "#Load tokenizer & base model\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # ✅ Required for padding\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "#Tokenization with longer context length\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message.\\n{example['instruction']} [/INST]\"\n",
    "    output = f\"{example['output']}</s>\"\n",
    "\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=768)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=768)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "#LoRA config – Trial 7 (Lightweight)\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"mistral-lora-3000-trial7\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Save model & tokenizer\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-3000-trial7\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-3000-trial7\")\n",
    "\n",
    "print(\"✅ Trial 7 complete! Model saved to Drive.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZXRhcpIeLrZ"
   },
   "source": [
    "# Evaluation Trial 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9L4FqCYueOTc"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "27b6a17bf9114897987a75c4d31d0cec",
      "a4e18f3bcaf34c91a189d32d98aa057a",
      "d6522894f1354a3dbac3dfbc0ed975df",
      "68ec5f786fe24f77badebd83540b1559",
      "83a5afd706034c1591e6ef012f1ce0b7",
      "31a78d110cdd4dc58e6816c0cf895638",
      "c24ef5a08b7c48e3b3e418f3e3dd8dd6",
      "e7c970d024ce484c89d7effe4c7f7050",
      "23c1aba0257046daab6f3c9cfc0e36dc",
      "04af8e19deac495b85fe58faef93c623",
      "8a6b856d9e2b4e659d113ab144f3cbe1",
      "e412d7fbba0d43d4a8f45148499e63da",
      "27ff89584dcb482a92c019aa0337eec3",
      "c08708d1673b4400945a36af0789d521",
      "95c46447d3304e12907f3ad212c19817",
      "fcc1da89e489413fab8756c12ad3fada",
      "8ec949e75a3f445c904008f7887bbbfe",
      "2aa4fd06f064404fa50bde3fb6fd2aca",
      "375c6d855abf42d68e4aaf62e1f2f4c8",
      "adcabd41c6424ef99be9de98b5c88db5",
      "a375541e4cac47e793ec1a13635cf467",
      "d4bea1e34a29497f83ccb946998fdf88",
      "aa51fa2e7fc741d09253b656d114a482",
      "e1c973d75ec047f38aeb8843279a2488",
      "18ac6d1274694acfaa4cf57cecd0fae5",
      "ddeb0c66190f4e7a8f7fa85cdf2d3bba",
      "3660c54c85464cefb51aed0fecb011e9",
      "4b22697d219d48a09c9e1d5496f022e6",
      "65e3b73c9e9c4395987df71efcc33c15",
      "ce59ec670c224d3884dece0d38f540a3",
      "ed68625f931a454e94ece6beb64ba9ce",
      "2fd49a722a01413d91cdf8bb5e040c60",
      "697be69d713347659a144ae4b1b99aa6",
      "f94c9570c7bc401fba72888469f2c286",
      "47b6ce7bea5e4ebf9ca4e687bff0f893",
      "2589fff0e2e940e890b62288fadf33df",
      "2e530d63249747479b9452df3ad8f698",
      "204aef74121d442cb45b4496cda40edc",
      "935795eb94ba4ee788f6f21f9f42c462",
      "bc34ca81f9f540f7abf59012cd251f8c",
      "5159ed58fda54457ab20d09d381a8197",
      "bf51ef23b9bc440895cd75ccefbdbf6f",
      "891feba209104a49a218ad5f18c541bf",
      "3bad501d8b874bd69dfcd3af7c016b4f",
      "5e7a972cb830416a8951c4faa7b319c3",
      "e1debf91b9e3452f82f32479d1bc42e8",
      "1affdc07512d46a9a64586accc8b1dd9",
      "f5cb1d51a3394fbb98a99dfa472d12ba",
      "b6e93dacfc7a4038a188c23a24e6ddef",
      "73088f45bd614d5494abcd56ce909740",
      "81679f68a199408388ca7e5481905d05",
      "bcc047073d2f4e4ba3a0a4e998f68d49",
      "b89f9927fce84035a333796b3edaec48",
      "9d7b71b3cbc1412495c695a5570d45d6",
      "8290c1579728493a9d7b0260a44fc86d",
      "447c364505174ea18aa987946977f962",
      "c081cf4e07c5464e9f9bb473ebe1f47f",
      "9130d1a5958140e98d5ef0b3a14854fd",
      "c9664bc3becf4ba9a3927010f6698546",
      "a9edb18d373c408b916896ee579278fd",
      "c90713ca59de47db84a57c93c5e04ece",
      "194ea212199e4903baee4a286cfe2a62",
      "68b1d24471d54231965bfeb572d4086a",
      "13554b22d97b4d5aab189bf6a5fda3d4",
      "697c31d3ef3b402284b69e11ce334934",
      "6c2f0e06aa06401b8ebf4586139dbfc0",
      "cbe6810fc89141f7a043d4d40d185b50",
      "e11a7612cc9242c88a4d168bd7c329cf",
      "b13dbe16bde945969f7e32a9416c8da2",
      "c521b87a5d0c4abb8c69f9935bd63a1f",
      "2c39b6ee275246c79261a00931c41c50",
      "a1d1f1349ae748a2a07019d062251e84",
      "530c8165a3b941878eb04a88e7f30210",
      "ddbd1133bcd24ddca1730170c2b43399",
      "32eaa63f8eba48e0a96ea745c2f6d9cd",
      "98e267f8d74c4829a2e13bc893c74548",
      "bc8b11159ada4ea48db745492fefeaf5",
      "eb2a17dc35254ed5ad32dc73199589a6",
      "eb17e179104949e38e35dc4d5fbda92e",
      "feaf113552a4459cad2231a68a830866",
      "0ef38ded752641d6b5c6cec2cc2522ae",
      "5d4d58b22ec345779b322b5f87f2cca3",
      "9b2346b78b714359bff1476060aa66e9",
      "228bf73325c645738078dd56f2e1e8c7",
      "c2841df4460d429d813937aadcf0dbfc",
      "107b6cc3eff448f3ab6417c63f473b27",
      "7197adde387b4a2792686d3e3be195bf",
      "0e9022d880de4edca53ee23586068574",
      "a46ac38b2d204541a67f3cfa0b7d77dd",
      "a93dfad1d9ca4fcba452f17372bdb08d",
      "134168081352466ca05113c160a8861d",
      "dfb295f0a8424ca188990903963a54f7",
      "0b80006b569942e5be9876b0dcac6a1a",
      "a7a65c2265dc4f3da1c73ed107d509cd",
      "f862faab4b5e47808a3bf369a05ab7da",
      "c7e8d88e855845cca8cde092337b976a",
      "af282d245a9d429ebc5ae0ff5ba2a785",
      "74efebb150664c6889a83bf93b4e2f7a",
      "68a602fa44b342858ddafcfa4d289bd2",
      "c45f7feca5254ca6ab8f2cf0e1df3db4",
      "396357acdf4a41c58ef5db987946eb94",
      "6063baea067a4f12ab264fe003513578",
      "ee688d3640d8462ca2c2860543291079",
      "a85bdf06bda44007b52a20a0a4ea2d54",
      "8bd7a38c712245e1906d66fa4a2c6e10",
      "b1b3cc0b51d14bbcbd1538642d573dd7",
      "f89b876adf3d4d0c8572451de3a7ded4",
      "180a0bf19aa4431c991b367253f04ab6",
      "90ed2c557a4146f4a3d73b3f48ec3014",
      "25c8b1d9dac8440b92dc0da50e9e6bff",
      "5c75309cfb58485798d5ef6ed1997389",
      "2733b0fff2a54d658859f88bbb4a3951",
      "e8bf20bdc8274bd79d5c1d234e4e4927",
      "2141dc8463a4457d9167f78d06a26b00",
      "94123b943abd4bdf803f5fe6056a685c",
      "1c76705f3a9b49e3aaaf4192acda347e",
      "f9e8718f6f1f44b38cae8c7e69222d61",
      "8fffdbc76e01489f84f7032db0408e4e",
      "a7d70f534e5a4c46a7fbe6b7b67f304d",
      "3754b424d41f47afb01c7c3b5da524de",
      "4576ccd0ea6143b79b9a9a4e019a355c",
      "bcacd84095034b5dbde70fd5239bdbb2",
      "3d4a3f8536a744cbb210d0bc9582c47c",
      "bf39cbdda07b4c9285ed4c959d194988",
      "f70216878a6c4eac91e4f58fa3b81c01",
      "6c37ff9f156147d88efdc6ff667e631c",
      "4f1e2c0b374943b59fa1e66bbd05cdcd",
      "9700d7dfd5934d59b8b4c44129fc43a3",
      "7afa42ebe9c848dea3294746c0eb5379",
      "fa06b44ca98b4273a51403e2b892c394",
      "dfc7e5b0422545b6835d8d3a4bf6d795",
      "d87c8587e6a44ff3be6640bf01501554",
      "345caf17b2994c2ab6994d790505f516",
      "72700d2fd8f34e029fa58912640e55b0",
      "3cd7ef83f7d3491ba19fc224f0e30b17",
      "ec17d0673968401ca9e817a9c0330b69",
      "93b3d0b12f594c7c87ea48862c6ce0f0",
      "c1670dd5aab84d4d81b0101561406846",
      "cd64cdd8ace543b4886c940aacefe3d8",
      "f332d38a9da147168b74ceb89e94e49f",
      "4a80c52bc9a94c4c866d2e32f64eb993",
      "d000ceb53aa64425afe1a838d073f9a7",
      "975b393d49684b6aad283998a470deb3"
     ]
    },
    "executionInfo": {
     "elapsed": 523412,
     "status": "ok",
     "timestamp": 1744302908469,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "YxvFo4GXU8wY",
    "outputId": "2061d702-2b6d-49e4-f456-940833eb600c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b6a17bf9114897987a75c4d31d0cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e412d7fbba0d43d4a8f45148499e63da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa51fa2e7fc741d09253b656d114a482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94c9570c7bc401fba72888469f2c286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7a972cb830416a8951c4faa7b319c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447c364505174ea18aa987946977f962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe6810fc89141f7a043d4d40d185b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🔍 Evaluating Trial 6:   0%|          | 0/500 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   0%|          | 1/500 [00:01<10:56,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   0%|          | 2/500 [00:02<09:39,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   1%|          | 3/500 [00:03<09:44,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   1%|          | 4/500 [00:04<08:57,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   1%|          | 5/500 [00:05<08:30,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   1%|          | 6/500 [00:05<07:08,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   1%|▏         | 7/500 [00:07<07:57,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   2%|▏         | 8/500 [00:08<07:59,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   2%|▏         | 9/500 [00:09<09:01,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   2%|▏         | 10/500 [00:10<09:09,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   2%|▏         | 11/500 [00:11<09:15,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   2%|▏         | 12/500 [00:12<08:44,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   3%|▎         | 13/500 [00:13<07:26,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   3%|▎         | 14/500 [00:14<07:31,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   3%|▎         | 15/500 [00:15<08:09,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   3%|▎         | 16/500 [00:16<08:34,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   3%|▎         | 17/500 [00:17<08:50,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   4%|▎         | 18/500 [00:19<08:55,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   4%|▍         | 19/500 [00:20<09:06,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   4%|▍         | 20/500 [00:21<09:12,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   4%|▍         | 21/500 [00:21<07:44,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   4%|▍         | 22/500 [00:23<08:13,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   5%|▍         | 23/500 [00:24<08:13,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   5%|▍         | 24/500 [00:25<09:05,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   5%|▌         | 25/500 [00:26<09:11,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   5%|▌         | 26/500 [00:27<07:43,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   5%|▌         | 27/500 [00:28<07:38,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   6%|▌         | 28/500 [00:29<08:07,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   6%|▌         | 29/500 [00:30<08:08,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   6%|▌         | 30/500 [00:31<07:53,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   6%|▌         | 31/500 [00:31<06:33,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   6%|▋         | 32/500 [00:32<05:31,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   7%|▋         | 33/500 [00:33<06:37,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   7%|▋         | 34/500 [00:34<07:01,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   7%|▋         | 35/500 [00:35<07:38,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   7%|▋         | 36/500 [00:36<07:32,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   7%|▋         | 37/500 [00:37<06:31,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   8%|▊         | 38/500 [00:38<06:57,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   8%|▊         | 39/500 [00:39<07:16,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   8%|▊         | 40/500 [00:40<07:13,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   8%|▊         | 41/500 [00:41<07:12,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   8%|▊         | 42/500 [00:42<07:45,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   9%|▊         | 43/500 [00:42<06:40,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   9%|▉         | 44/500 [00:44<07:22,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   9%|▉         | 45/500 [00:44<07:15,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   9%|▉         | 46/500 [00:46<07:43,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:   9%|▉         | 47/500 [00:47<08:05,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  10%|▉         | 48/500 [00:47<07:00,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  10%|▉         | 49/500 [00:48<07:01,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  10%|█         | 50/500 [00:50<07:36,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  10%|█         | 51/500 [00:50<06:33,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  10%|█         | 52/500 [00:51<05:55,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  11%|█         | 53/500 [00:52<06:49,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  11%|█         | 54/500 [00:53<07:05,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  11%|█         | 55/500 [00:54<06:23,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  11%|█         | 56/500 [00:55<06:46,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  11%|█▏        | 57/500 [00:56<07:20,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  12%|█▏        | 58/500 [00:57<07:12,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  12%|█▏        | 59/500 [00:58<07:36,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  12%|█▏        | 60/500 [00:59<07:37,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  12%|█▏        | 61/500 [01:00<06:32,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  12%|█▏        | 62/500 [01:01<07:09,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  13%|█▎        | 63/500 [01:02<07:03,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  13%|█▎        | 64/500 [01:03<07:30,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  13%|█▎        | 65/500 [01:04<08:22,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  13%|█▎        | 66/500 [01:05<07:53,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  13%|█▎        | 67/500 [01:06<08:05,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  14%|█▎        | 68/500 [01:07<07:47,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  14%|█▍        | 69/500 [01:08<06:38,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  14%|█▍        | 70/500 [01:09<07:13,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  14%|█▍        | 71/500 [01:10<07:36,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  14%|█▍        | 72/500 [01:12<07:52,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  15%|█▍        | 73/500 [01:13<08:01,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  15%|█▍        | 74/500 [01:14<08:06,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  15%|█▌        | 75/500 [01:15<08:11,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  15%|█▌        | 76/500 [01:16<08:14,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  15%|█▌        | 77/500 [01:17<07:01,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  16%|█▌        | 78/500 [01:17<05:57,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  16%|█▌        | 79/500 [01:19<06:38,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  16%|█▌        | 80/500 [01:20<07:07,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  16%|█▌        | 81/500 [01:21<07:27,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  16%|█▋        | 82/500 [01:22<06:21,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  17%|█▋        | 83/500 [01:23<06:55,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  17%|█▋        | 84/500 [01:24<06:29,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  17%|█▋        | 85/500 [01:25<07:00,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  17%|█▋        | 86/500 [01:26<07:23,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  17%|█▋        | 87/500 [01:27<07:39,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  18%|█▊        | 88/500 [01:28<06:22,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  18%|█▊        | 89/500 [01:29<06:53,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  18%|█▊        | 90/500 [01:30<06:58,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  18%|█▊        | 91/500 [01:31<07:17,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  18%|█▊        | 92/500 [01:32<07:01,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  19%|█▊        | 93/500 [01:33<06:47,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  19%|█▉        | 94/500 [01:34<06:40,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  19%|█▉        | 95/500 [01:35<06:33,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  19%|█▉        | 96/500 [01:36<06:30,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  19%|█▉        | 97/500 [01:37<06:56,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  20%|█▉        | 98/500 [01:38<07:15,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  20%|█▉        | 99/500 [01:39<06:59,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  20%|██        | 100/500 [01:40<07:17,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  20%|██        | 101/500 [01:41<06:11,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  20%|██        | 102/500 [01:42<06:41,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  21%|██        | 103/500 [01:43<07:01,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  21%|██        | 104/500 [01:44<07:14,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  21%|██        | 105/500 [01:45<07:07,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  21%|██        | 106/500 [01:47<07:18,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  21%|██▏       | 107/500 [01:48<07:09,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  22%|██▏       | 108/500 [01:49<07:20,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  22%|██▏       | 109/500 [01:50<07:29,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  22%|██▏       | 110/500 [01:51<07:15,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  22%|██▏       | 111/500 [01:53<07:46,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  22%|██▏       | 112/500 [01:54<07:43,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  23%|██▎       | 113/500 [01:55<07:39,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  23%|██▎       | 114/500 [01:56<07:38,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  23%|██▎       | 115/500 [01:57<06:24,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  23%|██▎       | 116/500 [01:58<06:17,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  23%|██▎       | 117/500 [01:58<05:26,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  24%|██▎       | 118/500 [01:59<06:03,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  24%|██▍       | 119/500 [02:00<05:59,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  24%|██▍       | 120/500 [02:01<05:59,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  24%|██▍       | 121/500 [02:02<06:27,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  24%|██▍       | 122/500 [02:03<06:28,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  25%|██▍       | 123/500 [02:05<06:45,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  25%|██▍       | 124/500 [02:06<06:41,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  25%|██▌       | 125/500 [02:07<06:55,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  25%|██▌       | 126/500 [02:08<06:02,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  25%|██▌       | 127/500 [02:09<06:07,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  26%|██▌       | 128/500 [02:10<06:29,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  26%|██▌       | 129/500 [02:11<06:17,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  26%|██▌       | 130/500 [02:12<06:10,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  26%|██▌       | 131/500 [02:13<06:30,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  26%|██▋       | 132/500 [02:14<06:42,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  27%|██▋       | 133/500 [02:15<06:52,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  27%|██▋       | 134/500 [02:16<07:04,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  27%|██▋       | 135/500 [02:17<05:56,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  27%|██▋       | 136/500 [02:18<06:02,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  27%|██▋       | 137/500 [02:19<05:54,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  28%|██▊       | 138/500 [02:19<04:29,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  28%|██▊       | 139/500 [02:20<05:01,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  28%|██▊       | 140/500 [02:21<05:38,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  28%|██▊       | 141/500 [02:22<05:38,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  28%|██▊       | 142/500 [02:23<04:49,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  29%|██▊       | 143/500 [02:24<05:30,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  29%|██▉       | 144/500 [02:25<05:57,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  29%|██▉       | 145/500 [02:26<06:18,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  29%|██▉       | 146/500 [02:27<05:23,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  29%|██▉       | 147/500 [02:28<05:26,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  30%|██▉       | 148/500 [02:29<05:54,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  30%|██▉       | 149/500 [02:30<05:46,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  30%|███       | 150/500 [02:31<06:06,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  30%|███       | 151/500 [02:32<06:20,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  30%|███       | 152/500 [02:34<06:29,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  31%|███       | 153/500 [02:35<06:19,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  31%|███       | 154/500 [02:36<06:29,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  31%|███       | 155/500 [02:37<06:09,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  31%|███       | 156/500 [02:38<05:51,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  31%|███▏      | 157/500 [02:39<06:12,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  32%|███▏      | 158/500 [02:40<06:23,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  32%|███▏      | 159/500 [02:41<05:24,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  32%|███▏      | 160/500 [02:41<04:42,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  32%|███▏      | 161/500 [02:42<04:54,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  32%|███▏      | 162/500 [02:43<05:28,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  33%|███▎      | 163/500 [02:44<04:49,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  33%|███▎      | 164/500 [02:44<03:47,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  33%|███▎      | 165/500 [02:45<03:18,  1.69it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  33%|███▎      | 166/500 [02:46<04:01,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  33%|███▎      | 167/500 [02:47<04:45,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  34%|███▎      | 168/500 [02:48<04:24,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  34%|███▍      | 169/500 [02:48<04:37,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  34%|███▍      | 170/500 [02:49<04:08,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  34%|███▍      | 171/500 [02:50<03:48,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  34%|███▍      | 172/500 [02:51<04:24,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  35%|███▍      | 173/500 [02:52<05:02,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  35%|███▍      | 174/500 [02:53<05:27,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  35%|███▌      | 175/500 [02:54<04:47,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  35%|███▌      | 176/500 [02:55<04:52,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  35%|███▌      | 177/500 [02:56<05:20,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  36%|███▌      | 178/500 [02:57<05:24,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  36%|███▌      | 179/500 [02:58<05:42,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  36%|███▌      | 180/500 [02:59<05:55,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  36%|███▌      | 181/500 [03:00<05:58,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  36%|███▋      | 182/500 [03:02<06:05,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  37%|███▋      | 183/500 [03:03<05:45,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  37%|███▋      | 184/500 [03:04<05:40,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  37%|███▋      | 185/500 [03:05<05:50,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  37%|███▋      | 186/500 [03:06<05:42,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  37%|███▋      | 187/500 [03:07<05:29,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  38%|███▊      | 188/500 [03:07<04:36,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  38%|███▊      | 189/500 [03:08<04:40,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  38%|███▊      | 190/500 [03:09<05:05,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  38%|███▊      | 191/500 [03:10<05:05,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  38%|███▊      | 192/500 [03:11<05:02,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  39%|███▊      | 193/500 [03:12<05:05,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  39%|███▉      | 194/500 [03:13<04:23,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  39%|███▉      | 195/500 [03:14<03:52,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  39%|███▉      | 196/500 [03:15<04:30,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  39%|███▉      | 197/500 [03:16<04:55,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  40%|███▉      | 198/500 [03:17<05:00,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  40%|███▉      | 199/500 [03:18<05:16,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  40%|████      | 200/500 [03:19<05:13,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  40%|████      | 201/500 [03:20<05:02,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  40%|████      | 202/500 [03:21<05:16,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  41%|████      | 203/500 [03:22<05:26,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  41%|████      | 204/500 [03:23<04:10,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  41%|████      | 205/500 [03:24<04:18,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  41%|████      | 206/500 [03:25<04:44,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  41%|████▏     | 207/500 [03:26<04:39,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  42%|████▏     | 208/500 [03:27<04:37,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  42%|████▏     | 209/500 [03:28<04:35,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  42%|████▏     | 210/500 [03:29<04:56,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  42%|████▏     | 211/500 [03:30<04:48,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  42%|████▏     | 212/500 [03:31<05:04,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  43%|████▎     | 213/500 [03:32<05:14,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  43%|████▎     | 214/500 [03:33<05:04,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  43%|████▎     | 215/500 [03:34<04:52,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  43%|████▎     | 216/500 [03:35<05:04,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  43%|████▎     | 217/500 [03:36<05:13,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  44%|████▎     | 218/500 [03:37<04:58,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  44%|████▍     | 219/500 [03:38<04:15,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  44%|████▍     | 220/500 [03:39<04:29,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  44%|████▍     | 221/500 [03:40<04:26,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  44%|████▍     | 222/500 [03:41<04:31,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  45%|████▍     | 223/500 [03:42<04:04,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  45%|████▍     | 224/500 [03:43<04:16,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  45%|████▌     | 225/500 [03:43<03:45,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  45%|████▌     | 226/500 [03:44<04:00,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  45%|████▌     | 227/500 [03:45<04:25,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  46%|████▌     | 228/500 [03:47<04:40,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  46%|████▌     | 229/500 [03:47<04:00,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  46%|████▌     | 230/500 [03:48<03:31,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  46%|████▌     | 231/500 [03:48<03:11,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  46%|████▋     | 232/500 [03:49<03:29,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  47%|████▋     | 233/500 [03:50<04:02,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  47%|████▋     | 234/500 [03:52<04:24,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  47%|████▋     | 235/500 [03:53<04:39,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  47%|████▋     | 236/500 [03:54<04:56,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  47%|████▋     | 237/500 [03:55<04:10,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  48%|████▊     | 238/500 [03:56<04:07,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  48%|████▊     | 239/500 [03:57<04:05,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  48%|████▊     | 240/500 [03:57<03:52,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  48%|████▊     | 241/500 [03:58<04:13,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  48%|████▊     | 242/500 [03:59<04:09,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  49%|████▊     | 243/500 [04:00<03:58,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  49%|████▉     | 244/500 [04:01<03:57,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  49%|████▉     | 245/500 [04:02<03:58,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  49%|████▉     | 246/500 [04:03<04:17,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  49%|████▉     | 247/500 [04:04<04:11,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  50%|████▉     | 248/500 [04:05<04:15,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  50%|████▉     | 249/500 [04:07<04:27,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  50%|█████     | 250/500 [04:08<04:34,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  50%|█████     | 251/500 [04:09<04:39,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  50%|█████     | 252/500 [04:10<04:42,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  51%|█████     | 253/500 [04:11<03:49,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  51%|█████     | 254/500 [04:11<03:49,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  51%|█████     | 255/500 [04:12<03:47,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  51%|█████     | 256/500 [04:14<04:05,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  51%|█████▏    | 257/500 [04:15<04:02,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  52%|█████▏    | 258/500 [04:16<04:33,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  52%|█████▏    | 259/500 [04:17<04:35,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  52%|█████▏    | 260/500 [04:18<03:51,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  52%|█████▏    | 261/500 [04:19<04:04,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  52%|█████▏    | 262/500 [04:20<04:14,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  53%|█████▎    | 263/500 [04:21<04:03,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  53%|█████▎    | 264/500 [04:22<04:14,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  53%|█████▎    | 265/500 [04:23<04:03,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  53%|█████▎    | 266/500 [04:24<04:13,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  53%|█████▎    | 267/500 [04:25<04:02,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  54%|█████▎    | 268/500 [04:26<03:26,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  54%|█████▍    | 269/500 [04:27<03:28,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  54%|█████▍    | 270/500 [04:29<04:44,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  54%|█████▍    | 271/500 [04:30<04:22,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  54%|█████▍    | 272/500 [04:31<04:07,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  55%|█████▍    | 273/500 [04:31<03:29,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  55%|█████▍    | 274/500 [04:32<03:02,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  55%|█████▌    | 275/500 [04:33<03:16,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  55%|█████▌    | 276/500 [04:33<02:53,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  55%|█████▌    | 277/500 [04:34<03:19,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  56%|█████▌    | 278/500 [04:36<03:37,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  56%|█████▌    | 279/500 [04:37<03:48,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  56%|█████▌    | 280/500 [04:38<03:47,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  56%|█████▌    | 281/500 [04:39<03:56,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  56%|█████▋    | 282/500 [04:40<03:20,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  57%|█████▋    | 283/500 [04:41<03:38,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  57%|█████▋    | 284/500 [04:42<03:39,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  57%|█████▋    | 285/500 [04:43<03:33,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  57%|█████▋    | 286/500 [04:43<03:01,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  57%|█████▋    | 287/500 [04:44<03:06,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  58%|█████▊    | 288/500 [04:45<03:08,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  58%|█████▊    | 289/500 [04:46<02:45,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  58%|█████▊    | 290/500 [04:46<02:29,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  58%|█████▊    | 291/500 [04:47<02:58,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  58%|█████▊    | 292/500 [04:49<03:16,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  59%|█████▊    | 293/500 [04:50<03:22,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  59%|█████▉    | 294/500 [04:51<03:18,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  59%|█████▉    | 295/500 [04:52<03:22,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  59%|█████▉    | 296/500 [04:53<03:33,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  59%|█████▉    | 297/500 [04:54<03:39,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  60%|█████▉    | 298/500 [04:54<03:05,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  60%|█████▉    | 299/500 [04:55<03:04,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  60%|██████    | 300/500 [04:56<02:41,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  60%|██████    | 301/500 [04:56<02:22,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  60%|██████    | 302/500 [04:58<02:49,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  61%|██████    | 303/500 [04:59<03:07,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  61%|██████    | 304/500 [05:00<03:19,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  61%|██████    | 305/500 [05:01<03:23,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  61%|██████    | 306/500 [05:02<02:55,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  61%|██████▏   | 307/500 [05:03<03:03,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  62%|██████▏   | 308/500 [05:04<03:16,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  62%|██████▏   | 309/500 [05:05<03:10,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  62%|██████▏   | 310/500 [05:06<03:11,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  62%|██████▏   | 311/500 [05:07<03:19,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  62%|██████▏   | 312/500 [05:08<03:25,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  63%|██████▎   | 313/500 [05:09<03:29,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  63%|██████▎   | 314/500 [05:11<03:31,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  63%|██████▎   | 315/500 [05:12<03:32,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  63%|██████▎   | 316/500 [05:12<02:58,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  63%|██████▎   | 317/500 [05:13<03:09,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  64%|██████▎   | 318/500 [05:15<03:16,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  64%|██████▍   | 319/500 [05:16<03:13,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  64%|██████▍   | 320/500 [05:17<03:19,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  64%|██████▍   | 321/500 [05:18<03:22,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  64%|██████▍   | 322/500 [05:19<03:15,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  65%|██████▍   | 323/500 [05:20<03:11,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  65%|██████▍   | 324/500 [05:21<02:41,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  65%|██████▌   | 325/500 [05:22<02:55,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  65%|██████▌   | 326/500 [05:23<02:54,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  65%|██████▌   | 327/500 [05:24<02:53,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  66%|██████▌   | 328/500 [05:25<03:01,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  66%|██████▌   | 329/500 [05:26<03:08,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  66%|██████▌   | 330/500 [05:27<03:04,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  66%|██████▌   | 331/500 [05:28<02:33,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  66%|██████▋   | 332/500 [05:29<02:46,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  67%|██████▋   | 333/500 [05:29<02:06,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  67%|██████▋   | 334/500 [05:30<01:59,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  67%|██████▋   | 335/500 [05:31<02:09,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  67%|██████▋   | 336/500 [05:32<02:54,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  67%|██████▋   | 337/500 [05:33<02:27,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  68%|██████▊   | 338/500 [05:34<02:39,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  68%|██████▊   | 339/500 [05:35<02:40,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  68%|██████▊   | 340/500 [05:36<02:49,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  68%|██████▊   | 341/500 [05:38<02:54,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  68%|██████▊   | 342/500 [05:39<02:48,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  69%|██████▊   | 343/500 [05:40<02:52,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  69%|██████▉   | 344/500 [05:41<02:44,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  69%|██████▉   | 345/500 [05:42<02:39,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  69%|██████▉   | 346/500 [05:42<02:16,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  69%|██████▉   | 347/500 [05:43<02:17,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  70%|██████▉   | 348/500 [05:44<02:30,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  70%|██████▉   | 349/500 [05:45<02:26,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  70%|███████   | 350/500 [05:46<02:24,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  70%|███████   | 351/500 [05:47<02:33,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  70%|███████   | 352/500 [05:49<02:34,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  71%|███████   | 353/500 [05:50<02:39,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  71%|███████   | 354/500 [05:51<02:32,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  71%|███████   | 355/500 [05:51<02:06,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  71%|███████   | 356/500 [05:52<02:08,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  71%|███████▏  | 357/500 [05:53<02:20,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  72%|███████▏  | 358/500 [05:54<02:19,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  72%|███████▏  | 359/500 [05:55<02:01,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  72%|███████▏  | 360/500 [05:55<01:47,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  72%|███████▏  | 361/500 [05:57<02:03,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  72%|███████▏  | 362/500 [05:58<02:14,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  73%|███████▎  | 363/500 [05:59<02:22,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  73%|███████▎  | 364/500 [06:00<02:27,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  73%|███████▎  | 365/500 [06:01<02:16,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  73%|███████▎  | 366/500 [06:02<02:30,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  73%|███████▎  | 367/500 [06:03<02:26,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  74%|███████▎  | 368/500 [06:04<02:19,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  74%|███████▍  | 369/500 [06:05<02:07,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  74%|███████▍  | 370/500 [06:06<02:01,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  74%|███████▍  | 371/500 [06:06<01:45,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  74%|███████▍  | 372/500 [06:07<01:49,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  75%|███████▍  | 373/500 [06:09<02:00,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  75%|███████▍  | 374/500 [06:10<02:02,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  75%|███████▌  | 375/500 [06:11<02:00,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  75%|███████▌  | 376/500 [06:12<01:58,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  75%|███████▌  | 377/500 [06:13<02:13,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  76%|███████▌  | 378/500 [06:13<01:52,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  76%|███████▌  | 379/500 [06:14<01:36,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  76%|███████▌  | 380/500 [06:15<01:50,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  76%|███████▌  | 381/500 [06:16<01:59,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  76%|███████▋  | 382/500 [06:18<02:05,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  77%|███████▋  | 383/500 [06:19<02:08,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  77%|███████▋  | 384/500 [06:20<02:01,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  77%|███████▋  | 385/500 [06:21<01:58,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  77%|███████▋  | 386/500 [06:21<01:40,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  77%|███████▋  | 387/500 [06:22<01:42,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  78%|███████▊  | 388/500 [06:23<01:46,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  78%|███████▊  | 389/500 [06:25<01:59,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  78%|███████▊  | 390/500 [06:26<02:01,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  78%|███████▊  | 391/500 [06:27<02:03,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  78%|███████▊  | 392/500 [06:28<01:46,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  79%|███████▊  | 393/500 [06:29<01:47,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  79%|███████▉  | 394/500 [06:30<01:44,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  79%|███████▉  | 395/500 [06:30<01:29,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  79%|███████▉  | 396/500 [06:31<01:38,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  79%|███████▉  | 397/500 [06:32<01:39,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  80%|███████▉  | 398/500 [06:33<01:24,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  80%|███████▉  | 399/500 [06:34<01:34,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  80%|████████  | 400/500 [06:34<01:18,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  80%|████████  | 401/500 [06:35<01:14,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  80%|████████  | 402/500 [06:36<01:26,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  81%|████████  | 403/500 [06:37<01:14,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  81%|████████  | 404/500 [06:38<01:18,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  81%|████████  | 405/500 [06:39<01:28,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  81%|████████  | 406/500 [06:40<01:34,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  81%|████████▏ | 407/500 [06:41<01:33,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  82%|████████▏ | 408/500 [06:41<01:11,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  82%|████████▏ | 409/500 [06:42<01:15,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  82%|████████▏ | 410/500 [06:43<01:17,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  82%|████████▏ | 411/500 [06:44<01:25,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  82%|████████▏ | 412/500 [06:45<01:24,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  83%|████████▎ | 413/500 [06:46<01:23,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  83%|████████▎ | 414/500 [06:48<01:34,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  83%|████████▎ | 415/500 [06:49<01:29,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  83%|████████▎ | 416/500 [06:50<01:40,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  83%|████████▎ | 417/500 [06:51<01:32,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  84%|████████▎ | 418/500 [06:52<01:29,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  84%|████████▍ | 419/500 [06:53<01:24,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  84%|████████▍ | 420/500 [06:54<01:26,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  84%|████████▍ | 421/500 [06:55<01:13,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  84%|████████▍ | 422/500 [06:56<01:17,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  85%|████████▍ | 423/500 [06:57<01:15,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  85%|████████▍ | 424/500 [06:58<01:14,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  85%|████████▌ | 425/500 [06:59<01:13,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  85%|████████▌ | 426/500 [07:00<01:04,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  85%|████████▌ | 427/500 [07:01<01:10,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  86%|████████▌ | 428/500 [07:02<01:14,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  86%|████████▌ | 429/500 [07:03<01:13,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  86%|████████▌ | 430/500 [07:04<01:17,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  86%|████████▌ | 431/500 [07:05<01:04,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  86%|████████▋ | 432/500 [07:06<01:09,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  87%|████████▋ | 433/500 [07:07<01:11,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  87%|████████▋ | 434/500 [07:08<01:13,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  87%|████████▋ | 435/500 [07:09<01:09,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  87%|████████▋ | 436/500 [07:10<00:57,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  87%|████████▋ | 437/500 [07:11<01:02,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  88%|████████▊ | 438/500 [07:12<01:05,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  88%|████████▊ | 439/500 [07:13<01:06,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  88%|████████▊ | 440/500 [07:15<01:05,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  88%|████████▊ | 441/500 [07:16<01:02,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  88%|████████▊ | 442/500 [07:17<01:00,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  89%|████████▊ | 443/500 [07:18<01:04,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  89%|████████▉ | 444/500 [07:19<01:04,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  89%|████████▉ | 445/500 [07:20<01:04,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  89%|████████▉ | 446/500 [07:21<01:03,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  89%|████████▉ | 447/500 [07:23<01:00,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  90%|████████▉ | 448/500 [07:23<00:56,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  90%|████████▉ | 449/500 [07:25<00:56,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  90%|█████████ | 450/500 [07:25<00:47,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  90%|█████████ | 451/500 [07:26<00:46,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  90%|█████████ | 452/500 [07:27<00:45,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  91%|█████████ | 453/500 [07:28<00:39,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  91%|█████████ | 454/500 [07:29<00:40,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  91%|█████████ | 455/500 [07:29<00:35,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  91%|█████████ | 456/500 [07:30<00:36,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  91%|█████████▏| 457/500 [07:31<00:37,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  92%|█████████▏| 458/500 [07:32<00:32,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  92%|█████████▏| 459/500 [07:33<00:37,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  92%|█████████▏| 460/500 [07:34<00:33,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  92%|█████████▏| 461/500 [07:34<00:33,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  92%|█████████▏| 462/500 [07:36<00:35,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  93%|█████████▎| 463/500 [07:37<00:37,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  93%|█████████▎| 464/500 [07:38<00:38,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  93%|█████████▎| 465/500 [07:39<00:31,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  93%|█████████▎| 466/500 [07:39<00:27,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  93%|█████████▎| 467/500 [07:40<00:29,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  94%|█████████▎| 468/500 [07:41<00:29,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  94%|█████████▍| 469/500 [07:42<00:29,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  94%|█████████▍| 470/500 [07:43<00:30,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  94%|█████████▍| 471/500 [07:44<00:24,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  94%|█████████▍| 472/500 [07:45<00:26,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  95%|█████████▍| 473/500 [07:46<00:25,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  95%|█████████▍| 474/500 [07:47<00:26,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  95%|█████████▌| 475/500 [07:48<00:25,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  95%|█████████▌| 476/500 [07:49<00:21,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  95%|█████████▌| 477/500 [07:50<00:20,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  96%|█████████▌| 478/500 [07:51<00:20,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  96%|█████████▌| 479/500 [07:52<00:21,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  96%|█████████▌| 480/500 [07:53<00:20,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  96%|█████████▌| 481/500 [07:54<00:20,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  96%|█████████▋| 482/500 [07:55<00:19,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  97%|█████████▋| 483/500 [07:56<00:18,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  97%|█████████▋| 484/500 [07:58<00:17,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  97%|█████████▋| 485/500 [07:59<00:16,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  97%|█████████▋| 486/500 [08:00<00:15,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  97%|█████████▋| 487/500 [08:00<00:12,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  98%|█████████▊| 488/500 [08:02<00:12,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  98%|█████████▊| 489/500 [08:02<00:09,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  98%|█████████▊| 490/500 [08:03<00:08,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  98%|█████████▊| 491/500 [08:03<00:06,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  98%|█████████▊| 492/500 [08:05<00:07,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  99%|█████████▊| 493/500 [08:06<00:06,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  99%|█████████▉| 494/500 [08:07<00:05,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  99%|█████████▉| 495/500 [08:08<00:05,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  99%|█████████▉| 496/500 [08:08<00:03,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6:  99%|█████████▉| 497/500 [08:09<00:02,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6: 100%|█████████▉| 498/500 [08:10<00:01,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6: 100%|█████████▉| 499/500 [08:11<00:00,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 6: 100%|██████████| 500/500 [08:12<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2a17dc35254ed5ad32dc73199589a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46ac38b2d204541a67f3cfa0b7d77dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45f7feca5254ca6ab8f2cf0e1df3db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c75309cfb58485798d5ef6ed1997389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcacd84095034b5dbde70fd5239bdbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345caf17b2994c2ab6994d790505f516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 6 Results on 1000 samples:\n",
      "BLEU: 0.0036\n",
      "ROUGE-1: 0.0972\n",
      "ROUGE-2: 0.006\n",
      "ROUGE-L: 0.076\n",
      "BERTScore (F1): 0.8242\n"
     ]
    }
   ],
   "source": [
    "# Trial 6 Evaluation Script (1000 samples)\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load 1000-sample evaluation set\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_3000.jsonl\", split=\"train\")\n",
    "\n",
    "# Load Trial 6 fine-tuned model and tokenizer\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-3000-trial6\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Prepare predictions and references\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"🔍 Evaluating Trial 6\"):\n",
    "    input_text = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "# Compute and print metrics\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "print(\"\\n📊 Trial 6 Results on 1000 samples:\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0iW779nk43i"
   },
   "source": [
    "# Evaluation Trial 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0ac1a7702ec74afcbcdf1ef4157dcd24",
      "314dd0d92295417581d60e011a55eec7",
      "346ab306737a4039aa5d4043eedbb3ca",
      "bbac81a9604b4742b9bf92b200ebf71c",
      "b7d10e7ce1bd4152b872bea4378d8a1d",
      "59c8d0b75658406d9530c7121cd4f52c",
      "40b302e833604484be04b510e99f090f",
      "65c51c0f0b714fba9b83c6bd8fb24b41",
      "9a244497fba34358ba620ceac8e9f19c",
      "57f297afdb7f46d2925f6ffb3bd1d37c",
      "4d2fa41a9be74ca2a71acad523474fc3"
     ]
    },
    "executionInfo": {
     "elapsed": 1772500,
     "status": "ok",
     "timestamp": 1744307315350,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "ArWZnwaxk-3a",
    "outputId": "6e66ef7d-75ad-4a78-a2e6-749ac5c97b69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac1a7702ec74afcbcdf1ef4157dcd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🔍 Evaluating Trial 7:   0%|          | 0/1500 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   0%|          | 1/1500 [00:02<51:38,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   0%|          | 2/1500 [00:03<37:16,  1.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   0%|          | 3/1500 [00:03<26:35,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   0%|          | 4/1500 [00:04<27:00,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   0%|          | 5/1500 [00:05<27:11,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   0%|          | 6/1500 [00:07<30:12,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   0%|          | 7/1500 [00:08<29:19,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 8/1500 [00:09<28:36,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 9/1500 [00:11<30:54,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 10/1500 [00:11<28:08,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 11/1500 [00:12<27:20,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 12/1500 [00:14<29:51,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 13/1500 [00:15<31:22,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 14/1500 [00:17<32:11,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 15/1500 [00:18<33:20,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 16/1500 [00:19<32:41,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 17/1500 [00:20<30:39,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|          | 18/1500 [00:21<29:17,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|▏         | 19/1500 [00:23<29:57,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|▏         | 20/1500 [00:24<31:28,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|▏         | 21/1500 [00:25<30:26,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   1%|▏         | 22/1500 [00:26<26:14,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 23/1500 [00:27<28:23,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 24/1500 [00:28<23:17,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 25/1500 [00:28<21:08,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 26/1500 [00:30<24:42,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 27/1500 [00:31<25:18,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 28/1500 [00:32<27:06,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 29/1500 [00:33<28:16,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 30/1500 [00:35<30:19,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 31/1500 [00:36<31:49,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 32/1500 [00:38<33:04,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 33/1500 [00:39<32:57,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 34/1500 [00:40<32:51,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 35/1500 [00:42<31:04,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 36/1500 [00:43<30:29,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   2%|▏         | 37/1500 [00:44<30:51,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 38/1500 [00:46<32:06,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 39/1500 [00:46<27:09,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 40/1500 [00:47<27:03,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 41/1500 [00:49<28:48,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 42/1500 [00:50<29:58,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 43/1500 [00:51<28:37,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 44/1500 [00:52<30:27,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 45/1500 [00:53<28:28,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 46/1500 [00:55<29:59,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 47/1500 [00:56<30:17,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 48/1500 [00:58<31:17,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 49/1500 [00:59<31:13,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 50/1500 [01:00<30:29,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 51/1500 [01:01<29:01,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   3%|▎         | 52/1500 [01:02<26:58,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▎         | 53/1500 [01:03<26:03,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▎         | 54/1500 [01:04<28:20,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▎         | 55/1500 [01:05<27:44,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▎         | 56/1500 [01:07<27:35,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 57/1500 [01:08<28:36,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 58/1500 [01:09<27:50,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 59/1500 [01:10<28:43,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 60/1500 [01:11<27:33,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 61/1500 [01:12<26:17,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 62/1500 [01:14<28:52,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 63/1500 [01:15<30:07,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 64/1500 [01:16<26:52,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 65/1500 [01:17<27:19,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 66/1500 [01:18<26:31,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   4%|▍         | 67/1500 [01:19<28:07,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▍         | 68/1500 [01:21<27:29,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▍         | 69/1500 [01:22<28:47,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▍         | 70/1500 [01:23<27:35,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▍         | 71/1500 [01:24<26:42,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▍         | 72/1500 [01:25<27:11,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▍         | 73/1500 [01:26<28:04,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▍         | 74/1500 [01:27<23:33,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▌         | 75/1500 [01:28<25:38,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▌         | 76/1500 [01:30<27:08,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▌         | 77/1500 [01:31<29:11,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▌         | 78/1500 [01:32<29:32,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▌         | 79/1500 [01:33<28:07,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▌         | 80/1500 [01:34<24:14,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▌         | 81/1500 [01:35<27:12,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   5%|▌         | 82/1500 [01:37<26:42,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 83/1500 [01:38<27:12,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 84/1500 [01:39<26:20,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 85/1500 [01:40<27:54,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 86/1500 [01:41<26:56,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 87/1500 [01:42<26:13,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 88/1500 [01:43<27:19,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 89/1500 [01:45<26:43,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 90/1500 [01:45<24:14,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 91/1500 [01:46<24:38,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 92/1500 [01:48<27:17,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▌         | 93/1500 [01:49<26:49,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▋         | 94/1500 [01:50<23:20,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▋         | 95/1500 [01:51<23:40,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▋         | 96/1500 [01:52<26:08,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   6%|▋         | 97/1500 [01:53<27:23,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 98/1500 [01:54<26:52,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 99/1500 [01:55<26:09,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 100/1500 [01:57<26:40,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 101/1500 [01:58<28:29,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 102/1500 [01:59<29:24,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 103/1500 [02:01<30:15,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 104/1500 [02:02<30:10,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 105/1500 [02:03<30:52,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 106/1500 [02:05<28:50,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 107/1500 [02:06<29:31,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 108/1500 [02:07<25:13,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 109/1500 [02:08<25:20,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 110/1500 [02:09<27:17,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 111/1500 [02:10<24:52,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   7%|▋         | 112/1500 [02:11<24:41,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 113/1500 [02:12<25:12,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 114/1500 [02:13<25:00,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 115/1500 [02:14<26:20,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 116/1500 [02:16<27:57,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 117/1500 [02:17<26:44,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 118/1500 [02:18<25:50,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 119/1500 [02:19<27:22,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 120/1500 [02:21<28:24,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 121/1500 [02:22<28:45,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 122/1500 [02:23<29:24,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 123/1500 [02:24<24:22,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 124/1500 [02:25<25:14,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 125/1500 [02:26<25:05,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 126/1500 [02:27<24:59,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   8%|▊         | 127/1500 [02:28<25:36,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▊         | 128/1500 [02:30<27:43,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▊         | 129/1500 [02:31<28:34,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▊         | 130/1500 [02:32<29:45,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▊         | 131/1500 [02:33<28:00,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 132/1500 [02:34<22:20,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 133/1500 [02:35<21:08,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 134/1500 [02:36<21:43,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 135/1500 [02:37<24:27,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 136/1500 [02:39<26:57,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 137/1500 [02:40<27:42,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 138/1500 [02:41<28:15,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 139/1500 [02:42<28:33,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 140/1500 [02:44<29:48,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 141/1500 [02:45<30:01,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:   9%|▉         | 142/1500 [02:47<30:52,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|▉         | 143/1500 [02:48<29:45,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|▉         | 144/1500 [02:49<28:28,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|▉         | 145/1500 [02:50<26:59,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|▉         | 146/1500 [02:51<27:40,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|▉         | 147/1500 [02:53<28:05,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|▉         | 148/1500 [02:54<29:22,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|▉         | 149/1500 [02:55<29:13,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|█         | 150/1500 [02:56<24:47,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|█         | 151/1500 [02:57<21:42,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|█         | 152/1500 [02:58<24:44,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|█         | 153/1500 [02:59<24:00,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|█         | 154/1500 [03:00<23:44,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|█         | 155/1500 [03:01<25:13,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|█         | 156/1500 [03:02<24:19,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  10%|█         | 157/1500 [03:03<21:21,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 158/1500 [03:04<23:35,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 159/1500 [03:06<25:07,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 160/1500 [03:07<26:24,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 161/1500 [03:08<27:21,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 162/1500 [03:10<28:12,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 163/1500 [03:11<26:22,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 164/1500 [03:12<27:30,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 165/1500 [03:13<26:14,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 166/1500 [03:14<25:18,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 167/1500 [03:15<26:15,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█         | 168/1500 [03:16<24:54,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█▏        | 169/1500 [03:17<24:01,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█▏        | 170/1500 [03:19<25:41,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█▏        | 171/1500 [03:20<24:54,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  11%|█▏        | 172/1500 [03:21<24:22,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 173/1500 [03:21<21:23,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 174/1500 [03:22<21:37,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 175/1500 [03:24<24:01,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 176/1500 [03:24<20:27,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 177/1500 [03:25<21:33,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 178/1500 [03:27<23:59,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 179/1500 [03:27<21:06,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 180/1500 [03:29<23:14,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 181/1500 [03:30<24:42,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 182/1500 [03:31<26:45,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 183/1500 [03:33<27:30,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 184/1500 [03:34<26:12,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 185/1500 [03:35<28:04,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 186/1500 [03:36<27:05,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  12%|█▏        | 187/1500 [03:37<24:40,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 188/1500 [03:39<26:23,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 189/1500 [03:40<27:37,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 190/1500 [03:41<27:53,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 191/1500 [03:43<29:01,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 192/1500 [03:44<29:43,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 193/1500 [03:45<27:34,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 194/1500 [03:46<26:55,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 195/1500 [03:48<28:04,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 196/1500 [03:49<26:28,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 197/1500 [03:50<22:43,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 198/1500 [03:50<20:01,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 199/1500 [03:51<21:28,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 200/1500 [03:53<23:41,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 201/1500 [03:54<23:36,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  13%|█▎        | 202/1500 [03:55<25:06,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▎        | 203/1500 [03:56<26:08,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▎        | 204/1500 [03:57<22:28,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▎        | 205/1500 [03:58<22:27,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▎        | 206/1500 [03:59<21:12,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 207/1500 [04:00<21:55,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 208/1500 [04:01<23:35,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 209/1500 [04:02<23:22,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 210/1500 [04:04<24:45,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 211/1500 [04:05<23:57,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 212/1500 [04:06<23:21,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 213/1500 [04:07<25:39,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 214/1500 [04:09<26:33,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 215/1500 [04:10<25:08,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 216/1500 [04:11<26:46,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  14%|█▍        | 217/1500 [04:12<28:18,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▍        | 218/1500 [04:14<26:51,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▍        | 219/1500 [04:15<25:48,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▍        | 220/1500 [04:16<24:26,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▍        | 221/1500 [04:17<25:38,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▍        | 222/1500 [04:18<24:34,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▍        | 223/1500 [04:19<24:09,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▍        | 224/1500 [04:20<23:13,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▌        | 225/1500 [04:21<23:54,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▌        | 226/1500 [04:23<25:12,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▌        | 227/1500 [04:24<24:38,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▌        | 228/1500 [04:25<25:35,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▌        | 229/1500 [04:26<24:35,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▌        | 230/1500 [04:27<25:45,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▌        | 231/1500 [04:29<24:40,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  15%|█▌        | 232/1500 [04:30<25:42,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 233/1500 [04:31<24:41,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 234/1500 [04:32<26:06,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 235/1500 [04:33<24:18,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 236/1500 [04:34<24:30,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 237/1500 [04:36<25:02,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 238/1500 [04:37<26:28,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 239/1500 [04:38<25:08,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 240/1500 [04:40<26:24,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 241/1500 [04:41<27:41,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 242/1500 [04:42<25:58,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▌        | 243/1500 [04:43<25:37,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▋        | 244/1500 [04:45<26:27,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▋        | 245/1500 [04:46<26:57,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▋        | 246/1500 [04:47<25:29,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  16%|█▋        | 247/1500 [04:48<25:58,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 248/1500 [04:50<26:27,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 249/1500 [04:51<25:20,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 250/1500 [04:52<26:40,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 251/1500 [04:53<25:07,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 252/1500 [04:55<26:00,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 253/1500 [04:55<21:39,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 254/1500 [04:57<24:04,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 255/1500 [04:58<24:55,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 256/1500 [04:59<26:07,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 257/1500 [05:00<24:40,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 258/1500 [05:01<21:17,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 259/1500 [05:02<23:08,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 260/1500 [05:03<22:37,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 261/1500 [05:05<23:09,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  17%|█▋        | 262/1500 [05:05<20:14,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 263/1500 [05:06<20:34,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 264/1500 [05:07<20:33,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 265/1500 [05:08<18:24,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 266/1500 [05:08<15:40,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 267/1500 [05:09<15:55,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 268/1500 [05:11<19:54,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 269/1500 [05:12<22:47,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 270/1500 [05:13<23:55,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 271/1500 [05:15<25:08,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 272/1500 [05:16<26:41,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 273/1500 [05:17<22:40,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 274/1500 [05:18<24:34,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 275/1500 [05:20<25:11,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 276/1500 [05:21<26:11,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  18%|█▊        | 277/1500 [05:22<24:28,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▊        | 278/1500 [05:23<22:00,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▊        | 279/1500 [05:24<20:16,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▊        | 280/1500 [05:25<22:24,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▊        | 281/1500 [05:26<23:48,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 282/1500 [05:27<20:38,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 283/1500 [05:28<20:48,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 284/1500 [05:29<18:31,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 285/1500 [05:30<21:06,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 286/1500 [05:31<22:54,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 287/1500 [05:33<24:14,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 288/1500 [05:34<24:47,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 289/1500 [05:35<24:38,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 290/1500 [05:36<21:13,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 291/1500 [05:37<23:29,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  19%|█▉        | 292/1500 [05:39<24:27,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|█▉        | 293/1500 [05:40<25:17,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|█▉        | 294/1500 [05:41<25:47,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|█▉        | 295/1500 [05:43<26:54,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|█▉        | 296/1500 [05:44<27:49,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|█▉        | 297/1500 [05:46<28:04,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|█▉        | 298/1500 [05:47<27:19,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|█▉        | 299/1500 [05:48<25:13,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|██        | 300/1500 [05:49<24:18,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|██        | 301/1500 [05:50<24:10,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|██        | 302/1500 [05:51<23:24,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|██        | 303/1500 [05:53<25:02,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|██        | 304/1500 [05:53<20:49,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|██        | 305/1500 [05:54<20:50,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|██        | 306/1500 [05:55<20:50,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  20%|██        | 307/1500 [05:57<23:06,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 308/1500 [05:58<22:25,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 309/1500 [05:59<20:51,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 310/1500 [06:00<21:44,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 311/1500 [06:01<21:47,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 312/1500 [06:03<23:57,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 313/1500 [06:03<20:36,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 314/1500 [06:04<20:16,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 315/1500 [06:05<17:26,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 316/1500 [06:06<20:29,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 317/1500 [06:07<20:33,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██        | 318/1500 [06:09<22:20,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██▏       | 319/1500 [06:10<21:47,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██▏       | 320/1500 [06:11<24:21,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██▏       | 321/1500 [06:12<24:54,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  21%|██▏       | 322/1500 [06:14<25:37,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 323/1500 [06:15<25:50,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 324/1500 [06:16<24:26,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 325/1500 [06:18<24:41,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 326/1500 [06:19<23:32,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 327/1500 [06:20<22:37,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 328/1500 [06:21<21:49,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 329/1500 [06:22<23:09,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 330/1500 [06:23<23:48,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 331/1500 [06:25<24:44,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 332/1500 [06:26<22:33,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 333/1500 [06:27<21:41,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 334/1500 [06:27<19:00,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 335/1500 [06:28<19:40,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 336/1500 [06:30<20:14,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  22%|██▏       | 337/1500 [06:31<20:33,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 338/1500 [06:32<22:44,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 339/1500 [06:33<22:15,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 340/1500 [06:34<18:10,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 341/1500 [06:35<18:48,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 342/1500 [06:36<21:01,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 343/1500 [06:37<22:17,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 344/1500 [06:39<23:57,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 345/1500 [06:40<23:08,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 346/1500 [06:41<23:43,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 347/1500 [06:42<24:01,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 348/1500 [06:44<22:46,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 349/1500 [06:45<23:07,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 350/1500 [06:46<22:11,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 351/1500 [06:47<22:58,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  23%|██▎       | 352/1500 [06:49<24:24,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▎       | 353/1500 [06:50<24:46,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▎       | 354/1500 [06:51<23:36,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▎       | 355/1500 [06:52<24:12,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▎       | 356/1500 [06:53<20:39,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 357/1500 [06:54<20:06,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 358/1500 [06:55<22:14,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 359/1500 [06:57<23:50,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 360/1500 [06:58<23:34,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 361/1500 [06:59<24:36,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 362/1500 [07:01<25:31,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 363/1500 [07:02<25:21,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 364/1500 [07:03<23:57,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 365/1500 [07:04<22:41,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 366/1500 [07:05<21:45,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  24%|██▍       | 367/1500 [07:07<21:06,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▍       | 368/1500 [07:08<22:08,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▍       | 369/1500 [07:09<22:13,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▍       | 370/1500 [07:10<21:29,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▍       | 371/1500 [07:11<18:10,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▍       | 372/1500 [07:12<20:59,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▍       | 373/1500 [07:13<22:20,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▍       | 374/1500 [07:14<21:23,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▌       | 375/1500 [07:16<20:55,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▌       | 376/1500 [07:17<21:58,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▌       | 377/1500 [07:18<20:57,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▌       | 378/1500 [07:19<21:15,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▌       | 379/1500 [07:20<17:56,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▌       | 380/1500 [07:21<19:55,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▌       | 381/1500 [07:22<19:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  25%|██▌       | 382/1500 [07:23<17:29,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 383/1500 [07:23<16:09,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 384/1500 [07:25<19:21,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 385/1500 [07:26<20:44,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 386/1500 [07:27<20:02,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 387/1500 [07:28<21:28,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 388/1500 [07:30<21:58,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 389/1500 [07:31<21:07,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 390/1500 [07:32<20:31,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 391/1500 [07:33<22:05,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 392/1500 [07:34<21:13,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▌       | 393/1500 [07:35<22:20,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▋       | 394/1500 [07:37<21:31,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▋       | 395/1500 [07:38<22:33,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▋       | 396/1500 [07:39<21:34,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  26%|██▋       | 397/1500 [07:40<20:25,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 398/1500 [07:41<21:31,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 399/1500 [07:42<22:05,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 400/1500 [07:44<22:48,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 401/1500 [07:45<22:27,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 402/1500 [07:46<21:13,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 403/1500 [07:47<20:51,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 404/1500 [07:48<20:33,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 405/1500 [07:49<18:10,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 406/1500 [07:50<19:19,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 407/1500 [07:51<19:13,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 408/1500 [07:52<18:52,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 409/1500 [07:53<20:32,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 410/1500 [07:55<21:24,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 411/1500 [07:56<19:02,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  27%|██▋       | 412/1500 [07:56<16:57,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 413/1500 [07:58<19:23,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 414/1500 [07:59<19:17,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 415/1500 [08:00<20:49,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 416/1500 [08:01<22:24,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 417/1500 [08:02<21:18,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 418/1500 [08:04<20:33,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 419/1500 [08:05<21:53,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 420/1500 [08:06<20:09,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 421/1500 [08:07<18:09,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 422/1500 [08:08<18:20,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 423/1500 [08:09<20:16,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 424/1500 [08:10<20:07,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 425/1500 [08:11<17:36,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 426/1500 [08:12<20:11,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  28%|██▊       | 427/1500 [08:13<16:35,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▊       | 428/1500 [08:13<15:03,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▊       | 429/1500 [08:14<16:07,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▊       | 430/1500 [08:16<18:26,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▊       | 431/1500 [08:17<18:47,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 432/1500 [08:18<19:02,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 433/1500 [08:19<16:45,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 434/1500 [08:20<18:53,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 435/1500 [08:21<16:39,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 436/1500 [08:22<18:44,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 437/1500 [08:23<16:33,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 438/1500 [08:24<17:28,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 439/1500 [08:25<17:35,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 440/1500 [08:25<15:45,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 441/1500 [08:27<18:06,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  29%|██▉       | 442/1500 [08:28<20:01,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|██▉       | 443/1500 [08:29<18:44,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|██▉       | 444/1500 [08:30<20:27,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|██▉       | 445/1500 [08:31<19:48,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|██▉       | 446/1500 [08:32<16:17,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|██▉       | 447/1500 [08:33<17:08,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|██▉       | 448/1500 [08:34<17:49,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|██▉       | 449/1500 [08:35<15:56,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|███       | 450/1500 [08:36<15:38,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|███       | 451/1500 [08:37<18:34,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|███       | 452/1500 [08:38<18:28,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|███       | 453/1500 [08:39<18:25,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|███       | 454/1500 [08:41<20:18,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|███       | 455/1500 [08:41<17:07,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|███       | 456/1500 [08:42<14:52,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  30%|███       | 457/1500 [08:43<17:24,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 458/1500 [08:44<15:33,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 459/1500 [08:45<16:19,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 460/1500 [08:46<17:08,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 461/1500 [08:47<19:32,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 462/1500 [08:49<21:17,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 463/1500 [08:50<22:26,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 464/1500 [08:51<22:21,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 465/1500 [08:53<23:06,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 466/1500 [08:54<21:18,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 467/1500 [08:55<19:31,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███       | 468/1500 [08:56<18:16,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███▏      | 469/1500 [08:57<18:07,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███▏      | 470/1500 [08:58<18:06,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███▏      | 471/1500 [08:58<16:01,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  31%|███▏      | 472/1500 [08:59<14:35,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 473/1500 [09:01<17:36,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 474/1500 [09:02<19:39,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 475/1500 [09:03<19:50,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 476/1500 [09:05<21:01,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 477/1500 [09:06<20:06,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 478/1500 [09:07<19:23,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 479/1500 [09:08<20:26,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 480/1500 [09:09<20:58,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 481/1500 [09:10<17:29,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 482/1500 [09:11<15:30,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 483/1500 [09:12<16:14,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 484/1500 [09:12<14:12,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 485/1500 [09:13<16:31,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 486/1500 [09:15<17:35,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  32%|███▏      | 487/1500 [09:16<17:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 488/1500 [09:16<15:45,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 489/1500 [09:18<17:30,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 490/1500 [09:18<15:30,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 491/1500 [09:19<15:54,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 492/1500 [09:21<17:44,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 493/1500 [09:22<19:09,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 494/1500 [09:23<19:52,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 495/1500 [09:25<20:57,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 496/1500 [09:26<19:40,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 497/1500 [09:26<16:17,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 498/1500 [09:28<18:36,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 499/1500 [09:29<18:15,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 500/1500 [09:29<16:31,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 501/1500 [09:30<17:01,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  33%|███▎      | 502/1500 [09:32<18:52,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▎      | 503/1500 [09:32<14:28,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▎      | 504/1500 [09:33<13:25,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▎      | 505/1500 [09:34<16:03,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▎      | 506/1500 [09:35<17:43,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 507/1500 [09:36<17:23,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 508/1500 [09:38<17:29,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 509/1500 [09:39<19:07,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 510/1500 [09:40<20:35,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 511/1500 [09:41<17:39,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 512/1500 [09:42<17:33,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 513/1500 [09:43<17:43,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 514/1500 [09:44<15:09,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 515/1500 [09:45<17:14,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 516/1500 [09:47<19:05,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  34%|███▍      | 517/1500 [09:48<19:51,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▍      | 518/1500 [09:49<20:43,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▍      | 519/1500 [09:51<21:32,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▍      | 520/1500 [09:52<21:52,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▍      | 521/1500 [09:54<22:23,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▍      | 522/1500 [09:54<18:50,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▍      | 523/1500 [09:56<20:10,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▍      | 524/1500 [09:57<20:40,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▌      | 525/1500 [09:58<20:43,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▌      | 526/1500 [09:59<19:35,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▌      | 527/1500 [10:00<18:50,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▌      | 528/1500 [10:01<17:06,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▌      | 529/1500 [10:02<14:41,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▌      | 530/1500 [10:02<12:56,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▌      | 531/1500 [10:04<15:30,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  35%|███▌      | 532/1500 [10:05<17:55,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 533/1500 [10:06<17:39,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 534/1500 [10:07<18:38,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 535/1500 [10:08<18:03,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 536/1500 [10:09<16:55,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 537/1500 [10:10<17:08,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 538/1500 [10:12<18:31,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 539/1500 [10:13<18:01,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 540/1500 [10:14<19:05,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 541/1500 [10:15<18:36,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 542/1500 [10:17<19:59,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▌      | 543/1500 [10:18<19:15,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▋      | 544/1500 [10:19<18:12,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▋      | 545/1500 [10:20<19:24,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▋      | 546/1500 [10:22<20:14,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  36%|███▋      | 547/1500 [10:22<17:15,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 548/1500 [10:24<17:54,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 549/1500 [10:25<18:49,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 550/1500 [10:26<18:21,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 551/1500 [10:27<18:41,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 552/1500 [10:29<19:19,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 553/1500 [10:29<16:35,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 554/1500 [10:30<16:33,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 555/1500 [10:32<17:55,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 556/1500 [10:33<17:12,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 557/1500 [10:34<16:58,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 558/1500 [10:35<17:03,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 559/1500 [10:35<15:01,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 560/1500 [10:36<13:34,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 561/1500 [10:37<15:53,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  37%|███▋      | 562/1500 [10:39<17:30,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 563/1500 [10:40<18:59,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 564/1500 [10:42<20:09,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 565/1500 [10:43<20:39,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 566/1500 [10:44<20:28,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 567/1500 [10:46<20:48,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 568/1500 [10:47<20:53,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 569/1500 [10:49<21:23,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 570/1500 [10:50<21:09,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 571/1500 [10:51<20:48,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 572/1500 [10:52<19:40,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 573/1500 [10:54<20:25,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 574/1500 [10:55<19:47,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 575/1500 [10:56<20:00,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 576/1500 [10:57<19:03,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  38%|███▊      | 577/1500 [10:58<16:21,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▊      | 578/1500 [10:59<16:33,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▊      | 579/1500 [11:00<16:13,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▊      | 580/1500 [11:01<14:22,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▊      | 581/1500 [11:01<13:02,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 582/1500 [11:03<14:10,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 583/1500 [11:04<16:03,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 584/1500 [11:05<14:52,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 585/1500 [11:06<15:07,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 586/1500 [11:07<16:40,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 587/1500 [11:08<15:18,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 588/1500 [11:09<16:46,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 589/1500 [11:10<16:30,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 590/1500 [11:11<17:01,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 591/1500 [11:13<18:30,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  39%|███▉      | 592/1500 [11:14<17:28,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|███▉      | 593/1500 [11:15<18:44,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|███▉      | 594/1500 [11:16<15:35,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|███▉      | 595/1500 [11:17<16:39,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|███▉      | 596/1500 [11:18<17:25,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|███▉      | 597/1500 [11:20<18:08,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|███▉      | 598/1500 [11:21<19:11,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|███▉      | 599/1500 [11:22<18:20,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|████      | 600/1500 [11:24<19:09,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|████      | 601/1500 [11:25<18:15,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|████      | 602/1500 [11:26<17:25,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|████      | 603/1500 [11:27<16:38,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|████      | 604/1500 [11:28<17:25,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|████      | 605/1500 [11:29<16:50,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|████      | 606/1500 [11:30<17:48,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  40%|████      | 607/1500 [11:32<17:19,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 608/1500 [11:33<18:18,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 609/1500 [11:34<17:28,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 610/1500 [11:35<18:00,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 611/1500 [11:36<17:20,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 612/1500 [11:38<18:34,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 613/1500 [11:39<17:35,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 614/1500 [11:40<18:15,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 615/1500 [11:42<18:31,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 616/1500 [11:43<19:21,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 617/1500 [11:44<15:57,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████      | 618/1500 [11:45<16:52,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████▏     | 619/1500 [11:46<16:20,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████▏     | 620/1500 [11:47<17:07,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████▏     | 621/1500 [11:48<16:01,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  41%|████▏     | 622/1500 [11:49<14:05,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 623/1500 [11:50<15:41,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 624/1500 [11:51<13:49,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 625/1500 [11:51<12:03,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 626/1500 [11:53<14:16,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 627/1500 [11:53<13:53,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 628/1500 [11:55<15:21,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 629/1500 [11:56<15:29,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 630/1500 [11:57<15:24,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 631/1500 [11:58<15:21,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 632/1500 [11:59<16:44,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 633/1500 [12:00<16:18,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 634/1500 [12:02<17:04,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 635/1500 [12:03<16:39,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 636/1500 [12:04<17:30,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  42%|████▏     | 637/1500 [12:05<17:49,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 638/1500 [12:07<18:30,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 639/1500 [12:07<15:41,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 640/1500 [12:09<16:46,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 641/1500 [12:09<14:31,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 642/1500 [12:11<14:50,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 643/1500 [12:12<15:13,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 644/1500 [12:12<13:24,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 645/1500 [12:13<12:22,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 646/1500 [12:15<14:45,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 647/1500 [12:16<14:45,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 648/1500 [12:16<13:04,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 649/1500 [12:17<13:42,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 650/1500 [12:19<15:20,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 651/1500 [12:20<15:43,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  43%|████▎     | 652/1500 [12:21<16:03,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▎     | 653/1500 [12:22<13:34,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▎     | 654/1500 [12:22<12:16,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▎     | 655/1500 [12:23<13:47,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▎     | 656/1500 [12:24<13:29,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 657/1500 [12:26<15:22,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 658/1500 [12:27<15:10,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 659/1500 [12:28<14:01,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 660/1500 [12:29<15:38,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 661/1500 [12:30<16:24,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 662/1500 [12:32<17:04,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 663/1500 [12:32<15:04,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 664/1500 [12:33<14:56,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 665/1500 [12:35<16:31,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 666/1500 [12:36<17:12,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  44%|████▍     | 667/1500 [12:37<16:36,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▍     | 668/1500 [12:39<17:09,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▍     | 669/1500 [12:40<17:23,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▍     | 670/1500 [12:41<17:45,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▍     | 671/1500 [12:43<17:49,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▍     | 672/1500 [12:44<18:25,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▍     | 673/1500 [12:45<17:25,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▍     | 674/1500 [12:46<17:14,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▌     | 675/1500 [12:48<17:25,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▌     | 676/1500 [12:49<15:25,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▌     | 677/1500 [12:50<15:08,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▌     | 678/1500 [12:51<14:40,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▌     | 679/1500 [12:52<14:31,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▌     | 680/1500 [12:53<15:05,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▌     | 681/1500 [12:54<14:38,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  45%|████▌     | 682/1500 [12:54<12:30,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 683/1500 [12:55<11:26,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 684/1500 [12:56<12:17,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 685/1500 [12:57<11:17,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 686/1500 [12:57<10:08,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 687/1500 [12:58<09:32,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 688/1500 [12:59<12:39,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 689/1500 [13:01<14:23,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 690/1500 [13:02<14:21,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 691/1500 [13:03<15:30,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 692/1500 [13:04<14:05,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▌     | 693/1500 [13:05<14:10,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▋     | 694/1500 [13:06<15:21,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▋     | 695/1500 [13:07<15:08,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▋     | 696/1500 [13:09<15:29,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  46%|████▋     | 697/1500 [13:10<16:41,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 698/1500 [13:11<13:29,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 699/1500 [13:12<14:56,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 700/1500 [13:13<16:14,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 701/1500 [13:14<15:32,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 702/1500 [13:16<16:12,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 703/1500 [13:17<15:29,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 704/1500 [13:18<15:11,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 705/1500 [13:19<14:48,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 706/1500 [13:20<14:31,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 707/1500 [13:21<14:17,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 708/1500 [13:22<15:18,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 709/1500 [13:24<15:29,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 710/1500 [13:25<15:05,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 711/1500 [13:26<14:40,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  47%|████▋     | 712/1500 [13:27<15:44,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 713/1500 [13:29<16:28,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 714/1500 [13:30<16:40,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 715/1500 [13:31<16:43,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 716/1500 [13:32<16:42,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 717/1500 [13:33<14:15,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 718/1500 [13:34<15:12,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 719/1500 [13:36<15:59,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 720/1500 [13:37<16:42,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 721/1500 [13:39<16:56,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 722/1500 [13:40<15:58,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 723/1500 [13:41<15:28,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 724/1500 [13:42<16:07,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 725/1500 [13:43<16:26,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 726/1500 [13:44<14:02,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  48%|████▊     | 727/1500 [13:45<15:00,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▊     | 728/1500 [13:47<14:36,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▊     | 729/1500 [13:48<14:31,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▊     | 730/1500 [13:49<15:49,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▊     | 731/1500 [13:50<16:01,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 732/1500 [13:52<16:22,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 733/1500 [13:52<13:58,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 734/1500 [13:54<14:57,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 735/1500 [13:55<15:03,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 736/1500 [13:56<15:28,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 737/1500 [13:58<15:56,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 738/1500 [13:59<15:31,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 739/1500 [14:00<16:25,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 740/1500 [14:01<13:38,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 741/1500 [14:01<11:05,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  49%|████▉     | 742/1500 [14:02<12:42,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|████▉     | 743/1500 [14:04<13:51,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|████▉     | 744/1500 [14:05<15:11,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|████▉     | 745/1500 [14:07<15:42,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|████▉     | 746/1500 [14:08<15:58,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|████▉     | 747/1500 [14:09<15:59,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|████▉     | 748/1500 [14:10<14:53,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|████▉     | 749/1500 [14:12<15:32,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|█████     | 750/1500 [14:12<13:19,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|█████     | 751/1500 [14:13<13:28,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|█████     | 752/1500 [14:15<14:25,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|█████     | 753/1500 [14:16<14:13,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|█████     | 754/1500 [14:17<15:20,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|█████     | 755/1500 [14:19<16:05,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|█████     | 756/1500 [14:20<16:03,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  50%|█████     | 757/1500 [14:21<16:22,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 758/1500 [14:23<16:25,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 759/1500 [14:24<16:30,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 760/1500 [14:26<16:57,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 761/1500 [14:27<16:56,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 762/1500 [14:28<15:31,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 763/1500 [14:29<15:45,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 764/1500 [14:31<16:13,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 765/1500 [14:31<13:43,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 766/1500 [14:33<14:19,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 767/1500 [14:34<15:21,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████     | 768/1500 [14:35<14:26,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████▏    | 769/1500 [14:36<13:51,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████▏    | 770/1500 [14:37<13:52,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████▏    | 771/1500 [14:38<13:43,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  51%|█████▏    | 772/1500 [14:40<14:01,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 773/1500 [14:41<14:12,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 774/1500 [14:42<14:51,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 775/1500 [14:43<12:25,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 776/1500 [14:44<12:33,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 777/1500 [14:45<12:37,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 778/1500 [14:46<14:05,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 779/1500 [14:47<11:52,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 780/1500 [14:48<13:12,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 781/1500 [14:49<13:15,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 782/1500 [14:50<12:50,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 783/1500 [14:51<12:02,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 784/1500 [14:53<13:40,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 785/1500 [14:54<14:34,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 786/1500 [14:55<13:48,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  52%|█████▏    | 787/1500 [14:56<13:07,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 788/1500 [14:57<12:51,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 789/1500 [14:58<13:55,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 790/1500 [15:00<14:52,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 791/1500 [15:01<13:57,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 792/1500 [15:02<12:06,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 793/1500 [15:03<13:04,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 794/1500 [15:04<13:56,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 795/1500 [15:05<11:23,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 796/1500 [15:06<13:11,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 797/1500 [15:08<13:56,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 798/1500 [15:09<13:13,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 799/1500 [15:09<11:35,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 800/1500 [15:11<12:43,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 801/1500 [15:12<13:53,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  53%|█████▎    | 802/1500 [15:13<13:23,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▎    | 803/1500 [15:15<14:43,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▎    | 804/1500 [15:16<15:25,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▎    | 805/1500 [15:17<15:29,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▎    | 806/1500 [15:19<15:50,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 807/1500 [15:20<15:44,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 808/1500 [15:21<14:46,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 809/1500 [15:22<13:01,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 810/1500 [15:23<13:57,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 811/1500 [15:24<11:40,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 812/1500 [15:25<12:39,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 813/1500 [15:26<12:26,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 814/1500 [15:28<12:52,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 815/1500 [15:29<13:27,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 816/1500 [15:30<12:59,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  54%|█████▍    | 817/1500 [15:31<13:36,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▍    | 818/1500 [15:32<13:08,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▍    | 819/1500 [15:33<11:24,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▍    | 820/1500 [15:34<10:10,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▍    | 821/1500 [15:35<11:57,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▍    | 822/1500 [15:36<13:19,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▍    | 823/1500 [15:38<13:31,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▍    | 824/1500 [15:39<13:48,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▌    | 825/1500 [15:40<14:23,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▌    | 826/1500 [15:42<13:44,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▌    | 827/1500 [15:43<14:31,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▌    | 828/1500 [15:44<13:43,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▌    | 829/1500 [15:45<12:46,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▌    | 830/1500 [15:46<13:25,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▌    | 831/1500 [15:48<14:18,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  55%|█████▌    | 832/1500 [15:49<13:40,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 833/1500 [15:50<11:42,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 834/1500 [15:51<12:59,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 835/1500 [15:52<11:14,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 836/1500 [15:53<12:21,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 837/1500 [15:54<12:07,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 838/1500 [15:55<12:56,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 839/1500 [15:57<13:29,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 840/1500 [15:58<14:04,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 841/1500 [15:59<14:10,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 842/1500 [16:01<14:34,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▌    | 843/1500 [16:02<14:36,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▋    | 844/1500 [16:04<14:49,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▋    | 845/1500 [16:04<12:31,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▋    | 846/1500 [16:05<10:33,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  56%|█████▋    | 847/1500 [16:06<10:48,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 848/1500 [16:07<12:16,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 849/1500 [16:09<13:14,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 850/1500 [16:10<13:48,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 851/1500 [16:11<13:06,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 852/1500 [16:13<13:33,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 853/1500 [16:14<13:37,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 854/1500 [16:15<13:44,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 855/1500 [16:16<11:05,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 856/1500 [16:17<10:28,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 857/1500 [16:18<10:39,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 858/1500 [16:19<11:33,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 859/1500 [16:20<11:19,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 860/1500 [16:21<12:21,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 861/1500 [16:23<12:55,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  57%|█████▋    | 862/1500 [16:24<13:31,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 863/1500 [16:25<12:50,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 864/1500 [16:26<12:19,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 865/1500 [16:27<11:57,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 866/1500 [16:28<11:40,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 867/1500 [16:30<12:35,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 868/1500 [16:31<13:02,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 869/1500 [16:32<13:14,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 870/1500 [16:34<13:25,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 871/1500 [16:35<13:35,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 872/1500 [16:36<13:57,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 873/1500 [16:37<13:07,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 874/1500 [16:38<12:32,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 875/1500 [16:40<12:04,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 876/1500 [16:41<12:39,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  58%|█████▊    | 877/1500 [16:42<13:22,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▊    | 878/1500 [16:44<13:32,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▊    | 879/1500 [16:45<14:01,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▊    | 880/1500 [16:46<13:29,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▊    | 881/1500 [16:47<12:34,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 882/1500 [16:49<13:19,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 883/1500 [16:50<13:35,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 884/1500 [16:51<12:36,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 885/1500 [16:52<10:29,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 886/1500 [16:52<09:00,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 887/1500 [16:54<10:25,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 888/1500 [16:55<11:21,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 889/1500 [16:56<11:54,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 890/1500 [16:58<12:43,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 891/1500 [16:58<10:50,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  59%|█████▉    | 892/1500 [16:59<10:50,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|█████▉    | 893/1500 [17:00<09:34,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|█████▉    | 894/1500 [17:02<11:05,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|█████▉    | 895/1500 [17:03<11:31,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|█████▉    | 896/1500 [17:04<12:05,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|█████▉    | 897/1500 [17:05<12:23,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|█████▉    | 898/1500 [17:07<12:32,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|█████▉    | 899/1500 [17:08<11:58,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|██████    | 900/1500 [17:09<11:45,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|██████    | 901/1500 [17:10<12:26,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|██████    | 902/1500 [17:11<11:51,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|██████    | 903/1500 [17:13<12:19,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|██████    | 904/1500 [17:14<11:35,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|██████    | 905/1500 [17:15<11:14,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|██████    | 906/1500 [17:16<12:10,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  60%|██████    | 907/1500 [17:18<12:21,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 908/1500 [17:19<11:43,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 909/1500 [17:20<11:22,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 910/1500 [17:21<12:11,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 911/1500 [17:22<12:21,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 912/1500 [17:23<10:33,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 913/1500 [17:24<10:55,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 914/1500 [17:26<11:36,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 915/1500 [17:26<10:01,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 916/1500 [17:27<10:13,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 917/1500 [17:29<11:04,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████    | 918/1500 [17:30<11:16,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████▏   | 919/1500 [17:31<10:53,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████▏   | 920/1500 [17:32<11:18,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████▏   | 921/1500 [17:34<11:40,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  61%|██████▏   | 922/1500 [17:35<12:20,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 923/1500 [17:36<12:38,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 924/1500 [17:38<12:38,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 925/1500 [17:39<12:44,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 926/1500 [17:40<10:49,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 927/1500 [17:41<11:28,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 928/1500 [17:43<12:12,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 929/1500 [17:44<12:16,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 930/1500 [17:45<11:36,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 931/1500 [17:46<12:05,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 932/1500 [17:48<12:14,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 933/1500 [17:49<11:39,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 934/1500 [17:50<11:17,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 935/1500 [17:51<11:59,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 936/1500 [17:53<12:29,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  62%|██████▏   | 937/1500 [17:54<12:31,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 938/1500 [17:56<12:31,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 939/1500 [17:57<12:47,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 940/1500 [17:58<12:43,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 941/1500 [18:00<12:45,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 942/1500 [18:01<12:46,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 943/1500 [18:02<11:51,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 944/1500 [18:03<11:56,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 945/1500 [18:05<12:20,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 946/1500 [18:06<12:21,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 947/1500 [18:08<12:25,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 948/1500 [18:09<11:25,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 949/1500 [18:10<12:00,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 950/1500 [18:11<11:58,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 951/1500 [18:12<10:12,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  63%|██████▎   | 952/1500 [18:14<11:08,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▎   | 953/1500 [18:14<08:53,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▎   | 954/1500 [18:15<08:53,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▎   | 955/1500 [18:16<09:42,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▎   | 956/1500 [18:17<09:32,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 957/1500 [18:18<09:30,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 958/1500 [18:20<10:34,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 959/1500 [18:21<10:13,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 960/1500 [18:22<10:47,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 961/1500 [18:23<10:22,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 962/1500 [18:24<10:08,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 963/1500 [18:25<10:05,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 964/1500 [18:27<10:51,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 965/1500 [18:28<10:24,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 966/1500 [18:29<09:16,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  64%|██████▍   | 967/1500 [18:30<09:08,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▍   | 968/1500 [18:31<09:58,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▍   | 969/1500 [18:32<10:48,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▍   | 970/1500 [18:33<10:19,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▍   | 971/1500 [18:34<08:58,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▍   | 972/1500 [18:35<09:11,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▍   | 973/1500 [18:37<10:05,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▍   | 974/1500 [18:38<10:32,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▌   | 975/1500 [18:39<10:14,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▌   | 976/1500 [18:40<10:58,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▌   | 977/1500 [18:41<09:07,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▌   | 978/1500 [18:42<10:03,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▌   | 979/1500 [18:44<10:16,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▌   | 980/1500 [18:45<10:39,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▌   | 981/1500 [18:46<10:11,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  65%|██████▌   | 982/1500 [18:47<10:31,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 983/1500 [18:48<10:03,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 984/1500 [18:50<10:34,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 985/1500 [18:51<10:03,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 986/1500 [18:52<10:53,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 987/1500 [18:54<11:12,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 988/1500 [18:55<10:22,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 989/1500 [18:56<11:01,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 990/1500 [18:57<10:24,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 991/1500 [18:59<10:41,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 992/1500 [19:00<10:49,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▌   | 993/1500 [19:01<10:50,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▋   | 994/1500 [19:02<10:04,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▋   | 995/1500 [19:03<10:06,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▋   | 996/1500 [19:04<08:42,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  66%|██████▋   | 997/1500 [19:05<09:27,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 998/1500 [19:07<09:59,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 999/1500 [19:08<10:36,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1000/1500 [19:10<11:01,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1001/1500 [19:11<10:16,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1002/1500 [19:12<10:11,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1003/1500 [19:13<10:19,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1004/1500 [19:15<10:47,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1005/1500 [19:16<10:51,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1006/1500 [19:17<10:57,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1007/1500 [19:19<11:11,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1008/1500 [19:20<11:10,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1009/1500 [19:21<10:29,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1010/1500 [19:22<10:12,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1011/1500 [19:23<08:43,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  67%|██████▋   | 1012/1500 [19:24<07:28,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1013/1500 [19:25<07:48,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1014/1500 [19:26<08:45,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1015/1500 [19:27<09:23,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1016/1500 [19:29<10:01,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1017/1500 [19:30<09:26,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1018/1500 [19:31<09:49,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1019/1500 [19:32<08:24,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1020/1500 [19:33<09:18,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1021/1500 [19:34<09:00,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1022/1500 [19:35<08:06,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1023/1500 [19:36<07:52,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1024/1500 [19:37<08:08,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1025/1500 [19:39<09:01,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1026/1500 [19:40<09:46,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  68%|██████▊   | 1027/1500 [19:41<10:19,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▊   | 1028/1500 [19:43<10:02,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▊   | 1029/1500 [19:44<10:25,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▊   | 1030/1500 [19:45<08:48,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▊   | 1031/1500 [19:46<08:45,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1032/1500 [19:47<08:56,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1033/1500 [19:48<09:25,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1034/1500 [19:50<09:36,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1035/1500 [19:51<10:04,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1036/1500 [19:52<09:20,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1037/1500 [19:54<09:52,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1038/1500 [19:55<10:11,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1039/1500 [19:56<09:36,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1040/1500 [19:57<09:48,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1041/1500 [19:59<10:02,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  69%|██████▉   | 1042/1500 [20:00<09:22,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|██████▉   | 1043/1500 [20:01<09:25,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|██████▉   | 1044/1500 [20:02<09:31,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|██████▉   | 1045/1500 [20:04<09:57,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|██████▉   | 1046/1500 [20:05<10:15,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|██████▉   | 1047/1500 [20:06<09:05,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|██████▉   | 1048/1500 [20:08<09:22,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|██████▉   | 1049/1500 [20:08<08:20,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|███████   | 1050/1500 [20:10<08:35,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|███████   | 1051/1500 [20:10<07:27,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|███████   | 1052/1500 [20:11<07:27,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|███████   | 1053/1500 [20:12<07:46,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|███████   | 1054/1500 [20:13<06:54,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|███████   | 1055/1500 [20:14<07:15,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|███████   | 1056/1500 [20:15<07:57,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  70%|███████   | 1057/1500 [20:16<07:07,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1058/1500 [20:17<07:24,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1059/1500 [20:18<07:35,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1060/1500 [20:19<07:30,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1061/1500 [20:21<08:11,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1062/1500 [20:22<08:01,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1063/1500 [20:23<08:00,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1064/1500 [20:24<08:49,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1065/1500 [20:25<08:35,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1066/1500 [20:26<08:15,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1067/1500 [20:28<09:01,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████   | 1068/1500 [20:29<09:14,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████▏  | 1069/1500 [20:30<08:37,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████▏  | 1070/1500 [20:31<07:28,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████▏  | 1071/1500 [20:32<08:20,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  71%|███████▏  | 1072/1500 [20:34<08:49,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1073/1500 [20:35<08:16,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1074/1500 [20:35<06:58,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1075/1500 [20:36<06:18,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1076/1500 [20:38<07:41,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1077/1500 [20:39<07:24,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1078/1500 [20:40<07:25,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1079/1500 [20:41<07:56,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1080/1500 [20:42<08:25,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1081/1500 [20:44<08:49,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1082/1500 [20:45<08:58,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1083/1500 [20:46<08:28,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1084/1500 [20:47<08:01,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1085/1500 [20:48<07:46,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1086/1500 [20:50<08:11,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  72%|███████▏  | 1087/1500 [20:51<08:32,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1088/1500 [20:52<08:39,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1089/1500 [20:54<08:44,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1090/1500 [20:55<08:17,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1091/1500 [20:56<08:29,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1092/1500 [20:57<08:00,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1093/1500 [20:58<08:27,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1094/1500 [21:00<08:44,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1095/1500 [21:00<07:28,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1096/1500 [21:01<07:17,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1097/1500 [21:03<07:12,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1098/1500 [21:03<06:43,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1099/1500 [21:04<06:54,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1100/1500 [21:06<06:55,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1101/1500 [21:07<07:25,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  73%|███████▎  | 1102/1500 [21:08<07:59,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▎  | 1103/1500 [21:10<08:09,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▎  | 1104/1500 [21:11<08:35,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▎  | 1105/1500 [21:12<07:21,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▎  | 1106/1500 [21:13<08:03,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1107/1500 [21:14<08:10,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1108/1500 [21:16<08:21,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1109/1500 [21:17<07:48,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1110/1500 [21:18<08:10,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1111/1500 [21:19<07:45,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1112/1500 [21:20<06:30,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1113/1500 [21:21<06:35,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1114/1500 [21:22<07:13,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1115/1500 [21:24<07:36,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1116/1500 [21:25<07:39,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  74%|███████▍  | 1117/1500 [21:26<07:13,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▍  | 1118/1500 [21:27<07:32,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▍  | 1119/1500 [21:28<07:09,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▍  | 1120/1500 [21:30<07:44,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▍  | 1121/1500 [21:31<07:57,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▍  | 1122/1500 [21:32<07:58,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▍  | 1123/1500 [21:34<08:10,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▍  | 1124/1500 [21:35<08:25,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▌  | 1125/1500 [21:36<06:54,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▌  | 1126/1500 [21:37<07:22,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▌  | 1127/1500 [21:38<07:37,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▌  | 1128/1500 [21:40<07:55,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▌  | 1129/1500 [21:41<07:44,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▌  | 1130/1500 [21:42<08:05,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▌  | 1131/1500 [21:44<08:12,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  75%|███████▌  | 1132/1500 [21:44<07:06,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1133/1500 [21:46<07:28,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1134/1500 [21:47<07:42,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1135/1500 [21:48<07:52,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1136/1500 [21:49<07:20,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1137/1500 [21:51<07:09,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1138/1500 [21:51<06:00,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1139/1500 [21:52<06:04,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1140/1500 [21:53<06:11,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1141/1500 [21:55<06:44,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1142/1500 [21:55<05:51,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▌  | 1143/1500 [21:56<06:02,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▋  | 1144/1500 [21:58<06:47,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▋  | 1145/1500 [21:59<06:51,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▋  | 1146/1500 [22:00<06:41,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  76%|███████▋  | 1147/1500 [22:01<07:04,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1148/1500 [22:02<06:15,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1149/1500 [22:04<06:38,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1150/1500 [22:05<06:54,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1151/1500 [22:06<07:09,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1152/1500 [22:08<07:31,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1153/1500 [22:09<07:31,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1154/1500 [22:10<06:59,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1155/1500 [22:11<07:20,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1156/1500 [22:12<06:16,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1157/1500 [22:13<06:09,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1158/1500 [22:14<06:01,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1159/1500 [22:15<06:19,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1160/1500 [22:17<06:35,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1161/1500 [22:18<06:56,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  77%|███████▋  | 1162/1500 [22:19<07:21,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1163/1500 [22:21<07:25,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1164/1500 [22:21<06:16,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1165/1500 [22:22<06:03,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1166/1500 [22:24<06:36,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1167/1500 [22:25<06:27,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1168/1500 [22:26<06:15,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1169/1500 [22:27<06:31,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1170/1500 [22:29<06:48,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1171/1500 [22:30<07:08,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1172/1500 [22:31<06:43,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1173/1500 [22:32<06:25,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1174/1500 [22:34<06:27,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1175/1500 [22:35<06:41,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1176/1500 [22:36<06:20,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  78%|███████▊  | 1177/1500 [22:37<06:50,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▊  | 1178/1500 [22:39<06:57,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▊  | 1179/1500 [22:40<06:06,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▊  | 1180/1500 [22:41<06:27,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▊  | 1181/1500 [22:42<06:49,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1182/1500 [22:43<06:27,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1183/1500 [22:45<06:33,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1184/1500 [22:45<05:27,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1185/1500 [22:47<05:51,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1186/1500 [22:47<05:07,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1187/1500 [22:48<05:31,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1188/1500 [22:50<05:58,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1189/1500 [22:51<06:20,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1190/1500 [22:53<06:34,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1191/1500 [22:54<06:35,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  79%|███████▉  | 1192/1500 [22:55<06:49,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|███████▉  | 1193/1500 [22:57<06:54,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|███████▉  | 1194/1500 [22:58<06:53,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|███████▉  | 1195/1500 [22:59<05:48,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|███████▉  | 1196/1500 [23:00<06:14,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|███████▉  | 1197/1500 [23:02<06:34,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|███████▉  | 1198/1500 [23:03<06:23,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|███████▉  | 1199/1500 [23:04<06:34,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|████████  | 1200/1500 [23:06<06:31,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|████████  | 1201/1500 [23:07<06:34,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|████████  | 1202/1500 [23:08<06:09,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|████████  | 1203/1500 [23:08<04:57,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|████████  | 1204/1500 [23:09<04:03,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|████████  | 1205/1500 [23:09<03:47,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|████████  | 1206/1500 [23:11<04:25,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  80%|████████  | 1207/1500 [23:12<04:39,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1208/1500 [23:13<05:11,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1209/1500 [23:15<05:45,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1210/1500 [23:16<05:59,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1211/1500 [23:17<06:16,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1212/1500 [23:18<05:41,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1213/1500 [23:19<04:37,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1214/1500 [23:20<05:05,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1215/1500 [23:22<05:45,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1216/1500 [23:23<06:03,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1217/1500 [23:24<05:43,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████  | 1218/1500 [23:25<05:53,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████▏ | 1219/1500 [23:27<06:00,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████▏ | 1220/1500 [23:28<05:51,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████▏ | 1221/1500 [23:29<06:01,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  81%|████████▏ | 1222/1500 [23:31<06:00,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1223/1500 [23:32<05:43,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1224/1500 [23:33<05:52,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1225/1500 [23:34<05:57,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1226/1500 [23:36<05:36,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1227/1500 [23:37<05:47,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1228/1500 [23:38<05:49,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1229/1500 [23:40<05:49,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1230/1500 [23:41<05:51,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1231/1500 [23:42<05:54,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1232/1500 [23:43<05:28,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1233/1500 [23:45<05:36,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1234/1500 [23:45<05:07,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1235/1500 [23:47<05:21,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1236/1500 [23:48<05:33,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  82%|████████▏ | 1237/1500 [23:50<05:40,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1238/1500 [23:50<04:40,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1239/1500 [23:51<04:57,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1240/1500 [23:53<05:12,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1241/1500 [23:54<05:22,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1242/1500 [23:55<04:58,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1243/1500 [23:56<04:45,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1244/1500 [23:57<04:24,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1245/1500 [23:58<04:52,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1246/1500 [24:00<05:03,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1247/1500 [24:01<05:04,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1248/1500 [24:01<04:13,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1249/1500 [24:03<04:46,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1250/1500 [24:04<04:08,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1251/1500 [24:05<04:16,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  83%|████████▎ | 1252/1500 [24:06<04:16,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▎ | 1253/1500 [24:07<04:35,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▎ | 1254/1500 [24:08<04:48,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▎ | 1255/1500 [24:10<05:07,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▎ | 1256/1500 [24:11<05:20,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1257/1500 [24:13<05:24,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1258/1500 [24:14<05:29,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1259/1500 [24:15<05:32,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1260/1500 [24:16<05:07,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1261/1500 [24:18<04:51,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1262/1500 [24:19<04:38,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1263/1500 [24:20<04:30,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1264/1500 [24:21<04:47,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1265/1500 [24:22<04:56,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1266/1500 [24:23<04:37,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  84%|████████▍ | 1267/1500 [24:25<04:53,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▍ | 1268/1500 [24:26<04:59,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▍ | 1269/1500 [24:27<04:38,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▍ | 1270/1500 [24:29<04:43,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▍ | 1271/1500 [24:30<04:31,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▍ | 1272/1500 [24:31<04:20,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▍ | 1273/1500 [24:32<04:13,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▍ | 1274/1500 [24:33<04:12,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▌ | 1275/1500 [24:34<04:27,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▌ | 1276/1500 [24:36<04:34,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▌ | 1277/1500 [24:36<03:56,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▌ | 1278/1500 [24:37<04:00,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▌ | 1279/1500 [24:39<04:18,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▌ | 1280/1500 [24:40<04:33,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▌ | 1281/1500 [24:41<04:35,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  85%|████████▌ | 1282/1500 [24:43<04:32,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1283/1500 [24:43<03:52,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1284/1500 [24:44<03:24,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1285/1500 [24:45<03:15,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1286/1500 [24:45<02:51,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1287/1500 [24:46<03:06,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1288/1500 [24:47<03:18,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1289/1500 [24:49<03:51,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1290/1500 [24:50<03:51,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1291/1500 [24:51<04:13,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1292/1500 [24:53<04:01,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▌ | 1293/1500 [24:54<04:13,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▋ | 1294/1500 [24:55<04:24,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▋ | 1295/1500 [24:56<04:08,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▋ | 1296/1500 [24:57<03:58,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  86%|████████▋ | 1297/1500 [24:58<03:26,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1298/1500 [25:00<03:51,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1299/1500 [25:01<04:08,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1300/1500 [25:02<03:59,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1301/1500 [25:03<03:46,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1302/1500 [25:05<04:01,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1303/1500 [25:06<03:47,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1304/1500 [25:07<03:59,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1305/1500 [25:08<03:40,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1306/1500 [25:09<03:48,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1307/1500 [25:11<04:01,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1308/1500 [25:12<03:46,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1309/1500 [25:13<03:37,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1310/1500 [25:14<03:49,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1311/1500 [25:15<03:53,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  87%|████████▋ | 1312/1500 [25:17<03:56,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1313/1500 [25:18<04:06,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1314/1500 [25:19<04:08,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1315/1500 [25:21<03:55,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1316/1500 [25:22<03:53,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1317/1500 [25:22<03:10,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1318/1500 [25:23<03:10,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1319/1500 [25:25<03:28,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1320/1500 [25:26<03:22,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1321/1500 [25:27<03:41,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1322/1500 [25:28<03:32,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1323/1500 [25:30<03:26,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1324/1500 [25:31<03:40,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1325/1500 [25:31<02:58,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1326/1500 [25:33<03:14,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  88%|████████▊ | 1327/1500 [25:34<03:23,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▊ | 1328/1500 [25:35<03:33,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▊ | 1329/1500 [25:37<03:41,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▊ | 1330/1500 [25:38<03:07,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▊ | 1331/1500 [25:39<03:03,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1332/1500 [25:40<03:15,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1333/1500 [25:41<03:17,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1334/1500 [25:42<03:07,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1335/1500 [25:43<03:11,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1336/1500 [25:45<03:20,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1337/1500 [25:46<03:18,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1338/1500 [25:47<03:24,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1339/1500 [25:49<03:32,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1340/1500 [25:50<03:19,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1341/1500 [25:51<03:03,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  89%|████████▉ | 1342/1500 [25:52<03:09,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|████████▉ | 1343/1500 [25:53<03:03,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|████████▉ | 1344/1500 [25:54<02:34,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|████████▉ | 1345/1500 [25:55<02:38,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|████████▉ | 1346/1500 [25:56<02:53,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|████████▉ | 1347/1500 [25:58<03:00,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|████████▉ | 1348/1500 [25:59<03:09,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|████████▉ | 1349/1500 [26:00<03:01,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|█████████ | 1350/1500 [26:01<03:08,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|█████████ | 1351/1500 [26:02<02:40,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|█████████ | 1352/1500 [26:04<02:55,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|█████████ | 1353/1500 [26:05<02:48,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|█████████ | 1354/1500 [26:06<02:44,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|█████████ | 1355/1500 [26:07<02:31,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|█████████ | 1356/1500 [26:08<02:46,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  90%|█████████ | 1357/1500 [26:09<02:57,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1358/1500 [26:10<02:37,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1359/1500 [26:12<02:45,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1360/1500 [26:13<02:40,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1361/1500 [26:14<02:48,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1362/1500 [26:15<02:56,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1363/1500 [26:16<02:46,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1364/1500 [26:18<02:50,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1365/1500 [26:19<02:39,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1366/1500 [26:20<02:32,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1367/1500 [26:21<02:37,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████ | 1368/1500 [26:22<02:29,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████▏| 1369/1500 [26:23<02:09,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████▏| 1370/1500 [26:24<02:22,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████▏| 1371/1500 [26:25<02:29,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  91%|█████████▏| 1372/1500 [26:27<02:38,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1373/1500 [26:28<02:35,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1374/1500 [26:29<02:27,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1375/1500 [26:31<02:34,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1376/1500 [26:32<02:38,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1377/1500 [26:33<02:41,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1378/1500 [26:35<02:44,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1379/1500 [26:36<02:47,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1380/1500 [26:38<02:46,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1381/1500 [26:39<02:35,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1382/1500 [26:40<02:24,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1383/1500 [26:41<02:32,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1384/1500 [26:43<02:33,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1385/1500 [26:44<02:21,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1386/1500 [26:45<02:15,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  92%|█████████▏| 1387/1500 [26:45<01:56,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1388/1500 [26:47<02:08,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1389/1500 [26:48<01:55,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1390/1500 [26:49<02:04,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1391/1500 [26:50<02:14,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1392/1500 [26:51<01:51,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1393/1500 [26:52<01:51,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1394/1500 [26:53<02:02,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1395/1500 [26:55<02:07,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1396/1500 [26:55<01:48,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1397/1500 [26:56<01:35,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1398/1500 [26:57<01:26,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1399/1500 [26:58<01:41,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1400/1500 [27:00<01:54,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1401/1500 [27:01<02:00,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  93%|█████████▎| 1402/1500 [27:02<02:02,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▎| 1403/1500 [27:04<02:04,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▎| 1404/1500 [27:05<01:57,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▎| 1405/1500 [27:06<02:00,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▎| 1406/1500 [27:08<02:04,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1407/1500 [27:09<01:57,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1408/1500 [27:10<02:01,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1409/1500 [27:12<02:01,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1410/1500 [27:13<02:01,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1411/1500 [27:14<01:42,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1412/1500 [27:15<01:34,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1413/1500 [27:16<01:34,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1414/1500 [27:17<01:42,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1415/1500 [27:19<01:47,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1416/1500 [27:20<01:41,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  94%|█████████▍| 1417/1500 [27:21<01:47,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▍| 1418/1500 [27:22<01:40,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▍| 1419/1500 [27:23<01:35,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▍| 1420/1500 [27:25<01:39,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▍| 1421/1500 [27:26<01:44,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▍| 1422/1500 [27:27<01:36,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▍| 1423/1500 [27:29<01:39,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▍| 1424/1500 [27:30<01:34,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▌| 1425/1500 [27:31<01:35,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▌| 1426/1500 [27:32<01:32,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▌| 1427/1500 [27:33<01:26,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▌| 1428/1500 [27:35<01:31,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▌| 1429/1500 [27:36<01:26,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▌| 1430/1500 [27:37<01:29,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▌| 1431/1500 [27:39<01:28,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  95%|█████████▌| 1432/1500 [27:40<01:22,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1433/1500 [27:41<01:23,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1434/1500 [27:42<01:25,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1435/1500 [27:43<01:10,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1436/1500 [27:44<01:08,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1437/1500 [27:45<00:57,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1438/1500 [27:46<01:07,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1439/1500 [27:47<00:58,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1440/1500 [27:48<01:04,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1441/1500 [27:49<00:58,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1442/1500 [27:50<01:03,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▌| 1443/1500 [27:51<01:01,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▋| 1444/1500 [27:53<01:06,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▋| 1445/1500 [27:54<01:05,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▋| 1446/1500 [27:55<01:02,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  96%|█████████▋| 1447/1500 [27:56<01:04,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1448/1500 [27:57<00:59,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1449/1500 [27:59<01:01,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1450/1500 [28:00<01:02,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1451/1500 [28:01<00:57,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1452/1500 [28:02<00:53,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1453/1500 [28:03<00:51,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1454/1500 [28:04<00:54,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1455/1500 [28:06<00:55,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1456/1500 [28:07<00:56,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1457/1500 [28:08<00:56,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1458/1500 [28:10<00:56,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1459/1500 [28:11<00:56,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1460/1500 [28:13<00:54,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1461/1500 [28:14<00:53,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  97%|█████████▋| 1462/1500 [28:15<00:43,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1463/1500 [28:16<00:41,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1464/1500 [28:17<00:40,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1465/1500 [28:18<00:41,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1466/1500 [28:20<00:42,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1467/1500 [28:20<00:33,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1468/1500 [28:21<00:32,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1469/1500 [28:22<00:31,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1470/1500 [28:24<00:34,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1471/1500 [28:24<00:28,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1472/1500 [28:25<00:27,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1473/1500 [28:26<00:29,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1474/1500 [28:28<00:29,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1475/1500 [28:29<00:30,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1476/1500 [28:30<00:28,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  98%|█████████▊| 1477/1500 [28:31<00:27,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▊| 1478/1500 [28:32<00:25,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▊| 1479/1500 [28:34<00:24,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▊| 1480/1500 [28:35<00:22,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▊| 1481/1500 [28:36<00:22,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1482/1500 [28:38<00:22,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1483/1500 [28:38<00:20,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1484/1500 [28:40<00:20,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1485/1500 [28:41<00:19,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1486/1500 [28:43<00:18,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1487/1500 [28:44<00:17,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1488/1500 [28:45<00:16,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1489/1500 [28:47<00:14,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1490/1500 [28:48<00:12,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1491/1500 [28:49<00:11,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7:  99%|█████████▉| 1492/1500 [28:50<00:10,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7: 100%|█████████▉| 1493/1500 [28:52<00:09,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7: 100%|█████████▉| 1494/1500 [28:53<00:07,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7: 100%|█████████▉| 1495/1500 [28:54<00:06,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7: 100%|█████████▉| 1496/1500 [28:55<00:04,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7: 100%|█████████▉| 1497/1500 [28:57<00:03,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7: 100%|█████████▉| 1498/1500 [28:58<00:02,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7: 100%|█████████▉| 1499/1500 [28:59<00:01,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 7: 100%|██████████| 1500/1500 [29:00<00:00,  1.16s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 7 Results on 1000 samples:\n",
      "BLEU: 0.0033\n",
      "ROUGE-1: 0.0995\n",
      "ROUGE-2: 0.0072\n",
      "ROUGE-L: 0.0768\n",
      "BERTScore (F1): 0.8255\n"
     ]
    }
   ],
   "source": [
    "# Trial 7 Evaluation Script (1000 Samples with Prompt Format Match)\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the 1000-sample evaluation set\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_3000.jsonl\", split=\"train\")\n",
    "\n",
    "# Load Trial 7 fine-tuned model and tokenizer\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-3000-trial7\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"🔍 Evaluating Trial 7\"):\n",
    "    input_text = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "# Compute metrics\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Print results\n",
    "print(\"\\n📊 Trial 7 Results on 1000 samples:\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFKKts0L1be_"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLXAv7WX1b9T"
   },
   "source": [
    "# Adding Synthetic examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1744307801658,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "fYHSLxGZ1gDa",
    "outputId": "dc9f3dd1-8b80-4651-f28e-67bcb09ee3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 600 synthetic samples to: /content/drive/MyDrive/SIT782/datasets/synthetic_600.jsonl\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define emotion categories relevant for a mental health chatbot\n",
    "emotions = [\n",
    "    \"anxious\", \"depressed\", \"lonely\", \"stressed\", \"angry\", \"insecure\",\n",
    "    \"grateful\", \"hopeful\", \"confused\", \"burned out\", \"rejected\", \"ashamed\",\n",
    "    \"guilty\", \"afraid\", \"calm\", \"relieved\", \"understood\", \"supported\"\n",
    "]\n",
    "\n",
    "user_statements = [\n",
    "    \"I feel like I'm not good enough no matter how hard I try.\",\n",
    "    \"Lately I've been having trouble sleeping and my mind won't stop racing.\",\n",
    "    \"I don’t have anyone to talk to, and I feel so alone.\",\n",
    "    \"I'm overwhelmed with everything happening in my life.\",\n",
    "    \"I can't stop blaming myself for what happened.\",\n",
    "    \"I'm scared things will never get better.\",\n",
    "    \"Sometimes I just want to disappear.\",\n",
    "    \"It’s exhausting pretending to be okay every day.\",\n",
    "    \"I feel like a failure for not reaching my goals.\",\n",
    "    \"I’ve been anxious about everything, even the smallest things.\",\n",
    "    \"My thoughts are spiraling out of control.\",\n",
    "    \"I feel broken and don’t know how to fix myself.\",\n",
    "    \"Nothing I do feels meaningful anymore.\",\n",
    "    \"I’m tired of being strong all the time.\",\n",
    "    \"Even when I’m surrounded by people, I feel alone.\"\n",
    "]\n",
    "\n",
    "bot_responses = [\n",
    "    \"I'm really sorry you're feeling this way. You're not alone, and I'm here to support you.\",\n",
    "    \"It’s okay to feel overwhelmed. Just know that these feelings won’t last forever, and you’re doing your best.\",\n",
    "    \"You deserve compassion, especially from yourself. Let's take this one step at a time.\",\n",
    "    \"Please remember that you're not a burden. Talking about it is a sign of strength.\",\n",
    "    \"It might not feel like it now, but things can get better with time and the right support.\",\n",
    "    \"You’ve already taken a brave step by expressing this. That matters.\",\n",
    "    \"You’re worthy of kindness and understanding. Let’s work through this together.\",\n",
    "    \"No feeling is final. I’m here for you in this moment.\",\n",
    "    \"It’s okay to not have it all figured out. You're doing the best you can.\",\n",
    "    \"What you’re feeling is valid, and you’re not alone in this.\"\n",
    "]\n",
    "\n",
    "synthetic_data = []\n",
    "for _ in range(600):\n",
    "    instruction = random.choice(user_statements)\n",
    "    output = random.choice(bot_responses)\n",
    "    emotion = random.choice(emotions)\n",
    "\n",
    "    synthetic_data.append({\n",
    "        \"instruction\": instruction,\n",
    "        \"output\": output\n",
    "    })\n",
    "\n",
    "synthetic_path = \"/content/drive/MyDrive/SIT782/datasets/synthetic_600.jsonl\"\n",
    "with open(synthetic_path, \"w\") as f:\n",
    "    for r in synthetic_data:\n",
    "        json.dump(r, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Saved 600 synthetic samples to: {synthetic_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0I7xFKM2vxx"
   },
   "source": [
    "Merging with 3000 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1744307971931,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "yELXOq9k2yRa",
    "outputId": "c31f3515-69aa-4e2d-dd09-639807c0e654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined dataset saved to: /content/drive/MyDrive/SIT782/datasets/empdiag_augmented_3600.jsonl\n",
      "📝 Total pairs: 2100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Paths\n",
    "real_path = \"/content/drive/MyDrive/SIT782/datasets/empdiag_3000.jsonl\"\n",
    "synthetic_path = \"/content/drive/MyDrive/SIT782/datasets/synthetic_600.jsonl\"\n",
    "combined_path = \"/content/drive/MyDrive/SIT782/datasets/empdiag_augmented_3600.jsonl\"\n",
    "\n",
    "# Load both\n",
    "def load_jsonl(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "real_data = load_jsonl(real_path)\n",
    "synthetic_data = load_jsonl(synthetic_path)\n",
    "\n",
    "# Merge and save\n",
    "combined_data = real_data + synthetic_data\n",
    "with open(combined_path, \"w\") as f:\n",
    "    for r in combined_data:\n",
    "        json.dump({\n",
    "            \"instruction\": r[\"instruction\"],\n",
    "            \"output\": r[\"output\"]\n",
    "        }, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Combined dataset saved to: {combined_path}\")\n",
    "print(f\"Total pairs: {len(combined_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KizLi0F03HPJ"
   },
   "source": [
    "#🔁 Tuning with Synthetic merged data Trial 8\n",
    " -  Trial 8 Enhanced Empathetic Fine-tuning (3600 Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9225d6ebaf814c508fffb4fc3edd5d5b",
      "12e7180b64f843d6bfafb02716221377",
      "373367c346304b65a3131e6ec15d10ee",
      "0f9113706f574bfb9608ec9673605081",
      "39c87db813984b59825f25e6d15f0d53",
      "ba95fdce4d0e4229b99be75a17e2035e",
      "fc14cc16085246499847e45ad8b13d51",
      "26ad10afc4934dec9147a2c3dcf72698",
      "0e8a86723588467784538a3dda955890",
      "9008f35566f04d26a5b89f2abe1c5a65",
      "71b3988eaa9d4b9fa800a036c88ffe52",
      "5d1a0c64e50b4c6b9b3a41f81df58ea0",
      "9229e4a8990241ee865bd3310f0ba09c",
      "3e4aa074cdc5429b9406405b379cb98a",
      "24086f2897f04ad39d9c83236eabd439",
      "3ecd00f9d8c44e5b9cd6b37f0a338d82",
      "191bc32bee0a4c229b7928d859ec8d1f",
      "f6d70cf4288b4d64aa7deda343d4a2f9",
      "2f4495c5de3c4dce962fa7e9021a4e86",
      "e629a2e72a5f4ad38de15a5aafdae44a",
      "bee1b491587d46ea9ac4ee3ae9155502",
      "0352709effc54dfeaec36a4d8d6a91bd"
     ]
    },
    "executionInfo": {
     "elapsed": 912992,
     "status": "ok",
     "timestamp": 1744309118257,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "5kd6Op1r3L4z",
    "outputId": "0a026159-7e7b-4c44-f376-82539882ee6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9225d6ebaf814c508fffb4fc3edd5d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1a0c64e50b4c6b9b3a41f81df58ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-fa45680aecbb>:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1048' max='1048' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1048/1048 14:50, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13.194900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.334000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.337500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.463500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.821300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.260900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.198800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.182300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.181600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.168400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.160200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.158100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.141300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.140300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.128800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.128400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.130200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.125100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.121100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.109500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.093300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.099400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.087800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.080600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.099200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.087900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.097200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 8 fine-tuning complete and saved to Drive!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_augmented_3600.jsonl\", split=\"train\")\n",
    "\n",
    "# Load base Mistral model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # fix pad token issue\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Tokenization function (no emotion or prompt in the dataset)\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "# Only remove 'instruction' and 'output'\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "\n",
    "# LoRA Configuration (Trial 8 settings)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "#  Apply LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/mistral-lora-trial8\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#  Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save model & tokenizer\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial8\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial8\")\n",
    "\n",
    "print(\"✅ Trial 8 fine-tuning complete and saved to Drive!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBeBu9sX3arD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGl--g6i7Z1i"
   },
   "source": [
    "# Evaluation Trial 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9ce6992f56c247b5bdb33f606c072531",
      "e6b09265a855458c87f193af36ad2d4a",
      "b2208d72de3142b68af820b488f55409",
      "b1476d1443f74673825ddaf9710bd2dc",
      "0ab5e4f79f95449fb552e18d39df177c",
      "42f631d6399a4772b49f07e62ceb24af",
      "a38a4821095e4789a9d58302bb25648b",
      "53176217e5a64ec3898a3c2f8f309bac",
      "6dff7a9d424a4a96bd47bcb98c8cc463",
      "ee3ebafd62e449b98d8ff9126d3be8c7",
      "1b1adc5810f04800931041885c2d99b7"
     ]
    },
    "executionInfo": {
     "elapsed": 2071823,
     "status": "ok",
     "timestamp": 1744311601787,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "DQ9gybJb7dig",
    "outputId": "69d49c02-4675-4ec3-c1be-aad57fdbf7e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce6992f56c247b5bdb33f606c072531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🔍 Evaluating Trial 8:   0%|          | 0/2100 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 1/2100 [00:01<57:36,  1.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 2/2100 [00:02<45:40,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 3/2100 [00:03<40:18,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 4/2100 [00:04<38:21,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 5/2100 [00:05<37:50,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 6/2100 [00:06<37:29,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 7/2100 [00:08<41:30,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 8/2100 [00:09<39:51,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 9/2100 [00:10<38:26,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   0%|          | 10/2100 [00:11<36:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 11/2100 [00:12<36:45,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 12/2100 [00:13<36:50,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 13/2100 [00:14<39:24,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 14/2100 [00:15<35:57,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 15/2100 [00:16<36:11,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 16/2100 [00:17<36:19,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 17/2100 [00:18<34:18,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 18/2100 [00:19<34:35,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 19/2100 [00:20<35:19,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 20/2100 [00:21<35:49,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 21/2100 [00:22<35:38,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 22/2100 [00:23<35:59,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 23/2100 [00:24<35:33,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 24/2100 [00:25<35:57,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 25/2100 [00:26<36:11,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|          | 26/2100 [00:27<35:45,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|▏         | 27/2100 [00:28<30:15,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|▏         | 28/2100 [00:28<27:20,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|▏         | 29/2100 [00:29<29:27,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|▏         | 30/2100 [00:30<30:44,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   1%|▏         | 31/2100 [00:32<34:31,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 32/2100 [00:33<34:10,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 33/2100 [00:34<34:59,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 34/2100 [00:35<35:23,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 35/2100 [00:36<35:36,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 36/2100 [00:37<35:50,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 37/2100 [00:37<31:19,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 38/2100 [00:39<32:52,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 39/2100 [00:39<29:15,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 40/2100 [00:40<29:13,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 41/2100 [00:41<31:09,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 42/2100 [00:41<25:55,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 43/2100 [00:42<29:00,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 44/2100 [00:43<30:01,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 45/2100 [00:45<32:15,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 46/2100 [00:46<33:50,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 47/2100 [00:47<33:23,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 48/2100 [00:48<34:01,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 49/2100 [00:49<37:12,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 50/2100 [00:50<32:14,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 51/2100 [00:50<28:42,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   2%|▏         | 52/2100 [00:51<29:22,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 53/2100 [00:52<30:10,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 54/2100 [00:52<25:13,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 55/2100 [00:53<27:27,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 56/2100 [00:55<32:28,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 57/2100 [00:55<28:51,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 58/2100 [00:56<30:57,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 59/2100 [00:57<32:26,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 60/2100 [00:58<32:09,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 61/2100 [00:59<32:46,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 62/2100 [01:00<32:35,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 63/2100 [01:01<33:29,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 64/2100 [01:02<28:02,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 65/2100 [01:03<30:19,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 66/2100 [01:03<27:16,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 67/2100 [01:04<23:07,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 68/2100 [01:05<26:47,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 69/2100 [01:06<29:18,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 70/2100 [01:07<30:34,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 71/2100 [01:08<31:03,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 72/2100 [01:09<32:28,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   3%|▎         | 73/2100 [01:09<28:55,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▎         | 74/2100 [01:11<30:52,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▎         | 75/2100 [01:11<31:13,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▎         | 76/2100 [01:13<35:57,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▎         | 77/2100 [01:14<35:47,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▎         | 78/2100 [01:15<35:05,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 79/2100 [01:16<35:08,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 80/2100 [01:17<34:39,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 81/2100 [01:18<34:45,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 82/2100 [01:19<34:48,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 83/2100 [01:19<28:31,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 84/2100 [01:21<30:42,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 85/2100 [01:22<32:11,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 86/2100 [01:23<32:16,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 87/2100 [01:23<28:31,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 88/2100 [01:24<30:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 89/2100 [01:25<31:47,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 90/2100 [01:26<32:19,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 91/2100 [01:27<32:48,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 92/2100 [01:28<33:26,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 93/2100 [01:29<33:34,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   4%|▍         | 94/2100 [01:30<33:57,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 95/2100 [01:32<36:43,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 96/2100 [01:33<35:50,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 97/2100 [01:33<31:09,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 98/2100 [01:34<31:45,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 99/2100 [01:35<33:22,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 100/2100 [01:36<33:15,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 101/2100 [01:37<29:14,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 102/2100 [01:38<30:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 103/2100 [01:39<31:10,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▍         | 104/2100 [01:40<32:11,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 105/2100 [01:41<32:58,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 106/2100 [01:42<36:54,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 107/2100 [01:43<35:18,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 108/2100 [01:44<30:43,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 109/2100 [01:45<27:29,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 110/2100 [01:46<29:42,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 111/2100 [01:47<31:09,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 112/2100 [01:48<32:04,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 113/2100 [01:48<28:28,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 114/2100 [01:49<29:58,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   5%|▌         | 115/2100 [01:50<31:26,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 116/2100 [01:51<31:24,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 117/2100 [01:52<32:27,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 118/2100 [01:53<32:34,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 119/2100 [01:54<33:06,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 120/2100 [01:55<33:06,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 121/2100 [01:56<33:35,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 122/2100 [01:57<30:58,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 123/2100 [01:58<27:42,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 124/2100 [01:58<25:23,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 125/2100 [01:59<23:11,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 126/2100 [02:00<26:43,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 127/2100 [02:01<23:41,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 128/2100 [02:02<26:59,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 129/2100 [02:03<31:15,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 130/2100 [02:04<32:52,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▌         | 131/2100 [02:05<32:22,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▋         | 132/2100 [02:05<26:37,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▋         | 133/2100 [02:06<28:31,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▋         | 134/2100 [02:07<30:20,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▋         | 135/2100 [02:08<30:22,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   6%|▋         | 136/2100 [02:09<31:37,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 137/2100 [02:10<31:55,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 138/2100 [02:11<28:18,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 139/2100 [02:12<25:52,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 140/2100 [02:13<28:26,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 141/2100 [02:14<30:41,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 142/2100 [02:15<31:18,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 143/2100 [02:15<27:49,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 144/2100 [02:16<29:44,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 145/2100 [02:17<30:12,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 146/2100 [02:18<30:33,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 147/2100 [02:19<31:14,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 148/2100 [02:20<27:54,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 149/2100 [02:21<28:55,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 150/2100 [02:22<29:43,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 151/2100 [02:23<31:08,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 152/2100 [02:24<32:00,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 153/2100 [02:25<32:40,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 154/2100 [02:26<33:06,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 155/2100 [02:27<28:07,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 156/2100 [02:28<28:56,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   7%|▋         | 157/2100 [02:29<29:30,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 158/2100 [02:29<26:31,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 159/2100 [02:30<27:57,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 160/2100 [02:31<28:47,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 161/2100 [02:32<30:32,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 162/2100 [02:33<26:17,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 163/2100 [02:34<28:14,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 164/2100 [02:35<29:26,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 165/2100 [02:36<30:39,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 166/2100 [02:37<31:32,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 167/2100 [02:38<32:14,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 168/2100 [02:39<31:38,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 169/2100 [02:40<32:21,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 170/2100 [02:41<30:54,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 171/2100 [02:42<29:25,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 172/2100 [02:43<30:13,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 173/2100 [02:43<30:34,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 174/2100 [02:45<31:49,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 175/2100 [02:45<28:19,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 176/2100 [02:46<23:42,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 177/2100 [02:47<25:44,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   8%|▊         | 178/2100 [02:48<27:15,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▊         | 179/2100 [02:49<29:20,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▊         | 180/2100 [02:50<29:43,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▊         | 181/2100 [02:51<33:47,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▊         | 182/2100 [02:52<33:43,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▊         | 183/2100 [02:53<29:19,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 184/2100 [02:54<33:03,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 185/2100 [02:55<33:23,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 186/2100 [02:56<33:36,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 187/2100 [02:57<34:10,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 188/2100 [02:58<35:16,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 189/2100 [02:59<34:45,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 190/2100 [03:00<34:39,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 191/2100 [03:01<33:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 192/2100 [03:02<27:35,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 193/2100 [03:03<29:01,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 194/2100 [03:04<32:26,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 195/2100 [03:05<33:16,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 196/2100 [03:06<29:08,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 197/2100 [03:07<30:35,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 198/2100 [03:08<31:33,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:   9%|▉         | 199/2100 [03:09<28:02,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 200/2100 [03:10<28:47,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 201/2100 [03:11<30:14,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 202/2100 [03:12<30:39,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 203/2100 [03:13<31:22,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 204/2100 [03:13<26:43,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 205/2100 [03:14<28:43,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 206/2100 [03:15<30:55,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 207/2100 [03:17<32:36,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 208/2100 [03:18<32:58,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|▉         | 209/2100 [03:19<32:32,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 210/2100 [03:19<27:30,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 211/2100 [03:20<28:16,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 212/2100 [03:21<29:12,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 213/2100 [03:22<30:07,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 214/2100 [03:24<33:50,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 215/2100 [03:25<35:56,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 216/2100 [03:26<35:16,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 217/2100 [03:27<33:32,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 218/2100 [03:28<33:19,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 219/2100 [03:28<28:36,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  10%|█         | 220/2100 [03:29<29:32,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 221/2100 [03:30<25:50,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 222/2100 [03:31<28:04,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 223/2100 [03:32<29:04,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 224/2100 [03:33<29:26,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 225/2100 [03:34<30:21,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 226/2100 [03:35<30:24,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 227/2100 [03:36<29:40,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 228/2100 [03:37<30:09,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 229/2100 [03:38<30:28,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 230/2100 [03:39<31:11,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 231/2100 [03:40<31:47,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 232/2100 [03:41<32:01,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 233/2100 [03:42<31:41,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 234/2100 [03:43<31:55,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 235/2100 [03:44<31:43,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█         | 236/2100 [03:45<31:02,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█▏        | 237/2100 [03:46<31:38,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█▏        | 238/2100 [03:47<31:59,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█▏        | 239/2100 [03:48<31:17,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█▏        | 240/2100 [03:49<30:55,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  11%|█▏        | 241/2100 [03:50<30:55,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 242/2100 [03:51<31:33,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 243/2100 [03:52<31:54,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 244/2100 [03:53<32:07,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 245/2100 [03:54<32:17,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 246/2100 [03:55<32:24,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 247/2100 [03:57<32:09,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 248/2100 [03:58<34:37,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 249/2100 [03:59<33:28,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 250/2100 [04:00<33:37,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 251/2100 [04:01<36:31,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 252/2100 [04:02<32:32,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 253/2100 [04:03<28:22,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 254/2100 [04:04<28:35,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 255/2100 [04:04<24:39,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 256/2100 [04:05<27:00,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 257/2100 [04:06<27:35,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 258/2100 [04:07<28:57,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 259/2100 [04:08<29:27,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 260/2100 [04:09<30:22,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 261/2100 [04:10<30:30,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  12%|█▏        | 262/2100 [04:11<25:04,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 263/2100 [04:12<27:06,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 264/2100 [04:13<27:43,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 265/2100 [04:14<28:04,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 266/2100 [04:15<28:23,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 267/2100 [04:15<27:37,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 268/2100 [04:16<28:54,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 269/2100 [04:17<29:21,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 270/2100 [04:18<29:15,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 271/2100 [04:19<29:33,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 272/2100 [04:20<29:30,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 273/2100 [04:21<29:22,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 274/2100 [04:22<30:18,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 275/2100 [04:23<29:54,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 276/2100 [04:24<30:34,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 277/2100 [04:25<30:57,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 278/2100 [04:26<30:51,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 279/2100 [04:27<30:49,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 280/2100 [04:29<31:02,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 281/2100 [04:29<27:20,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 282/2100 [04:30<24:43,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  13%|█▎        | 283/2100 [04:31<26:57,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▎        | 284/2100 [04:32<28:26,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▎        | 285/2100 [04:33<29:30,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▎        | 286/2100 [04:34<32:02,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▎        | 287/2100 [04:35<31:45,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▎        | 288/2100 [04:36<31:17,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 289/2100 [04:37<27:21,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 290/2100 [04:38<28:40,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 291/2100 [04:39<29:35,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 292/2100 [04:40<29:39,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 293/2100 [04:41<33:19,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 294/2100 [04:42<32:19,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 295/2100 [04:43<31:34,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 296/2100 [04:44<32:12,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 297/2100 [04:45<31:40,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 298/2100 [04:46<31:17,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 299/2100 [04:47<30:52,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 300/2100 [04:49<34:17,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 301/2100 [04:50<32:05,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 302/2100 [04:51<32:20,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 303/2100 [04:52<32:26,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  14%|█▍        | 304/2100 [04:53<31:44,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 305/2100 [04:54<31:33,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 306/2100 [04:55<32:02,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 307/2100 [04:56<31:50,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 308/2100 [04:57<31:40,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 309/2100 [04:58<30:42,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 310/2100 [04:59<30:25,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 311/2100 [05:00<30:08,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 312/2100 [05:01<30:32,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 313/2100 [05:02<29:57,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▍        | 314/2100 [05:03<26:21,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 315/2100 [05:03<23:49,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 316/2100 [05:04<26:03,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 317/2100 [05:05<23:31,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 318/2100 [05:06<25:48,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 319/2100 [05:07<27:17,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 320/2100 [05:08<28:11,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 321/2100 [05:09<29:19,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 322/2100 [05:10<29:56,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 323/2100 [05:11<28:33,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 324/2100 [05:12<29:10,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  15%|█▌        | 325/2100 [05:13<28:45,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 326/2100 [05:14<28:56,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 327/2100 [05:15<29:26,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 328/2100 [05:16<29:24,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 329/2100 [05:17<28:53,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 330/2100 [05:18<29:26,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 331/2100 [05:19<25:52,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 332/2100 [05:19<24:49,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 333/2100 [05:20<26:21,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 334/2100 [05:21<23:24,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 335/2100 [05:22<24:03,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 336/2100 [05:23<26:05,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 337/2100 [05:24<27:29,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 338/2100 [05:25<28:02,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 339/2100 [05:26<28:21,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 340/2100 [05:27<25:10,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▌        | 341/2100 [05:28<26:49,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▋        | 342/2100 [05:29<28:04,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▋        | 343/2100 [05:30<28:56,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▋        | 344/2100 [05:30<25:33,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▋        | 345/2100 [05:31<27:05,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  16%|█▋        | 346/2100 [05:32<27:50,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 347/2100 [05:33<28:18,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 348/2100 [05:35<28:59,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 349/2100 [05:36<29:20,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 350/2100 [05:37<29:39,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 351/2100 [05:38<29:47,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 352/2100 [05:39<29:01,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 353/2100 [05:40<29:11,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 354/2100 [05:41<29:06,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 355/2100 [05:42<29:00,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 356/2100 [05:43<28:35,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 357/2100 [05:44<32:07,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 358/2100 [05:45<30:45,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 359/2100 [05:46<30:19,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 360/2100 [05:47<30:15,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 361/2100 [05:48<30:14,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 362/2100 [05:49<27:38,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 363/2100 [05:50<28:30,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 364/2100 [05:50<25:12,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 365/2100 [05:51<26:41,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 366/2100 [05:52<27:22,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  17%|█▋        | 367/2100 [05:53<27:48,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 368/2100 [05:54<28:04,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 369/2100 [05:55<28:09,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 370/2100 [05:56<26:59,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 371/2100 [05:57<27:08,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 372/2100 [05:58<27:16,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 373/2100 [05:59<28:09,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 374/2100 [06:00<28:41,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 375/2100 [06:01<28:37,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 376/2100 [06:02<29:01,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 377/2100 [06:03<28:49,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 378/2100 [06:04<29:08,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 379/2100 [06:05<28:52,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 380/2100 [06:06<30:06,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 381/2100 [06:07<30:02,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 382/2100 [06:08<26:17,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 383/2100 [06:09<27:29,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 384/2100 [06:10<29:32,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 385/2100 [06:11<28:45,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 386/2100 [06:12<29:04,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 387/2100 [06:13<29:18,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  18%|█▊        | 388/2100 [06:14<29:23,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▊        | 389/2100 [06:15<29:27,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▊        | 390/2100 [06:16<25:48,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▊        | 391/2100 [06:17<26:31,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▊        | 392/2100 [06:18<27:08,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▊        | 393/2100 [06:19<26:38,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 394/2100 [06:20<27:19,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 395/2100 [06:21<26:28,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 396/2100 [06:22<27:04,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 397/2100 [06:22<24:06,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 398/2100 [06:23<24:57,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 399/2100 [06:24<25:29,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 400/2100 [06:25<26:41,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 401/2100 [06:26<27:27,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 402/2100 [06:27<22:35,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 403/2100 [06:28<24:07,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 404/2100 [06:29<25:42,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 405/2100 [06:29<22:41,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 406/2100 [06:30<20:55,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 407/2100 [06:31<23:05,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 408/2100 [06:32<24:41,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  19%|█▉        | 409/2100 [06:33<26:14,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 410/2100 [06:34<26:45,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 411/2100 [06:35<27:40,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 412/2100 [06:36<27:46,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 413/2100 [06:37<27:45,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 414/2100 [06:38<28:17,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 415/2100 [06:39<28:12,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 416/2100 [06:40<28:32,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 417/2100 [06:41<29:12,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 418/2100 [06:42<25:35,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|█▉        | 419/2100 [06:43<26:23,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 420/2100 [06:44<26:57,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 421/2100 [06:45<27:18,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 422/2100 [06:46<27:59,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 423/2100 [06:47<30:00,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 424/2100 [06:48<29:48,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 425/2100 [06:50<32:31,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 426/2100 [06:50<29:01,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 427/2100 [06:51<26:57,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 428/2100 [06:52<27:19,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 429/2100 [06:53<22:29,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  20%|██        | 430/2100 [06:54<24:32,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 431/2100 [06:55<28:45,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 432/2100 [06:56<27:51,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 433/2100 [06:57<27:23,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 434/2100 [06:58<27:36,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 435/2100 [06:59<24:18,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 436/2100 [07:00<25:46,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 437/2100 [07:01<25:27,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 438/2100 [07:02<26:08,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 439/2100 [07:03<27:22,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 440/2100 [07:04<27:31,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 441/2100 [07:05<27:55,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 442/2100 [07:06<28:12,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 443/2100 [07:07<27:51,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 444/2100 [07:07<24:33,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 445/2100 [07:08<25:48,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██        | 446/2100 [07:09<26:47,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██▏       | 447/2100 [07:10<23:21,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██▏       | 448/2100 [07:11<25:20,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██▏       | 449/2100 [07:12<21:53,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██▏       | 450/2100 [07:13<23:10,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  21%|██▏       | 451/2100 [07:14<24:26,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 452/2100 [07:15<25:21,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 453/2100 [07:16<26:19,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 454/2100 [07:17<29:06,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 455/2100 [07:18<28:07,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 456/2100 [07:18<24:35,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 457/2100 [07:19<25:24,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 458/2100 [07:20<26:02,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 459/2100 [07:21<26:28,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 460/2100 [07:22<23:33,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 461/2100 [07:23<25:13,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 462/2100 [07:24<26:12,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 463/2100 [07:25<23:13,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 464/2100 [07:26<24:57,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 465/2100 [07:27<25:53,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 466/2100 [07:28<27:04,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 467/2100 [07:29<26:18,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 468/2100 [07:30<26:34,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 469/2100 [07:31<25:51,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 470/2100 [07:32<26:36,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 471/2100 [07:33<26:48,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  22%|██▏       | 472/2100 [07:34<27:20,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 473/2100 [07:35<27:08,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 474/2100 [07:36<26:56,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 475/2100 [07:37<26:50,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 476/2100 [07:38<27:39,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 477/2100 [07:39<27:02,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 478/2100 [07:40<26:59,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 479/2100 [07:41<26:27,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 480/2100 [07:42<26:54,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 481/2100 [07:43<26:48,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 482/2100 [07:44<26:25,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 483/2100 [07:45<27:00,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 484/2100 [07:46<26:40,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 485/2100 [07:47<27:08,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 486/2100 [07:48<27:27,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 487/2100 [07:49<28:01,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 488/2100 [07:50<24:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 489/2100 [07:50<21:54,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 490/2100 [07:51<23:44,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 491/2100 [07:52<24:35,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 492/2100 [07:53<25:19,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  23%|██▎       | 493/2100 [07:56<36:20,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▎       | 494/2100 [07:57<33:49,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▎       | 495/2100 [07:58<32:02,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▎       | 496/2100 [07:58<29:14,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▎       | 497/2100 [07:59<28:46,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▎       | 498/2100 [08:00<28:02,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 499/2100 [08:02<27:58,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 500/2100 [08:02<26:47,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 501/2100 [08:04<29:52,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 502/2100 [08:05<28:27,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 503/2100 [08:06<27:03,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 504/2100 [08:07<26:55,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 505/2100 [08:08<26:17,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 506/2100 [08:09<29:33,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 507/2100 [08:10<30:58,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 508/2100 [08:12<31:53,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 509/2100 [08:13<30:56,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 510/2100 [08:14<29:32,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 511/2100 [08:14<25:03,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 512/2100 [08:15<25:29,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 513/2100 [08:16<25:16,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  24%|██▍       | 514/2100 [08:17<25:06,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 515/2100 [08:18<25:35,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 516/2100 [08:19<25:51,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 517/2100 [08:20<26:27,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 518/2100 [08:21<27:10,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 519/2100 [08:22<27:03,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 520/2100 [08:23<27:11,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 521/2100 [08:24<27:16,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 522/2100 [08:25<26:32,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 523/2100 [08:26<26:02,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▍       | 524/2100 [08:27<22:53,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 525/2100 [08:28<24:10,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 526/2100 [08:29<24:19,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 527/2100 [08:30<25:08,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 528/2100 [08:31<26:52,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 529/2100 [08:32<25:47,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 530/2100 [08:33<26:18,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 531/2100 [08:34<27:06,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 532/2100 [08:35<26:45,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 533/2100 [08:36<26:29,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 534/2100 [08:37<24:52,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  25%|██▌       | 535/2100 [08:38<25:30,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 536/2100 [08:39<25:55,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 537/2100 [08:40<25:53,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 538/2100 [08:41<26:10,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 539/2100 [08:42<29:06,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 540/2100 [08:43<25:01,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 541/2100 [08:44<25:34,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 542/2100 [08:45<27:56,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 543/2100 [08:46<27:40,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 544/2100 [08:47<27:29,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 545/2100 [08:48<27:26,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 546/2100 [08:49<27:14,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 547/2100 [08:50<26:32,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 548/2100 [08:52<29:28,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 549/2100 [08:53<30:19,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 550/2100 [08:54<28:56,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▌       | 551/2100 [08:55<29:05,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▋       | 552/2100 [08:56<28:29,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▋       | 553/2100 [08:57<28:04,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▋       | 554/2100 [08:58<27:54,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▋       | 555/2100 [08:59<27:39,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  26%|██▋       | 556/2100 [09:01<27:48,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 557/2100 [09:01<24:05,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 558/2100 [09:02<24:53,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 559/2100 [09:03<25:18,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 560/2100 [09:04<21:58,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 561/2100 [09:05<22:59,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 562/2100 [09:05<19:54,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 563/2100 [09:06<21:54,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 564/2100 [09:07<23:19,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 565/2100 [09:08<22:26,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 566/2100 [09:09<23:46,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 567/2100 [09:10<24:42,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 568/2100 [09:11<25:16,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 569/2100 [09:12<25:42,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 570/2100 [09:13<25:13,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 571/2100 [09:14<25:37,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 572/2100 [09:15<25:47,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 573/2100 [09:16<25:14,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 574/2100 [09:17<25:15,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 575/2100 [09:18<25:37,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 576/2100 [09:19<25:29,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  27%|██▋       | 577/2100 [09:20<23:58,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 578/2100 [09:21<24:57,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 579/2100 [09:22<26:10,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 580/2100 [09:23<25:09,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 581/2100 [09:24<24:50,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 582/2100 [09:25<25:21,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 583/2100 [09:26<25:17,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 584/2100 [09:27<24:53,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 585/2100 [09:28<25:20,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 586/2100 [09:29<25:56,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 587/2100 [09:30<22:41,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 588/2100 [09:31<20:25,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 589/2100 [09:32<21:44,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 590/2100 [09:33<23:18,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 591/2100 [09:34<24:08,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 592/2100 [09:35<25:16,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 593/2100 [09:36<25:06,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 594/2100 [09:36<22:05,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 595/2100 [09:37<23:37,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 596/2100 [09:38<24:06,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 597/2100 [09:39<24:19,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  28%|██▊       | 598/2100 [09:40<24:24,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▊       | 599/2100 [09:41<24:47,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▊       | 600/2100 [09:42<25:09,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▊       | 601/2100 [09:44<25:47,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▊       | 602/2100 [09:45<25:12,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▊       | 603/2100 [09:46<25:29,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 604/2100 [09:47<25:39,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 605/2100 [09:48<25:16,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 606/2100 [09:49<25:27,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 607/2100 [09:50<25:54,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 608/2100 [09:51<25:29,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 609/2100 [09:52<26:56,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 610/2100 [09:53<23:15,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 611/2100 [09:54<23:37,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 612/2100 [09:54<23:32,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 613/2100 [09:56<24:13,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 614/2100 [09:57<24:44,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 615/2100 [09:58<24:47,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 616/2100 [09:59<25:08,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 617/2100 [09:59<22:01,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 618/2100 [10:00<23:07,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  29%|██▉       | 619/2100 [10:01<25:00,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 620/2100 [10:02<24:50,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 621/2100 [10:03<25:03,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 622/2100 [10:04<24:27,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 623/2100 [10:05<21:29,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 624/2100 [10:06<22:43,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 625/2100 [10:06<18:50,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 626/2100 [10:07<19:46,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 627/2100 [10:09<23:24,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 628/2100 [10:10<23:43,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|██▉       | 629/2100 [10:11<24:02,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 630/2100 [10:12<24:32,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 631/2100 [10:13<24:54,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 632/2100 [10:14<23:42,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 633/2100 [10:15<24:14,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 634/2100 [10:16<24:11,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 635/2100 [10:17<23:50,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 636/2100 [10:18<24:22,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 637/2100 [10:19<24:19,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 638/2100 [10:20<24:38,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 639/2100 [10:21<24:15,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  30%|███       | 640/2100 [10:22<24:40,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 641/2100 [10:23<24:15,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 642/2100 [10:24<24:11,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 643/2100 [10:25<24:32,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 644/2100 [10:26<24:42,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 645/2100 [10:27<24:53,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 646/2100 [10:28<25:23,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 647/2100 [10:29<25:17,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 648/2100 [10:30<24:36,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 649/2100 [10:31<24:28,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 650/2100 [10:31<21:08,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 651/2100 [10:32<22:22,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 652/2100 [10:33<21:26,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 653/2100 [10:34<22:16,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 654/2100 [10:35<23:07,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 655/2100 [10:36<20:30,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███       | 656/2100 [10:36<17:59,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███▏      | 657/2100 [10:38<20:24,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███▏      | 658/2100 [10:39<21:27,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███▏      | 659/2100 [10:39<19:18,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███▏      | 660/2100 [10:40<20:37,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  31%|███▏      | 661/2100 [10:41<18:41,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 662/2100 [10:41<17:23,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 663/2100 [10:42<19:41,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 664/2100 [10:43<20:29,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 665/2100 [10:44<21:48,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 666/2100 [10:46<25:17,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 667/2100 [10:47<25:12,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 668/2100 [10:48<25:27,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 669/2100 [10:49<26:45,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 670/2100 [10:50<25:27,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 671/2100 [10:51<25:34,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 672/2100 [10:52<25:20,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 673/2100 [10:53<24:50,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 674/2100 [10:54<24:54,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 675/2100 [10:55<24:55,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 676/2100 [10:57<27:26,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 677/2100 [10:58<26:45,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 678/2100 [10:59<26:11,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 679/2100 [10:59<22:33,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 680/2100 [11:00<22:27,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 681/2100 [11:01<23:09,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  32%|███▏      | 682/2100 [11:02<20:25,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 683/2100 [11:03<19:55,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 684/2100 [11:04<20:40,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 685/2100 [11:05<21:32,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 686/2100 [11:06<23:31,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 687/2100 [11:07<23:10,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 688/2100 [11:08<22:53,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 689/2100 [11:09<23:22,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 690/2100 [11:10<24:04,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 691/2100 [11:11<23:58,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 692/2100 [11:12<23:23,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 693/2100 [11:13<24:01,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 694/2100 [11:14<22:44,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 695/2100 [11:15<23:15,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 696/2100 [11:16<23:38,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 697/2100 [11:17<23:48,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 698/2100 [11:18<23:19,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 699/2100 [11:19<23:38,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 700/2100 [11:20<23:54,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 701/2100 [11:21<23:48,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 702/2100 [11:22<26:16,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  33%|███▎      | 703/2100 [11:23<25:41,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▎      | 704/2100 [11:24<24:54,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▎      | 705/2100 [11:26<24:41,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▎      | 706/2100 [11:26<21:26,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▎      | 707/2100 [11:27<22:16,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▎      | 708/2100 [11:28<19:49,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 709/2100 [11:29<20:45,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 710/2100 [11:30<22:27,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 711/2100 [11:30<18:47,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 712/2100 [11:31<20:24,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 713/2100 [11:32<21:07,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 714/2100 [11:33<21:45,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 715/2100 [11:35<23:52,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 716/2100 [11:36<25:38,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 717/2100 [11:37<24:28,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 718/2100 [11:38<24:01,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 719/2100 [11:39<23:00,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 720/2100 [11:39<20:15,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 721/2100 [11:40<16:55,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 722/2100 [11:41<18:52,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 723/2100 [11:41<17:18,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  34%|███▍      | 724/2100 [11:42<18:13,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 725/2100 [11:43<19:52,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 726/2100 [11:44<17:40,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 727/2100 [11:45<19:37,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 728/2100 [11:46<20:52,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 729/2100 [11:47<18:26,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 730/2100 [11:47<18:19,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 731/2100 [11:48<20:14,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 732/2100 [11:49<21:15,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 733/2100 [11:50<22:02,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▍      | 734/2100 [11:52<22:30,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 735/2100 [11:53<22:50,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 736/2100 [11:54<23:01,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 737/2100 [11:54<20:09,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 738/2100 [11:55<20:52,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 739/2100 [11:56<20:59,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 740/2100 [11:57<21:32,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 741/2100 [11:58<21:56,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 742/2100 [11:59<22:20,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 743/2100 [12:00<22:42,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 744/2100 [12:01<22:58,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  35%|███▌      | 745/2100 [12:02<23:08,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 746/2100 [12:03<23:15,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 747/2100 [12:04<22:36,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 748/2100 [12:05<22:53,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 749/2100 [12:06<22:44,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 750/2100 [12:08<24:54,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 751/2100 [12:09<24:19,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 752/2100 [12:09<21:14,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 753/2100 [12:10<21:48,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 754/2100 [12:11<20:42,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 755/2100 [12:12<21:35,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 756/2100 [12:13<21:50,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 757/2100 [12:14<22:19,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 758/2100 [12:15<22:15,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 759/2100 [12:16<19:35,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 760/2100 [12:17<20:19,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▌      | 761/2100 [12:18<21:11,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▋      | 762/2100 [12:19<21:09,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▋      | 763/2100 [12:20<21:06,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▋      | 764/2100 [12:21<23:32,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▋      | 765/2100 [12:22<22:52,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  36%|███▋      | 766/2100 [12:23<23:21,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 767/2100 [12:24<22:37,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 768/2100 [12:25<22:28,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 769/2100 [12:26<22:36,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 770/2100 [12:27<22:24,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 771/2100 [12:28<19:40,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 772/2100 [12:29<20:24,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 773/2100 [12:30<20:48,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 774/2100 [12:31<21:02,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 775/2100 [12:32<20:36,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 776/2100 [12:33<20:41,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 777/2100 [12:34<21:29,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 778/2100 [12:35<21:59,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 779/2100 [12:36<21:38,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 780/2100 [12:37<22:00,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 781/2100 [12:38<22:15,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 782/2100 [12:39<22:18,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 783/2100 [12:40<22:15,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 784/2100 [12:40<19:13,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 785/2100 [12:41<20:14,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 786/2100 [12:42<21:04,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  37%|███▋      | 787/2100 [12:43<21:37,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 788/2100 [12:44<21:43,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 789/2100 [12:45<21:50,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 790/2100 [12:46<22:13,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 791/2100 [12:48<22:28,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 792/2100 [12:48<21:57,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 793/2100 [12:50<22:08,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 794/2100 [12:50<19:24,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 795/2100 [12:51<17:09,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 796/2100 [12:52<18:27,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 797/2100 [12:53<19:24,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 798/2100 [12:54<19:43,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 799/2100 [12:55<22:16,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 800/2100 [12:56<22:03,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 801/2100 [12:57<21:44,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 802/2100 [12:58<21:27,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 803/2100 [12:59<21:55,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 804/2100 [13:00<20:50,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 805/2100 [13:01<19:25,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 806/2100 [13:02<20:00,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 807/2100 [13:02<20:05,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  38%|███▊      | 808/2100 [13:04<21:39,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▊      | 809/2100 [13:05<21:32,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▊      | 810/2100 [13:06<21:50,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▊      | 811/2100 [13:07<21:22,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▊      | 812/2100 [13:08<21:37,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▊      | 813/2100 [13:09<21:55,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 814/2100 [13:10<22:13,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 815/2100 [13:11<22:19,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 816/2100 [13:12<22:18,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 817/2100 [13:13<22:19,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 818/2100 [13:14<22:19,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 819/2100 [13:15<22:00,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 820/2100 [13:16<21:48,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 821/2100 [13:17<22:01,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 822/2100 [13:18<21:48,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 823/2100 [13:19<21:24,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 824/2100 [13:20<21:03,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 825/2100 [13:21<18:37,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 826/2100 [13:22<19:32,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 827/2100 [13:23<19:49,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 828/2100 [13:24<20:15,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  39%|███▉      | 829/2100 [13:25<20:41,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 830/2100 [13:26<20:51,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 831/2100 [13:27<20:37,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 832/2100 [13:28<21:02,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 833/2100 [13:29<21:05,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 834/2100 [13:30<21:06,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 835/2100 [13:31<21:23,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 836/2100 [13:32<21:19,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 837/2100 [13:33<21:14,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 838/2100 [13:34<21:11,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|███▉      | 839/2100 [13:35<20:50,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 840/2100 [13:35<18:22,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 841/2100 [13:36<19:46,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 842/2100 [13:37<20:27,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 843/2100 [13:38<18:05,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 844/2100 [13:39<19:21,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 845/2100 [13:40<19:48,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 846/2100 [13:41<19:50,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 847/2100 [13:42<20:06,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 848/2100 [13:43<20:36,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 849/2100 [13:44<18:10,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  40%|████      | 850/2100 [13:45<18:56,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 851/2100 [13:46<20:11,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 852/2100 [13:46<18:52,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 853/2100 [13:48<19:43,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 854/2100 [13:49<20:23,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 855/2100 [13:50<20:46,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 856/2100 [13:51<21:02,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 857/2100 [13:52<20:34,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 858/2100 [13:53<20:56,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 859/2100 [13:54<20:33,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 860/2100 [13:55<21:14,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 861/2100 [13:56<21:22,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 862/2100 [13:57<21:31,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 863/2100 [13:58<21:52,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 864/2100 [13:59<21:48,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 865/2100 [14:00<21:05,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████      | 866/2100 [14:01<21:31,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████▏     | 867/2100 [14:02<21:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████▏     | 868/2100 [14:03<17:45,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████▏     | 869/2100 [14:03<16:07,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████▏     | 870/2100 [14:04<17:24,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  41%|████▏     | 871/2100 [14:05<18:37,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 872/2100 [14:06<19:48,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 873/2100 [14:07<20:18,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 874/2100 [14:08<20:21,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 875/2100 [14:09<20:42,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 876/2100 [14:11<21:29,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 877/2100 [14:12<21:08,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 878/2100 [14:12<20:04,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 879/2100 [14:13<20:27,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 880/2100 [14:15<20:39,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 881/2100 [14:16<20:47,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 882/2100 [14:17<20:53,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 883/2100 [14:18<20:57,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 884/2100 [14:19<21:01,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 885/2100 [14:20<20:47,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 886/2100 [14:21<20:58,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 887/2100 [14:22<21:11,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 888/2100 [14:23<21:00,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 889/2100 [14:24<20:46,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 890/2100 [14:25<20:52,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 891/2100 [14:25<17:56,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  42%|████▏     | 892/2100 [14:27<18:52,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 893/2100 [14:28<19:15,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 894/2100 [14:28<19:13,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 895/2100 [14:29<19:29,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 896/2100 [14:31<19:59,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 897/2100 [14:32<20:15,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 898/2100 [14:32<19:15,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 899/2100 [14:33<17:04,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 900/2100 [14:34<18:18,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 901/2100 [14:35<18:51,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 902/2100 [14:36<19:09,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 903/2100 [14:37<19:42,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 904/2100 [14:38<20:57,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 905/2100 [14:39<20:37,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 906/2100 [14:40<20:45,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 907/2100 [14:41<18:08,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 908/2100 [14:42<18:46,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 909/2100 [14:43<19:19,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 910/2100 [14:44<19:50,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 911/2100 [14:45<20:16,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 912/2100 [14:46<20:13,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  43%|████▎     | 913/2100 [14:47<17:59,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▎     | 914/2100 [14:48<17:37,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▎     | 915/2100 [14:49<18:34,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▎     | 916/2100 [14:50<19:18,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▎     | 917/2100 [14:50<15:53,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▎     | 918/2100 [14:51<16:58,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 919/2100 [14:52<18:23,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 920/2100 [14:53<19:02,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 921/2100 [14:54<19:15,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 922/2100 [14:55<19:37,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 923/2100 [14:56<19:28,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 924/2100 [14:57<17:08,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 925/2100 [14:58<17:54,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 926/2100 [14:59<18:45,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 927/2100 [15:00<19:11,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 928/2100 [15:01<19:30,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 929/2100 [15:02<19:12,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 930/2100 [15:03<19:31,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 931/2100 [15:04<17:12,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 932/2100 [15:05<18:11,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 933/2100 [15:06<18:56,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  44%|████▍     | 934/2100 [15:07<19:23,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 935/2100 [15:08<19:07,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 936/2100 [15:09<19:38,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 937/2100 [15:10<20:00,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 938/2100 [15:11<19:53,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 939/2100 [15:11<16:15,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 940/2100 [15:13<18:53,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 941/2100 [15:14<19:14,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 942/2100 [15:15<18:36,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 943/2100 [15:16<19:00,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▍     | 944/2100 [15:16<16:09,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 945/2100 [15:17<17:23,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 946/2100 [15:18<15:38,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 947/2100 [15:19<16:58,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 948/2100 [15:20<17:21,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 949/2100 [15:21<17:59,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 950/2100 [15:22<18:44,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 951/2100 [15:23<18:57,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 952/2100 [15:24<19:16,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 953/2100 [15:24<15:49,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 954/2100 [15:25<17:01,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  45%|████▌     | 955/2100 [15:26<17:19,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 956/2100 [15:27<18:08,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 957/2100 [15:29<18:59,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 958/2100 [15:30<19:17,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 959/2100 [15:31<19:15,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 960/2100 [15:32<20:50,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 961/2100 [15:33<20:32,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 962/2100 [15:34<20:12,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 963/2100 [15:35<20:05,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 964/2100 [15:36<20:01,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 965/2100 [15:37<21:21,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 966/2100 [15:38<17:49,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 967/2100 [15:38<15:37,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 968/2100 [15:40<16:53,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 969/2100 [15:41<17:29,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 970/2100 [15:42<19:16,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▌     | 971/2100 [15:42<16:36,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▋     | 972/2100 [15:44<18:24,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▋     | 973/2100 [15:45<18:37,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▋     | 974/2100 [15:46<18:43,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▋     | 975/2100 [15:46<15:58,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  46%|████▋     | 976/2100 [15:47<17:07,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 977/2100 [15:48<18:24,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 978/2100 [15:49<18:47,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 979/2100 [15:50<18:58,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 980/2100 [15:51<18:00,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 981/2100 [15:52<18:29,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 982/2100 [15:53<16:19,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 983/2100 [15:54<17:09,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 984/2100 [15:55<15:37,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 985/2100 [15:55<14:15,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 986/2100 [15:56<15:46,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 987/2100 [15:57<16:34,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 988/2100 [15:58<16:53,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 989/2100 [15:59<18:28,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 990/2100 [16:00<16:14,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 991/2100 [16:01<16:55,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 992/2100 [16:02<15:07,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 993/2100 [16:03<17:42,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 994/2100 [16:04<18:45,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 995/2100 [16:05<19:05,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 996/2100 [16:06<19:11,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  47%|████▋     | 997/2100 [16:07<16:46,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 998/2100 [16:08<17:14,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 999/2100 [16:09<19:00,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1000/2100 [16:10<18:39,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1001/2100 [16:11<18:54,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1002/2100 [16:12<17:34,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1003/2100 [16:13<17:48,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1004/2100 [16:14<20:09,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1005/2100 [16:15<19:38,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1006/2100 [16:16<19:47,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1007/2100 [16:17<19:37,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1008/2100 [16:18<19:12,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1009/2100 [16:19<19:00,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1010/2100 [16:20<15:32,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1011/2100 [16:20<14:09,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1012/2100 [16:21<15:08,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1013/2100 [16:22<15:54,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1014/2100 [16:23<16:22,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1015/2100 [16:24<14:43,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1016/2100 [16:25<16:14,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1017/2100 [16:26<16:46,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  48%|████▊     | 1018/2100 [16:27<17:26,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▊     | 1019/2100 [16:28<17:49,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▊     | 1020/2100 [16:29<17:51,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▊     | 1021/2100 [16:30<18:12,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▊     | 1022/2100 [16:31<17:51,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▊     | 1023/2100 [16:32<18:10,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1024/2100 [16:33<18:27,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1025/2100 [16:34<17:18,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1026/2100 [16:35<17:13,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1027/2100 [16:36<17:34,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1028/2100 [16:37<18:26,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1029/2100 [16:38<18:17,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1030/2100 [16:39<15:48,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1031/2100 [16:40<16:39,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1032/2100 [16:41<17:02,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1033/2100 [16:42<17:03,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1034/2100 [16:43<17:30,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1035/2100 [16:44<17:17,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1036/2100 [16:45<17:26,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1037/2100 [16:46<17:51,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1038/2100 [16:47<17:31,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  49%|████▉     | 1039/2100 [16:47<15:25,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1040/2100 [16:48<15:24,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1041/2100 [16:49<16:15,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1042/2100 [16:50<16:56,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1043/2100 [16:52<21:39,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1044/2100 [16:53<20:41,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1045/2100 [16:54<19:56,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1046/2100 [16:55<19:07,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1047/2100 [16:57<19:54,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1048/2100 [16:58<19:11,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|████▉     | 1049/2100 [16:59<18:59,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1050/2100 [17:00<18:56,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1051/2100 [17:01<18:12,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1052/2100 [17:02<18:11,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1053/2100 [17:03<17:57,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1054/2100 [17:04<17:37,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1055/2100 [17:05<17:48,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1056/2100 [17:06<17:54,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1057/2100 [17:07<17:30,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1058/2100 [17:08<18:44,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1059/2100 [17:09<18:20,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  50%|█████     | 1060/2100 [17:10<18:22,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1061/2100 [17:11<18:04,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1062/2100 [17:12<18:58,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1063/2100 [17:13<18:26,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1064/2100 [17:14<16:00,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1065/2100 [17:15<16:21,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1066/2100 [17:16<16:37,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1067/2100 [17:17<17:01,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1068/2100 [17:18<17:17,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1069/2100 [17:19<17:16,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1070/2100 [17:20<17:17,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1071/2100 [17:21<17:02,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1072/2100 [17:22<17:27,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1073/2100 [17:23<14:50,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1074/2100 [17:23<12:27,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1075/2100 [17:23<11:17,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████     | 1076/2100 [17:25<13:16,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████▏    | 1077/2100 [17:25<14:08,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████▏    | 1078/2100 [17:26<14:41,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████▏    | 1079/2100 [17:27<15:09,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████▏    | 1080/2100 [17:28<15:47,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  51%|█████▏    | 1081/2100 [17:29<16:05,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1082/2100 [17:30<16:25,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1083/2100 [17:32<18:20,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1084/2100 [17:33<18:09,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1085/2100 [17:34<16:35,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1086/2100 [17:34<14:47,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1087/2100 [17:35<15:44,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1088/2100 [17:36<16:17,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1089/2100 [17:37<14:24,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1090/2100 [17:38<15:41,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1091/2100 [17:39<16:19,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1092/2100 [17:40<16:30,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1093/2100 [17:41<16:53,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1094/2100 [17:42<14:49,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1095/2100 [17:42<13:24,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1096/2100 [17:43<14:38,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1097/2100 [17:44<15:47,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1098/2100 [17:45<15:49,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1099/2100 [17:46<16:23,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1100/2100 [17:47<14:28,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1101/2100 [17:48<15:21,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  52%|█████▏    | 1102/2100 [17:49<15:43,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1103/2100 [17:51<17:58,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1104/2100 [17:52<18:02,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1105/2100 [17:53<17:21,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1106/2100 [17:53<15:07,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1107/2100 [17:54<15:45,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1108/2100 [17:55<16:15,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1109/2100 [17:56<14:22,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1110/2100 [17:57<17:07,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1111/2100 [17:58<16:59,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1112/2100 [17:59<17:06,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1113/2100 [18:00<16:40,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1114/2100 [18:01<16:16,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1115/2100 [18:02<14:17,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1116/2100 [18:03<15:11,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1117/2100 [18:04<15:31,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1118/2100 [18:05<15:45,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1119/2100 [18:06<13:57,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1120/2100 [18:07<14:56,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1121/2100 [18:08<15:19,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1122/2100 [18:09<15:49,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  53%|█████▎    | 1123/2100 [18:10<16:16,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▎    | 1124/2100 [18:11<16:37,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▎    | 1125/2100 [18:11<14:37,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▎    | 1126/2100 [18:12<15:26,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▎    | 1127/2100 [18:13<15:39,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▎    | 1128/2100 [18:14<15:48,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1129/2100 [18:16<16:09,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1130/2100 [18:17<16:23,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1131/2100 [18:18<16:33,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1132/2100 [18:19<16:34,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1133/2100 [18:20<16:41,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1134/2100 [18:21<16:48,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1135/2100 [18:22<16:39,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1136/2100 [18:23<16:42,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1137/2100 [18:24<18:01,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1138/2100 [18:25<15:30,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1139/2100 [18:26<15:37,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1140/2100 [18:27<15:46,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1141/2100 [18:28<16:02,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1142/2100 [18:29<16:16,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1143/2100 [18:30<15:54,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  54%|█████▍    | 1144/2100 [18:31<16:12,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1145/2100 [18:32<16:17,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1146/2100 [18:33<16:08,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1147/2100 [18:34<16:20,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1148/2100 [18:35<16:27,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1149/2100 [18:36<16:14,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1150/2100 [18:37<16:32,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1151/2100 [18:38<16:35,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1152/2100 [18:39<16:24,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1153/2100 [18:40<14:22,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▍    | 1154/2100 [18:41<15:02,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1155/2100 [18:42<15:28,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1156/2100 [18:43<15:47,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1157/2100 [18:44<13:40,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1158/2100 [18:45<14:17,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1159/2100 [18:46<14:43,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1160/2100 [18:47<15:04,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1161/2100 [18:48<15:30,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1162/2100 [18:49<16:03,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1163/2100 [18:50<15:40,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1164/2100 [18:51<15:55,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  55%|█████▌    | 1165/2100 [18:52<15:48,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1166/2100 [18:53<15:47,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1167/2100 [18:54<15:55,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1168/2100 [18:55<15:34,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1169/2100 [18:56<15:47,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1170/2100 [18:57<15:42,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1171/2100 [18:58<15:54,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1172/2100 [18:59<15:33,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1173/2100 [19:00<15:47,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1174/2100 [19:00<13:52,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1175/2100 [19:02<14:34,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1176/2100 [19:03<14:53,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1177/2100 [19:04<14:59,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1178/2100 [19:04<13:15,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1179/2100 [19:05<13:27,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1180/2100 [19:06<13:49,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▌    | 1181/2100 [19:07<14:35,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▋    | 1182/2100 [19:08<14:53,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▋    | 1183/2100 [19:09<15:15,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▋    | 1184/2100 [19:10<15:04,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▋    | 1185/2100 [19:11<15:26,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  56%|█████▋    | 1186/2100 [19:12<15:39,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1187/2100 [19:13<15:16,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1188/2100 [19:14<15:00,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1189/2100 [19:15<15:17,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1190/2100 [19:16<15:26,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1191/2100 [19:17<15:52,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1192/2100 [19:18<15:53,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1193/2100 [19:20<16:07,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1194/2100 [19:21<16:02,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1195/2100 [19:21<13:57,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1196/2100 [19:22<13:41,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1197/2100 [19:23<14:16,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1198/2100 [19:24<15:53,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1199/2100 [19:25<15:35,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1200/2100 [19:26<15:35,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1201/2100 [19:27<13:34,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1202/2100 [19:28<11:59,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1203/2100 [19:29<13:08,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1204/2100 [19:30<13:38,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1205/2100 [19:31<14:12,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1206/2100 [19:31<12:09,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  57%|█████▋    | 1207/2100 [19:32<12:59,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1208/2100 [19:33<13:29,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1209/2100 [19:34<14:11,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1210/2100 [19:35<14:41,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1211/2100 [19:36<14:58,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1212/2100 [19:37<14:55,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1213/2100 [19:38<15:06,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1214/2100 [19:39<15:12,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1215/2100 [19:40<13:22,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1216/2100 [19:41<13:58,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1217/2100 [19:42<12:26,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1218/2100 [19:43<13:20,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1219/2100 [19:44<13:44,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1220/2100 [19:45<14:05,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1221/2100 [19:46<14:29,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1222/2100 [19:47<14:29,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1223/2100 [19:48<14:34,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1224/2100 [19:49<14:49,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1225/2100 [19:50<14:43,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1226/2100 [19:51<14:29,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1227/2100 [19:52<14:44,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  58%|█████▊    | 1228/2100 [19:53<14:55,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▊    | 1229/2100 [19:54<15:01,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▊    | 1230/2100 [19:55<16:23,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▊    | 1231/2100 [19:56<14:03,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▊    | 1232/2100 [19:57<14:24,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▊    | 1233/2100 [19:58<16:11,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1234/2100 [20:00<15:47,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1235/2100 [20:00<13:41,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1236/2100 [20:01<13:43,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1237/2100 [20:02<13:41,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1238/2100 [20:03<13:50,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1239/2100 [20:04<13:56,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1240/2100 [20:05<14:11,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1241/2100 [20:06<14:26,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1242/2100 [20:07<14:34,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1243/2100 [20:08<14:28,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1244/2100 [20:09<14:13,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1245/2100 [20:10<14:35,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1246/2100 [20:11<12:52,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1247/2100 [20:12<13:21,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1248/2100 [20:13<13:37,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  59%|█████▉    | 1249/2100 [20:14<13:47,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1250/2100 [20:15<13:44,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1251/2100 [20:16<15:19,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1252/2100 [20:17<15:09,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1253/2100 [20:18<14:36,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1254/2100 [20:19<14:10,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1255/2100 [20:20<14:21,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1256/2100 [20:21<14:19,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1257/2100 [20:22<14:36,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1258/2100 [20:23<14:54,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|█████▉    | 1259/2100 [20:24<14:41,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1260/2100 [20:25<12:53,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1261/2100 [20:26<13:25,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1262/2100 [20:27<13:45,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1263/2100 [20:28<15:00,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1264/2100 [20:29<14:35,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1265/2100 [20:30<14:20,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1266/2100 [20:31<14:12,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1267/2100 [20:32<12:27,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1268/2100 [20:33<11:02,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1269/2100 [20:34<12:16,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  60%|██████    | 1270/2100 [20:35<12:58,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1271/2100 [20:36<13:12,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1272/2100 [20:37<13:20,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1273/2100 [20:38<13:52,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1274/2100 [20:38<12:13,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1275/2100 [20:39<12:30,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1276/2100 [20:40<12:40,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1277/2100 [20:41<12:58,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1278/2100 [20:43<14:48,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1279/2100 [20:44<14:29,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1280/2100 [20:45<14:13,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1281/2100 [20:46<13:52,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1282/2100 [20:47<13:39,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1283/2100 [20:48<13:17,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1284/2100 [20:49<13:10,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1285/2100 [20:49<11:40,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████    | 1286/2100 [20:50<11:49,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████▏   | 1287/2100 [20:51<12:31,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████▏   | 1288/2100 [20:52<12:34,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████▏   | 1289/2100 [20:53<13:02,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████▏   | 1290/2100 [20:54<13:19,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  61%|██████▏   | 1291/2100 [20:55<13:23,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1292/2100 [20:56<13:11,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1293/2100 [20:57<14:29,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1294/2100 [20:58<14:20,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1295/2100 [21:00<14:39,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1296/2100 [21:01<14:40,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1297/2100 [21:02<14:30,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1298/2100 [21:03<14:23,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1299/2100 [21:04<14:14,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1300/2100 [21:05<14:10,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1301/2100 [21:06<13:54,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1302/2100 [21:06<11:20,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1303/2100 [21:07<11:51,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1304/2100 [21:08<12:15,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1305/2100 [21:09<12:32,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1306/2100 [21:10<13:14,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1307/2100 [21:11<13:07,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1308/2100 [21:12<13:28,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1309/2100 [21:13<13:34,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1310/2100 [21:15<13:35,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1311/2100 [21:16<13:25,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  62%|██████▏   | 1312/2100 [21:17<13:21,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1313/2100 [21:18<13:13,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1314/2100 [21:18<12:33,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1315/2100 [21:19<12:44,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1316/2100 [21:20<13:15,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1317/2100 [21:22<13:24,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1318/2100 [21:23<13:10,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1319/2100 [21:23<11:35,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1320/2100 [21:24<12:25,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1321/2100 [21:25<12:34,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1322/2100 [21:26<12:34,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1323/2100 [21:27<12:39,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1324/2100 [21:28<12:56,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1325/2100 [21:29<13:09,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1326/2100 [21:30<13:21,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1327/2100 [21:31<13:24,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1328/2100 [21:32<13:04,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1329/2100 [21:33<13:01,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1330/2100 [21:34<11:27,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1331/2100 [21:35<12:02,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1332/2100 [21:36<12:20,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  63%|██████▎   | 1333/2100 [21:37<12:15,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▎   | 1334/2100 [21:38<12:10,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▎   | 1335/2100 [21:39<12:32,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▎   | 1336/2100 [21:40<12:44,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▎   | 1337/2100 [21:41<12:53,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▎   | 1338/2100 [21:42<13:00,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1339/2100 [21:43<11:23,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1340/2100 [21:44<12:07,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1341/2100 [21:45<12:27,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1342/2100 [21:46<12:31,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1343/2100 [21:47<12:39,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1344/2100 [21:48<12:42,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1345/2100 [21:49<12:53,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1346/2100 [21:50<12:44,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1347/2100 [21:51<13:47,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1348/2100 [21:52<13:42,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1349/2100 [21:53<13:17,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1350/2100 [21:54<13:16,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1351/2100 [21:55<13:00,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1352/2100 [21:56<11:19,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1353/2100 [21:57<12:04,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  64%|██████▍   | 1354/2100 [21:58<12:22,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1355/2100 [21:59<12:16,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1356/2100 [22:00<12:18,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1357/2100 [22:01<12:26,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1358/2100 [22:02<12:42,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1359/2100 [22:03<12:48,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1360/2100 [22:04<12:40,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1361/2100 [22:05<11:05,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1362/2100 [22:06<11:37,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1363/2100 [22:07<11:48,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▍   | 1364/2100 [22:08<11:55,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1365/2100 [22:09<12:13,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1366/2100 [22:10<13:06,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1367/2100 [22:11<12:42,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1368/2100 [22:12<12:35,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1369/2100 [22:13<12:16,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1370/2100 [22:14<10:47,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1371/2100 [22:15<11:26,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1372/2100 [22:16<11:28,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1373/2100 [22:17<11:47,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1374/2100 [22:18<12:01,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  65%|██████▌   | 1375/2100 [22:19<12:12,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1376/2100 [22:20<11:38,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1377/2100 [22:21<10:31,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1378/2100 [22:21<10:48,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1379/2100 [22:22<11:14,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1380/2100 [22:23<10:33,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1381/2100 [22:24<09:16,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1382/2100 [22:25<10:17,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1383/2100 [22:26<11:17,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1384/2100 [22:27<10:02,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1385/2100 [22:28<10:43,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1386/2100 [22:29<11:12,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1387/2100 [22:30<11:13,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1388/2100 [22:31<11:35,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1389/2100 [22:32<11:47,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1390/2100 [22:33<11:55,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▌   | 1391/2100 [22:34<12:08,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▋   | 1392/2100 [22:35<12:00,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▋   | 1393/2100 [22:36<12:30,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▋   | 1394/2100 [22:37<12:26,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▋   | 1395/2100 [22:38<12:25,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  66%|██████▋   | 1396/2100 [22:39<12:12,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1397/2100 [22:40<12:03,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1398/2100 [22:41<11:56,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1399/2100 [22:42<11:52,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1400/2100 [22:43<10:24,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1401/2100 [22:44<10:56,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1402/2100 [22:45<11:18,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1403/2100 [22:46<11:03,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1404/2100 [22:47<11:06,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1405/2100 [22:48<11:28,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1406/2100 [22:50<14:45,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1407/2100 [22:51<13:50,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1408/2100 [22:52<13:37,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1409/2100 [22:53<13:06,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1410/2100 [22:54<12:47,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1411/2100 [22:55<12:14,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1412/2100 [22:56<12:11,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1413/2100 [22:57<13:01,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1414/2100 [22:58<12:43,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1415/2100 [22:59<10:58,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1416/2100 [23:00<11:16,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  67%|██████▋   | 1417/2100 [23:01<11:08,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1418/2100 [23:02<11:20,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1419/2100 [23:03<11:08,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1420/2100 [23:04<11:20,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1421/2100 [23:05<11:30,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1422/2100 [23:06<11:36,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1423/2100 [23:07<11:39,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1424/2100 [23:08<11:42,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1425/2100 [23:09<11:36,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1426/2100 [23:10<09:28,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1427/2100 [23:11<10:14,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1428/2100 [23:12<10:23,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1429/2100 [23:13<10:44,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1430/2100 [23:14<11:08,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1431/2100 [23:15<11:40,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1432/2100 [23:16<11:49,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1433/2100 [23:17<11:36,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1434/2100 [23:18<11:36,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1435/2100 [23:19<10:09,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1436/2100 [23:20<10:43,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1437/2100 [23:20<09:30,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  68%|██████▊   | 1438/2100 [23:21<09:48,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▊   | 1439/2100 [23:22<10:23,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▊   | 1440/2100 [23:23<10:36,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▊   | 1441/2100 [23:25<11:43,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▊   | 1442/2100 [23:26<11:41,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▊   | 1443/2100 [23:26<09:51,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1444/2100 [23:27<10:18,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1445/2100 [23:28<10:50,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1446/2100 [23:29<11:02,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1447/2100 [23:31<11:10,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1448/2100 [23:32<11:11,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1449/2100 [23:33<11:15,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1450/2100 [23:34<11:17,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1451/2100 [23:35<11:24,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1452/2100 [23:36<11:24,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1453/2100 [23:37<11:24,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1454/2100 [23:38<11:13,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1455/2100 [23:39<11:24,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1456/2100 [23:40<11:24,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1457/2100 [23:40<09:17,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1458/2100 [23:41<09:42,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  69%|██████▉   | 1459/2100 [23:43<10:12,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1460/2100 [23:44<10:32,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1461/2100 [23:45<10:35,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1462/2100 [23:46<10:45,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1463/2100 [23:47<10:35,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1464/2100 [23:48<10:47,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1465/2100 [23:49<10:59,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1466/2100 [23:50<10:46,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1467/2100 [23:51<10:33,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1468/2100 [23:52<10:30,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|██████▉   | 1469/2100 [23:53<10:38,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1470/2100 [23:54<10:46,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1471/2100 [23:55<10:42,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1472/2100 [23:55<09:22,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1473/2100 [23:56<09:43,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1474/2100 [23:57<09:55,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1475/2100 [23:58<10:04,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1476/2100 [23:59<10:16,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1477/2100 [24:01<10:30,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1478/2100 [24:02<10:46,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1479/2100 [24:03<10:47,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  70%|███████   | 1480/2100 [24:04<10:55,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1481/2100 [24:05<10:44,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1482/2100 [24:06<10:35,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1483/2100 [24:07<10:38,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1484/2100 [24:08<10:41,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1485/2100 [24:09<10:34,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1486/2100 [24:10<10:38,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1487/2100 [24:11<10:41,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1488/2100 [24:12<10:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1489/2100 [24:13<10:32,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1490/2100 [24:14<10:24,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1491/2100 [24:15<09:07,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1492/2100 [24:16<09:35,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1493/2100 [24:17<10:02,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1494/2100 [24:18<10:04,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1495/2100 [24:18<08:53,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████   | 1496/2100 [24:20<10:03,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████▏  | 1497/2100 [24:21<10:02,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████▏  | 1498/2100 [24:22<10:10,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████▏  | 1499/2100 [24:23<10:23,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████▏  | 1500/2100 [24:24<10:15,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  71%|███████▏  | 1501/2100 [24:25<09:53,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1502/2100 [24:26<09:37,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1503/2100 [24:27<09:25,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1504/2100 [24:28<09:16,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1505/2100 [24:28<09:12,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1506/2100 [24:29<08:56,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1507/2100 [24:30<09:28,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1508/2100 [24:31<09:15,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1509/2100 [24:32<09:06,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1510/2100 [24:33<08:55,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1511/2100 [24:34<10:23,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1512/2100 [24:36<10:31,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1513/2100 [24:37<10:39,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1514/2100 [24:38<10:39,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1515/2100 [24:39<09:55,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1516/2100 [24:40<09:39,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1517/2100 [24:41<09:30,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1518/2100 [24:41<09:17,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1519/2100 [24:43<10:38,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1520/2100 [24:44<10:03,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1521/2100 [24:45<09:39,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  72%|███████▏  | 1522/2100 [24:46<09:57,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1523/2100 [24:47<09:33,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1524/2100 [24:48<09:15,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1525/2100 [24:48<09:06,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1526/2100 [24:49<08:49,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1527/2100 [24:50<08:45,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1528/2100 [24:51<08:41,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1529/2100 [24:52<08:32,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1530/2100 [24:53<08:33,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1531/2100 [24:54<08:34,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1532/2100 [24:55<08:34,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1533/2100 [24:56<09:57,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1534/2100 [24:57<09:31,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1535/2100 [24:58<09:14,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1536/2100 [24:59<09:01,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1537/2100 [25:00<08:50,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1538/2100 [25:01<08:47,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1539/2100 [25:02<09:14,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1540/2100 [25:03<08:57,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1541/2100 [25:04<08:46,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1542/2100 [25:04<08:31,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  73%|███████▎  | 1543/2100 [25:05<08:28,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▎  | 1544/2100 [25:06<08:26,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▎  | 1545/2100 [25:08<09:46,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▎  | 1546/2100 [25:09<09:20,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▎  | 1547/2100 [25:09<09:05,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▎  | 1548/2100 [25:10<08:55,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1549/2100 [25:11<08:41,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1550/2100 [25:12<08:30,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1551/2100 [25:13<08:25,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1552/2100 [25:14<08:13,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1553/2100 [25:15<08:13,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1554/2100 [25:16<08:45,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1555/2100 [25:17<08:34,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1556/2100 [25:18<08:31,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1557/2100 [25:19<08:26,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1558/2100 [25:20<08:20,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1559/2100 [25:21<09:39,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1560/2100 [25:22<09:12,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1561/2100 [25:23<08:54,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1562/2100 [25:24<08:43,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1563/2100 [25:25<09:50,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  74%|███████▍  | 1564/2100 [25:26<09:18,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1565/2100 [25:27<08:55,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1566/2100 [25:28<09:59,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1567/2100 [25:29<09:16,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1568/2100 [25:30<09:26,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1569/2100 [25:31<09:02,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1570/2100 [25:32<08:42,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1571/2100 [25:33<08:19,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1572/2100 [25:34<08:08,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1573/2100 [25:35<08:04,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▍  | 1574/2100 [25:36<08:01,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1575/2100 [25:37<07:59,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1576/2100 [25:38<07:56,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1577/2100 [25:38<07:53,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1578/2100 [25:39<07:49,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1579/2100 [25:40<08:17,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1580/2100 [25:42<08:42,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1581/2100 [25:42<08:23,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1582/2100 [25:43<08:12,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1583/2100 [25:44<08:06,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1584/2100 [25:45<07:59,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  75%|███████▌  | 1585/2100 [25:46<08:23,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1586/2100 [25:47<08:41,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1587/2100 [25:48<08:23,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1588/2100 [25:49<08:10,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1589/2100 [25:50<08:01,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1590/2100 [25:51<09:10,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1591/2100 [25:53<09:57,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1592/2100 [25:54<09:13,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1593/2100 [25:55<09:15,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1594/2100 [25:56<09:14,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1595/2100 [25:57<08:43,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1596/2100 [25:58<09:36,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1597/2100 [26:00<10:16,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1598/2100 [26:01<09:26,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1599/2100 [26:02<09:19,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1600/2100 [26:03<08:44,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▌  | 1601/2100 [26:03<08:26,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▋  | 1602/2100 [26:05<09:24,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▋  | 1603/2100 [26:06<09:21,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▋  | 1604/2100 [26:07<08:45,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▋  | 1605/2100 [26:08<08:22,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  76%|███████▋  | 1606/2100 [26:09<08:06,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1607/2100 [26:10<07:47,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1608/2100 [26:10<07:39,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1609/2100 [26:11<07:34,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1610/2100 [26:12<07:30,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1611/2100 [26:13<07:30,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1612/2100 [26:14<07:26,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1613/2100 [26:15<07:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1614/2100 [26:16<07:23,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1615/2100 [26:17<07:20,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1616/2100 [26:18<07:17,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1617/2100 [26:19<07:17,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1618/2100 [26:20<07:15,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1619/2100 [26:20<07:13,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1620/2100 [26:21<07:13,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1621/2100 [26:22<07:42,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1622/2100 [26:23<07:33,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1623/2100 [26:24<07:18,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1624/2100 [26:25<07:16,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1625/2100 [26:26<07:05,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1626/2100 [26:27<06:59,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  77%|███████▋  | 1627/2100 [26:28<07:00,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1628/2100 [26:29<07:03,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1629/2100 [26:30<07:32,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1630/2100 [26:31<07:25,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1631/2100 [26:32<07:18,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1632/2100 [26:33<07:16,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1633/2100 [26:33<07:10,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1634/2100 [26:35<07:40,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1635/2100 [26:36<07:56,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1636/2100 [26:37<07:34,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1637/2100 [26:37<07:24,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1638/2100 [26:38<07:16,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1639/2100 [26:39<07:04,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1640/2100 [26:40<07:02,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1641/2100 [26:41<06:59,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1642/2100 [26:42<08:05,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1643/2100 [26:43<07:43,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1644/2100 [26:44<07:27,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1645/2100 [26:46<08:24,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1646/2100 [26:47<08:22,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1647/2100 [26:48<07:53,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  78%|███████▊  | 1648/2100 [26:49<07:33,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▊  | 1649/2100 [26:49<07:18,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▊  | 1650/2100 [26:50<07:08,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▊  | 1651/2100 [26:51<06:58,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▊  | 1652/2100 [26:52<06:53,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▊  | 1653/2100 [26:53<06:50,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1654/2100 [26:54<06:47,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1655/2100 [26:55<06:44,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1656/2100 [26:56<06:41,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1657/2100 [26:57<06:39,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1658/2100 [26:58<06:38,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1659/2100 [26:58<06:37,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1660/2100 [26:59<06:39,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1661/2100 [27:01<07:10,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1662/2100 [27:01<06:52,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1663/2100 [27:03<07:52,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1664/2100 [27:04<07:28,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1665/2100 [27:05<07:10,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1666/2100 [27:06<06:59,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1667/2100 [27:06<06:52,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1668/2100 [27:07<06:44,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  79%|███████▉  | 1669/2100 [27:08<06:32,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1670/2100 [27:09<06:29,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1671/2100 [27:10<06:54,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1672/2100 [27:11<06:46,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1673/2100 [27:12<06:41,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1674/2100 [27:13<06:38,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1675/2100 [27:14<06:59,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1676/2100 [27:15<07:14,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1677/2100 [27:16<06:56,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1678/2100 [27:17<06:44,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|███████▉  | 1679/2100 [27:18<07:01,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1680/2100 [27:19<06:46,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1681/2100 [27:20<06:38,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1682/2100 [27:21<06:33,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1683/2100 [27:22<06:55,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1684/2100 [27:23<07:09,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1685/2100 [27:24<06:48,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1686/2100 [27:25<06:38,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1687/2100 [27:26<06:32,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1688/2100 [27:27<06:26,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1689/2100 [27:28<06:20,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  80%|████████  | 1690/2100 [27:28<06:19,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1691/2100 [27:30<06:40,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1692/2100 [27:30<06:31,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1693/2100 [27:31<06:25,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1694/2100 [27:32<06:19,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1695/2100 [27:33<06:14,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1696/2100 [27:34<06:11,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1697/2100 [27:35<06:08,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1698/2100 [27:36<06:04,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1699/2100 [27:37<06:04,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1700/2100 [27:38<06:04,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1701/2100 [27:39<06:04,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1702/2100 [27:40<07:01,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1703/2100 [27:41<06:41,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1704/2100 [27:42<06:30,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1705/2100 [27:43<06:20,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████  | 1706/2100 [27:44<07:09,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████▏ | 1707/2100 [27:45<06:48,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████▏ | 1708/2100 [27:46<06:30,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████▏ | 1709/2100 [27:47<06:42,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████▏ | 1710/2100 [27:48<06:26,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  81%|████████▏ | 1711/2100 [27:49<06:16,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1712/2100 [27:50<06:33,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1713/2100 [27:51<06:19,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1714/2100 [27:52<06:32,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1715/2100 [27:53<06:18,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1716/2100 [27:54<06:34,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1717/2100 [27:55<06:22,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1718/2100 [27:56<06:11,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1719/2100 [27:57<06:01,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1720/2100 [27:58<05:55,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1721/2100 [27:59<06:13,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1722/2100 [28:00<06:04,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1723/2100 [28:01<05:58,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1724/2100 [28:02<06:17,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1725/2100 [28:03<06:06,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1726/2100 [28:04<06:23,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1727/2100 [28:05<06:09,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1728/2100 [28:06<05:52,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1729/2100 [28:07<06:08,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1730/2100 [28:08<06:19,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1731/2100 [28:09<06:06,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  82%|████████▏ | 1732/2100 [28:10<05:56,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1733/2100 [28:11<05:49,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1734/2100 [28:11<05:44,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1735/2100 [28:12<05:40,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1736/2100 [28:13<05:36,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1737/2100 [28:14<05:32,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1738/2100 [28:15<05:31,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1739/2100 [28:16<05:27,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1740/2100 [28:17<05:27,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1741/2100 [28:18<05:26,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1742/2100 [28:19<05:25,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1743/2100 [28:20<06:14,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1744/2100 [28:21<05:59,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1745/2100 [28:22<05:47,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1746/2100 [28:23<05:42,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1747/2100 [28:24<05:36,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1748/2100 [28:25<05:30,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1749/2100 [28:26<05:27,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1750/2100 [28:26<05:23,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1751/2100 [28:27<05:20,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1752/2100 [28:28<05:18,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  83%|████████▎ | 1753/2100 [28:29<05:37,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▎ | 1754/2100 [28:30<05:29,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▎ | 1755/2100 [28:31<05:23,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▎ | 1756/2100 [28:32<05:14,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▎ | 1757/2100 [28:33<05:13,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▎ | 1758/2100 [28:34<05:10,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1759/2100 [28:35<05:08,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1760/2100 [28:36<05:10,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1761/2100 [28:37<05:06,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1762/2100 [28:37<05:06,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1763/2100 [28:39<05:25,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1764/2100 [28:40<05:37,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1765/2100 [28:41<05:24,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1766/2100 [28:41<05:16,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1767/2100 [28:42<05:11,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1768/2100 [28:43<05:07,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1769/2100 [28:44<05:02,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1770/2100 [28:45<05:01,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1771/2100 [28:46<04:59,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1772/2100 [28:47<04:59,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1773/2100 [28:48<05:20,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  84%|████████▍ | 1774/2100 [28:49<05:16,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1775/2100 [28:50<05:08,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1776/2100 [28:51<05:02,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1777/2100 [28:52<05:17,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1778/2100 [28:53<05:09,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1779/2100 [28:54<05:03,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1780/2100 [28:55<04:57,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1781/2100 [28:55<04:53,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1782/2100 [28:57<05:10,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1783/2100 [28:58<05:02,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▍ | 1784/2100 [28:59<05:16,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1785/2100 [29:00<05:06,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1786/2100 [29:01<05:18,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1787/2100 [29:02<05:07,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1788/2100 [29:02<04:56,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1789/2100 [29:03<04:49,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1790/2100 [29:05<05:34,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1791/2100 [29:06<05:17,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1792/2100 [29:07<05:04,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1793/2100 [29:07<04:56,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1794/2100 [29:08<04:52,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  85%|████████▌ | 1795/2100 [29:09<04:45,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1796/2100 [29:10<04:41,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1797/2100 [29:11<04:38,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1798/2100 [29:12<04:37,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1799/2100 [29:13<04:54,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1800/2100 [29:14<04:47,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1801/2100 [29:15<04:42,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1802/2100 [29:16<04:39,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1803/2100 [29:17<04:35,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1804/2100 [29:18<04:28,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1805/2100 [29:19<04:25,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1806/2100 [29:19<04:24,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1807/2100 [29:21<04:41,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1808/2100 [29:22<05:21,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1809/2100 [29:23<05:24,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1810/2100 [29:24<05:04,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▌ | 1811/2100 [29:25<05:36,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▋ | 1812/2100 [29:26<05:08,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▋ | 1813/2100 [29:27<04:52,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▋ | 1814/2100 [29:28<04:42,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▋ | 1815/2100 [29:29<04:30,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  86%|████████▋ | 1816/2100 [29:30<04:25,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1817/2100 [29:31<04:22,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1818/2100 [29:32<04:20,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1819/2100 [29:33<04:16,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1820/2100 [29:33<04:15,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1821/2100 [29:35<04:32,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1822/2100 [29:36<04:26,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1823/2100 [29:36<04:21,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1824/2100 [29:37<04:18,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1825/2100 [29:38<04:15,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1826/2100 [29:39<04:14,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1827/2100 [29:40<04:10,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1828/2100 [29:41<04:50,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1829/2100 [29:42<04:35,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1830/2100 [29:43<04:41,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1831/2100 [29:44<04:28,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1832/2100 [29:45<04:20,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1833/2100 [29:46<04:14,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1834/2100 [29:47<04:27,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1835/2100 [29:48<04:35,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1836/2100 [29:49<04:23,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  87%|████████▋ | 1837/2100 [29:50<04:31,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1838/2100 [29:51<04:20,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1839/2100 [29:52<04:12,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1840/2100 [29:53<04:05,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1841/2100 [29:54<04:01,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1842/2100 [29:55<03:58,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1843/2100 [29:56<03:56,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1844/2100 [29:57<04:31,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1845/2100 [29:58<04:18,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1846/2100 [29:59<04:09,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1847/2100 [30:00<04:02,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1848/2100 [30:01<03:58,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1849/2100 [30:02<03:54,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1850/2100 [30:03<03:51,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1851/2100 [30:04<03:48,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1852/2100 [30:05<03:46,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1853/2100 [30:05<03:44,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1854/2100 [30:07<03:57,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1855/2100 [30:07<03:51,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1856/2100 [30:08<03:47,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1857/2100 [30:09<03:44,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  88%|████████▊ | 1858/2100 [30:10<03:58,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▊ | 1859/2100 [30:11<03:53,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▊ | 1860/2100 [30:12<03:47,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▊ | 1861/2100 [30:13<03:43,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▊ | 1862/2100 [30:14<03:40,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▊ | 1863/2100 [30:15<03:51,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1864/2100 [30:16<03:45,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1865/2100 [30:17<03:56,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1866/2100 [30:18<03:47,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1867/2100 [30:19<03:43,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1868/2100 [30:20<03:38,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1869/2100 [30:21<03:36,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1870/2100 [30:22<03:35,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1871/2100 [30:23<03:33,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1872/2100 [30:24<03:46,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1873/2100 [30:25<03:40,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1874/2100 [30:26<03:33,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1875/2100 [30:27<04:03,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1876/2100 [30:28<03:51,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1877/2100 [30:29<03:41,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1878/2100 [30:30<03:34,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  89%|████████▉ | 1879/2100 [30:31<03:29,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1880/2100 [30:31<03:26,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1881/2100 [30:32<03:23,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1882/2100 [30:33<03:21,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1883/2100 [30:34<03:19,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1884/2100 [30:35<03:20,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1885/2100 [30:36<03:19,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1886/2100 [30:37<03:18,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1887/2100 [30:38<03:12,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1888/2100 [30:39<03:12,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|████████▉ | 1889/2100 [30:40<03:10,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1890/2100 [30:41<03:22,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1891/2100 [30:42<03:17,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1892/2100 [30:43<03:14,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1893/2100 [30:44<03:11,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1894/2100 [30:44<03:09,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1895/2100 [30:45<03:07,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1896/2100 [30:46<03:06,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1897/2100 [30:47<03:05,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1898/2100 [30:48<03:16,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1899/2100 [30:49<03:11,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  90%|█████████ | 1900/2100 [30:50<03:18,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1901/2100 [30:51<03:13,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1902/2100 [30:52<03:07,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1903/2100 [30:53<03:15,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1904/2100 [30:54<03:20,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1905/2100 [30:55<03:12,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1906/2100 [30:56<03:06,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1907/2100 [30:57<03:03,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1908/2100 [30:58<03:00,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1909/2100 [30:59<02:57,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1910/2100 [31:00<02:55,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1911/2100 [31:01<02:54,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1912/2100 [31:02<02:52,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1913/2100 [31:02<02:51,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1914/2100 [31:03<02:49,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1915/2100 [31:04<02:59,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████ | 1916/2100 [31:05<02:54,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████▏| 1917/2100 [31:06<02:50,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████▏| 1918/2100 [31:07<02:48,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████▏| 1919/2100 [31:08<02:43,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████▏| 1920/2100 [31:09<02:40,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  91%|█████████▏| 1921/2100 [31:10<02:51,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1922/2100 [31:11<02:47,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1923/2100 [31:12<02:44,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1924/2100 [31:13<02:42,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1925/2100 [31:14<02:41,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1926/2100 [31:15<02:50,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1927/2100 [31:16<02:46,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1928/2100 [31:17<02:40,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1929/2100 [31:18<03:04,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1930/2100 [31:19<02:54,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1931/2100 [31:20<02:47,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1932/2100 [31:21<02:42,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1933/2100 [31:22<02:39,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1934/2100 [31:22<02:36,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1935/2100 [31:23<02:33,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1936/2100 [31:25<02:56,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1937/2100 [31:26<02:47,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1938/2100 [31:27<02:41,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1939/2100 [31:28<02:35,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1940/2100 [31:28<02:31,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1941/2100 [31:29<02:28,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  92%|█████████▏| 1942/2100 [31:30<02:25,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1943/2100 [31:31<02:25,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1944/2100 [31:32<02:23,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1945/2100 [31:33<02:22,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1946/2100 [31:34<02:30,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1947/2100 [31:35<02:26,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1948/2100 [31:36<02:23,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1949/2100 [31:37<02:20,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1950/2100 [31:38<02:17,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1951/2100 [31:39<02:38,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1952/2100 [31:40<02:30,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1953/2100 [31:41<02:24,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1954/2100 [31:42<02:28,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1955/2100 [31:43<02:22,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1956/2100 [31:44<02:18,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1957/2100 [31:45<02:14,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1958/2100 [31:46<02:12,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1959/2100 [31:47<02:09,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1960/2100 [31:47<02:06,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1961/2100 [31:48<02:05,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1962/2100 [31:49<02:05,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  93%|█████████▎| 1963/2100 [31:50<02:04,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▎| 1964/2100 [31:51<02:03,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▎| 1965/2100 [31:52<02:22,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▎| 1966/2100 [31:53<02:15,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▎| 1967/2100 [31:54<02:10,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▎| 1968/2100 [31:55<02:06,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1969/2100 [31:56<02:02,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1970/2100 [31:57<02:08,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1971/2100 [31:58<02:04,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1972/2100 [31:59<02:01,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1973/2100 [32:00<02:07,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1974/2100 [32:01<02:02,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1975/2100 [32:02<01:58,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1976/2100 [32:03<01:55,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1977/2100 [32:04<01:53,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1978/2100 [32:05<01:51,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1979/2100 [32:06<01:50,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1980/2100 [32:06<01:50,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1981/2100 [32:08<02:07,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1982/2100 [32:09<02:18,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1983/2100 [32:10<02:07,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  94%|█████████▍| 1984/2100 [32:11<01:58,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1985/2100 [32:12<01:53,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1986/2100 [32:13<01:49,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1987/2100 [32:14<01:53,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1988/2100 [32:15<01:47,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1989/2100 [32:16<01:45,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1990/2100 [32:17<01:59,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1991/2100 [32:18<01:52,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1992/2100 [32:19<01:47,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1993/2100 [32:20<01:42,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▍| 1994/2100 [32:21<01:40,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 1995/2100 [32:22<01:54,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 1996/2100 [32:23<01:54,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 1997/2100 [32:24<01:47,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 1998/2100 [32:25<01:43,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 1999/2100 [32:26<01:39,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 2000/2100 [32:27<01:36,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 2001/2100 [32:28<01:33,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 2002/2100 [32:29<01:31,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 2003/2100 [32:30<01:44,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 2004/2100 [32:31<01:38,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  95%|█████████▌| 2005/2100 [32:32<01:34,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2006/2100 [32:33<01:29,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2007/2100 [32:34<01:41,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2008/2100 [32:36<01:49,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2009/2100 [32:37<01:46,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2010/2100 [32:38<01:38,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2011/2100 [32:39<01:31,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2012/2100 [32:40<01:27,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2013/2100 [32:40<01:23,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2014/2100 [32:41<01:21,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2015/2100 [32:43<01:32,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2016/2100 [32:44<01:26,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2017/2100 [32:45<01:27,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2018/2100 [32:46<01:23,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2019/2100 [32:47<01:19,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2020/2100 [32:48<01:21,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▌| 2021/2100 [32:49<01:18,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▋| 2022/2100 [32:50<01:15,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▋| 2023/2100 [32:50<01:13,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▋| 2024/2100 [32:51<01:11,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▋| 2025/2100 [32:52<01:09,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  96%|█████████▋| 2026/2100 [32:54<01:19,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2027/2100 [32:55<01:19,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2028/2100 [32:56<01:14,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2029/2100 [32:57<01:10,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2030/2100 [32:58<01:18,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2031/2100 [32:59<01:12,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2032/2100 [33:00<01:09,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2033/2100 [33:01<01:05,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2034/2100 [33:02<01:03,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2035/2100 [33:03<01:05,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2036/2100 [33:04<01:02,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2037/2100 [33:05<01:00,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2038/2100 [33:06<00:58,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2039/2100 [33:07<01:00,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2040/2100 [33:08<01:06,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2041/2100 [33:09<01:05,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2042/2100 [33:10<01:00,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2043/2100 [33:11<00:57,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2044/2100 [33:12<00:54,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2045/2100 [33:13<00:52,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2046/2100 [33:14<00:51,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  97%|█████████▋| 2047/2100 [33:15<00:49,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2048/2100 [33:16<00:48,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2049/2100 [33:16<00:46,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2050/2100 [33:17<00:46,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2051/2100 [33:18<00:44,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2052/2100 [33:20<00:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2053/2100 [33:21<00:50,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2054/2100 [33:22<00:47,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2055/2100 [33:23<00:44,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2056/2100 [33:24<00:42,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2057/2100 [33:24<00:41,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2058/2100 [33:25<00:39,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2059/2100 [33:26<00:38,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2060/2100 [33:27<00:36,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2061/2100 [33:28<00:35,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2062/2100 [33:29<00:34,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2063/2100 [33:30<00:33,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2064/2100 [33:31<00:32,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2065/2100 [33:32<00:31,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2066/2100 [33:33<00:30,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2067/2100 [33:33<00:29,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  98%|█████████▊| 2068/2100 [33:35<00:30,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▊| 2069/2100 [33:35<00:29,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▊| 2070/2100 [33:36<00:28,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▊| 2071/2100 [33:37<00:26,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▊| 2072/2100 [33:38<00:27,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▊| 2073/2100 [33:40<00:29,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2074/2100 [33:41<00:27,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2075/2100 [33:42<00:25,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2076/2100 [33:43<00:23,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2077/2100 [33:44<00:23,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2078/2100 [33:45<00:21,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2079/2100 [33:45<00:20,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2080/2100 [33:47<00:21,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2081/2100 [33:48<00:19,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2082/2100 [33:49<00:18,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2083/2100 [33:50<00:16,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2084/2100 [33:51<00:15,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2085/2100 [33:51<00:14,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2086/2100 [33:53<00:13,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2087/2100 [33:53<00:12,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2088/2100 [33:54<00:11,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8:  99%|█████████▉| 2089/2100 [33:56<00:11,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2090/2100 [33:57<00:10,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2091/2100 [33:58<00:08,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2092/2100 [33:58<00:07,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2093/2100 [33:59<00:06,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2094/2100 [34:00<00:05,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2095/2100 [34:02<00:05,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2096/2100 [34:03<00:04,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2097/2100 [34:04<00:03,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2098/2100 [34:05<00:02,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|█████████▉| 2099/2100 [34:06<00:01,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 8: 100%|██████████| 2100/2100 [34:07<00:00,  1.03it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 8 Results on 1000 samples:\n",
      "BLEU: 0.0177\n",
      "ROUGE-1: 0.133\n",
      "ROUGE-2: 0.0289\n",
      "ROUGE-L: 0.1028\n",
      "BERTScore (F1): 0.8349\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load evaluation subset (first 1000 from 3600)\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_augmented_3600.jsonl\", split=\"train\")\n",
    "\n",
    "# Load Trial 7 fine-tuned model and tokenizer\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial8\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"🔍 Evaluating Trial 8\"):\n",
    "    input_text = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "# Calculate metrics\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n📊 Trial 8 Results on 1000 samples:\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UorzQG0q8H-L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DoGUrUhFlbW"
   },
   "source": [
    "# Adding few more sympathetic data - enhanced 500 more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1744312123162,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "D1mLpo01GY5o",
    "outputId": "2f85bdbf-a562-422d-de42-2696ec552873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 500 enhanced synthetic samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Everything just feels overwhelming lately.\",\n          \"There\\u2019s so much noise in my head. I just want peace.\",\n          \"I feel trapped in my own mind.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"I know it may not seem like it, but healing is possible. Let\\u2019s talk through it together.\",\n          \"I'm really sorry you're feeling like this. You\\u2019re not alone, and I\\u2019m here to support you every step of the way.\",\n          \"You\\u2019re worthy of love and compassion \\u2014 especially from yourself.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-87b5d196-a595-466f-8d30-ec4fe3e063b0\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I feel trapped in my own mind.</td>\n",
       "      <td>You matter. Your pain is real, and I'm here to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No one really understands what I’m going through.</td>\n",
       "      <td>I'm really sorry you're feeling like this. You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why can’t I be happy like everyone else?</td>\n",
       "      <td>Thank you for trusting me with this. You're no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why can’t I be happy like everyone else?</td>\n",
       "      <td>You’ve come this far, and that already shows c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s getting hard to even get out of bed in th...</td>\n",
       "      <td>It’s okay to slow down. Take a breath, and let...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87b5d196-a595-466f-8d30-ec4fe3e063b0')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-87b5d196-a595-466f-8d30-ec4fe3e063b0 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-87b5d196-a595-466f-8d30-ec4fe3e063b0');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ab1b1c31-b2be-4396-bdf7-cc27fbc65a80\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab1b1c31-b2be-4396-bdf7-cc27fbc65a80')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ab1b1c31-b2be-4396-bdf7-cc27fbc65a80 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0                     I feel trapped in my own mind.   \n",
       "1  No one really understands what I’m going through.   \n",
       "2           Why can’t I be happy like everyone else?   \n",
       "3           Why can’t I be happy like everyone else?   \n",
       "4  It’s getting hard to even get out of bed in th...   \n",
       "\n",
       "                                              output  \n",
       "0  You matter. Your pain is real, and I'm here to...  \n",
       "1  I'm really sorry you're feeling like this. You...  \n",
       "2  Thank you for trusting me with this. You're no...  \n",
       "3  You’ve come this far, and that already shows c...  \n",
       "4  It’s okay to slow down. Take a breath, and let...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Emotion categories\n",
    "emotions = [\n",
    "    \"anxious\", \"depressed\", \"lonely\", \"stressed\", \"angry\", \"insecure\",\n",
    "    \"grateful\", \"hopeful\", \"confused\", \"burned out\", \"rejected\", \"ashamed\",\n",
    "    \"guilty\", \"afraid\", \"calm\", \"relieved\", \"understood\", \"supported\"\n",
    "]\n",
    "\n",
    "# Emotionally rich user statements\n",
    "user_statements = [\n",
    "    \"I don’t know how much longer I can keep going like this...\",\n",
    "    \"It’s getting hard to even get out of bed in the morning 😞\",\n",
    "    \"I feel like I’m constantly disappointing everyone.\",\n",
    "    \"No one really understands what I’m going through.\",\n",
    "    \"Everything just feels overwhelming lately.\",\n",
    "    \"I hate feeling like this all the time 😔\",\n",
    "    \"Why do I always mess things up?\",\n",
    "    \"I’ve been crying every night. I feel so drained.\",\n",
    "    \"I feel invisible, like no one would notice if I disappeared.\",\n",
    "    \"Every time I try to open up, I regret it.\",\n",
    "    \"There’s so much noise in my head. I just want peace.\",\n",
    "    \"My anxiety is ruining everything for me.\",\n",
    "    \"I'm exhausted from pretending I'm okay.\",\n",
    "    \"I feel trapped in my own mind.\",\n",
    "    \"Why can’t I be happy like everyone else?\"\n",
    "]\n",
    "\n",
    "# Paraphrased supportive responses\n",
    "bot_responses = [\n",
    "    \"I'm really sorry you're feeling like this. You’re not alone, and I’m here to support you every step of the way.\",\n",
    "    \"That sounds incredibly heavy to carry. You're doing the best you can, and that matters more than you know.\",\n",
    "    \"Your emotions are valid. It's okay to feel lost, and it's also okay to ask for help. You’re strong for opening up.\",\n",
    "    \"You don’t need to face this alone. Let’s take this one moment at a time, together.\",\n",
    "    \"Thank you for trusting me with this. You're not a burden — your voice deserves to be heard.\",\n",
    "    \"I know it may not seem like it, but healing is possible. Let’s talk through it together.\",\n",
    "    \"You matter. Your pain is real, and I'm here to listen and help you process it.\",\n",
    "    \"It’s okay to slow down. Take a breath, and let’s figure this out together.\",\n",
    "    \"You’re worthy of love and compassion — especially from yourself.\",\n",
    "    \"You’ve come this far, and that already shows courage. Let’s take the next step together.\"\n",
    "]\n",
    "\n",
    "# Generate synthetic dataset\n",
    "synthetic_data = []\n",
    "for _ in range(500):\n",
    "    instruction = random.choice(user_statements)\n",
    "    output = random.choice(bot_responses)\n",
    "    emotion = random.choice(emotions)\n",
    "\n",
    "    synthetic_data.append({\n",
    "        \"instruction\": instruction.strip(),\n",
    "        \"output\": output.strip()\n",
    "    })\n",
    "\n",
    "# Save to JSONL\n",
    "output_path = \"/content/drive/MyDrive/SIT782/datasets/enhanced_synthetic_500.jsonl\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    for r in synthetic_data:\n",
    "        json.dump(r, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Preview\n",
    "df = pd.DataFrame(synthetic_data)\n",
    "print(\"✅ Saved 500 enhanced synthetic samples\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmRfeyiPGf1H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsfUuqvqG7Qc"
   },
   "source": [
    "# Merging enhanced_synthetic_500.jsonl with empdiag_augmented_3600.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1744312275289,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "Tp9Ut3YsHDQt",
    "outputId": "e9bf2955-1572-4a89-8a53-09f370415122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged dataset saved as: /content/drive/MyDrive/SIT782/datasets/empdiag_augmented_4100.jsonl\n",
      "📝 Total samples: 2600\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# File paths\n",
    "real_data_path = \"/content/drive/MyDrive/SIT782/datasets/empdiag_augmented_3600.jsonl\"\n",
    "synthetic_data_path = \"/content/drive/MyDrive/SIT782/datasets/enhanced_synthetic_500.jsonl\"\n",
    "output_path = \"/content/drive/MyDrive/SIT782/datasets/empdiag_augmented_4100.jsonl\"\n",
    "\n",
    "# Load real data\n",
    "with open(real_data_path, \"r\") as f:\n",
    "    real_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Load enhanced synthetic data\n",
    "with open(synthetic_data_path, \"r\") as f:\n",
    "    synthetic_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Merge and shuffle\n",
    "combined_data = real_data + synthetic_data\n",
    "import random\n",
    "random.shuffle(combined_data)\n",
    "\n",
    "# Save merged dataset\n",
    "with open(output_path, \"w\") as f:\n",
    "    for record in combined_data:\n",
    "        json.dump({\n",
    "            \"instruction\": record[\"instruction\"],\n",
    "            \"output\": record[\"output\"]\n",
    "        }, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"✅ Merged dataset saved as: {output_path}\")\n",
    "print(f\"📝 Total samples: {len(combined_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8avGCYqFHRBc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cu41NQrHHzYV"
   },
   "source": [
    "#🔁 Trial 9 tuning with 4100 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e218ca9bd06c4033a0061de2e2bb604c",
      "d82dffd5a7244f3a988801dc8d48494c",
      "92eb8f21ab5047fea3c75403e0ff9e19",
      "65b0d06effb44415bb98df726a15dca9",
      "e0f47d3ed73047e4b2a1478afda79754",
      "959ba8a3e8b5427bae0214c3955d11bd",
      "79c1f710e3164741a5783f7e569ef972",
      "8f4f457608734434a7e4e440b1755192",
      "2d9e3628220342d98e18a7320672a644",
      "ac0f29d20976432f95b92855f246de34",
      "799537e88eb7461aa67695943f45bfba",
      "d31205c3c6a647f18606d2ae9cefac0a",
      "f74310e6e6204368996887a28886a186",
      "59271c9fe52e4d448a4c39972b3407e0",
      "5ff526e735a148928bd6b3c2417593fb",
      "2eb337adda0743ee96a881ac73cd851d",
      "0b438de891934a4284e1f8e6b47cc186",
      "7130e566f86b43ee8ea9c593592264c3",
      "d240afd103a948609e5d7ad9378899a2",
      "d0d6411d8ac54230b4576da7bff557a7",
      "0b71c19bf29744289b4e35c465114059",
      "a80cc5374186454f8c98199c264434ce"
     ]
    },
    "executionInfo": {
     "elapsed": 907671,
     "status": "ok",
     "timestamp": 1744313803429,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "sYRGYzsLH4tC",
    "outputId": "13c8a4a0-784f-45c4-87bb-9ce8c89a63ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e218ca9bd06c4033a0061de2e2bb604c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31205c3c6a647f18606d2ae9cefac0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-fc61402bb963>:63: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1300 14:44, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>16.781200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>10.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.676500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.530900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.041100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.503200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.508300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.637600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.277400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.250600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.239300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.213800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.197700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.203400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.203500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.197100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.183100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.179300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.184500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.202600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.178700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.177600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.155900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.159300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.180100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.182900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.175800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.159400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.165300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.160700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.154200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.154500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.134900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.135700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.135600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.129700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.171600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.132200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.139600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.125700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.126400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.133500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.158600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.137100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.135600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.134100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.122500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 9 fine-tuning complete and saved to Drive!\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import gc, json\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load dataset (4100 samples)\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_augmented_4100.jsonl\", split=\"train\")\n",
    "\n",
    "# Load base model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # fix padding error\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "#  Tokenization function (reduced max_length for memory)\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, padding=\"max_length\", truncation=True, max_length=384)\n",
    "    result[\"labels\"] = tokenizer(output, padding=\"max_length\", truncation=True, max_length=384)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA config (same as Trial 8)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments (adjusted for Colab memory)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial9\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=1e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial9\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial9\")\n",
    "\n",
    "print(\"✅ Trial 9 fine-tuning complete and saved to Drive!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voe--29XNemz"
   },
   "source": [
    "# Evaluation\n",
    " - Evaluation on Full Training Set (4100 samples) with trial 9 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b0bf90cfc2874e8cb37648887f14c305",
      "527df02748184d05a624960977cd2a3c",
      "ca48e2932e794bb8a723a13181fb6ee2",
      "1b4ad540cf2947c5a0df104333abbccf",
      "596dd6412fae47e88c9ffe134d566e64",
      "2adb99002e2c4f069c436b6995795f49",
      "50f305133d264017b9ce182607579cf4",
      "2dd2329844844aa3b292d2e249bd3181",
      "8d94d65a81f44f209959209d7bd68fcb",
      "f80d18fbc21b423fabfd71951f0de32f",
      "9d90093a5cc94744a44f3f5cfa4b13bf",
      "3f8ea8c2394b4239978304aa8b760592",
      "ac0e7242f672488a8695d0f0a3cdd130",
      "b76fd925d7e5417ab86f87424506940d",
      "d5d868f8369549dc93f10341eea5416a",
      "8696b974ae16405b9a9b5e88844dd587",
      "9653a4cd1bcf480f81e3712dfc69640d",
      "0a40ccc711ce4383a962bb33cb6d9356",
      "83dc4285bff44eaab25ef9f2a90e7bba",
      "e376597a64234a90aa4408c712698a32",
      "548bfc874de24e388c644ca967b61fdb",
      "365eb771f82b427b9e2be966d980236a",
      "39a4ca1882b746229af691cf88507858",
      "2af7fb51f98c472681646618f0a9cd85",
      "68849bed8d9c4442977ad93e837dc049",
      "09cdb15ac799462691e4e6cf16f2a3c5",
      "6eb693d263a04b8ba795035b46441b18",
      "3386dfc906df421ebf5c8282d6efca2c",
      "5d48910e0f0a462badd91d7311416df6",
      "5ba02cc83caf4448a56defb6f4366059",
      "15d10dd1e9c0422491cb0222bdcc62f8",
      "73edf5e6c33a446d9b23293bddbccc66",
      "ae720a10203343b49c4796b06ce50224",
      "c2b13e6de32c476bbd178e8a1ddef520",
      "cdfe3f739d6247cba536277227de4818",
      "74867060f62648ab9366fa606d75ad75",
      "7d6e935ec17a45f4bf4520766df7e9b1",
      "3c295409049f4a3b8e2cb7d97c7fcdca",
      "5f0e3ded303b4c52b435731b3fc1b6e5",
      "576cd169aefd4398a008a34c0f033756",
      "c9015e89deca4f888e4bb8f441d9db0b",
      "e505e976b8f745cf821782f21fc9578a",
      "51ee2d8a9b764cd1b31ac60a221cd6af",
      "86c22bfab743479aae0af5d6add4d874",
      "a60f50bf0c7a476693db336b25cb3172",
      "7aea4f932c264d2495eed060b17fc62c",
      "2e54da57db824968b8a920aeb96f3a17",
      "0fbf8bde4ad84fe4a538e8a23bc4eea3",
      "a1302a1d720d44b5b0604cfdca329177",
      "b3895dd1ce874189b29db5e15d0c9a0f",
      "83f50d51e2c540f4ae2614727fe17222",
      "1bbb609220bc471baa5a3e7e05a2f7c5",
      "0e1e6a6fe8384338a2cc3f2198775b33",
      "d1f7bf933925452b83a79336e93b926e",
      "0bca7537e8984aa3a9fbea50fca55720",
      "9901dc78878445569b9374eb33300ea3",
      "67b8c692a16d48e6b0a5ed152d519bc3",
      "346c548014db46b381b9f7f9431fabe6",
      "56ac0921e19142e6a9b5d1407c6fffbd",
      "6d3c2a4d84a24573bca933585e98f61b",
      "02e8ac34fc404752bfb9db8484a7dcb1",
      "127b30b371d84abb95c556cfa9529ff9",
      "40ff3793688242358594e608f01f5109",
      "70a72e88516949728277f79df3230b1c",
      "f3c90ea77d134495a28da258dd20c999",
      "138a85b191864bad800c4358db8a279e",
      "c0e5ff7726df4bf59077b4de1dc2d63e",
      "ed1d5b76dffd402d83f4a0f5f487e11b",
      "3c210693e52442d493bcbdb3f6bbe148",
      "6079345c78c442c098598bd6aa7b4d0b",
      "ef13fc0568c9402db3813ce3e8d03c1d",
      "218f7a4eb58245f5a07ddffa0e3db916",
      "b30daf1f753846f680532c8ee062a088",
      "b45d0a1d50f54a4aaa7f2233b07a5491",
      "b306be947dd64b03800334f02aeff59c",
      "8a739fb15be345e5bafd436d1fd4717e",
      "0f3bca9fdaa14568a607cce1b1bcd7bf",
      "8ec6d84333c1448ebd1fd023c756eccb",
      "8a86d25ae4df4d1ba752bd69a23ef97d",
      "b0974ea6072e4c7fb0354a5a89ed4b7b",
      "b48fa57327e64483be200cf86daa3c01",
      "f519ca9012914241860fe082fa0fd8c0",
      "c0dfe65c0a61419591e5a68670bef3ca",
      "1932d38138064641851d1c7da159df49",
      "c20f7e279fdd4a91b54019475c7c5156",
      "e1d105aa5acb4beab22c09cb144cb33d",
      "fb191e0cc0584e48bd7cf5f86c4d8505",
      "81955a1b8d57488a93c437a7252c1f3d",
      "ed89247e5968450da878dbfd1bfa638c",
      "73b7cc55843948718cbe14e26e11e3ad",
      "369c2cf2c9d548d9b1f1f4b2bb1b9db6",
      "96aa7acff1de42f3b0732b645b7931fc",
      "c9e1fd21af0248b3a9120a9713d0b340",
      "0c826903d6dd4aaabbb84f0fe4cc818e",
      "a27d97f77e3a4fec9d7290b87bf13697",
      "99e3434b23934cd89cc0790119203a25",
      "ba400560dc084413b99e665759ff7a02",
      "f269731824844fcdad90add0381f5dd1",
      "a5d52b7d037b4ae1b06c9377f18e87c7",
      "865b90ef39284cf69c4f9974de2c7cd2",
      "3eb0b761c8b14d269a385ce31970f9b1",
      "01c691cfd76b41a58669121094922b6b",
      "8d89707f852c42f8bb97241a0fa4cb04",
      "7a99a9d2051240398e74f55b7113fb71",
      "486f56343f28457383abbb9595e2396d",
      "1d5b68a93b174819b0da7504b85bc345",
      "f56830eef49b47ef9425075cd7247c7d",
      "ee292d1746c1486fa341c64ec60c2f8b",
      "a3453119799d4fdcbb815d80b2cad708",
      "f139c08675d54637a40bc210e0b919da",
      "0ee4052dfc134a5db2f12d758eb6a51d",
      "98ddbe97300a44dca0f2154331e8aff0",
      "07516343da08470a939527e4a98f99db",
      "7005613ad7044f40ab0d13bd725a0a71",
      "af809efffab74b369ec33fcf083214b4",
      "f539cbc15a8048b69c53d96a7df6d49c",
      "3ac4d1d851354a6f8462fe112b75091f",
      "13bfbd427b824fb0b45ea80a1826e7bc",
      "e0bdab2141694ff886244f090ccb792e",
      "18149b7e570d42038bb712507905c340",
      "5e964fe992ff4acc9df46d513d6af1f1",
      "a6ab1a810d5a4dd1b2d0c3b5c4d5716e",
      "96b55d12e0904d3cb06c4b0af45558f6",
      "866a1c02a6a845519b3cc33a8c44bd9e",
      "abe2d584556a46178ef241f670c152eb",
      "c7067b2f5ab845098340026b46ebaac3",
      "72e4ed81e7b14d6796431d7180e7e62a",
      "bacbcbdf09ae429bae9b067c142d7c74",
      "b78d58fe6d184304a3222cc42f37e8ce",
      "f2c2613ea3534be6a2373a814d006c44",
      "34f9ef8024144eb29b5583f8b374f668",
      "6473eb6232fe4a66b1e63f0af3456fa9"
     ]
    },
    "executionInfo": {
     "elapsed": 2270870,
     "status": "ok",
     "timestamp": 1744316213549,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "Q-C5gP_vNk4D",
    "outputId": "760f921d-5902-4761-e4f3-aa2ff2d7e8b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bf90cfc2874e8cb37648887f14c305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8ea8c2394b4239978304aa8b760592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a4ca1882b746229af691cf88507858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b13e6de32c476bbd178e8a1ddef520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60f50bf0c7a476693db336b25cb3172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9901dc78878445569b9374eb33300ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 0/2600 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 1/2600 [00:01<1:00:50,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 2/2600 [00:02<42:58,  1.01it/s]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 3/2600 [00:03<45:04,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 4/2600 [00:03<39:10,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 5/2600 [00:04<38:17,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 6/2600 [00:05<38:24,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 7/2600 [00:06<39:12,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 8/2600 [00:07<36:24,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 9/2600 [00:08<34:30,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 10/2600 [00:08<35:39,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 11/2600 [00:09<33:58,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 12/2600 [00:10<41:42,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   0%|          | 13/2600 [00:11<40:10,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 14/2600 [00:12<39:02,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 15/2600 [00:13<38:12,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 16/2600 [00:14<36:21,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 17/2600 [00:14<34:24,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 18/2600 [00:15<34:46,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 19/2600 [00:16<38:55,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 20/2600 [00:17<36:11,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 21/2600 [00:18<34:15,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 22/2600 [00:18<32:51,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 23/2600 [00:19<32:00,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 24/2600 [00:20<37:12,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 25/2600 [00:21<35:11,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 26/2600 [00:22<38:34,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 27/2600 [00:23<35:56,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 28/2600 [00:24<35:49,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 29/2600 [00:24<33:54,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 30/2600 [00:25<35:41,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 31/2600 [00:26<35:30,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|          | 32/2600 [00:27<36:22,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|▏         | 33/2600 [00:28<36:17,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|▏         | 34/2600 [00:29<37:30,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|▏         | 35/2600 [00:30<37:09,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|▏         | 36/2600 [00:31<37:30,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|▏         | 37/2600 [00:31<37:53,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   1%|▏         | 38/2600 [00:32<37:35,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 39/2600 [00:33<40:39,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 40/2600 [00:34<41:41,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 41/2600 [00:35<39:58,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 42/2600 [00:36<38:41,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 43/2600 [00:37<40:59,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 44/2600 [00:38<37:28,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 45/2600 [00:39<36:52,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 46/2600 [00:39<34:43,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 47/2600 [00:40<37:21,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 48/2600 [00:41<33:06,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 49/2600 [00:42<31:56,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 50/2600 [00:43<34:51,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 51/2600 [00:44<37:00,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 52/2600 [00:44<34:39,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 53/2600 [00:45<33:06,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 54/2600 [00:46<30:02,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 55/2600 [00:46<31:35,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 56/2600 [00:48<35:44,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 57/2600 [00:49<41:05,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 58/2600 [00:50<39:14,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 59/2600 [00:50<36:09,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 60/2600 [00:51<35:53,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 61/2600 [00:52<36:56,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 62/2600 [00:53<32:07,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 63/2600 [00:53<33:01,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▏         | 64/2600 [00:54<31:47,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   2%|▎         | 65/2600 [00:55<37:08,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 66/2600 [00:57<43:17,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 67/2600 [00:57<39:06,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 68/2600 [00:58<41:33,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 69/2600 [00:59<37:39,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 70/2600 [01:00<35:06,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 71/2600 [01:01<38:11,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 72/2600 [01:02<35:24,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 73/2600 [01:02<33:28,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 74/2600 [01:03<32:05,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 75/2600 [01:04<31:06,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 76/2600 [01:04<32:21,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 77/2600 [01:05<29:29,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 78/2600 [01:06<31:43,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 79/2600 [01:07<30:52,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 80/2600 [01:07<32:13,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 81/2600 [01:08<33:24,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 82/2600 [01:09<32:30,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 83/2600 [01:10<33:08,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 84/2600 [01:11<33:41,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 85/2600 [01:11<32:16,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 86/2600 [01:12<33:02,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 87/2600 [01:13<33:41,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 88/2600 [01:14<35:55,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 89/2600 [01:15<33:48,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   3%|▎         | 90/2600 [01:15<32:19,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▎         | 91/2600 [01:16<31:15,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▎         | 92/2600 [01:17<39:00,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▎         | 93/2600 [01:18<37:42,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▎         | 94/2600 [01:19<35:01,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▎         | 95/2600 [01:20<33:04,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▎         | 96/2600 [01:21<40:22,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▎         | 97/2600 [01:22<34:59,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 98/2600 [01:23<38:38,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 99/2600 [01:23<35:33,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 100/2600 [01:24<37:08,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 101/2600 [01:25<34:33,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 102/2600 [01:26<32:49,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 103/2600 [01:27<34:36,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 104/2600 [01:28<37:06,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 105/2600 [01:28<34:28,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 106/2600 [01:29<34:23,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 107/2600 [01:30<34:21,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 108/2600 [01:31<32:33,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 109/2600 [01:31<29:36,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 110/2600 [01:32<29:19,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 111/2600 [01:33<28:59,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 112/2600 [01:33<28:57,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 113/2600 [01:34<34:04,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 114/2600 [01:35<32:22,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 115/2600 [01:36<31:49,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 116/2600 [01:37<30:53,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   4%|▍         | 117/2600 [01:38<36:46,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 118/2600 [01:39<36:00,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 119/2600 [01:39<33:40,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 120/2600 [01:40<32:07,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 121/2600 [01:41<35:49,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 122/2600 [01:42<35:24,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 123/2600 [01:43<35:03,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 124/2600 [01:44<35:35,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 125/2600 [01:45<38:51,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 126/2600 [01:45<35:47,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 127/2600 [01:47<42:02,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 128/2600 [01:48<39:45,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▍         | 129/2600 [01:49<38:43,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 130/2600 [01:49<35:32,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 131/2600 [01:50<33:19,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 132/2600 [01:51<40:08,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 133/2600 [01:52<41:24,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 134/2600 [01:53<37:30,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 135/2600 [01:54<34:42,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 136/2600 [01:54<32:47,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 137/2600 [01:55<31:30,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 138/2600 [01:56<30:38,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 139/2600 [01:57<33:35,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 140/2600 [01:58<35:39,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 141/2600 [01:59<41:45,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   5%|▌         | 142/2600 [02:00<37:39,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 143/2600 [02:01<34:48,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 144/2600 [02:01<32:48,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 145/2600 [02:02<34:21,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 146/2600 [02:03<32:25,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 147/2600 [02:04<33:35,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 148/2600 [02:05<37:05,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 149/2600 [02:06<34:20,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 150/2600 [02:06<32:25,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 151/2600 [02:07<34:17,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 152/2600 [02:08<34:19,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 153/2600 [02:09<32:31,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 154/2600 [02:10<36:22,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 155/2600 [02:10<33:59,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 156/2600 [02:11<32:09,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 157/2600 [02:12<29:05,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 158/2600 [02:13<37:08,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 159/2600 [02:14<36:10,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 160/2600 [02:14<31:54,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 161/2600 [02:15<32:28,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▌         | 162/2600 [02:16<32:52,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▋         | 163/2600 [02:17<37:52,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▋         | 164/2600 [02:18<33:09,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▋         | 165/2600 [02:19<33:29,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▋         | 166/2600 [02:19<30:11,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▋         | 167/2600 [02:20<34:21,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▋         | 168/2600 [02:21<32:30,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   6%|▋         | 169/2600 [02:22<31:10,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 170/2600 [02:22<28:21,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 171/2600 [02:23<28:09,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 172/2600 [02:24<29:37,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 173/2600 [02:25<30:39,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 174/2600 [02:25<29:46,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 175/2600 [02:26<30:55,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 176/2600 [02:27<31:41,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 177/2600 [02:28<33:30,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 178/2600 [02:29<34:45,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 179/2600 [02:30<35:01,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 180/2600 [02:31<34:35,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 181/2600 [02:31<34:32,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 182/2600 [02:32<32:36,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 183/2600 [02:33<31:16,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 184/2600 [02:33<28:31,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 185/2600 [02:34<27:41,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 186/2600 [02:35<29:24,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 187/2600 [02:36<28:52,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 188/2600 [02:36<30:21,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 189/2600 [02:37<31:22,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 190/2600 [02:38<36:07,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 191/2600 [02:39<35:19,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 192/2600 [02:40<39:58,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 193/2600 [02:42<41:40,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   7%|▋         | 194/2600 [02:43<40:18,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 195/2600 [02:43<36:32,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 196/2600 [02:44<38:56,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 197/2600 [02:45<40:13,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 198/2600 [02:46<36:26,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 199/2600 [02:47<32:00,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 200/2600 [02:47<30:39,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 201/2600 [02:48<34:23,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 202/2600 [02:49<32:18,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 203/2600 [02:50<29:07,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 204/2600 [02:51<32:10,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 205/2600 [02:51<30:48,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 206/2600 [02:52<31:35,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 207/2600 [02:53<30:19,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 208/2600 [02:54<31:12,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 209/2600 [02:55<31:51,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 210/2600 [02:55<30:36,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 211/2600 [02:56<34:22,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 212/2600 [02:57<34:43,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 213/2600 [02:58<32:34,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 214/2600 [02:58<29:12,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 215/2600 [02:59<28:35,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 216/2600 [03:00<26:29,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 217/2600 [03:00<26:42,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 218/2600 [03:01<27:24,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 219/2600 [03:02<25:41,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 220/2600 [03:03<28:31,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   8%|▊         | 221/2600 [03:03<26:26,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▊         | 222/2600 [03:04<31:55,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▊         | 223/2600 [03:05<31:38,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▊         | 224/2600 [03:06<29:48,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▊         | 225/2600 [03:06<30:49,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▊         | 226/2600 [03:07<29:45,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▊         | 227/2600 [03:08<30:50,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 228/2600 [03:09<28:03,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 229/2600 [03:09<29:41,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 230/2600 [03:10<31:15,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 231/2600 [03:11<30:02,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 232/2600 [03:12<29:04,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 233/2600 [03:13<32:09,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 234/2600 [03:13<30:42,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 235/2600 [03:14<32:33,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 236/2600 [03:15<34:50,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 237/2600 [03:16<32:28,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 238/2600 [03:17<30:53,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 239/2600 [03:18<31:28,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 240/2600 [03:19<36:01,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 241/2600 [03:20<39:24,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 242/2600 [03:21<36:03,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 243/2600 [03:21<35:17,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 244/2600 [03:23<37:57,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 245/2600 [03:23<34:45,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):   9%|▉         | 246/2600 [03:24<34:15,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 247/2600 [03:25<37:15,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 248/2600 [03:26<35:51,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 249/2600 [03:27<38:26,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 250/2600 [03:28<35:02,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 251/2600 [03:29<34:25,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 252/2600 [03:30<34:32,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 253/2600 [03:30<32:13,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 254/2600 [03:31<34:45,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 255/2600 [03:32<32:31,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 256/2600 [03:33<36:05,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 257/2600 [03:34<33:23,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 258/2600 [03:35<31:28,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|▉         | 259/2600 [03:35<30:04,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 260/2600 [03:37<36:35,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 261/2600 [03:38<36:01,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 262/2600 [03:38<33:12,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 263/2600 [03:39<33:01,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 264/2600 [03:40<32:53,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 265/2600 [03:41<32:13,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 266/2600 [03:41<30:35,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 267/2600 [03:42<29:23,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 268/2600 [03:43<28:43,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 269/2600 [03:44<30:07,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 270/2600 [03:45<32:15,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 271/2600 [03:45<30:58,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 272/2600 [03:46<29:39,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  10%|█         | 273/2600 [03:47<27:05,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 274/2600 [03:47<29:15,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 275/2600 [03:48<28:33,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 276/2600 [03:49<28:01,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 277/2600 [03:50<29:09,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 278/2600 [03:50<28:23,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 279/2600 [03:51<29:33,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 280/2600 [03:52<28:43,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 281/2600 [03:53<28:10,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 282/2600 [03:53<29:28,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 283/2600 [03:54<28:35,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 284/2600 [03:55<33:12,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 285/2600 [03:56<31:19,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 286/2600 [03:57<31:43,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 287/2600 [03:58<31:57,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 288/2600 [03:58<32:02,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 289/2600 [04:00<37:11,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 290/2600 [04:01<41:54,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 291/2600 [04:02<37:20,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█         | 292/2600 [04:03<36:56,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█▏        | 293/2600 [04:04<35:32,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█▏        | 294/2600 [04:05<37:33,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█▏        | 295/2600 [04:06<37:01,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█▏        | 296/2600 [04:07<41:41,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█▏        | 297/2600 [04:08<40:41,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  11%|█▏        | 298/2600 [04:09<40:58,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 299/2600 [04:10<36:36,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 300/2600 [04:10<33:33,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 301/2600 [04:11<34:16,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 302/2600 [04:12<36:25,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 303/2600 [04:13<33:23,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 304/2600 [04:14<36:18,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 305/2600 [04:15<35:02,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 306/2600 [04:16<30:46,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 307/2600 [04:17<33:19,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 308/2600 [04:17<31:16,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 309/2600 [04:18<30:51,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 310/2600 [04:19<32:18,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 311/2600 [04:20<38:19,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 312/2600 [04:21<33:09,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 313/2600 [04:22<32:44,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 314/2600 [04:23<35:15,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 315/2600 [04:24<32:22,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 316/2600 [04:24<32:02,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 317/2600 [04:25<30:15,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 318/2600 [04:26<26:53,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 319/2600 [04:26<28:20,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 320/2600 [04:27<29:50,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 321/2600 [04:28<32:01,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 322/2600 [04:29<31:57,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 323/2600 [04:30<31:56,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▏        | 324/2600 [04:31<30:06,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  12%|█▎        | 325/2600 [04:31<28:55,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 326/2600 [04:32<30:29,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 327/2600 [04:33<31:05,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 328/2600 [04:34<31:15,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 329/2600 [04:35<31:28,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 330/2600 [04:36<35:33,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 331/2600 [04:37<34:17,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 332/2600 [04:38<31:48,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 333/2600 [04:38<30:08,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 334/2600 [04:39<30:37,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 335/2600 [04:40<31:29,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 336/2600 [04:41<37:35,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 337/2600 [04:43<41:52,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 338/2600 [04:43<37:20,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 339/2600 [04:44<35:56,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 340/2600 [04:45<33:10,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 341/2600 [04:46<33:03,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 342/2600 [04:47<34:13,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 343/2600 [04:48<31:43,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 344/2600 [04:48<30:01,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 345/2600 [04:49<30:24,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 346/2600 [04:50<30:43,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 347/2600 [04:51<30:53,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 348/2600 [04:51<29:24,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 349/2600 [04:52<30:00,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  13%|█▎        | 350/2600 [04:53<27:08,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▎        | 351/2600 [04:54<28:26,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▎        | 352/2600 [04:54<29:18,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▎        | 353/2600 [04:56<33:14,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▎        | 354/2600 [04:56<32:47,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▎        | 355/2600 [04:57<30:47,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▎        | 356/2600 [04:58<32:37,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▎        | 357/2600 [04:59<31:08,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 358/2600 [05:00<29:32,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 359/2600 [05:01<33:17,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 360/2600 [05:02<32:37,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 361/2600 [05:02<30:27,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 362/2600 [05:03<28:58,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 363/2600 [05:04<29:36,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 364/2600 [05:04<28:25,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 365/2600 [05:06<32:00,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 366/2600 [05:07<34:16,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 367/2600 [05:08<34:32,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 368/2600 [05:08<30:19,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 369/2600 [05:09<28:23,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 370/2600 [05:09<27:35,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 371/2600 [05:10<25:22,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 372/2600 [05:11<25:24,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 373/2600 [05:11<25:25,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 374/2600 [05:12<29:48,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 375/2600 [05:13<28:33,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 376/2600 [05:14<27:34,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  14%|█▍        | 377/2600 [05:15<34:35,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 378/2600 [05:16<35:07,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 379/2600 [05:17<33:52,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 380/2600 [05:18<31:21,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 381/2600 [05:18<29:38,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 382/2600 [05:19<31:43,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 383/2600 [05:20<31:31,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 384/2600 [05:21<32:57,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 385/2600 [05:22<33:16,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 386/2600 [05:23<35:43,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 387/2600 [05:24<35:14,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 388/2600 [05:25<34:21,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▍        | 389/2600 [05:26<38:53,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 390/2600 [05:27<36:55,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 391/2600 [05:28<35:06,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 392/2600 [05:29<37:04,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 393/2600 [05:30<35:10,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 394/2600 [05:31<36:32,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 395/2600 [05:32<33:17,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 396/2600 [05:33<30:44,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 397/2600 [05:34<32:47,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 398/2600 [05:35<35:22,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 399/2600 [05:35<32:19,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 400/2600 [05:36<32:23,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 401/2600 [05:37<33:31,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  15%|█▌        | 402/2600 [05:39<38:29,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 403/2600 [05:39<34:25,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 404/2600 [05:40<31:36,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 405/2600 [05:41<31:21,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 406/2600 [05:42<29:27,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 407/2600 [05:42<28:11,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 408/2600 [05:43<28:53,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 409/2600 [05:44<29:35,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 410/2600 [05:45<28:17,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 411/2600 [05:46<31:51,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 412/2600 [05:46<28:16,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 413/2600 [05:47<25:41,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 414/2600 [05:48<32:49,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 415/2600 [05:49<30:22,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 416/2600 [05:50<30:23,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 417/2600 [05:50<28:48,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 418/2600 [05:51<30:54,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 419/2600 [05:53<36:37,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 420/2600 [05:53<33:05,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 421/2600 [05:54<30:35,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▌        | 422/2600 [05:55<28:56,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▋        | 423/2600 [05:56<32:40,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▋        | 424/2600 [05:57<30:22,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▋        | 425/2600 [05:57<28:47,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▋        | 426/2600 [05:58<27:35,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▋        | 427/2600 [05:59<26:49,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▋        | 428/2600 [06:00<33:41,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  16%|█▋        | 429/2600 [06:01<35:52,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 430/2600 [06:02<34:12,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 431/2600 [06:03<31:25,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 432/2600 [06:03<29:27,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 433/2600 [06:04<29:36,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 434/2600 [06:05<26:38,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 435/2600 [06:06<33:33,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 436/2600 [06:07<33:37,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 437/2600 [06:09<38:55,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 438/2600 [06:10<42:15,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 439/2600 [06:11<39:13,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 440/2600 [06:12<37:03,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 441/2600 [06:13<36:57,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 442/2600 [06:14<34:53,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 443/2600 [06:14<33:58,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 444/2600 [06:15<31:13,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 445/2600 [06:16<33:28,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 446/2600 [06:17<32:26,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 447/2600 [06:18<34:52,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 448/2600 [06:19<33:28,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 449/2600 [06:20<30:58,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 450/2600 [06:20<29:10,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 451/2600 [06:22<32:13,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 452/2600 [06:22<32:07,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 453/2600 [06:24<34:34,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  17%|█▋        | 454/2600 [06:24<33:11,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 455/2600 [06:25<32:14,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 456/2600 [06:27<37:15,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 457/2600 [06:27<33:26,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 458/2600 [06:28<32:20,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 459/2600 [06:29<30:34,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 460/2600 [06:30<28:47,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 461/2600 [06:30<28:03,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 462/2600 [06:31<27:02,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 463/2600 [06:32<28:31,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 464/2600 [06:32<25:49,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 465/2600 [06:34<30:12,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 466/2600 [06:35<32:39,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 467/2600 [06:35<30:16,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 468/2600 [06:36<31:11,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 469/2600 [06:37<29:13,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 470/2600 [06:38<27:50,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 471/2600 [06:38<27:52,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 472/2600 [06:40<31:01,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 473/2600 [06:41<33:14,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 474/2600 [06:41<32:03,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 475/2600 [06:43<36:47,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 476/2600 [06:44<34:46,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 477/2600 [06:44<33:22,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 478/2600 [06:45<32:25,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 479/2600 [06:46<28:23,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 480/2600 [06:47<31:55,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  18%|█▊        | 481/2600 [06:48<34:22,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▊        | 482/2600 [06:49<31:22,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▊        | 483/2600 [06:50<29:20,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▊        | 484/2600 [06:50<27:19,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▊        | 485/2600 [06:51<26:20,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▊        | 486/2600 [06:52<27:19,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▊        | 487/2600 [06:52<26:22,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 488/2600 [06:53<25:44,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 489/2600 [06:54<30:31,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 490/2600 [06:55<28:40,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 491/2600 [06:56<32:17,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 492/2600 [06:57<32:39,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 493/2600 [06:58<30:08,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 494/2600 [06:59<31:57,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 495/2600 [07:00<31:12,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 496/2600 [07:01<31:39,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 497/2600 [07:02<32:32,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 498/2600 [07:02<31:38,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 499/2600 [07:03<30:21,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 500/2600 [07:04<29:57,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 501/2600 [07:05<28:08,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 502/2600 [07:05<26:50,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 503/2600 [07:06<25:59,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 504/2600 [07:07<27:04,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 505/2600 [07:08<29:20,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  19%|█▉        | 506/2600 [07:09<29:26,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 507/2600 [07:09<27:53,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 508/2600 [07:10<29:15,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 509/2600 [07:12<32:17,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 510/2600 [07:12<29:48,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 511/2600 [07:13<29:39,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 512/2600 [07:14<28:59,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 513/2600 [07:15<30:05,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 514/2600 [07:16<32:22,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 515/2600 [07:17<32:54,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 516/2600 [07:18<30:15,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 517/2600 [07:19<33:02,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 518/2600 [07:20<35:25,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|█▉        | 519/2600 [07:21<33:29,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 520/2600 [07:22<32:16,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 521/2600 [07:22<29:47,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 522/2600 [07:23<26:28,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 523/2600 [07:23<25:43,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 524/2600 [07:24<27:38,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 525/2600 [07:25<25:33,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 526/2600 [07:26<24:59,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 527/2600 [07:26<24:41,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 528/2600 [07:27<24:26,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 529/2600 [07:28<25:46,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 530/2600 [07:29<25:08,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 531/2600 [07:29<24:47,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 532/2600 [07:30<26:05,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  20%|██        | 533/2600 [07:31<29:38,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 534/2600 [07:32<30:05,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 535/2600 [07:33<26:43,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 536/2600 [07:33<25:55,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 537/2600 [07:34<28:39,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 538/2600 [07:35<28:45,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 539/2600 [07:36<29:52,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 540/2600 [07:37<28:06,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 541/2600 [07:38<29:25,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 542/2600 [07:39<29:19,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 543/2600 [07:40<29:43,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 544/2600 [07:40<29:27,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 545/2600 [07:41<27:45,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 546/2600 [07:42<30:11,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 547/2600 [07:43<33:50,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 548/2600 [07:44<29:21,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 549/2600 [07:45<30:19,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 550/2600 [07:46<35:21,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 551/2600 [07:47<31:53,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██        | 552/2600 [07:48<33:03,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██▏       | 553/2600 [07:49<30:19,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██▏       | 554/2600 [07:50<29:55,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██▏       | 555/2600 [07:50<28:07,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██▏       | 556/2600 [07:51<26:49,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██▏       | 557/2600 [07:52<25:53,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  21%|██▏       | 558/2600 [07:52<25:17,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 559/2600 [07:54<30:23,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 560/2600 [07:55<29:58,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 561/2600 [07:55<28:12,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 562/2600 [07:56<26:56,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 563/2600 [07:57<28:08,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 564/2600 [07:58<28:52,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 565/2600 [07:59<31:46,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 566/2600 [08:00<30:51,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 567/2600 [08:00<28:42,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 568/2600 [08:02<31:42,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 569/2600 [08:03<31:43,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 570/2600 [08:03<28:16,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 571/2600 [08:05<33:52,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 572/2600 [08:06<33:52,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 573/2600 [08:06<32:20,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 574/2600 [08:08<39:36,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 575/2600 [08:09<39:19,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 576/2600 [08:10<35:59,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 577/2600 [08:11<33:42,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 578/2600 [08:12<33:43,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 579/2600 [08:13<32:13,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 580/2600 [08:13<29:34,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 581/2600 [08:14<29:17,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 582/2600 [08:15<31:30,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 583/2600 [08:16<30:35,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▏       | 584/2600 [08:17<28:31,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  22%|██▎       | 585/2600 [08:18<33:58,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 586/2600 [08:19<32:20,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 587/2600 [08:20<35:18,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 588/2600 [08:21<31:54,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 589/2600 [08:22<29:22,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 590/2600 [08:23<30:03,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 591/2600 [08:24<29:35,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 592/2600 [08:24<29:03,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 593/2600 [08:25<28:45,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 594/2600 [08:26<27:05,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 595/2600 [08:27<29:53,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 596/2600 [08:28<29:19,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 597/2600 [08:29<31:52,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 598/2600 [08:30<31:46,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 599/2600 [08:31<34:15,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 600/2600 [08:32<30:59,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 601/2600 [08:33<28:42,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 602/2600 [08:34<34:04,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 603/2600 [08:35<32:20,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 604/2600 [08:36<34:28,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 605/2600 [08:37<32:34,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 606/2600 [08:38<33:39,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 607/2600 [08:39<30:29,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 608/2600 [08:39<28:17,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 609/2600 [08:40<26:43,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  23%|██▎       | 610/2600 [08:41<27:05,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▎       | 611/2600 [08:42<29:21,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▎       | 612/2600 [08:43<29:32,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▎       | 613/2600 [08:44<27:35,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▎       | 614/2600 [08:44<28:07,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▎       | 615/2600 [08:45<26:44,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▎       | 616/2600 [08:46<29:30,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▎       | 617/2600 [08:47<27:32,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 618/2600 [08:48<29:03,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 619/2600 [08:49<30:08,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 620/2600 [08:50<28:02,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 621/2600 [08:51<28:00,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 622/2600 [08:51<28:26,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 623/2600 [08:53<30:41,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 624/2600 [08:53<28:23,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 625/2600 [08:54<25:16,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 626/2600 [08:55<26:01,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 627/2600 [08:56<27:34,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 628/2600 [08:56<28:40,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 629/2600 [08:57<27:03,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 630/2600 [08:58<30:06,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 631/2600 [08:59<30:45,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 632/2600 [09:00<29:48,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 633/2600 [09:01<29:07,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 634/2600 [09:02<31:59,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 635/2600 [09:03<30:38,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 636/2600 [09:04<28:19,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  24%|██▍       | 637/2600 [09:04<26:37,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 638/2600 [09:05<26:54,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 639/2600 [09:06<25:37,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 640/2600 [09:07<24:45,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 641/2600 [09:07<22:44,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 642/2600 [09:08<26:09,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 643/2600 [09:09<25:08,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 644/2600 [09:10<24:33,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 645/2600 [09:10<23:59,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 646/2600 [09:11<25:31,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 647/2600 [09:13<30:01,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 648/2600 [09:14<31:40,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▍       | 649/2600 [09:14<29:00,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 650/2600 [09:16<32:13,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 651/2600 [09:16<29:21,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 652/2600 [09:17<28:48,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 653/2600 [09:18<29:20,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 654/2600 [09:19<28:44,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 655/2600 [09:20<28:36,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 656/2600 [09:20<27:03,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 657/2600 [09:21<25:57,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 658/2600 [09:22<28:51,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 659/2600 [09:23<26:55,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 660/2600 [09:24<27:03,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 661/2600 [09:25<25:44,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  25%|██▌       | 662/2600 [09:25<26:12,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 663/2600 [09:26<26:30,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 664/2600 [09:27<29:38,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 665/2600 [09:28<30:20,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 666/2600 [09:29<31:19,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 667/2600 [09:30<30:31,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 668/2600 [09:31<29:24,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 669/2600 [09:32<28:54,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 670/2600 [09:33<28:30,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 671/2600 [09:34<26:46,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 672/2600 [09:34<27:20,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 673/2600 [09:35<27:42,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 674/2600 [09:36<26:06,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 675/2600 [09:37<26:28,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 676/2600 [09:38<25:10,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 677/2600 [09:39<28:30,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 678/2600 [09:40<28:00,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 679/2600 [09:41<30:55,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 680/2600 [09:42<29:42,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 681/2600 [09:42<29:19,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▌       | 682/2600 [09:44<31:31,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▋       | 683/2600 [09:44<28:50,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▋       | 684/2600 [09:45<28:23,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▋       | 685/2600 [09:46<28:25,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▋       | 686/2600 [09:47<28:56,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▋       | 687/2600 [09:48<31:28,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▋       | 688/2600 [09:49<32:50,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  26%|██▋       | 689/2600 [09:50<29:40,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 690/2600 [09:51<30:43,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 691/2600 [09:52<26:49,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 692/2600 [09:52<24:00,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 693/2600 [09:53<24:48,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 694/2600 [09:54<26:19,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 695/2600 [09:55<28:48,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 696/2600 [09:56<29:34,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 697/2600 [09:57<31:07,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 698/2600 [09:58<28:24,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 699/2600 [09:58<25:33,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 700/2600 [09:59<24:28,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 701/2600 [10:00<27:24,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 702/2600 [10:01<25:44,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 703/2600 [10:02<26:00,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 704/2600 [10:02<24:45,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 705/2600 [10:03<23:55,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 706/2600 [10:04<23:18,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 707/2600 [10:05<25:36,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 708/2600 [10:06<24:30,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 709/2600 [10:06<25:05,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 710/2600 [10:07<25:31,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 711/2600 [10:08<24:29,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 712/2600 [10:09<23:36,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 713/2600 [10:09<24:34,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  27%|██▋       | 714/2600 [10:10<23:42,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 715/2600 [10:11<23:08,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 716/2600 [10:12<24:05,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 717/2600 [10:12<23:22,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 718/2600 [10:13<24:13,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 719/2600 [10:14<27:34,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 720/2600 [10:15<25:46,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 721/2600 [10:16<25:55,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 722/2600 [10:17<24:41,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 723/2600 [10:17<25:17,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 724/2600 [10:18<26:02,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 725/2600 [10:19<26:09,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 726/2600 [10:21<31:14,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 727/2600 [10:21<28:22,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 728/2600 [10:22<27:42,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 729/2600 [10:23<27:14,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 730/2600 [10:24<29:36,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 731/2600 [10:25<27:11,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 732/2600 [10:26<26:52,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 733/2600 [10:27<31:42,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 734/2600 [10:28<30:24,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 735/2600 [10:28<27:39,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 736/2600 [10:29<27:10,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 737/2600 [10:30<25:28,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 738/2600 [10:31<24:15,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 739/2600 [10:32<24:44,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 740/2600 [10:32<25:25,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  28%|██▊       | 741/2600 [10:34<28:36,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▊       | 742/2600 [10:34<27:47,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▊       | 743/2600 [10:35<25:54,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▊       | 744/2600 [10:36<27:42,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▊       | 745/2600 [10:37<27:07,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▊       | 746/2600 [10:38<25:17,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▊       | 747/2600 [10:39<25:28,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 748/2600 [10:40<27:48,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 749/2600 [10:40<27:14,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 750/2600 [10:41<25:28,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 751/2600 [10:42<24:13,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 752/2600 [10:43<27:22,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 753/2600 [10:44<25:42,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 754/2600 [10:44<24:30,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 755/2600 [10:46<27:44,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 756/2600 [10:47<29:51,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 757/2600 [10:48<30:03,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 758/2600 [10:49<29:41,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 759/2600 [10:49<27:06,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 760/2600 [10:50<25:23,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 761/2600 [10:51<27:45,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 762/2600 [10:52<25:48,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 763/2600 [10:53<26:13,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 764/2600 [10:53<26:04,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 765/2600 [10:54<26:30,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  29%|██▉       | 766/2600 [10:55<26:20,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 767/2600 [10:56<26:22,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 768/2600 [10:57<26:25,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 769/2600 [10:58<24:52,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 770/2600 [10:59<25:03,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 771/2600 [10:59<23:51,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 772/2600 [11:00<22:59,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 773/2600 [11:01<22:27,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 774/2600 [11:01<23:22,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 775/2600 [11:02<23:58,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 776/2600 [11:03<24:51,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 777/2600 [11:04<23:40,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 778/2600 [11:05<26:54,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|██▉       | 779/2600 [11:06<25:09,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 780/2600 [11:06<23:55,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 781/2600 [11:07<24:21,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 782/2600 [11:08<26:26,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 783/2600 [11:09<28:50,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 784/2600 [11:10<25:05,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 785/2600 [11:11<25:12,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 786/2600 [11:12<25:10,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 787/2600 [11:12<25:13,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 788/2600 [11:13<25:42,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 789/2600 [11:14<22:30,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 790/2600 [11:14<21:30,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 791/2600 [11:15<22:40,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 792/2600 [11:16<24:47,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  30%|███       | 793/2600 [11:17<27:35,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 794/2600 [11:18<26:28,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 795/2600 [11:19<28:39,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 796/2600 [11:20<27:42,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 797/2600 [11:21<28:22,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 798/2600 [11:22<29:38,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 799/2600 [11:23<25:39,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 800/2600 [11:23<23:17,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 801/2600 [11:24<23:47,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 802/2600 [11:25<22:50,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 803/2600 [11:26<22:09,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 804/2600 [11:27<26:05,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 805/2600 [11:28<25:37,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 806/2600 [11:29<29:34,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 807/2600 [11:30<26:54,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 808/2600 [11:31<26:47,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 809/2600 [11:31<23:38,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 810/2600 [11:32<24:11,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 811/2600 [11:33<26:37,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███       | 812/2600 [11:34<29:10,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███▏      | 813/2600 [11:35<27:55,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███▏      | 814/2600 [11:36<24:24,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███▏      | 815/2600 [11:36<24:32,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███▏      | 816/2600 [11:37<24:36,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███▏      | 817/2600 [11:38<25:58,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  31%|███▏      | 818/2600 [11:39<27:22,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 819/2600 [11:40<29:07,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 820/2600 [11:41<29:53,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 821/2600 [11:42<28:21,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 822/2600 [11:43<25:58,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 823/2600 [11:44<24:20,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 824/2600 [11:45<24:36,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 825/2600 [11:45<25:12,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 826/2600 [11:47<28:03,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 827/2600 [11:47<27:03,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 828/2600 [11:48<25:02,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 829/2600 [11:49<24:57,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 830/2600 [11:50<24:52,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 831/2600 [11:51<24:44,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 832/2600 [11:52<25:33,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 833/2600 [11:53<26:33,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 834/2600 [11:54<29:57,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 835/2600 [11:55<30:02,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 836/2600 [11:56<29:26,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 837/2600 [11:57<26:44,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 838/2600 [11:57<24:49,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 839/2600 [11:58<25:31,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 840/2600 [11:59<25:08,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 841/2600 [12:00<29:27,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 842/2600 [12:01<27:58,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 843/2600 [12:02<29:31,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▏      | 844/2600 [12:04<32:40,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  32%|███▎      | 845/2600 [12:04<28:55,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 846/2600 [12:05<24:57,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 847/2600 [12:06<26:00,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 848/2600 [12:07<27:39,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 849/2600 [12:08<25:24,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 850/2600 [12:09<26:00,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 851/2600 [12:09<24:19,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 852/2600 [12:10<25:38,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 853/2600 [12:11<27:49,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 854/2600 [12:12<25:29,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 855/2600 [12:13<25:06,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 856/2600 [12:14<23:37,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 857/2600 [12:14<24:12,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 858/2600 [12:15<22:55,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 859/2600 [12:16<21:56,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 860/2600 [12:17<24:10,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 861/2600 [12:18<24:56,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 862/2600 [12:19<25:05,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 863/2600 [12:19<23:33,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 864/2600 [12:20<22:35,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 865/2600 [12:21<23:01,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 866/2600 [12:22<22:06,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 867/2600 [12:22<22:45,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 868/2600 [12:23<24:26,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 869/2600 [12:24<24:21,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  33%|███▎      | 870/2600 [12:25<23:05,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▎      | 871/2600 [12:26<26:24,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▎      | 872/2600 [12:27<23:16,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▎      | 873/2600 [12:27<22:15,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▎      | 874/2600 [12:28<22:46,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▎      | 875/2600 [12:29<21:52,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▎      | 876/2600 [12:30<22:31,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▎      | 877/2600 [12:31<25:36,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 878/2600 [12:32<24:00,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 879/2600 [12:33<26:36,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 880/2600 [12:34<26:45,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 881/2600 [12:35<25:54,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 882/2600 [12:35<25:42,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 883/2600 [12:36<23:54,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 884/2600 [12:37<23:47,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 885/2600 [12:38<23:51,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 886/2600 [12:39<23:43,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 887/2600 [12:40<25:22,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 888/2600 [12:41<28:26,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 889/2600 [12:42<27:53,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 890/2600 [12:42<25:25,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 891/2600 [12:43<26:15,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 892/2600 [12:45<28:08,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 893/2600 [12:45<27:15,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 894/2600 [12:46<27:28,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 895/2600 [12:47<23:53,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 896/2600 [12:48<24:47,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  34%|███▍      | 897/2600 [12:49<23:17,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 898/2600 [12:50<24:39,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 899/2600 [12:50<24:24,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 900/2600 [12:52<28:45,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 901/2600 [12:53<25:59,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 902/2600 [12:53<25:16,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 903/2600 [12:54<23:36,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 904/2600 [12:55<22:25,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 905/2600 [12:56<22:45,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 906/2600 [12:57<23:55,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 907/2600 [12:58<26:46,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 908/2600 [12:59<28:41,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▍      | 909/2600 [13:00<27:15,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 910/2600 [13:00<24:58,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 911/2600 [13:01<25:02,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 912/2600 [13:02<24:36,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 913/2600 [13:03<24:17,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 914/2600 [13:04<21:33,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 915/2600 [13:04<19:39,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 916/2600 [13:05<18:45,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 917/2600 [13:05<18:56,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 918/2600 [13:06<20:20,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 919/2600 [13:07<21:47,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 920/2600 [13:08<22:23,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 921/2600 [13:09<22:46,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  35%|███▌      | 922/2600 [13:10<25:28,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 923/2600 [13:11<23:38,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 924/2600 [13:12<23:31,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 925/2600 [13:13<24:43,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 926/2600 [13:14<26:51,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 927/2600 [13:15<30:19,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 928/2600 [13:16<29:04,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 929/2600 [13:17<26:09,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 930/2600 [13:18<25:12,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 931/2600 [13:18<25:20,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 932/2600 [13:19<23:32,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 933/2600 [13:20<23:38,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 934/2600 [13:21<23:34,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 935/2600 [13:22<22:20,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 936/2600 [13:22<21:24,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 937/2600 [13:23<20:45,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 938/2600 [13:24<21:30,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 939/2600 [13:24<20:46,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 940/2600 [13:26<23:23,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 941/2600 [13:27<25:44,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▌      | 942/2600 [13:28<25:48,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▋      | 943/2600 [13:28<24:31,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▋      | 944/2600 [13:29<22:53,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▋      | 945/2600 [13:30<25:23,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▋      | 946/2600 [13:31<25:06,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▋      | 947/2600 [13:32<24:05,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▋      | 948/2600 [13:32<21:23,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  36%|███▋      | 949/2600 [13:33<20:44,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 950/2600 [13:34<20:13,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 951/2600 [13:35<21:28,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 952/2600 [13:36<24:14,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 953/2600 [13:37<23:48,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 954/2600 [13:38<26:02,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 955/2600 [13:38<23:53,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 956/2600 [13:39<22:27,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 957/2600 [13:40<20:13,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 958/2600 [13:41<21:28,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 959/2600 [13:41<19:06,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 960/2600 [13:42<20:40,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 961/2600 [13:43<22:53,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 962/2600 [13:44<20:32,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 963/2600 [13:45<23:34,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 964/2600 [13:46<23:26,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 965/2600 [13:46<21:59,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 966/2600 [13:47<22:58,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 967/2600 [13:48<22:56,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 968/2600 [13:49<21:45,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 969/2600 [13:50<22:33,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 970/2600 [13:50<21:21,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 971/2600 [13:51<21:47,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 972/2600 [13:52<24:56,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 973/2600 [13:53<25:50,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  37%|███▋      | 974/2600 [13:54<23:44,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 975/2600 [13:55<24:15,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 976/2600 [13:56<22:35,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 977/2600 [13:56<21:50,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 978/2600 [13:57<23:05,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 979/2600 [13:58<22:58,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 980/2600 [13:59<21:37,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 981/2600 [14:00<21:49,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 982/2600 [14:00<20:52,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 983/2600 [14:01<22:13,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 984/2600 [14:03<24:37,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 985/2600 [14:03<22:47,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 986/2600 [14:04<25:03,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 987/2600 [14:05<25:52,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 988/2600 [14:06<24:52,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 989/2600 [14:07<22:58,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 990/2600 [14:08<24:50,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 991/2600 [14:09<24:54,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 992/2600 [14:10<24:12,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 993/2600 [14:10<22:29,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 994/2600 [14:11<23:33,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 995/2600 [14:13<25:30,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 996/2600 [14:13<23:24,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 997/2600 [14:14<20:44,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 998/2600 [14:14<20:02,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 999/2600 [14:15<19:33,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 1000/2600 [14:17<24:37,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  38%|███▊      | 1001/2600 [14:17<24:22,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▊      | 1002/2600 [14:19<28:00,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▊      | 1003/2600 [14:20<28:19,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▊      | 1004/2600 [14:21<30:56,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▊      | 1005/2600 [14:22<29:05,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▊      | 1006/2600 [14:23<28:28,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▊      | 1007/2600 [14:24<25:45,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1008/2600 [14:25<24:43,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1009/2600 [14:26<28:13,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1010/2600 [14:27<25:15,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1011/2600 [14:27<22:02,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1012/2600 [14:28<19:47,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1013/2600 [14:29<19:19,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1014/2600 [14:29<17:49,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1015/2600 [14:30<17:55,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1016/2600 [14:31<18:01,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1017/2600 [14:31<19:17,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1018/2600 [14:32<18:59,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1019/2600 [14:33<18:48,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1020/2600 [14:34<22:01,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1021/2600 [14:35<20:51,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1022/2600 [14:36<23:08,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1023/2600 [14:37<22:55,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1024/2600 [14:38<24:34,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1025/2600 [14:39<23:49,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  39%|███▉      | 1026/2600 [14:39<22:06,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1027/2600 [14:40<22:27,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1028/2600 [14:41<24:37,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1029/2600 [14:42<22:40,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1030/2600 [14:43<24:21,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1031/2600 [14:44<22:32,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1032/2600 [14:45<22:20,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1033/2600 [14:45<22:50,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1034/2600 [14:47<24:29,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1035/2600 [14:47<24:07,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1036/2600 [14:48<22:39,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1037/2600 [14:49<25:25,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1038/2600 [14:50<23:11,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|███▉      | 1039/2600 [14:51<22:44,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1040/2600 [14:52<21:18,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1041/2600 [14:52<20:18,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1042/2600 [14:53<22:42,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1043/2600 [14:54<22:24,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1044/2600 [14:55<21:07,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1045/2600 [14:56<20:13,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1046/2600 [14:56<19:32,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1047/2600 [14:57<21:26,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1048/2600 [14:58<21:55,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1049/2600 [14:59<20:44,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1050/2600 [15:00<19:54,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1051/2600 [15:01<23:03,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1052/2600 [15:02<22:36,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  40%|████      | 1053/2600 [15:02<21:10,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1054/2600 [15:03<19:04,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1055/2600 [15:04<18:42,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1056/2600 [15:05<22:14,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1057/2600 [15:06<26:18,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1058/2600 [15:07<23:46,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1059/2600 [15:08<22:06,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1060/2600 [15:08<19:40,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1061/2600 [15:09<19:54,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1062/2600 [15:10<20:23,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1063/2600 [15:10<19:32,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1064/2600 [15:11<17:53,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1065/2600 [15:12<20:06,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1066/2600 [15:13<20:33,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1067/2600 [15:14<20:53,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1068/2600 [15:14<19:53,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1069/2600 [15:15<20:41,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1070/2600 [15:16<20:48,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1071/2600 [15:17<23:35,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████      | 1072/2600 [15:18<21:49,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████▏     | 1073/2600 [15:19<23:55,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████▏     | 1074/2600 [15:20<23:23,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████▏     | 1075/2600 [15:21<21:49,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████▏     | 1076/2600 [15:22<21:46,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████▏     | 1077/2600 [15:22<20:30,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  41%|████▏     | 1078/2600 [15:23<19:38,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1079/2600 [15:24<20:10,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1080/2600 [15:25<20:30,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1081/2600 [15:25<20:49,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1082/2600 [15:26<21:43,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1083/2600 [15:27<22:21,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1084/2600 [15:28<22:02,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1085/2600 [15:29<21:53,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1086/2600 [15:30<21:41,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1087/2600 [15:31<20:26,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1088/2600 [15:31<20:45,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1089/2600 [15:32<19:53,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1090/2600 [15:33<20:29,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1091/2600 [15:34<22:33,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1092/2600 [15:35<22:08,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1093/2600 [15:36<20:45,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1094/2600 [15:36<19:42,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1095/2600 [15:37<18:59,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1096/2600 [15:38<20:39,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1097/2600 [15:39<20:43,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1098/2600 [15:40<24:43,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1099/2600 [15:41<22:28,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1100/2600 [15:42<20:58,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1101/2600 [15:42<21:00,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1102/2600 [15:43<21:19,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1103/2600 [15:44<21:16,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▏     | 1104/2600 [15:45<22:04,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  42%|████▎     | 1105/2600 [15:46<20:37,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1106/2600 [15:47<25:05,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1107/2600 [15:48<24:31,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1108/2600 [15:49<23:46,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1109/2600 [15:50<25:04,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1110/2600 [15:51<26:00,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1111/2600 [15:52<24:45,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1112/2600 [15:53<22:32,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1113/2600 [15:54<20:55,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1114/2600 [15:55<25:12,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1115/2600 [15:56<22:51,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1116/2600 [15:56<21:15,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1117/2600 [15:58<22:22,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1118/2600 [15:58<22:38,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1119/2600 [15:59<22:04,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1120/2600 [16:01<25:35,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1121/2600 [16:02<24:09,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1122/2600 [16:03<29:15,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1123/2600 [16:04<25:38,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1124/2600 [16:05<23:04,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1125/2600 [16:05<22:19,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1126/2600 [16:06<22:57,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1127/2600 [16:07<21:10,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1128/2600 [16:08<18:56,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1129/2600 [16:08<18:04,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  43%|████▎     | 1130/2600 [16:09<18:51,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▎     | 1131/2600 [16:10<18:15,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▎     | 1132/2600 [16:11<17:56,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▎     | 1133/2600 [16:11<18:46,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▎     | 1134/2600 [16:12<20:01,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▎     | 1135/2600 [16:13<20:07,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▎     | 1136/2600 [16:14<20:12,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▎     | 1137/2600 [16:15<22:03,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1138/2600 [16:16<22:15,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1139/2600 [16:17<21:42,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1140/2600 [16:18<20:17,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1141/2600 [16:18<18:10,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1142/2600 [16:19<17:46,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1143/2600 [16:20<18:38,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1144/2600 [16:20<18:02,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1145/2600 [16:21<17:41,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1146/2600 [16:22<22:32,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1147/2600 [16:23<22:13,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1148/2600 [16:24<22:19,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1149/2600 [16:25<23:28,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1150/2600 [16:26<22:29,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1151/2600 [16:27<21:47,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1152/2600 [16:28<21:17,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1153/2600 [16:29<23:02,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1154/2600 [16:30<21:05,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1155/2600 [16:30<19:45,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1156/2600 [16:31<19:58,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  44%|████▍     | 1157/2600 [16:32<21:50,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1158/2600 [16:33<19:16,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1159/2600 [16:34<18:28,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1160/2600 [16:34<17:53,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1161/2600 [16:35<19:55,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1162/2600 [16:36<20:41,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1163/2600 [16:37<19:26,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1164/2600 [16:38<19:35,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1165/2600 [16:39<19:42,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1166/2600 [16:39<18:44,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1167/2600 [16:40<18:04,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1168/2600 [16:41<20:00,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▍     | 1169/2600 [16:42<22:41,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1170/2600 [16:43<23:03,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1171/2600 [16:44<21:10,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1172/2600 [16:45<22:45,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1173/2600 [16:46<21:58,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1174/2600 [16:47<23:06,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1175/2600 [16:48<22:50,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1176/2600 [16:49<21:59,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1177/2600 [16:50<22:03,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1178/2600 [16:50<19:18,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1179/2600 [16:51<18:29,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1180/2600 [16:52<18:56,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1181/2600 [16:53<19:54,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  45%|████▌     | 1182/2600 [16:53<18:52,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1183/2600 [16:54<19:31,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1184/2600 [16:55<19:41,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1185/2600 [16:56<18:42,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1186/2600 [16:57<17:58,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1187/2600 [16:57<17:34,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1188/2600 [16:58<18:32,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1189/2600 [16:59<17:53,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1190/2600 [17:00<17:24,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1191/2600 [17:01<20:09,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1192/2600 [17:02<22:09,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1193/2600 [17:03<20:21,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1194/2600 [17:04<21:51,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1195/2600 [17:05<23:14,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1196/2600 [17:06<22:01,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1197/2600 [17:07<23:17,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1198/2600 [17:08<22:32,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1199/2600 [17:08<21:38,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1200/2600 [17:09<21:01,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1201/2600 [17:11<24:18,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▌     | 1202/2600 [17:11<22:53,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▋     | 1203/2600 [17:12<20:49,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▋     | 1204/2600 [17:13<20:26,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▋     | 1205/2600 [17:14<19:05,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▋     | 1206/2600 [17:15<22:54,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▋     | 1207/2600 [17:16<21:54,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▋     | 1208/2600 [17:17<23:04,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  46%|████▋     | 1209/2600 [17:18<20:56,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1210/2600 [17:19<20:26,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1211/2600 [17:20<21:04,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1212/2600 [17:20<20:35,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1213/2600 [17:21<19:20,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1214/2600 [17:22<19:19,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1215/2600 [17:23<18:16,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1216/2600 [17:24<19:17,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1217/2600 [17:25<20:18,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1218/2600 [17:25<20:21,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1219/2600 [17:26<20:06,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1220/2600 [17:27<19:44,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1221/2600 [17:28<18:29,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1222/2600 [17:28<17:42,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1223/2600 [17:29<17:09,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1224/2600 [17:30<16:44,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1225/2600 [17:31<21:11,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1226/2600 [17:32<20:37,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1227/2600 [17:33<20:13,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1228/2600 [17:34<21:17,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1229/2600 [17:35<19:37,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1230/2600 [17:35<19:28,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1231/2600 [17:37<23:24,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1232/2600 [17:38<24:30,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1233/2600 [17:39<23:32,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  47%|████▋     | 1234/2600 [17:40<22:53,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1235/2600 [17:41<20:43,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1236/2600 [17:41<20:10,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1237/2600 [17:42<20:32,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1238/2600 [17:43<20:05,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1239/2600 [17:45<23:30,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1240/2600 [17:45<21:11,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1241/2600 [17:46<22:12,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1242/2600 [17:47<20:14,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1243/2600 [17:48<21:49,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1244/2600 [17:49<19:55,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1245/2600 [17:50<18:36,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1246/2600 [17:50<17:41,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1247/2600 [17:51<18:03,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1248/2600 [17:52<19:38,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1249/2600 [17:53<18:25,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1250/2600 [17:54<22:10,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1251/2600 [17:55<20:12,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1252/2600 [17:56<18:50,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1253/2600 [17:56<17:52,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1254/2600 [17:57<17:10,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1255/2600 [17:58<16:42,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1256/2600 [17:58<16:19,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1257/2600 [18:00<19:00,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1258/2600 [18:00<18:53,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1259/2600 [18:01<18:53,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1260/2600 [18:02<17:52,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  48%|████▊     | 1261/2600 [18:03<20:46,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▊     | 1262/2600 [18:04<20:07,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▊     | 1263/2600 [18:05<18:44,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▊     | 1264/2600 [18:05<16:47,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▊     | 1265/2600 [18:06<18:21,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▊     | 1266/2600 [18:07<16:29,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▊     | 1267/2600 [18:08<18:45,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1268/2600 [18:09<17:42,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1269/2600 [18:10<20:35,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1270/2600 [18:11<20:30,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1271/2600 [18:12<20:33,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1272/2600 [18:12<18:56,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1273/2600 [18:13<17:49,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1274/2600 [18:14<18:20,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1275/2600 [18:15<17:23,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1276/2600 [18:15<15:50,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1277/2600 [18:16<18:31,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1278/2600 [18:17<17:30,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1279/2600 [18:18<17:46,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1280/2600 [18:19<19:32,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1281/2600 [18:20<18:18,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1282/2600 [18:21<18:58,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1283/2600 [18:21<17:50,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1284/2600 [18:22<17:00,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1285/2600 [18:23<16:26,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  49%|████▉     | 1286/2600 [18:23<16:03,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1287/2600 [18:24<15:46,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1288/2600 [18:25<14:35,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1289/2600 [18:25<15:04,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1290/2600 [18:26<15:04,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1291/2600 [18:27<17:33,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1292/2600 [18:28<16:42,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1293/2600 [18:29<17:20,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1294/2600 [18:29<16:40,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1295/2600 [18:30<17:05,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1296/2600 [18:32<20:57,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1297/2600 [18:33<23:49,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1298/2600 [18:34<22:31,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|████▉     | 1299/2600 [18:35<23:10,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1300/2600 [18:36<21:42,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1301/2600 [18:37<22:34,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1302/2600 [18:38<22:54,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1303/2600 [18:39<22:07,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1304/2600 [18:40<20:57,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1305/2600 [18:41<19:10,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1306/2600 [18:41<17:53,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1307/2600 [18:42<20:07,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1308/2600 [18:43<20:26,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1309/2600 [18:44<21:04,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1310/2600 [18:45<19:17,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1311/2600 [18:46<17:57,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1312/2600 [18:47<19:31,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  50%|█████     | 1313/2600 [18:48<18:08,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1314/2600 [18:48<16:29,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1315/2600 [18:49<16:56,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1316/2600 [18:50<16:21,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1317/2600 [18:51<16:49,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1318/2600 [18:51<15:17,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1319/2600 [18:52<18:56,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1320/2600 [18:54<20:46,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1321/2600 [18:55<21:26,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1322/2600 [18:56<21:21,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1323/2600 [18:56<19:23,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1324/2600 [18:57<18:00,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1325/2600 [18:58<16:04,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1326/2600 [18:58<16:35,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1327/2600 [18:59<16:57,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1328/2600 [19:01<19:40,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1329/2600 [19:02<20:37,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1330/2600 [19:02<19:47,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1331/2600 [19:03<18:18,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████     | 1332/2600 [19:04<18:09,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████▏    | 1333/2600 [19:05<17:07,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████▏    | 1334/2600 [19:06<19:03,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████▏    | 1335/2600 [19:06<16:43,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████▏    | 1336/2600 [19:07<16:03,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████▏    | 1337/2600 [19:08<17:15,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  51%|█████▏    | 1338/2600 [19:09<16:24,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1339/2600 [19:10<18:19,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1340/2600 [19:11<18:02,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1341/2600 [19:12<18:47,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1342/2600 [19:13<20:17,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1343/2600 [19:13<18:32,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1344/2600 [19:14<19:45,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1345/2600 [19:15<18:11,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1346/2600 [19:16<17:04,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1347/2600 [19:17<16:16,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1348/2600 [19:18<18:08,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1349/2600 [19:18<17:55,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1350/2600 [19:19<17:46,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1351/2600 [19:20<19:32,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1352/2600 [19:21<18:58,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1353/2600 [19:22<18:31,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1354/2600 [19:23<16:20,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1355/2600 [19:23<15:43,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1356/2600 [19:24<16:11,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1357/2600 [19:25<16:30,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1358/2600 [19:26<17:26,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1359/2600 [19:27<17:24,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1360/2600 [19:28<17:26,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1361/2600 [19:29<17:42,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1362/2600 [19:29<15:45,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1363/2600 [19:30<15:20,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▏    | 1364/2600 [19:30<14:07,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  52%|█████▎    | 1365/2600 [19:31<16:03,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1366/2600 [19:32<15:32,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1367/2600 [19:33<16:44,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1368/2600 [19:34<16:55,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1369/2600 [19:35<18:47,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1370/2600 [19:36<16:29,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1371/2600 [19:36<16:25,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1372/2600 [19:37<15:44,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1373/2600 [19:38<16:09,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1374/2600 [19:39<16:27,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1375/2600 [19:40<18:22,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1376/2600 [19:41<18:01,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1377/2600 [19:42<21:05,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1378/2600 [19:43<19:02,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1379/2600 [19:43<16:43,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1380/2600 [19:44<16:56,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1381/2600 [19:45<16:11,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1382/2600 [19:46<17:29,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1383/2600 [19:47<18:00,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1384/2600 [19:48<17:45,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1385/2600 [19:49<19:21,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1386/2600 [19:50<17:45,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1387/2600 [19:50<16:38,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1388/2600 [19:51<19:06,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1389/2600 [19:52<16:41,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  53%|█████▎    | 1390/2600 [19:53<16:44,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▎    | 1391/2600 [19:53<15:01,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▎    | 1392/2600 [19:55<18:49,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▎    | 1393/2600 [19:56<19:38,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▎    | 1394/2600 [19:57<20:36,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▎    | 1395/2600 [19:58<19:31,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▎    | 1396/2600 [19:58<16:56,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▎    | 1397/2600 [19:59<17:12,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1398/2600 [20:00<17:02,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1399/2600 [20:01<16:03,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1400/2600 [20:01<15:23,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1401/2600 [20:02<15:46,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1402/2600 [20:03<14:19,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1403/2600 [20:03<13:19,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1404/2600 [20:04<12:01,  1.66it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1405/2600 [20:05<14:02,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1406/2600 [20:06<15:13,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1407/2600 [20:06<14:48,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1408/2600 [20:07<15:25,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1409/2600 [20:08<14:11,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1410/2600 [20:09<16:15,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1411/2600 [20:10<15:28,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1412/2600 [20:11<18:59,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1413/2600 [20:12<17:26,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1414/2600 [20:12<16:18,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1415/2600 [20:13<17:33,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  54%|█████▍    | 1416/2600 [20:14<18:27,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1417/2600 [20:15<18:09,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1418/2600 [20:16<16:49,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1419/2600 [20:17<18:11,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1420/2600 [20:18<15:57,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1421/2600 [20:19<19:16,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1422/2600 [20:20<16:45,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1423/2600 [20:20<16:40,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1424/2600 [20:21<16:45,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1425/2600 [20:22<18:08,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1426/2600 [20:24<20:50,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1427/2600 [20:25<19:32,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1428/2600 [20:26<20:39,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▍    | 1429/2600 [20:27<19:26,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1430/2600 [20:28<20:29,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1431/2600 [20:29<18:22,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1432/2600 [20:29<16:52,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1433/2600 [20:30<16:42,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1434/2600 [20:31<16:35,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1435/2600 [20:32<16:34,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1436/2600 [20:33<17:14,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1437/2600 [20:34<17:38,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1438/2600 [20:34<16:22,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1439/2600 [20:35<16:17,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1440/2600 [20:36<16:34,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1441/2600 [20:37<18:06,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  55%|█████▌    | 1442/2600 [20:38<19:15,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1443/2600 [20:39<18:54,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1444/2600 [20:40<17:14,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1445/2600 [20:41<16:56,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1446/2600 [20:42<15:52,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1447/2600 [20:42<15:08,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1448/2600 [20:43<14:34,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1449/2600 [20:44<18:19,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1450/2600 [20:45<18:20,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1451/2600 [20:46<17:42,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1452/2600 [20:47<16:23,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1453/2600 [20:48<17:45,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1454/2600 [20:49<17:13,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1455/2600 [20:50<17:42,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1456/2600 [20:51<17:11,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1457/2600 [20:51<15:09,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1458/2600 [20:52<15:23,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1459/2600 [20:53<15:52,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1460/2600 [20:54<15:53,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1461/2600 [20:55<15:54,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▌    | 1462/2600 [20:55<15:05,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▋    | 1463/2600 [20:56<15:33,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▋    | 1464/2600 [20:57<15:42,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▋    | 1465/2600 [20:58<14:57,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▋    | 1466/2600 [20:59<17:10,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▋    | 1467/2600 [21:00<18:26,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▋    | 1468/2600 [21:01<17:57,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  56%|█████▋    | 1469/2600 [21:02<19:47,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1470/2600 [21:03<17:45,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1471/2600 [21:04<16:20,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1472/2600 [21:04<15:21,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1473/2600 [21:05<14:37,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1474/2600 [21:06<14:05,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1475/2600 [21:07<17:36,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1476/2600 [21:08<16:11,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1477/2600 [21:09<15:57,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1478/2600 [21:09<14:29,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1479/2600 [21:10<13:11,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1480/2600 [21:11<14:27,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1481/2600 [21:12<16:24,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1482/2600 [21:13<16:12,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1483/2600 [21:13<15:12,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1484/2600 [21:14<14:28,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1485/2600 [21:15<14:47,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1486/2600 [21:16<14:59,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1487/2600 [21:16<14:18,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1488/2600 [21:17<13:50,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1489/2600 [21:18<14:54,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1490/2600 [21:19<16:10,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1491/2600 [21:20<17:26,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1492/2600 [21:21<17:11,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1493/2600 [21:22<18:00,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▋    | 1494/2600 [21:23<17:13,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  57%|█████▊    | 1495/2600 [21:24<15:52,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1496/2600 [21:25<17:04,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1497/2600 [21:25<15:44,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1498/2600 [21:26<14:49,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1499/2600 [21:27<14:10,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1500/2600 [21:28<13:42,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1501/2600 [21:28<12:50,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1502/2600 [21:29<12:47,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1503/2600 [21:30<13:34,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1504/2600 [21:30<12:29,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1505/2600 [21:31<15:17,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1506/2600 [21:32<15:53,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1507/2600 [21:33<15:44,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1508/2600 [21:34<15:51,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1509/2600 [21:35<14:55,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1510/2600 [21:36<17:52,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1511/2600 [21:37<18:39,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1512/2600 [21:38<16:44,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1513/2600 [21:38<14:40,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1514/2600 [21:39<14:01,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1515/2600 [21:40<14:37,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1516/2600 [21:41<15:17,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1517/2600 [21:42<14:27,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1518/2600 [21:42<13:03,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1519/2600 [21:43<14:13,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1520/2600 [21:44<15:37,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  58%|█████▊    | 1521/2600 [21:45<15:36,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▊    | 1522/2600 [21:46<14:38,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▊    | 1523/2600 [21:46<13:59,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▊    | 1524/2600 [21:47<13:32,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▊    | 1525/2600 [21:48<14:33,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▊    | 1526/2600 [21:49<16:11,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▊    | 1527/2600 [21:50<17:06,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1528/2600 [21:51<16:30,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1529/2600 [21:52<17:56,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1530/2600 [21:53<14:57,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1531/2600 [21:54<14:11,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1532/2600 [21:54<14:26,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1533/2600 [21:55<15:10,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1534/2600 [21:56<15:09,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1535/2600 [21:57<15:21,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1536/2600 [21:58<15:09,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1537/2600 [21:59<15:05,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1538/2600 [21:59<13:28,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1539/2600 [22:01<17:01,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1540/2600 [22:02<16:20,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1541/2600 [22:02<15:05,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1542/2600 [22:03<15:31,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1543/2600 [22:04<16:36,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1544/2600 [22:05<16:02,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1545/2600 [22:06<14:54,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  59%|█████▉    | 1546/2600 [22:07<14:46,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1547/2600 [22:08<14:49,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1548/2600 [22:08<14:02,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1549/2600 [22:09<14:17,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1550/2600 [22:10<14:25,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1551/2600 [22:11<16:01,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1552/2600 [22:12<17:25,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1553/2600 [22:13<15:50,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1554/2600 [22:13<13:56,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1555/2600 [22:14<14:10,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1556/2600 [22:15<13:31,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1557/2600 [22:16<15:17,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1558/2600 [22:17<15:05,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|█████▉    | 1559/2600 [22:18<14:07,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1560/2600 [22:18<14:14,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1561/2600 [22:19<13:34,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1562/2600 [22:20<14:39,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1563/2600 [22:21<14:40,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1564/2600 [22:22<14:48,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1565/2600 [22:23<14:55,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1566/2600 [22:23<13:57,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1567/2600 [22:24<14:06,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1568/2600 [22:25<13:28,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1569/2600 [22:26<13:01,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1570/2600 [22:27<14:54,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1571/2600 [22:28<14:45,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1572/2600 [22:29<14:36,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  60%|██████    | 1573/2600 [22:30<15:46,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1574/2600 [22:30<14:33,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1575/2600 [22:31<14:29,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1576/2600 [22:32<15:57,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1577/2600 [22:33<14:42,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1578/2600 [22:34<13:50,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1579/2600 [22:34<13:12,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1580/2600 [22:36<16:15,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1581/2600 [22:36<14:53,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1582/2600 [22:37<14:41,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1583/2600 [22:38<15:47,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1584/2600 [22:39<14:33,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1585/2600 [22:40<12:56,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1586/2600 [22:41<15:59,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1587/2600 [22:42<16:38,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1588/2600 [22:43<15:51,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1589/2600 [22:44<16:51,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1590/2600 [22:45<17:03,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1591/2600 [22:46<17:40,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████    | 1592/2600 [22:47<16:36,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████▏   | 1593/2600 [22:48<15:53,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████▏   | 1594/2600 [22:48<13:36,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████▏   | 1595/2600 [22:49<13:44,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████▏   | 1596/2600 [22:50<13:49,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████▏   | 1597/2600 [22:51<14:22,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  61%|██████▏   | 1598/2600 [22:52<15:27,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1599/2600 [22:53<14:16,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1600/2600 [22:54<14:08,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1601/2600 [22:54<13:20,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1602/2600 [22:55<12:48,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1603/2600 [22:56<12:26,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1604/2600 [22:57<13:40,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1605/2600 [22:57<13:04,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1606/2600 [22:58<13:18,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1607/2600 [22:59<14:58,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1608/2600 [23:00<14:40,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1609/2600 [23:01<13:41,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1610/2600 [23:02<13:45,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1611/2600 [23:02<13:03,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1612/2600 [23:03<12:31,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1613/2600 [23:04<11:27,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1614/2600 [23:05<12:11,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1615/2600 [23:05<12:41,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1616/2600 [23:06<13:05,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1617/2600 [23:07<12:35,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1618/2600 [23:08<12:19,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1619/2600 [23:09<12:56,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1620/2600 [23:09<13:19,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1621/2600 [23:10<13:31,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1622/2600 [23:11<12:50,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1623/2600 [23:12<14:31,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▏   | 1624/2600 [23:13<14:16,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  62%|██████▎   | 1625/2600 [23:14<14:03,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1626/2600 [23:15<15:07,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1627/2600 [23:16<13:58,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1628/2600 [23:16<13:49,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1629/2600 [23:17<13:01,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1630/2600 [23:18<12:25,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1631/2600 [23:19<12:42,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1632/2600 [23:19<12:17,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1633/2600 [23:20<11:58,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1634/2600 [23:21<11:44,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1635/2600 [23:22<13:23,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1636/2600 [23:23<13:23,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1637/2600 [23:23<12:42,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1638/2600 [23:24<13:21,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1639/2600 [23:26<15:57,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1640/2600 [23:27<16:37,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1641/2600 [23:27<14:56,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1642/2600 [23:28<14:31,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1643/2600 [23:29<13:28,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1644/2600 [23:30<13:39,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1645/2600 [23:30<12:10,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1646/2600 [23:31<13:02,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1647/2600 [23:32<13:22,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1648/2600 [23:33<13:24,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1649/2600 [23:34<12:39,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  63%|██████▎   | 1650/2600 [23:35<14:15,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▎   | 1651/2600 [23:36<15:09,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▎   | 1652/2600 [23:37<17:10,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▎   | 1653/2600 [23:38<15:18,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▎   | 1654/2600 [23:39<13:59,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▎   | 1655/2600 [23:39<13:04,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▎   | 1656/2600 [23:40<13:07,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▎   | 1657/2600 [23:41<14:19,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1658/2600 [23:42<13:18,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1659/2600 [23:44<15:49,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1660/2600 [23:44<13:39,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1661/2600 [23:45<13:33,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1662/2600 [23:46<14:42,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1663/2600 [23:47<14:11,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1664/2600 [23:48<13:10,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1665/2600 [23:49<14:32,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1666/2600 [23:49<13:23,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1667/2600 [23:50<12:34,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1668/2600 [23:51<14:05,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1669/2600 [23:52<14:28,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1670/2600 [23:53<14:02,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1671/2600 [23:54<13:02,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1672/2600 [23:55<13:02,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1673/2600 [23:56<14:13,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1674/2600 [23:57<14:27,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1675/2600 [23:57<13:20,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1676/2600 [23:58<12:30,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  64%|██████▍   | 1677/2600 [23:59<11:56,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1678/2600 [24:00<13:35,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1679/2600 [24:01<12:43,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1680/2600 [24:02<13:13,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1681/2600 [24:03<13:47,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1682/2600 [24:03<13:58,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1683/2600 [24:04<14:07,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1684/2600 [24:05<13:06,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1685/2600 [24:06<13:00,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1686/2600 [24:07<11:36,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1687/2600 [24:07<11:18,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1688/2600 [24:08<13:14,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▍   | 1689/2600 [24:09<12:31,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1690/2600 [24:10<13:02,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1691/2600 [24:11<12:16,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1692/2600 [24:11<11:46,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1693/2600 [24:12<11:22,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1694/2600 [24:13<12:12,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1695/2600 [24:14<12:17,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1696/2600 [24:15<12:51,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1697/2600 [24:16<14:49,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1698/2600 [24:17<14:12,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1699/2600 [24:18<13:04,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1700/2600 [24:18<12:16,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1701/2600 [24:19<12:26,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  65%|██████▌   | 1702/2600 [24:20<12:31,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1703/2600 [24:21<11:55,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1704/2600 [24:22<12:11,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1705/2600 [24:22<11:39,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1706/2600 [24:23<11:56,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1707/2600 [24:24<12:08,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1708/2600 [24:25<12:42,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1709/2600 [24:26<13:32,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1710/2600 [24:27<13:13,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1711/2600 [24:28<12:56,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1712/2600 [24:29<12:44,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1713/2600 [24:30<13:33,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1714/2600 [24:30<13:12,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1715/2600 [24:31<13:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1716/2600 [24:32<12:17,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1717/2600 [24:33<12:21,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1718/2600 [24:34<14:40,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1719/2600 [24:35<13:21,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1720/2600 [24:36<12:22,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1721/2600 [24:36<11:42,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▌   | 1722/2600 [24:37<11:17,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▋   | 1723/2600 [24:38<11:33,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▋   | 1724/2600 [24:39<11:07,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▋   | 1725/2600 [24:39<10:36,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▋   | 1726/2600 [24:40<10:28,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▋   | 1727/2600 [24:41<12:19,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▋   | 1728/2600 [24:42<12:20,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  66%|██████▋   | 1729/2600 [24:43<12:18,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1730/2600 [24:43<11:41,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1731/2600 [24:44<10:37,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1732/2600 [24:45<10:30,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1733/2600 [24:46<12:12,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1734/2600 [24:47<12:19,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1735/2600 [24:47<11:34,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1736/2600 [24:48<11:03,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1737/2600 [24:49<11:20,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1738/2600 [24:50<10:56,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1739/2600 [24:51<12:48,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1740/2600 [24:52<12:37,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1741/2600 [24:52<11:10,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1742/2600 [24:53<11:26,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1743/2600 [24:54<12:04,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1744/2600 [24:55<13:09,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1745/2600 [24:56<11:37,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1746/2600 [24:57<12:34,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1747/2600 [24:58<14:43,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1748/2600 [24:59<13:15,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1749/2600 [25:00<13:27,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1750/2600 [25:01<13:24,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1751/2600 [25:01<12:19,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1752/2600 [25:02<11:36,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1753/2600 [25:03<11:05,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  67%|██████▋   | 1754/2600 [25:04<12:33,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1755/2600 [25:05<12:20,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1756/2600 [25:06<12:36,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1757/2600 [25:07<12:24,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1758/2600 [25:08<12:18,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1759/2600 [25:08<11:39,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1760/2600 [25:09<11:13,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1761/2600 [25:10<11:25,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1762/2600 [25:10<10:16,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1763/2600 [25:11<10:05,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1764/2600 [25:12<11:02,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1765/2600 [25:13<10:42,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1766/2600 [25:14<11:35,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1767/2600 [25:15<11:39,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1768/2600 [25:16<12:43,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1769/2600 [25:16<11:46,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1770/2600 [25:17<12:21,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1771/2600 [25:18<12:07,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1772/2600 [25:19<13:30,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1773/2600 [25:21<14:05,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1774/2600 [25:21<13:25,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1775/2600 [25:22<12:14,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1776/2600 [25:23<12:00,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1777/2600 [25:23<10:40,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1778/2600 [25:24<10:17,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1779/2600 [25:25<10:03,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1780/2600 [25:26<11:29,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  68%|██████▊   | 1781/2600 [25:27<11:41,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▊   | 1782/2600 [25:28<12:01,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▊   | 1783/2600 [25:29<12:02,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▊   | 1784/2600 [25:30<11:51,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▊   | 1785/2600 [25:30<11:54,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▊   | 1786/2600 [25:31<12:09,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▊   | 1787/2600 [25:32<11:18,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1788/2600 [25:33<11:19,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1789/2600 [25:34<10:45,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1790/2600 [25:34<11:05,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1791/2600 [25:36<12:24,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1792/2600 [25:37<12:28,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1793/2600 [25:38<12:30,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1794/2600 [25:38<12:10,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1795/2600 [25:39<11:16,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1796/2600 [25:40<11:16,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1797/2600 [25:41<10:39,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1798/2600 [25:41<10:48,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1799/2600 [25:42<11:19,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1800/2600 [25:43<11:29,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1801/2600 [25:44<11:25,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1802/2600 [25:45<10:45,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1803/2600 [25:45<10:17,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1804/2600 [25:46<09:58,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1805/2600 [25:47<09:44,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  69%|██████▉   | 1806/2600 [25:48<10:09,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1807/2600 [25:49<10:25,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1808/2600 [25:49<10:35,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1809/2600 [25:50<10:08,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1810/2600 [25:51<11:34,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1811/2600 [25:52<10:50,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1812/2600 [25:53<11:53,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1813/2600 [25:54<11:39,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1814/2600 [25:55<10:53,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1815/2600 [25:56<11:56,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1816/2600 [25:56<11:04,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1817/2600 [25:58<13:09,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1818/2600 [25:58<11:52,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|██████▉   | 1819/2600 [25:59<10:59,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1820/2600 [26:00<10:56,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1821/2600 [26:01<10:55,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1822/2600 [26:01<10:19,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1823/2600 [26:03<11:49,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1824/2600 [26:03<10:58,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1825/2600 [26:04<11:08,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1826/2600 [26:05<09:55,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1827/2600 [26:06<11:07,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1828/2600 [26:07<11:01,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1829/2600 [26:08<11:32,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1830/2600 [26:08<10:44,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1831/2600 [26:09<10:46,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1832/2600 [26:10<10:44,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  70%|███████   | 1833/2600 [26:11<11:39,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1834/2600 [26:12<12:17,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1835/2600 [26:13<13:03,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1836/2600 [26:14<11:46,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1837/2600 [26:15<10:19,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1838/2600 [26:15<09:51,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1839/2600 [26:16<10:06,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1840/2600 [26:17<10:15,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1841/2600 [26:18<10:30,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1842/2600 [26:19<10:29,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1843/2600 [26:19<09:24,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1844/2600 [26:20<10:41,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1845/2600 [26:21<10:08,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1846/2600 [26:22<09:43,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1847/2600 [26:23<09:24,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1848/2600 [26:23<08:38,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1849/2600 [26:24<08:39,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1850/2600 [26:25<09:25,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1851/2600 [26:25<09:11,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████   | 1852/2600 [26:26<09:34,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████▏  | 1853/2600 [26:27<09:51,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████▏  | 1854/2600 [26:28<11:06,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████▏  | 1855/2600 [26:29<10:21,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████▏  | 1856/2600 [26:30<11:27,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████▏  | 1857/2600 [26:31<11:28,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  71%|███████▏  | 1858/2600 [26:32<11:43,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1859/2600 [26:33<10:45,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1860/2600 [26:34<12:18,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1861/2600 [26:35<11:41,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1862/2600 [26:36<11:29,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1863/2600 [26:36<11:07,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1864/2600 [26:38<12:50,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1865/2600 [26:39<14:03,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1866/2600 [26:40<12:25,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1867/2600 [26:41<12:51,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1868/2600 [26:42<12:03,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1869/2600 [26:43<12:22,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1870/2600 [26:44<11:53,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1871/2600 [26:45<11:22,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1872/2600 [26:46<11:50,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1873/2600 [26:47<10:47,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1874/2600 [26:47<10:48,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1875/2600 [26:48<11:08,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1876/2600 [26:49<10:19,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1877/2600 [26:50<09:12,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1878/2600 [26:50<09:28,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1879/2600 [26:51<09:39,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1880/2600 [26:52<09:46,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1881/2600 [26:53<10:44,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1882/2600 [26:54<10:31,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1883/2600 [26:55<10:23,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▏  | 1884/2600 [26:56<09:48,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  72%|███████▎  | 1885/2600 [26:56<09:51,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1886/2600 [26:57<09:54,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1887/2600 [26:58<10:36,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1888/2600 [26:59<11:23,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1889/2600 [27:01<12:06,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1890/2600 [27:01<10:54,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1891/2600 [27:02<11:36,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1892/2600 [27:03<11:15,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1893/2600 [27:04<10:49,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1894/2600 [27:06<12:25,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1895/2600 [27:06<11:07,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1896/2600 [27:07<10:44,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1897/2600 [27:08<10:56,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1898/2600 [27:09<10:57,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1899/2600 [27:10<10:50,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1900/2600 [27:11<09:59,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1901/2600 [27:12<11:00,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1902/2600 [27:12<10:07,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1903/2600 [27:13<10:00,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1904/2600 [27:14<09:54,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1905/2600 [27:15<10:21,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1906/2600 [27:16<10:30,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1907/2600 [27:17<09:45,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1908/2600 [27:18<09:41,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1909/2600 [27:19<10:37,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  73%|███████▎  | 1910/2600 [27:20<11:23,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▎  | 1911/2600 [27:21<12:47,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▎  | 1912/2600 [27:22<11:20,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▎  | 1913/2600 [27:23<11:41,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▎  | 1914/2600 [27:24<11:14,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▎  | 1915/2600 [27:25<11:13,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▎  | 1916/2600 [27:26<10:43,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▎  | 1917/2600 [27:26<09:22,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1918/2600 [27:27<09:25,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1919/2600 [27:28<08:27,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1920/2600 [27:29<08:56,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1921/2600 [27:29<08:36,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1922/2600 [27:30<08:22,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1923/2600 [27:31<09:34,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1924/2600 [27:32<09:06,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1925/2600 [27:33<08:46,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1926/2600 [27:33<08:59,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1927/2600 [27:34<09:06,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1928/2600 [27:35<08:02,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1929/2600 [27:35<07:58,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1930/2600 [27:36<08:23,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1931/2600 [27:37<08:40,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1932/2600 [27:38<08:21,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1933/2600 [27:38<08:09,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1934/2600 [27:39<08:19,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1935/2600 [27:40<09:24,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1936/2600 [27:41<09:21,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  74%|███████▍  | 1937/2600 [27:42<08:30,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1938/2600 [27:42<07:44,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1939/2600 [27:43<09:05,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1940/2600 [27:45<11:10,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1941/2600 [27:46<10:32,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1942/2600 [27:46<09:36,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1943/2600 [27:47<09:27,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1944/2600 [27:48<09:41,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1945/2600 [27:49<09:32,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1946/2600 [27:50<08:55,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1947/2600 [27:50<08:29,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1948/2600 [27:51<08:10,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▍  | 1949/2600 [27:52<07:57,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1950/2600 [27:53<08:27,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1951/2600 [27:53<08:09,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1952/2600 [27:54<08:23,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1953/2600 [27:55<08:05,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1954/2600 [27:56<08:24,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1955/2600 [27:56<08:06,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1956/2600 [27:57<07:25,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1957/2600 [27:58<07:27,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1958/2600 [27:59<07:56,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1959/2600 [27:59<07:46,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1960/2600 [28:00<07:10,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1961/2600 [28:01<07:43,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  75%|███████▌  | 1962/2600 [28:01<08:03,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1963/2600 [28:02<08:05,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1964/2600 [28:03<07:21,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1965/2600 [28:04<07:50,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1966/2600 [28:04<07:41,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1967/2600 [28:05<08:12,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1968/2600 [28:06<09:12,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1969/2600 [28:07<08:57,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1970/2600 [28:08<08:53,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1971/2600 [28:09<09:38,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1972/2600 [28:10<08:27,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1973/2600 [28:10<08:06,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1974/2600 [28:11<09:03,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1975/2600 [28:12<08:29,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1976/2600 [28:13<07:39,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1977/2600 [28:14<08:54,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1978/2600 [28:14<08:23,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1979/2600 [28:15<08:00,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1980/2600 [28:16<07:44,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1981/2600 [28:17<08:46,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▌  | 1982/2600 [28:18<09:01,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▋  | 1983/2600 [28:19<09:48,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▋  | 1984/2600 [28:20<09:28,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▋  | 1985/2600 [28:21<09:12,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▋  | 1986/2600 [28:21<08:36,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▋  | 1987/2600 [28:23<09:30,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▋  | 1988/2600 [28:23<09:13,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  76%|███████▋  | 1989/2600 [28:24<08:34,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1990/2600 [28:25<09:18,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1991/2600 [28:26<08:11,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1992/2600 [28:27<08:17,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1993/2600 [28:27<08:21,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1994/2600 [28:28<07:56,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1995/2600 [28:29<08:06,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1996/2600 [28:30<08:29,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1997/2600 [28:31<08:28,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1998/2600 [28:32<08:39,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 1999/2600 [28:32<08:35,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2000/2600 [28:33<08:10,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2001/2600 [28:34<08:32,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2002/2600 [28:35<08:03,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2003/2600 [28:36<08:26,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2004/2600 [28:37<08:25,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2005/2600 [28:37<07:32,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2006/2600 [28:38<07:21,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2007/2600 [28:38<06:45,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2008/2600 [28:39<06:11,  1.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2009/2600 [28:40<07:32,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2010/2600 [28:41<08:02,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2011/2600 [28:42<08:06,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2012/2600 [28:43<08:27,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2013/2600 [28:43<07:33,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  77%|███████▋  | 2014/2600 [28:44<07:43,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2015/2600 [28:45<08:38,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2016/2600 [28:46<08:03,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2017/2600 [28:47<07:40,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2018/2600 [28:47<07:22,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2019/2600 [28:48<07:43,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2020/2600 [28:49<07:49,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2021/2600 [28:50<09:25,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2022/2600 [28:51<09:00,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2023/2600 [28:52<08:43,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2024/2600 [28:53<10:04,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2025/2600 [28:55<10:27,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2026/2600 [28:56<10:38,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2027/2600 [28:57<10:02,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2028/2600 [28:57<09:01,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2029/2600 [28:59<09:24,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2030/2600 [28:59<08:58,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2031/2600 [29:00<09:28,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2032/2600 [29:01<08:35,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2033/2600 [29:02<09:14,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2034/2600 [29:03<08:59,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2035/2600 [29:04<08:47,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2036/2600 [29:05<08:29,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2037/2600 [29:06<07:52,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2038/2600 [29:06<07:50,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2039/2600 [29:07<07:25,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2040/2600 [29:08<07:59,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  78%|███████▊  | 2041/2600 [29:09<07:32,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▊  | 2042/2600 [29:10<07:39,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▊  | 2043/2600 [29:10<07:17,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▊  | 2044/2600 [29:11<07:02,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▊  | 2045/2600 [29:12<06:25,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▊  | 2046/2600 [29:12<06:24,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▊  | 2047/2600 [29:13<06:57,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2048/2600 [29:14<07:43,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2049/2600 [29:15<07:17,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2050/2600 [29:16<07:23,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2051/2600 [29:16<07:03,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2052/2600 [29:18<07:54,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2053/2600 [29:18<07:51,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2054/2600 [29:19<07:49,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2055/2600 [29:20<07:23,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2056/2600 [29:21<06:40,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2057/2600 [29:22<07:22,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2058/2600 [29:22<07:34,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2059/2600 [29:24<08:18,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2060/2600 [29:25<08:35,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2061/2600 [29:25<07:54,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2062/2600 [29:26<07:25,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2063/2600 [29:27<07:03,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2064/2600 [29:28<07:27,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2065/2600 [29:29<07:52,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  79%|███████▉  | 2066/2600 [29:29<07:44,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2067/2600 [29:30<07:39,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2068/2600 [29:31<06:48,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2069/2600 [29:32<07:39,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2070/2600 [29:33<07:44,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2071/2600 [29:34<08:17,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2072/2600 [29:35<08:00,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2073/2600 [29:36<07:48,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2074/2600 [29:36<06:53,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2075/2600 [29:37<07:55,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2076/2600 [29:38<07:21,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2077/2600 [29:39<07:20,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2078/2600 [29:40<08:06,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|███████▉  | 2079/2600 [29:41<07:29,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2080/2600 [29:42<07:25,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2081/2600 [29:42<06:58,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2082/2600 [29:43<07:02,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2083/2600 [29:44<07:54,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2084/2600 [29:45<07:19,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2085/2600 [29:46<06:53,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2086/2600 [29:47<07:46,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2087/2600 [29:48<07:56,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2088/2600 [29:48<06:57,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2089/2600 [29:49<07:46,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2090/2600 [29:50<07:13,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2091/2600 [29:51<07:11,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2092/2600 [29:52<07:54,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  80%|████████  | 2093/2600 [29:53<07:17,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2094/2600 [29:54<06:51,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2095/2600 [29:54<06:54,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2096/2600 [29:55<06:35,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2097/2600 [29:56<06:45,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2098/2600 [29:57<06:51,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2099/2600 [29:57<06:09,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2100/2600 [29:58<06:01,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2101/2600 [29:59<05:34,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2102/2600 [29:59<05:37,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2103/2600 [30:00<06:01,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2104/2600 [30:01<05:56,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2105/2600 [30:02<05:52,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2106/2600 [30:02<06:11,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2107/2600 [30:03<05:40,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2108/2600 [30:04<06:02,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2109/2600 [30:04<05:56,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2110/2600 [30:06<06:50,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2111/2600 [30:06<06:50,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████  | 2112/2600 [30:07<06:07,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████▏ | 2113/2600 [30:08<07:47,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████▏ | 2114/2600 [30:10<08:13,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████▏ | 2115/2600 [30:10<07:46,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████▏ | 2116/2600 [30:11<08:04,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████▏ | 2117/2600 [30:12<07:20,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  81%|████████▏ | 2118/2600 [30:13<06:50,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2119/2600 [30:14<06:26,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2120/2600 [30:14<06:30,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2121/2600 [30:15<06:33,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2122/2600 [30:16<06:12,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2123/2600 [30:17<06:21,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2124/2600 [30:18<07:09,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2125/2600 [30:19<07:00,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2126/2600 [30:19<06:34,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2127/2600 [30:20<06:58,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2128/2600 [30:22<08:16,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2129/2600 [30:23<07:25,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2130/2600 [30:23<07:10,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2131/2600 [30:24<07:06,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2132/2600 [30:25<06:15,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2133/2600 [30:26<07:02,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2134/2600 [30:27<06:31,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2135/2600 [30:28<06:59,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2136/2600 [30:29<07:23,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2137/2600 [30:30<07:08,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2138/2600 [30:31<06:55,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2139/2600 [30:31<06:56,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2140/2600 [30:32<06:28,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2141/2600 [30:33<05:47,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2142/2600 [30:33<05:39,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2143/2600 [30:35<06:28,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▏ | 2144/2600 [30:36<06:47,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  82%|████████▎ | 2145/2600 [30:36<06:33,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2146/2600 [30:37<06:03,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2147/2600 [30:38<05:49,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2148/2600 [30:38<05:38,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2149/2600 [30:39<05:31,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2150/2600 [30:40<05:52,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2151/2600 [30:41<06:00,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2152/2600 [30:42<06:06,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2153/2600 [30:43<06:22,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2154/2600 [30:44<07:36,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2155/2600 [30:45<07:12,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2156/2600 [30:46<06:34,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2157/2600 [30:46<05:46,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2158/2600 [30:47<06:31,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2159/2600 [30:48<06:36,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2160/2600 [30:49<06:09,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2161/2600 [30:50<05:50,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2162/2600 [30:50<05:55,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2163/2600 [30:51<06:05,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2164/2600 [30:53<07:10,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2165/2600 [30:54<06:57,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2166/2600 [30:55<07:13,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2167/2600 [30:56<07:04,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2168/2600 [30:57<07:57,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2169/2600 [30:58<07:24,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  83%|████████▎ | 2170/2600 [30:59<06:40,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▎ | 2171/2600 [31:00<07:06,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▎ | 2172/2600 [31:01<06:47,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▎ | 2173/2600 [31:01<06:32,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▎ | 2174/2600 [31:02<06:46,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▎ | 2175/2600 [31:03<06:44,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▎ | 2176/2600 [31:05<07:21,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▎ | 2177/2600 [31:05<06:37,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2178/2600 [31:06<06:06,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2179/2600 [31:07<06:38,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2180/2600 [31:08<06:06,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2181/2600 [31:09<05:43,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2182/2600 [31:10<06:25,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2183/2600 [31:10<05:49,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2184/2600 [31:11<05:43,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2185/2600 [31:12<05:27,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2186/2600 [31:13<05:15,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2187/2600 [31:14<05:49,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2188/2600 [31:14<05:11,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2189/2600 [31:15<05:21,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2190/2600 [31:16<06:02,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2191/2600 [31:17<05:37,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2192/2600 [31:18<05:45,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2193/2600 [31:19<06:37,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2194/2600 [31:20<06:22,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2195/2600 [31:21<05:53,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2196/2600 [31:21<05:33,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  84%|████████▍ | 2197/2600 [31:22<05:16,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2198/2600 [31:23<05:05,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2199/2600 [31:23<04:57,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2200/2600 [31:24<05:08,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2201/2600 [31:25<04:58,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2202/2600 [31:26<04:52,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2203/2600 [31:26<05:10,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2204/2600 [31:27<05:35,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2205/2600 [31:28<05:34,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2206/2600 [31:29<05:33,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2207/2600 [31:30<04:58,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2208/2600 [31:30<04:33,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▍ | 2209/2600 [31:31<05:20,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2210/2600 [31:32<05:06,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2211/2600 [31:33<04:56,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2212/2600 [31:33<04:47,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2213/2600 [31:34<04:41,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2214/2600 [31:35<04:37,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2215/2600 [31:36<04:33,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2216/2600 [31:36<04:31,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2217/2600 [31:37<04:47,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2218/2600 [31:38<04:57,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2219/2600 [31:39<05:05,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2220/2600 [31:40<05:15,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2221/2600 [31:41<05:49,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  85%|████████▌ | 2222/2600 [31:42<05:38,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2223/2600 [31:42<05:15,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2224/2600 [31:43<05:28,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2225/2600 [31:44<05:25,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2226/2600 [31:45<05:24,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2227/2600 [31:46<05:22,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2228/2600 [31:47<05:03,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2229/2600 [31:47<04:48,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2230/2600 [31:48<04:38,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2231/2600 [31:49<04:58,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2232/2600 [31:50<05:06,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2233/2600 [31:51<05:11,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2234/2600 [31:52<05:36,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2235/2600 [31:53<05:27,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2236/2600 [31:53<04:59,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2237/2600 [31:54<05:16,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2238/2600 [31:55<04:56,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2239/2600 [31:56<05:11,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2240/2600 [31:57<04:51,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2241/2600 [31:58<05:02,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▌ | 2242/2600 [31:58<04:30,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▋ | 2243/2600 [31:59<04:39,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▋ | 2244/2600 [32:00<04:50,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▋ | 2245/2600 [32:01<05:34,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▋ | 2246/2600 [32:02<05:28,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▋ | 2247/2600 [32:03<05:18,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▋ | 2248/2600 [32:03<04:51,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  86%|████████▋ | 2249/2600 [32:04<04:51,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2250/2600 [32:05<04:36,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2251/2600 [32:06<05:12,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2252/2600 [32:07<04:35,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2253/2600 [32:07<04:26,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2254/2600 [32:08<04:39,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2255/2600 [32:09<04:43,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2256/2600 [32:10<04:13,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2257/2600 [32:10<04:08,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2258/2600 [32:11<04:30,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2259/2600 [32:12<04:35,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2260/2600 [32:14<05:35,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2261/2600 [32:14<05:04,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2262/2600 [32:15<04:43,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2263/2600 [32:16<04:28,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2264/2600 [32:16<04:12,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2265/2600 [32:17<04:21,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2266/2600 [32:18<04:52,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2267/2600 [32:19<04:59,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2268/2600 [32:20<04:39,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2269/2600 [32:21<04:49,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2270/2600 [32:22<04:31,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2271/2600 [32:22<04:18,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2272/2600 [32:23<04:33,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2273/2600 [32:24<04:34,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  87%|████████▋ | 2274/2600 [32:25<04:37,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2275/2600 [32:26<04:21,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2276/2600 [32:26<04:10,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2277/2600 [32:27<04:25,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2278/2600 [32:28<04:31,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2279/2600 [32:29<04:44,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2280/2600 [32:30<04:11,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2281/2600 [32:30<04:01,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2282/2600 [32:31<03:53,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2283/2600 [32:32<04:07,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2284/2600 [32:33<04:12,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2285/2600 [32:34<04:01,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2286/2600 [32:34<04:08,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2287/2600 [32:35<03:58,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2288/2600 [32:36<04:04,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2289/2600 [32:37<04:37,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2290/2600 [32:38<04:31,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2291/2600 [32:39<04:27,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2292/2600 [32:40<04:51,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2293/2600 [32:41<05:08,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2294/2600 [32:42<04:53,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2295/2600 [32:43<04:41,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2296/2600 [32:44<04:57,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2297/2600 [32:45<04:58,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2298/2600 [32:45<04:18,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2299/2600 [32:46<03:49,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2300/2600 [32:47<03:56,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  88%|████████▊ | 2301/2600 [32:48<04:09,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▊ | 2302/2600 [32:48<03:56,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▊ | 2303/2600 [32:49<03:59,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▊ | 2304/2600 [32:50<03:48,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▊ | 2305/2600 [32:51<03:54,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▊ | 2306/2600 [32:52<04:01,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▊ | 2307/2600 [32:52<04:03,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2308/2600 [32:53<03:37,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2309/2600 [32:54<03:31,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2310/2600 [32:55<03:40,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2311/2600 [32:55<03:46,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2312/2600 [32:57<04:13,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2313/2600 [32:57<03:40,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2314/2600 [32:58<03:45,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2315/2600 [32:59<03:48,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2316/2600 [32:59<03:26,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2317/2600 [33:00<03:10,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2318/2600 [33:01<04:09,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2319/2600 [33:02<03:52,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2320/2600 [33:03<04:17,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2321/2600 [33:04<03:58,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2322/2600 [33:04<03:43,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2323/2600 [33:05<03:49,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2324/2600 [33:06<04:09,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2325/2600 [33:07<03:51,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  89%|████████▉ | 2326/2600 [33:08<03:38,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2327/2600 [33:08<03:17,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2328/2600 [33:09<03:27,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2329/2600 [33:10<03:21,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2330/2600 [33:11<03:49,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2331/2600 [33:12<03:36,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2332/2600 [33:13<04:02,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2333/2600 [33:14<04:03,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2334/2600 [33:14<03:45,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2335/2600 [33:15<03:48,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2336/2600 [33:16<03:22,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2337/2600 [33:17<03:16,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2338/2600 [33:17<03:19,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|████████▉ | 2339/2600 [33:18<03:14,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2340/2600 [33:19<03:09,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2341/2600 [33:19<03:06,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2342/2600 [33:21<03:35,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2343/2600 [33:21<03:12,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2344/2600 [33:22<03:18,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2345/2600 [33:23<03:11,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2346/2600 [33:23<03:06,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2347/2600 [33:24<03:21,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2348/2600 [33:25<03:43,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2349/2600 [33:26<03:57,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2350/2600 [33:27<03:59,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2351/2600 [33:28<03:57,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2352/2600 [33:30<04:28,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  90%|█████████ | 2353/2600 [33:30<03:57,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2354/2600 [33:32<04:06,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2355/2600 [33:32<03:53,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2356/2600 [33:33<03:33,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2357/2600 [33:34<03:48,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2358/2600 [33:35<03:30,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2359/2600 [33:36<03:16,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2360/2600 [33:37<03:43,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2361/2600 [33:38<04:15,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2362/2600 [33:39<03:47,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2363/2600 [33:40<03:59,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2364/2600 [33:41<03:53,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2365/2600 [33:42<03:50,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2366/2600 [33:43<04:00,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2367/2600 [33:44<03:57,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2368/2600 [33:45<03:33,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2369/2600 [33:45<03:18,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2370/2600 [33:46<03:07,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2371/2600 [33:47<02:58,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████ | 2372/2600 [33:48<03:18,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████▏| 2373/2600 [33:49<03:16,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████▏| 2374/2600 [33:50<03:13,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████▏| 2375/2600 [33:50<03:01,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████▏| 2376/2600 [33:51<03:03,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████▏| 2377/2600 [33:52<03:26,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  91%|█████████▏| 2378/2600 [33:53<03:20,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2379/2600 [33:54<03:31,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2380/2600 [33:56<03:53,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2381/2600 [33:57<03:50,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2382/2600 [33:58<04:12,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2383/2600 [33:59<03:40,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2384/2600 [34:00<03:37,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2385/2600 [34:00<03:06,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2386/2600 [34:01<03:26,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2387/2600 [34:02<03:10,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2388/2600 [34:03<02:56,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2389/2600 [34:04<03:15,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2390/2600 [34:05<03:00,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2391/2600 [34:06<03:04,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2392/2600 [34:06<03:04,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2393/2600 [34:07<02:42,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2394/2600 [34:08<02:36,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2395/2600 [34:09<02:47,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2396/2600 [34:10<03:06,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2397/2600 [34:11<02:51,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2398/2600 [34:12<02:59,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2399/2600 [34:12<02:46,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2400/2600 [34:13<02:52,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2401/2600 [34:14<02:42,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2402/2600 [34:15<02:34,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2403/2600 [34:16<02:51,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▏| 2404/2600 [34:16<02:41,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  92%|█████████▎| 2405/2600 [34:17<02:32,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2406/2600 [34:18<02:38,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2407/2600 [34:18<02:21,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2408/2600 [34:19<02:36,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2409/2600 [34:20<02:29,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2410/2600 [34:21<02:32,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2411/2600 [34:22<02:33,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2412/2600 [34:23<02:34,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2413/2600 [34:23<02:23,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2414/2600 [34:24<02:26,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2415/2600 [34:25<02:30,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2416/2600 [34:26<02:31,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2417/2600 [34:27<02:33,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2418/2600 [34:28<02:32,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2419/2600 [34:28<02:24,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2420/2600 [34:29<02:25,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2421/2600 [34:30<02:26,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2422/2600 [34:31<02:56,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2423/2600 [34:32<02:39,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2424/2600 [34:33<02:35,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2425/2600 [34:34<02:32,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2426/2600 [34:34<02:14,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2427/2600 [34:35<02:10,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2428/2600 [34:36<02:06,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2429/2600 [34:37<02:38,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  93%|█████████▎| 2430/2600 [34:38<02:33,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▎| 2431/2600 [34:39<02:21,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▎| 2432/2600 [34:39<02:13,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▎| 2433/2600 [34:40<02:15,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▎| 2434/2600 [34:41<02:30,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▎| 2435/2600 [34:42<02:36,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▎| 2436/2600 [34:43<02:23,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▎| 2437/2600 [34:44<02:22,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2438/2600 [34:45<02:20,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2439/2600 [34:46<02:25,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2440/2600 [34:47<02:21,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2441/2600 [34:47<02:04,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2442/2600 [34:48<02:20,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2443/2600 [34:49<02:18,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2444/2600 [34:50<02:22,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2445/2600 [34:51<02:17,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2446/2600 [34:52<02:18,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2447/2600 [34:53<02:22,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2448/2600 [34:54<02:28,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2449/2600 [34:55<02:32,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2450/2600 [34:56<02:37,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2451/2600 [34:57<02:30,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2452/2600 [34:58<02:15,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2453/2600 [34:59<02:05,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2454/2600 [34:59<02:03,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2455/2600 [35:00<02:05,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2456/2600 [35:01<01:50,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  94%|█████████▍| 2457/2600 [35:02<02:15,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2458/2600 [35:03<02:09,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2459/2600 [35:04<02:09,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2460/2600 [35:05<02:05,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2461/2600 [35:06<02:08,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2462/2600 [35:07<02:04,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2463/2600 [35:07<02:01,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2464/2600 [35:08<01:58,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2465/2600 [35:09<02:09,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2466/2600 [35:10<02:04,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2467/2600 [35:11<02:00,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2468/2600 [35:12<01:51,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▍| 2469/2600 [35:13<01:56,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2470/2600 [35:14<01:53,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2471/2600 [35:15<01:53,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2472/2600 [35:15<01:45,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2473/2600 [35:16<01:39,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2474/2600 [35:17<01:35,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2475/2600 [35:18<01:37,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2476/2600 [35:18<01:34,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2477/2600 [35:19<01:31,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2478/2600 [35:20<01:54,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2479/2600 [35:21<02:00,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2480/2600 [35:22<01:54,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2481/2600 [35:23<01:44,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  95%|█████████▌| 2482/2600 [35:24<01:31,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2483/2600 [35:24<01:27,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2484/2600 [35:25<01:20,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2485/2600 [35:26<01:24,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2486/2600 [35:26<01:22,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2487/2600 [35:27<01:25,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2488/2600 [35:28<01:22,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2489/2600 [35:28<01:15,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2490/2600 [35:29<01:20,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2491/2600 [35:30<01:24,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2492/2600 [35:31<01:21,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2493/2600 [35:32<01:33,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2494/2600 [35:33<01:31,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2495/2600 [35:34<01:30,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2496/2600 [35:35<01:42,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2497/2600 [35:36<01:37,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2498/2600 [35:37<01:37,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2499/2600 [35:38<01:45,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2500/2600 [35:39<01:45,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2501/2600 [35:40<01:33,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▌| 2502/2600 [35:41<01:31,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▋| 2503/2600 [35:41<01:23,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▋| 2504/2600 [35:42<01:17,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▋| 2505/2600 [35:43<01:08,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▋| 2506/2600 [35:43<01:06,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▋| 2507/2600 [35:44<01:05,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▋| 2508/2600 [35:45<01:09,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  96%|█████████▋| 2509/2600 [35:46<01:14,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2510/2600 [35:47<01:17,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2511/2600 [35:48<01:12,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2512/2600 [35:48<01:12,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2513/2600 [35:50<01:26,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2514/2600 [35:51<01:36,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2515/2600 [35:52<01:35,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2516/2600 [35:53<01:23,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2517/2600 [35:54<01:15,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2518/2600 [35:55<01:25,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2519/2600 [35:56<01:27,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2520/2600 [35:57<01:17,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2521/2600 [35:58<01:10,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2522/2600 [35:59<01:08,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2523/2600 [35:59<01:06,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2524/2600 [36:01<01:17,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2525/2600 [36:02<01:20,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2526/2600 [36:03<01:10,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2527/2600 [36:03<01:04,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2528/2600 [36:04<01:09,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2529/2600 [36:06<01:11,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2530/2600 [36:06<01:03,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2531/2600 [36:07<00:58,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2532/2600 [36:08<00:57,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2533/2600 [36:08<00:53,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  97%|█████████▋| 2534/2600 [36:10<00:58,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2535/2600 [36:10<00:53,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2536/2600 [36:11<00:54,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2537/2600 [36:12<00:50,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2538/2600 [36:13<00:50,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2539/2600 [36:13<00:47,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2540/2600 [36:14<00:45,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2541/2600 [36:15<00:51,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2542/2600 [36:16<00:55,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2543/2600 [36:17<00:52,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2544/2600 [36:18<00:52,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2545/2600 [36:19<00:47,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2546/2600 [36:19<00:41,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2547/2600 [36:21<00:47,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2548/2600 [36:22<00:46,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2549/2600 [36:22<00:40,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2550/2600 [36:23<00:38,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2551/2600 [36:24<00:40,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2552/2600 [36:25<00:41,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2553/2600 [36:26<00:43,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2554/2600 [36:26<00:37,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2555/2600 [36:27<00:34,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2556/2600 [36:28<00:35,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2557/2600 [36:29<00:33,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2558/2600 [36:30<00:36,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2559/2600 [36:30<00:33,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2560/2600 [36:31<00:30,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  98%|█████████▊| 2561/2600 [36:32<00:37,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▊| 2562/2600 [36:33<00:33,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▊| 2563/2600 [36:34<00:32,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▊| 2564/2600 [36:35<00:29,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▊| 2565/2600 [36:35<00:28,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▊| 2566/2600 [36:36<00:29,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▊| 2567/2600 [36:37<00:28,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2568/2600 [36:38<00:26,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2569/2600 [36:39<00:28,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2570/2600 [36:40<00:26,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2571/2600 [36:41<00:25,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2572/2600 [36:41<00:21,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2573/2600 [36:42<00:19,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2574/2600 [36:43<00:24,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2575/2600 [36:44<00:20,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2576/2600 [36:45<00:17,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2577/2600 [36:46<00:18,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2578/2600 [36:46<00:18,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2579/2600 [36:47<00:17,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2580/2600 [36:48<00:15,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2581/2600 [36:49<00:16,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2582/2600 [36:50<00:14,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2583/2600 [36:50<00:13,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2584/2600 [36:51<00:12,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2585/2600 [36:52<00:12,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples):  99%|█████████▉| 2586/2600 [36:53<00:11,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2587/2600 [36:54<00:11,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2588/2600 [36:55<00:11,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2589/2600 [36:56<00:10,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2590/2600 [36:57<00:09,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2591/2600 [36:58<00:08,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2592/2600 [36:58<00:06,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2593/2600 [36:59<00:05,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2594/2600 [37:00<00:04,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2595/2600 [37:01<00:04,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2596/2600 [37:02<00:03,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2597/2600 [37:03<00:02,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2598/2600 [37:03<00:01,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|█████████▉| 2599/2600 [37:04<00:00,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (4100 samples): 100%|██████████| 2600/2600 [37:05<00:00,  1.17it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e5ff7726df4bf59077b4de1dc2d63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec6d84333c1448ebd1fd023c756eccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed89247e5968450da878dbfd1bfa638c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865b90ef39284cf69c4f9974de2c7cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee4052dfc134a5db2f12d758eb6a51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ab1a810d5a4dd1b2d0c3b5c4d5716e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 9 Results on 4100 samples:\n",
      "BLEU: 0.0198\n",
      "ROUGE-1: 0.1434\n",
      "ROUGE-2: 0.0277\n",
      "ROUGE-L: 0.1103\n",
      "BERTScore (F1): 0.8406\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load evaluation dataset\n",
    "eval_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_cleaned.jsonl\",\n",
    "    split=\"train[:1000]\"\n",
    ")\n",
    "\n",
    "# Load the PEFT config + base model\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/counsel-trial1\"\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "\n",
    "# Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "# Load LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_model, model_path, local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, local_files_only=True)\n",
    "\n",
    "# Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Inference loop\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"🔍 Evaluating Trial 1\"):\n",
    "    prompt = f\"<s>[INST] You are a professional mental health assistant providing thoughtful, multi-step advice to help users with anxiety, stress, and emotional struggles.\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "# Evaluation\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Print results\n",
    "print(\"\\n📊 Trial 1 Evaluation Results (1000 samples):\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A82PWreDNoHG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAK4oSq6W65B"
   },
   "source": [
    "# Trial 9 Evaluation on 1000-Sample Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2168bdc7826445868ad188ac50c9168d",
      "fa1acb7c516a40e684720537a1f84622",
      "408222e3a05b4adfa3c9fdc86db07f7b",
      "36eb59ddd54f421592e4f9fa48dbec52",
      "c7437f2cb28e44e6b58e998f3aac0dd8",
      "420f1682d1d74f03874d1e706c362b95",
      "5c25b56d267d4b07bc25de7a544158b5",
      "4bfff76d5a014ca8a372ea68cf25e8bb",
      "e44cf2a5cd4b4b55bfa38caa3fe20073",
      "8eb244807f8f4788965541bb59541323",
      "b8217013a8e243e2a263db08f4e0cb9b",
      "0234b012cbb1480691c9591be2a974e0",
      "3166143f79b2450e9a120c3dd7ce5fba",
      "59bf87eff6be4176a9bd140c25018218",
      "f404fa9ab8bc4e81bf9ac7741a83310b",
      "b2b4475e1209435e81d0d9de2b6b84df",
      "990dd826211d478bb1c555c49270a50e",
      "ebc79ad1814d4b499089596fdd53c579",
      "2a96f3ea60994728a206b95f42db9440",
      "0ccbd181c688426588e6fb6f4535f078",
      "60831de2af0b4b58b30cfddcff0c9006",
      "a14f90ead72f4941875d8ee5423ddb27"
     ]
    },
    "executionInfo": {
     "elapsed": 422277,
     "status": "ok",
     "timestamp": 1744316842152,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "No7zSzeBW8IN",
    "outputId": "a1543c23-420f-4fd1-d086-b3e7b59b4f1d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2168bdc7826445868ad188ac50c9168d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0234b012cbb1480691c9591be2a974e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🔍 Evaluating Trial 9 (1000 samples):   0%|          | 0/500 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   0%|          | 1/500 [00:01<10:42,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   0%|          | 2/500 [00:02<09:30,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   1%|          | 3/500 [00:03<08:21,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   1%|          | 4/500 [00:04<08:37,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   1%|          | 5/500 [00:04<07:34,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   1%|          | 6/500 [00:05<07:39,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   1%|▏         | 7/500 [00:07<08:05,  1.02it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   2%|▏         | 8/500 [00:07<07:19,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   2%|▏         | 9/500 [00:08<07:11,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   2%|▏         | 10/500 [00:09<06:42,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   2%|▏         | 11/500 [00:09<06:25,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   2%|▏         | 12/500 [00:10<05:56,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   3%|▎         | 13/500 [00:11<05:50,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   3%|▎         | 14/500 [00:12<06:21,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   3%|▎         | 15/500 [00:13<06:43,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   3%|▎         | 16/500 [00:13<06:42,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   3%|▎         | 17/500 [00:14<07:04,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   4%|▎         | 18/500 [00:15<07:19,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   4%|▍         | 19/500 [00:17<07:45,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   4%|▍         | 20/500 [00:17<07:06,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   4%|▍         | 21/500 [00:18<06:37,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   4%|▍         | 22/500 [00:19<06:37,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   5%|▍         | 23/500 [00:19<06:18,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   5%|▍         | 24/500 [00:20<05:44,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   5%|▌         | 25/500 [00:21<06:20,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   5%|▌         | 26/500 [00:22<06:44,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   5%|▌         | 27/500 [00:23<06:39,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   6%|▌         | 28/500 [00:24<06:49,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   6%|▌         | 29/500 [00:24<06:22,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   6%|▌         | 30/500 [00:25<06:03,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   6%|▌         | 31/500 [00:26<05:50,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   6%|▋         | 32/500 [00:26<05:20,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   7%|▋         | 33/500 [00:27<06:05,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   7%|▋         | 34/500 [00:28<05:51,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   7%|▋         | 35/500 [00:29<06:47,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   7%|▋         | 36/500 [00:30<05:59,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   7%|▋         | 37/500 [00:31<06:32,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   8%|▊         | 38/500 [00:31<06:08,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   8%|▊         | 39/500 [00:32<05:51,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   8%|▊         | 40/500 [00:33<06:25,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   8%|▊         | 41/500 [00:34<06:43,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   8%|▊         | 42/500 [00:35<05:55,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   9%|▊         | 43/500 [00:35<05:21,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   9%|▉         | 44/500 [00:36<06:04,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   9%|▉         | 45/500 [00:37<06:20,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   9%|▉         | 46/500 [00:38<05:39,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):   9%|▉         | 47/500 [00:38<05:30,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  10%|▉         | 48/500 [00:39<05:03,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  10%|▉         | 49/500 [00:40<05:06,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  10%|█         | 50/500 [00:40<05:25,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  10%|█         | 51/500 [00:41<05:18,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  10%|█         | 52/500 [00:42<05:35,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  11%|█         | 53/500 [00:42<05:05,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  11%|█         | 54/500 [00:43<05:03,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  11%|█         | 55/500 [00:44<05:21,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  11%|█         | 56/500 [00:45<05:34,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  11%|█▏        | 57/500 [00:46<05:43,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  12%|█▏        | 58/500 [00:46<05:49,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  12%|█▏        | 59/500 [00:47<05:33,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  12%|█▏        | 60/500 [00:48<05:23,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  12%|█▏        | 61/500 [00:48<05:16,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  12%|█▏        | 62/500 [00:49<05:42,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  13%|█▎        | 63/500 [00:50<05:28,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  13%|█▎        | 64/500 [00:51<05:18,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  13%|█▎        | 65/500 [00:51<05:11,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  13%|█▎        | 66/500 [00:52<05:09,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  13%|█▎        | 67/500 [00:53<05:39,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  14%|█▎        | 68/500 [00:54<05:30,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  14%|█▍        | 69/500 [00:55<05:37,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  14%|█▍        | 70/500 [00:55<05:23,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  14%|█▍        | 71/500 [00:56<05:13,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  14%|█▍        | 72/500 [00:57<05:06,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  15%|█▍        | 73/500 [00:57<05:01,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  15%|█▍        | 74/500 [00:58<05:15,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  15%|█▌        | 75/500 [00:59<05:07,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  15%|█▌        | 76/500 [01:00<05:38,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  15%|█▌        | 77/500 [01:00<05:04,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  16%|█▌        | 78/500 [01:02<06:24,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  16%|█▌        | 79/500 [01:02<05:42,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  16%|█▌        | 80/500 [01:03<05:56,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  16%|█▌        | 81/500 [01:04<05:36,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  16%|█▋        | 82/500 [01:05<05:21,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  17%|█▋        | 83/500 [01:05<05:11,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  17%|█▋        | 84/500 [01:06<05:39,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  17%|█▋        | 85/500 [01:07<05:04,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  17%|█▋        | 86/500 [01:08<04:57,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  17%|█▋        | 87/500 [01:08<04:33,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  18%|█▊        | 88/500 [01:09<05:49,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  18%|█▊        | 89/500 [01:10<05:59,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  18%|█▊        | 90/500 [01:11<05:53,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  18%|█▊        | 91/500 [01:12<05:15,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  18%|█▊        | 92/500 [01:12<04:46,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  19%|█▊        | 93/500 [01:13<05:13,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  19%|█▉        | 94/500 [01:14<05:01,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  19%|█▉        | 95/500 [01:15<04:53,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  19%|█▉        | 96/500 [01:16<05:52,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  19%|█▉        | 97/500 [01:16<05:22,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  20%|█▉        | 98/500 [01:17<04:51,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  20%|█▉        | 99/500 [01:18<05:49,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  20%|██        | 100/500 [01:19<05:26,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  20%|██        | 101/500 [01:20<05:10,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  20%|██        | 102/500 [01:20<04:58,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  21%|██        | 103/500 [01:21<04:50,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  21%|██        | 104/500 [01:22<05:13,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  21%|██        | 105/500 [01:22<04:42,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  21%|██        | 106/500 [01:23<05:12,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  21%|██▏       | 107/500 [01:24<05:48,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  22%|██▏       | 108/500 [01:25<05:23,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  22%|██▏       | 109/500 [01:26<05:05,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  22%|██▏       | 110/500 [01:27<05:54,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  22%|██▏       | 111/500 [01:28<05:27,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  22%|██▏       | 112/500 [01:29<05:53,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  23%|██▎       | 113/500 [01:29<05:26,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  23%|██▎       | 114/500 [01:30<05:07,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  23%|██▎       | 115/500 [01:31<04:54,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  23%|██▎       | 116/500 [01:32<05:01,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  23%|██▎       | 117/500 [01:32<04:32,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  24%|██▎       | 118/500 [01:33<04:28,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  24%|██▍       | 119/500 [01:34<04:42,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  24%|██▍       | 120/500 [01:34<04:35,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  24%|██▍       | 121/500 [01:35<04:30,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  24%|██▍       | 122/500 [01:36<05:15,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  25%|██▍       | 123/500 [01:37<04:56,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  25%|██▍       | 124/500 [01:38<04:44,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  25%|██▌       | 125/500 [01:38<04:19,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  25%|██▌       | 126/500 [01:39<04:18,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  25%|██▌       | 127/500 [01:40<04:34,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  26%|██▌       | 128/500 [01:41<05:13,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  26%|██▌       | 129/500 [01:41<04:56,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  26%|██▌       | 130/500 [01:42<04:41,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  26%|██▌       | 131/500 [01:43<04:48,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  26%|██▋       | 132/500 [01:44<04:37,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  27%|██▋       | 133/500 [01:44<04:29,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  27%|██▋       | 134/500 [01:45<04:55,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  27%|██▋       | 135/500 [01:46<04:58,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  27%|██▋       | 136/500 [01:47<04:42,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  27%|██▋       | 137/500 [01:48<05:13,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  28%|██▊       | 138/500 [01:49<04:48,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  28%|██▊       | 139/500 [01:49<04:35,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  28%|██▊       | 140/500 [01:50<05:01,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  28%|██▊       | 141/500 [01:51<04:44,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  28%|██▊       | 142/500 [01:52<05:14,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  29%|██▊       | 143/500 [01:53<04:54,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  29%|██▉       | 144/500 [01:53<04:39,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  29%|██▉       | 145/500 [01:54<04:29,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  29%|██▉       | 146/500 [01:55<04:46,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  29%|██▉       | 147/500 [01:56<04:32,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  30%|██▉       | 148/500 [01:56<04:22,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  30%|██▉       | 149/500 [01:57<04:14,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  30%|███       | 150/500 [01:58<04:09,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  30%|███       | 151/500 [01:58<04:06,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  30%|███       | 152/500 [01:59<04:29,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  31%|███       | 153/500 [02:00<04:50,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  31%|███       | 154/500 [02:01<04:33,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  31%|███       | 155/500 [02:02<04:45,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  31%|███       | 156/500 [02:03<05:00,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  31%|███▏      | 157/500 [02:04<05:21,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  32%|███▏      | 158/500 [02:05<04:54,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  32%|███▏      | 159/500 [02:06<04:56,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  32%|███▏      | 160/500 [02:06<04:52,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  32%|███▏      | 161/500 [02:07<04:34,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  32%|███▏      | 162/500 [02:08<04:20,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  33%|███▎      | 163/500 [02:09<04:25,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  33%|███▎      | 164/500 [02:09<04:13,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  33%|███▎      | 165/500 [02:10<04:30,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  33%|███▎      | 166/500 [02:11<04:36,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  33%|███▎      | 167/500 [02:12<05:00,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  34%|███▎      | 168/500 [02:14<05:51,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  34%|███▍      | 169/500 [02:14<05:12,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  34%|███▍      | 170/500 [02:15<04:44,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  34%|███▍      | 171/500 [02:15<04:11,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  34%|███▍      | 172/500 [02:17<04:57,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  35%|███▍      | 173/500 [02:17<04:36,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  35%|███▍      | 174/500 [02:18<04:19,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  35%|███▌      | 175/500 [02:19<04:35,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  35%|███▌      | 176/500 [02:20<04:42,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  35%|███▌      | 177/500 [02:21<04:46,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  36%|███▌      | 178/500 [02:22<04:49,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  36%|███▌      | 179/500 [02:23<04:28,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  36%|███▌      | 180/500 [02:24<04:41,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  36%|███▌      | 181/500 [02:24<04:45,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  36%|███▋      | 182/500 [02:25<04:24,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  37%|███▋      | 183/500 [02:26<04:09,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  37%|███▋      | 184/500 [02:27<03:59,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  37%|███▋      | 185/500 [02:27<03:51,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  37%|███▋      | 186/500 [02:28<03:47,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  37%|███▋      | 187/500 [02:29<04:05,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  38%|███▊      | 188/500 [02:30<04:23,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  38%|███▊      | 189/500 [02:31<04:44,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  38%|███▊      | 190/500 [02:31<04:08,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  38%|███▊      | 191/500 [02:32<03:57,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  38%|███▊      | 192/500 [02:33<04:11,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  39%|███▊      | 193/500 [02:34<03:58,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  39%|███▉      | 194/500 [02:35<04:20,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  39%|███▉      | 195/500 [02:35<04:04,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  39%|███▉      | 196/500 [02:36<03:53,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  39%|███▉      | 197/500 [02:37<04:12,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  40%|███▉      | 198/500 [02:38<03:58,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  40%|███▉      | 199/500 [02:38<03:48,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  40%|████      | 200/500 [02:39<03:40,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  40%|████      | 201/500 [02:40<03:36,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  40%|████      | 202/500 [02:41<03:45,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  41%|████      | 203/500 [02:41<03:40,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  41%|████      | 204/500 [02:42<04:05,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  41%|████      | 205/500 [02:43<04:13,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  41%|████      | 206/500 [02:44<04:14,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  41%|████▏     | 207/500 [02:45<03:45,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  42%|████▏     | 208/500 [02:45<03:25,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  42%|████▏     | 209/500 [02:46<03:44,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  42%|████▏     | 210/500 [02:47<03:36,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  42%|████▏     | 211/500 [02:48<03:56,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  42%|████▏     | 212/500 [02:49<03:56,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  43%|████▎     | 213/500 [02:49<03:44,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  43%|████▎     | 214/500 [02:50<03:56,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  43%|████▎     | 215/500 [02:51<04:12,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  43%|████▎     | 216/500 [02:52<04:28,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  43%|████▎     | 217/500 [02:53<04:06,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  44%|████▎     | 218/500 [02:54<03:50,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  44%|████▍     | 219/500 [02:55<03:39,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  44%|████▍     | 220/500 [02:56<03:59,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  44%|████▍     | 221/500 [02:57<04:04,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  44%|████▍     | 222/500 [02:57<04:08,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  45%|████▍     | 223/500 [02:58<03:52,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  45%|████▍     | 224/500 [02:59<03:38,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  45%|████▌     | 225/500 [03:00<03:29,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  45%|████▌     | 226/500 [03:01<03:50,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  45%|████▌     | 227/500 [03:01<03:48,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  46%|████▌     | 228/500 [03:02<03:55,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  46%|████▌     | 229/500 [03:03<03:40,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  46%|████▌     | 230/500 [03:04<03:18,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  46%|████▌     | 231/500 [03:05<03:38,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  46%|████▋     | 232/500 [03:05<03:39,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  47%|████▋     | 233/500 [03:06<03:28,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  47%|████▋     | 234/500 [03:07<03:19,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  47%|████▋     | 235/500 [03:07<03:13,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  47%|████▋     | 236/500 [03:09<03:41,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  47%|████▋     | 237/500 [03:09<03:28,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  48%|████▊     | 238/500 [03:10<03:19,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  48%|████▊     | 239/500 [03:11<03:13,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  48%|████▊     | 240/500 [03:11<03:08,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  48%|████▊     | 241/500 [03:12<03:04,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  48%|████▊     | 242/500 [03:13<03:14,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  49%|████▊     | 243/500 [03:14<03:08,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  49%|████▉     | 244/500 [03:14<03:04,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  49%|████▉     | 245/500 [03:15<03:19,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  49%|████▉     | 246/500 [03:16<03:11,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  49%|████▉     | 247/500 [03:17<03:24,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  50%|████▉     | 248/500 [03:18<03:26,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  50%|████▉     | 249/500 [03:18<03:15,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  50%|█████     | 250/500 [03:19<03:06,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  50%|█████     | 251/500 [03:20<03:00,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  50%|█████     | 252/500 [03:20<03:07,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  51%|█████     | 253/500 [03:21<03:22,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  51%|█████     | 254/500 [03:22<03:36,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  51%|█████     | 255/500 [03:24<03:50,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  51%|█████     | 256/500 [03:25<03:52,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  51%|█████▏    | 257/500 [03:25<03:31,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  52%|█████▏    | 258/500 [03:26<03:17,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  52%|█████▏    | 259/500 [03:27<03:47,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  52%|█████▏    | 260/500 [03:28<03:28,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  52%|█████▏    | 261/500 [03:29<03:15,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  52%|█████▏    | 262/500 [03:29<03:25,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  53%|█████▎    | 263/500 [03:30<03:21,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  53%|█████▎    | 264/500 [03:31<03:28,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  53%|█████▎    | 265/500 [03:32<03:13,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  53%|█████▎    | 266/500 [03:33<03:03,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  53%|█████▎    | 267/500 [03:34<03:09,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  54%|█████▎    | 268/500 [03:34<02:59,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  54%|█████▍    | 269/500 [03:35<02:51,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  54%|█████▍    | 270/500 [03:36<02:46,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  54%|█████▍    | 271/500 [03:36<02:42,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  54%|█████▍    | 272/500 [03:37<02:56,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  55%|█████▍    | 273/500 [03:38<02:49,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  55%|█████▍    | 274/500 [03:39<02:44,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  55%|█████▌    | 275/500 [03:40<03:04,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  55%|█████▌    | 276/500 [03:40<02:45,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  55%|█████▌    | 277/500 [03:41<02:41,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  56%|█████▌    | 278/500 [03:41<02:38,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  56%|█████▌    | 279/500 [03:42<02:36,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  56%|█████▌    | 280/500 [03:43<02:33,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  56%|█████▌    | 281/500 [03:43<02:22,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  56%|█████▋    | 282/500 [03:44<02:24,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  57%|█████▋    | 283/500 [03:45<02:15,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  57%|█████▋    | 284/500 [03:45<02:08,  1.68it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  57%|█████▋    | 285/500 [03:46<02:29,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  57%|█████▋    | 286/500 [03:47<02:43,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  57%|█████▋    | 287/500 [03:48<02:36,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  58%|█████▊    | 288/500 [03:48<02:33,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  58%|█████▊    | 289/500 [03:49<02:30,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  58%|█████▊    | 290/500 [03:50<02:18,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  58%|█████▊    | 291/500 [03:51<03:04,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  58%|█████▊    | 292/500 [03:52<02:52,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  59%|█████▊    | 293/500 [03:52<02:37,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  59%|█████▉    | 294/500 [03:53<02:32,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  59%|█████▉    | 295/500 [03:54<02:49,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  59%|█████▉    | 296/500 [03:55<02:40,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  59%|█████▉    | 297/500 [03:55<02:33,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  60%|█████▉    | 298/500 [03:56<02:28,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  60%|█████▉    | 299/500 [03:57<02:24,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  60%|██████    | 300/500 [03:58<02:39,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  60%|██████    | 301/500 [03:58<02:32,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  60%|██████    | 302/500 [03:59<02:26,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  61%|██████    | 303/500 [04:00<02:05,  1.57it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  61%|██████    | 304/500 [04:00<02:16,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  61%|██████    | 305/500 [04:01<02:29,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  61%|██████    | 306/500 [04:02<02:15,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  61%|██████▏   | 307/500 [04:02<02:11,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  62%|██████▏   | 308/500 [04:04<02:35,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  62%|██████▏   | 309/500 [04:04<02:41,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  62%|██████▏   | 310/500 [04:05<02:31,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  62%|██████▏   | 311/500 [04:06<02:48,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  62%|██████▏   | 312/500 [04:07<02:48,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  63%|██████▎   | 313/500 [04:08<02:52,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  63%|██████▎   | 314/500 [04:09<02:38,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  63%|██████▎   | 315/500 [04:10<02:28,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  63%|██████▎   | 316/500 [04:10<02:21,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  63%|██████▎   | 317/500 [04:11<02:15,  1.35it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  64%|██████▎   | 318/500 [04:12<02:35,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  64%|██████▍   | 319/500 [04:13<02:25,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  64%|██████▍   | 320/500 [04:14<02:26,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  64%|██████▍   | 321/500 [04:14<02:19,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  64%|██████▍   | 322/500 [04:15<02:13,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  65%|██████▍   | 323/500 [04:16<02:10,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  65%|██████▍   | 324/500 [04:16<02:07,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  65%|██████▌   | 325/500 [04:17<02:18,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  65%|██████▌   | 326/500 [04:18<02:12,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  65%|██████▌   | 327/500 [04:19<02:00,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  66%|██████▌   | 328/500 [04:19<01:58,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  66%|██████▌   | 329/500 [04:20<01:57,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  66%|██████▌   | 330/500 [04:21<01:57,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  66%|██████▌   | 331/500 [04:21<01:51,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  66%|██████▋   | 332/500 [04:22<01:52,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  67%|██████▋   | 333/500 [04:22<01:45,  1.59it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  67%|██████▋   | 334/500 [04:23<01:47,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  67%|██████▋   | 335/500 [04:24<01:49,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  67%|██████▋   | 336/500 [04:25<01:52,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  67%|██████▋   | 337/500 [04:26<02:16,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  68%|██████▊   | 338/500 [04:26<02:07,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  68%|██████▊   | 339/500 [04:27<02:00,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  68%|██████▊   | 340/500 [04:28<02:11,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  68%|██████▊   | 341/500 [04:29<02:22,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  68%|██████▊   | 342/500 [04:30<02:04,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  69%|██████▊   | 343/500 [04:31<02:10,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  69%|██████▉   | 344/500 [04:31<02:02,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  69%|██████▉   | 345/500 [04:32<01:57,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  69%|██████▉   | 346/500 [04:33<02:04,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  69%|██████▉   | 347/500 [04:34<02:09,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  70%|██████▉   | 348/500 [04:34<01:59,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  70%|██████▉   | 349/500 [04:35<01:47,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  70%|███████   | 350/500 [04:36<02:07,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  70%|███████   | 351/500 [04:37<01:52,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  70%|███████   | 352/500 [04:37<01:42,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  71%|███████   | 353/500 [04:38<01:52,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  71%|███████   | 354/500 [04:39<02:07,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  71%|███████   | 355/500 [04:40<01:54,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  71%|███████   | 356/500 [04:41<01:50,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  71%|███████▏  | 357/500 [04:41<01:48,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  72%|███████▏  | 358/500 [04:43<02:15,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  72%|███████▏  | 359/500 [04:43<02:02,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  72%|███████▏  | 360/500 [04:44<01:54,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  72%|███████▏  | 361/500 [04:45<01:48,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  72%|███████▏  | 362/500 [04:46<01:59,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  73%|███████▎  | 363/500 [04:47<01:51,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  73%|███████▎  | 364/500 [04:47<01:51,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  73%|███████▎  | 365/500 [04:48<01:39,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  73%|███████▎  | 366/500 [04:49<01:52,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  73%|███████▎  | 367/500 [04:50<01:45,  1.26it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  74%|███████▎  | 368/500 [04:51<01:50,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  74%|███████▍  | 369/500 [04:51<01:37,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  74%|███████▍  | 370/500 [04:52<01:50,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  74%|███████▍  | 371/500 [04:53<01:43,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  74%|███████▍  | 372/500 [04:54<01:53,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  75%|███████▍  | 373/500 [04:55<01:45,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  75%|███████▍  | 374/500 [04:55<01:39,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  75%|███████▌  | 375/500 [04:56<01:42,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  75%|███████▌  | 376/500 [04:57<01:31,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  75%|███████▌  | 377/500 [04:57<01:23,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  76%|███████▌  | 378/500 [04:58<01:28,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  76%|███████▌  | 379/500 [04:59<01:27,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  76%|███████▌  | 380/500 [05:00<01:25,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  76%|███████▌  | 381/500 [05:00<01:23,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  76%|███████▋  | 382/500 [05:01<01:37,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  77%|███████▋  | 383/500 [05:02<01:32,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  77%|███████▋  | 384/500 [05:03<01:27,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  77%|███████▋  | 385/500 [05:04<01:30,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  77%|███████▋  | 386/500 [05:05<01:48,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  77%|███████▋  | 387/500 [05:06<01:39,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  78%|███████▊  | 388/500 [05:07<01:43,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  78%|███████▊  | 389/500 [05:08<01:36,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  78%|███████▊  | 390/500 [05:08<01:30,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  78%|███████▊  | 391/500 [05:09<01:33,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  78%|███████▊  | 392/500 [05:10<01:26,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  79%|███████▊  | 393/500 [05:11<01:22,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  79%|███████▉  | 394/500 [05:11<01:19,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  79%|███████▉  | 395/500 [05:12<01:16,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  79%|███████▉  | 396/500 [05:13<01:14,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  79%|███████▉  | 397/500 [05:13<01:12,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  80%|███████▉  | 398/500 [05:14<01:18,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  80%|███████▉  | 399/500 [05:15<01:21,  1.25it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  80%|████████  | 400/500 [05:16<01:16,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  80%|████████  | 401/500 [05:16<01:13,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  80%|████████  | 402/500 [05:17<01:19,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  81%|████████  | 403/500 [05:18<01:15,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  81%|████████  | 404/500 [05:19<01:11,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  81%|████████  | 405/500 [05:19<01:09,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  81%|████████  | 406/500 [05:20<01:07,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  81%|████████▏ | 407/500 [05:21<01:01,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  82%|████████▏ | 408/500 [05:22<01:08,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  82%|████████▏ | 409/500 [05:23<01:18,  1.17it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  82%|████████▏ | 410/500 [05:23<01:09,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  82%|████████▏ | 411/500 [05:24<01:06,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  82%|████████▏ | 412/500 [05:25<01:04,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  83%|████████▎ | 413/500 [05:25<00:59,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  83%|████████▎ | 414/500 [05:26<01:10,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  83%|████████▎ | 415/500 [05:27<01:06,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  83%|████████▎ | 416/500 [05:28<00:59,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  83%|████████▎ | 417/500 [05:29<01:05,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  84%|████████▎ | 418/500 [05:29<01:02,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  84%|████████▍ | 419/500 [05:30<01:00,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  84%|████████▍ | 420/500 [05:31<00:58,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  84%|████████▍ | 421/500 [05:32<01:02,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  84%|████████▍ | 422/500 [05:32<00:59,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  85%|████████▍ | 423/500 [05:33<01:02,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  85%|████████▍ | 424/500 [05:34<01:03,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  85%|████████▌ | 425/500 [05:35<00:59,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  85%|████████▌ | 426/500 [05:36<00:56,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  85%|████████▌ | 427/500 [05:36<00:53,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  86%|████████▌ | 428/500 [05:37<00:52,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  86%|████████▌ | 429/500 [05:37<00:47,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  86%|████████▌ | 430/500 [05:38<00:53,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  86%|████████▌ | 431/500 [05:39<00:51,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  86%|████████▋ | 432/500 [05:40<00:49,  1.37it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  87%|████████▋ | 433/500 [05:41<00:48,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  87%|████████▋ | 434/500 [05:41<00:47,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  87%|████████▋ | 435/500 [05:42<00:46,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  87%|████████▋ | 436/500 [05:43<00:49,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  87%|████████▋ | 437/500 [05:44<00:47,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  88%|████████▊ | 438/500 [05:45<00:53,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  88%|████████▊ | 439/500 [05:45<00:49,  1.23it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  88%|████████▊ | 440/500 [05:46<00:46,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  88%|████████▊ | 441/500 [05:47<00:52,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  88%|████████▊ | 442/500 [05:48<00:52,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  89%|████████▊ | 443/500 [05:49<00:47,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  89%|████████▉ | 444/500 [05:50<00:44,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  89%|████████▉ | 445/500 [05:50<00:41,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  89%|████████▉ | 446/500 [05:51<00:42,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  89%|████████▉ | 447/500 [05:52<00:47,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  90%|████████▉ | 448/500 [05:53<00:48,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  90%|████████▉ | 449/500 [05:54<00:48,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  90%|█████████ | 450/500 [05:55<00:45,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  90%|█████████ | 451/500 [05:56<00:42,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  90%|█████████ | 452/500 [05:57<00:47,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  91%|█████████ | 453/500 [05:58<00:42,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  91%|█████████ | 454/500 [05:59<00:42,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  91%|█████████ | 455/500 [06:00<00:41,  1.08it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  91%|█████████ | 456/500 [06:01<00:41,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  91%|█████████▏| 457/500 [06:01<00:37,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  92%|█████████▏| 458/500 [06:02<00:33,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  92%|█████████▏| 459/500 [06:03<00:31,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  92%|█████████▏| 460/500 [06:03<00:29,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  92%|█████████▏| 461/500 [06:04<00:31,  1.22it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  92%|█████████▏| 462/500 [06:05<00:29,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  93%|█████████▎| 463/500 [06:06<00:26,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  93%|█████████▎| 464/500 [06:06<00:25,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  93%|█████████▎| 465/500 [06:07<00:24,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  93%|█████████▎| 466/500 [06:08<00:23,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  93%|█████████▎| 467/500 [06:09<00:24,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  94%|█████████▎| 468/500 [06:09<00:22,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  94%|█████████▍| 469/500 [06:11<00:28,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  94%|█████████▍| 470/500 [06:11<00:25,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  94%|█████████▍| 471/500 [06:12<00:25,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  94%|█████████▍| 472/500 [06:13<00:21,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  95%|█████████▍| 473/500 [06:14<00:20,  1.33it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  95%|█████████▍| 474/500 [06:14<00:20,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  95%|█████████▌| 475/500 [06:15<00:21,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  95%|█████████▌| 476/500 [06:16<00:18,  1.32it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  95%|█████████▌| 477/500 [06:17<00:17,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  96%|█████████▌| 478/500 [06:17<00:16,  1.36it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  96%|█████████▌| 479/500 [06:18<00:14,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  96%|█████████▌| 480/500 [06:19<00:15,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  96%|█████████▌| 481/500 [06:20<00:15,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  96%|█████████▋| 482/500 [06:21<00:14,  1.28it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  97%|█████████▋| 483/500 [06:21<00:12,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  97%|█████████▋| 484/500 [06:22<00:11,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  97%|█████████▋| 485/500 [06:22<00:10,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  97%|█████████▋| 486/500 [06:24<00:12,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  97%|█████████▋| 487/500 [06:25<00:11,  1.15it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  98%|█████████▊| 488/500 [06:25<00:09,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  98%|█████████▊| 489/500 [06:26<00:08,  1.29it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  98%|█████████▊| 490/500 [06:27<00:07,  1.34it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  98%|█████████▊| 491/500 [06:27<00:06,  1.30it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  98%|█████████▊| 492/500 [06:28<00:06,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  99%|█████████▊| 493/500 [06:30<00:06,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  99%|█████████▉| 494/500 [06:30<00:05,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  99%|█████████▉| 495/500 [06:31<00:04,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  99%|█████████▉| 496/500 [06:32<00:03,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples):  99%|█████████▉| 497/500 [06:33<00:02,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples): 100%|█████████▉| 498/500 [06:34<00:01,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples): 100%|█████████▉| 499/500 [06:35<00:00,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "🔍 Evaluating Trial 9 (1000 samples): 100%|██████████| 500/500 [06:36<00:00,  1.26it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 9 Results on 1000-sample validation set:\n",
      "BLEU: 0.0038\n",
      "ROUGE-1: 0.1018\n",
      "ROUGE-2: 0.0064\n",
      "ROUGE-L: 0.079\n",
      "BERTScore (F1): 0.826\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load validation dataset (1000 unseen samples)\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_1000.jsonl\", split=\"train\")\n",
    "\n",
    "# Load Trial 9 fine-tuned model\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial9\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Run predictions\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"🔍 Evaluating Trial 9 (1000 samples)\"):\n",
    "    input_text = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "# Compute scores\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Print results\n",
    "print(\"\\n📊 Trial 9 Results on 1000-sample validation set:\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "554A7e1iXE5b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOCivDfqbQSm"
   },
   "source": [
    "# Evaluation result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZanf0lKbmma"
   },
   "source": [
    "## 📊 Evaluation Results Summary for Fine-Tuning Trials\n",
    "\n",
    "| **Trial** | **Dataset Size** | **BLEU** | **ROUGE-1** | **ROUGE-2** | **ROUGE-L** | **BERTScore (F1)** | **Notes** |\n",
    "|-----------|------------------|----------|-------------|-------------|-------------|--------------------|-----------|\n",
    "| Trial 1   | 1000             | 0.0018   | 0.0824      | 0.0044      | 0.0666      | 0.8229             | Baseline |\n",
    "| Trial 6   | 3000             | 0.0036   | 0.0972      | 0.0060      | 0.0760      | 0.8242             | Early improvement |\n",
    "| Trial 7   | 3000             | 0.0033   | 0.0995      | 0.0072      | 0.0767      | 0.8255             | Better ROUGE-1/L |\n",
    "| Trial 8   | 3600 (3000 + 600 synthetic) | 0.0177 | 0.1330 | **0.0289** | 0.1028 | 0.8349 | Large gain from synthetic data |\n",
    "| **Trial 9** | **4100 (3600 + 500 enhanced synthetic)** | **0.0198** | **0.1434** | 0.0277 | **0.1103** | **0.8406** | 🏆 **Best overall performance** |\n",
    "\n",
    "---\n",
    "\n",
    "### 🏆 Best Performing Model: Trial 9\n",
    "\n",
    "- **Model:** Fine-tuned Mistral-7B-Instruct-v0.2 using 4100 samples\n",
    "- **Training Enhancements:**\n",
    "  - Data filtering\n",
    "  - 500 enhanced synthetic samples\n",
    "  - LoRA config: `r=16`, `dropout=0.05`, `alpha=32`\n",
    "  - Prompt format emphasizing emotional context\n",
    "  - 3 epochs\n",
    "\n",
    "**Why it's the best:**\n",
    "- Achieved the highest **ROUGE-1**, **ROUGE-L**, and **BERTScore** — indicators of content similarity and fluency.\n",
    "- Also delivered the highest **BLEU** score — suggesting closer alignment with exact word usage in references.\n",
    "- Slight drop in ROUGE-2 vs. Trial 8, but BLEU and overall F1 score are stronger.\n",
    "\n",
    "This trial shows a well-balanced trade-off between **empathy, fluency, and relevance** in chatbot responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRlrKxiNbpcI"
   },
   "source": [
    "Trying best trial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "931a1893d723434981b84327759e0851",
      "8cf8222a293d4de7b408bd7417220647",
      "c1a424c08566440db68715c4627feb7a",
      "abd598837c33417a8375d16d41ffaba7",
      "e275603de1114235ba88124d91876845",
      "80d90f124b2a4efd9d5a403c0bb36f7e",
      "01330350e05f4868a2ae6b951d306af6",
      "d4ceaec7b7414e729145e5e407a3dcf7",
      "a1777c2ec4f345f9859b5cfe78bc7f59",
      "95510e3957874e9ab6d87f9edf99f45d",
      "536e73e286824d159d45ca8a68263c02"
     ]
    },
    "executionInfo": {
     "elapsed": 194011,
     "status": "ok",
     "timestamp": 1744317867366,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "zU8fbjcLbnWs",
    "outputId": "184faaaa-fc2d-4f49-92bb-1b2f73610598"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931a1893d723434981b84327759e0851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌿 Welcome to the Mistral Empathetic Chatbot (Trial 9)\n",
      "Type your message below. Type 'exit' to quit.\n",
      "\n",
      "You: hi\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "hi [/INST] I'm glad you're feeling better. I hope you have a great day!\n",
      "\n",
      "You: I've been feeling anxious all the time and I don’t even know why\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I've been feeling anxious all the time and I don’t even know why [/INST] I'm really sorry you're feeling this way. You're not alone, and I'm here to support you\n",
      "\n",
      "You: I'm constantly worried something bad will happen\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I'm constantly worried something bad will happen [/INST] I'm really sorry you're feeling this way. You're not alone, and I'm here to support you.\n",
      "\n",
      "You: I just feel numb. Nothing makes me happy anymore\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I just feel numb. Nothing makes me happy anymore [/INST] You’ve already taken a brave step by expressing this. That matters.\n",
      "\n",
      "You: Lately I feel like I’m just a burden to everyone\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Lately I feel like I’m just a burden to everyone [/INST] You’ve come this far, and that already shows courage. Let’s take the next step together.\n",
      "\n",
      "You: Even when I’m with people, I feel alone\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Even when I’m with people, I feel alone [/INST] I'm really sorry you're feeling this way. You're not alone, and I'm here to support you\n",
      "\n",
      "You: I feel invisible most of the time\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel invisible most of the time [/INST] I'm really sorry you're feeling this way. You're not alone, and I'm here to support you.\n",
      "\n",
      "You: Why do I always have to be the one to fix everything?\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Why do I always have to be the one to fix everything? [/INST] I'm really sorry you're feeling this way. You're not alone, and I'm here to support you.\n",
      "\n",
      "You: I made a mistake that I can’t stop thinking about\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I made a mistake that I can’t stop thinking about [/INST] I'm really sorry you're feeling this way. You're not alone, and I'm here to support you\n",
      "\n",
      "You: I don’t think I’m good enough for anything\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I don’t think I’m good enough for anything [/INST] You’ve come this far, and that already shows courage. Let’s take the next step together.\n",
      "\n",
      "You: I'm running on empty, emotionally and physically\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I'm running on empty, emotionally and physically [/INST] I'm really sorry you're feeling this way. You're not alone, and I'm here to support you.\n",
      "\n",
      "You: What’s the point of life if it just feels like survival?\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "What’s the point of life if it just feels like survival? [/INST] I'm really sorry you're feeling this way. You're not alone, and I'm here to support you\n",
      "\n",
      "You: thank you\n",
      "\n",
      "🤖 Mistral: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "thank you [/INST] I'm glad you're feeling better. I hope you have a great day!\n",
      "\n",
      "You: exit\n",
      "👋 Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load your Trial 9 fine-tuned model\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial9\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Conversation starts\n",
    "print(\"🌿 Welcome to the Mistral Empathetic Chatbot (Trial 9)\")\n",
    "print(\"Type your message below. Type 'exit' to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"👋 Goodbye!\")\n",
    "        break\n",
    "\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{user_input} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(f\"\\n🤖 Mistral: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_F1-mSCb27L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXY1jcaXjrEI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhAdgFofjrQw"
   },
   "source": [
    "# Empathetic Dataset without introducing Synthetic for TRIAL 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4916,
     "status": "ok",
     "timestamp": 1745175728017,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "uaON7xf-jx9I",
    "outputId": "d06d2067-d721-4618-f310-c2c2f4a96d52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6937"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the cleaned conversational data\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/SIT782/datasets/train-conv.csv\")\n",
    "\n",
    "# Step 1: Drop NaNs and retain only needed columns\n",
    "df = df[[\"utterance\"]].dropna().reset_index(drop=True)\n",
    "\n",
    "# Step 2: Pair every two utterances\n",
    "records = []\n",
    "for i in range(0, len(df) - 1, 2):\n",
    "    instruction = df.iloc[i][\"utterance\"].strip()\n",
    "    output = df.iloc[i + 1][\"utterance\"].strip()\n",
    "\n",
    "    # Smart Filter: Only include pairs where output is 20+ words and both fields are non-empty\n",
    "    if len(output.split()) >= 20 and instruction and output:\n",
    "        records.append({\n",
    "            \"instruction\": instruction,\n",
    "            \"output\": output\n",
    "        })\n",
    "\n",
    "# Save to JSONL format\n",
    "jsonl_path = \"/content/drive/MyDrive/SIT782/datasets/empdiag_filtered_cleaned.jsonl\"\n",
    "with open(jsonl_path, \"w\") as f:\n",
    "    for r in records:\n",
    "        json.dump(r, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Summary of the filtering process\n",
    "filtered_count = len(records)\n",
    "filtered_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6gGTtY4lDrZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHczilWKliVN"
   },
   "source": [
    "Trial 10 tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "15432308a3f04ea7a9a5fab6931037c9",
      "f33f342ce9bb4d16a56d441fae6f85d8",
      "acdcc7644b1d431a8c60b9c555b0e621",
      "8cca1afcb908472d9e56e6ef33c1d608",
      "f8f633e3355847a7bf78d7825bbb0352",
      "a48352c1c892409bb747d02a9a25d83f",
      "43c67621727a42f8a5e31aca279ed8d8",
      "15224bd283ed479aaf547910596132ee",
      "0bb9705379bb4ea287c7be6a930ff0b9",
      "f5a21d108a074a29a825d194e7e1412f",
      "d2fa093a125a4d81a1d56e6315633a9a"
     ]
    },
    "executionInfo": {
     "elapsed": 2369366,
     "status": "ok",
     "timestamp": 1745178513527,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "VNZWVp0Jlkvz",
    "outputId": "b4fab353-14f6-4e6b-e6d3-94fb824a1367"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15432308a3f04ea7a9a5fab6931037c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-1082cb80b256>:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3468' max='3468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3468/3468 39:20, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>17.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>10.765400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.468500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.791500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.121700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.568500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.864100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.738300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.449700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.415800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.398900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.362100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.356300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.345100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.334500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.324700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.331200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.526100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.320400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.290500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.323600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.298500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.302500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.317200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.293200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.318200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.302400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.313500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.299800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.303300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.305900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.422300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.287800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.298800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.293300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.280300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.424500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.279200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.278400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.288500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.406700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.267100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.407800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.295300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.406400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.282700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.272600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.278900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.378300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.286400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.254900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.260100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.254500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.245800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.364300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.270800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.278300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.263500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.252400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.258800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.382300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.247600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.259300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.388600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.365400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.265400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.255400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.270100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.355100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.253500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.264300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.264600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.264600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.254600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.265200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.337700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.265800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.266300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.250900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.252100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.263900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.253200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.253100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.251300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.350700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.265800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.336300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.250700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.262100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.252200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.244500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.229200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.329600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.244400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.232100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.239700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.333500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.227600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.224700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.213700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.220500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.202200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.211800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.215300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.204500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.217600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.216800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.210900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.300300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.206200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.315100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.197500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.199300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.199800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.213300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.200200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.298900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>0.334100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.291200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>0.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.201100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>0.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.215300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>0.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.215100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.220400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>0.212400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.324800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>0.305600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.224700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>0.213900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.214800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>0.300100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.308400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>0.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>0.216800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.304300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>0.290700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>0.205500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.202400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.323600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>0.205300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.197800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>0.207300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>0.219300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.211500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>0.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.206900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.210300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.228300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>0.204100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>0.205200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>0.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.234300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>0.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.203400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>0.215300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.332600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.206100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>0.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.217400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>0.214500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.207200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>0.210900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.294700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>0.200900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.208600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>0.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.311200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>0.210100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>0.217500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>0.204400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>0.205100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.286900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.205100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>0.215800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.214100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>0.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>0.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.205700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.201100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>0.209400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.220100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>0.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>0.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>0.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.202600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.204900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.199600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>0.212900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.222200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>0.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>0.208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>0.204500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>0.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.218200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>0.283200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>0.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>0.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>0.308700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>0.213900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>0.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.207800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>0.201100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.206900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>0.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.213800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>0.214900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.210300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>0.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>0.310300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3190</td>\n",
       "      <td>0.217500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>0.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.235200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3230</td>\n",
       "      <td>0.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.203100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>0.313900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>0.208100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3290</td>\n",
       "      <td>0.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3310</td>\n",
       "      <td>0.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.213800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>0.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.308900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>0.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>0.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.204400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>0.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.215800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3430</td>\n",
       "      <td>0.201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.224600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>0.239500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 10 fine-tuning complete and saved to Drive!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "\n",
    "# Load the filtered empathetic dataset (Trial 10)\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_filtered_cleaned.jsonl\", split=\"train\")\n",
    "\n",
    "# Base model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Tokenization with instructional prompt\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message.\\n{example['instruction']} [/INST]\"\n",
    "    output = f\"{example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=384)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=384)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA configuration (best-performing from previous trials)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Training arguments for Trial 10\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-empdiag-trial10\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=1e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Save metadata (not running train here, only preparing the script)\n",
    "{\n",
    "    \"status\": \"✅ Trial 10 script ready\",\n",
    "    \"samples\": len(dataset),\n",
    "    \"output_dir\": training_args.output_dir,\n",
    "    \"lora_r\": lora_config.r,\n",
    "    \"epochs\": training_args.num_train_epochs,\n",
    "    \"batch_size\": training_args.per_device_train_batch_size\n",
    "}\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save model & tokenizer\n",
    "model.save_pretrained(training_args.output_dir)\n",
    "tokenizer.save_pretrained(training_args.output_dir)\n",
    "\n",
    "print(\"✅ Trial 10 fine-tuning complete and saved to Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5v-iYIdwkZ1"
   },
   "source": [
    "# Trial 10 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733,
     "referenced_widgets": [
      "7682c2c840ad46b7b7a19e79c20b62bb",
      "d31044f380534c1bb908a44a9526953c",
      "1d9ef32b74d0449ca4e475876186a0b4",
      "4f0166341b5c4bc5b5a4da2f833270ec",
      "d286d3b6472146698ab6e8afcd81ba5d",
      "c3a280b6e55341dcbf8ffa451bc3f59d",
      "4a2c2e176ebc4aeba6a7f4e632eab041",
      "43d5aaf93e704ce88e1533b5c266367d",
      "a20852e8ac8340f799f72def80005547",
      "3bc24a8afb6546e6993f49d85a92c99b",
      "3eac4158ca2a410f9806b48345f69e6c",
      "0df46ba2391d4543936e748c9a308927",
      "6b1fb57562074e39a7632296f429aca7",
      "a7d55691349a4a63bf7846fb91b67b7e",
      "b2a03448d7a44af38525b9ef05a7225a",
      "e19a875bdfd94781b0149d5aed84b05f",
      "ac668258fb474f0b88582932d9cc11fb",
      "11cb343cfdaa441b8d6cf3e82eaba70a",
      "b184fac295aa4afd89a50e4baea9891a",
      "0f06c23d332b41f3a40cfd7a26d0dd85",
      "1b97a881a50c4210b384a22de5bb86b2",
      "cd3fb23c7e9a4c079e7e8cf0a373359b",
      "946146e8ea8b4dfe87413ce719ec1c0f",
      "a4af83cc89184402a9e6bb2fa2e79cc1",
      "baa2fa20f0a74abd93571fb79eae1a13",
      "fbd954006b94498c895635ff9d68d5c3",
      "5f2270af3d624827806faef2fbaf7644",
      "280c6e8bd3a74a6b86e8ce58de481506",
      "c9171391b06642609075c6c51cbe760f",
      "2912e3460bb54fe9b3d6e2749b3cfe0e",
      "2fa8d5b15a7f4a3e9c2d4e5047a4f1b7",
      "829eeae3e65e445089443a93986e9f3f",
      "519859bce4054aa3aabb3398e1c6eefd",
      "e77bef8445444e788f205e541a2791be",
      "6341f49b8c3c476391c242d076462ce2",
      "ceb0f00ebc324f2681e54aba9a32c492",
      "b44f71905c704821bca6aa7ba9d3d315",
      "f5ed437cca924d91a1036b7b2809f65d",
      "351a1a81e1154cff82322946368fee36",
      "3d520e7e738247c5ba21e534ed4d1de5",
      "127afe62516e4947a15ea3806215188d",
      "8385271d3a34449d9c2149359215c750",
      "e885e8cf0327486f9b6bac24de346d5a",
      "5651c59139aa431096710fb79a0bfcc0",
      "18346324742748dd91bcf852f97521e7",
      "bed96288a0ea4b11979864dd5517d094",
      "6b7b0a34e3cb4cea83306d07a6d5f21d",
      "f55570c0c0964a54aa9fc4f782c3e7f7",
      "8e4a461fcabe41b2809fec4a1df8e746",
      "92eedfb13cb64283afbdf94a4a4daa5c",
      "095e8c0c3e2d4a5d82f3308b8c7d133c",
      "d789483aa63e4d248f40a4bd179c070f",
      "7437267d0dec4d0ca1dd87565b662b28",
      "723e0bd63b7b44e79a3f1c668c33af7d",
      "3cf5188beae640a493f1e21880f6315e",
      "4f00c6d897024a888b0d7ba4d505a14a",
      "3cd58ee46ec24833b958d28549b153be",
      "12f5ce583577445a9b4c85954b960db9",
      "bb0230d43e0246fd9f088f1862b0684f",
      "ae7639bd52a5487e867c3fe232b12778",
      "accbdf469de443b9bcb3bb7b9c3c8a1c",
      "bf10c7312c0f4e3993ae13fe742dae2e",
      "5cc66602d512492f8d0417de7cd0ceb9",
      "5cd04f3a60d844c2bbe9cba763cf9b52",
      "76c050ba2ca94320a3df85c45e504aef",
      "9bd91a4f50d945ee8dfb7b85fe946a4f",
      "195fa4cc4f8f46fa90dd4d992023914a",
      "9bee9fdd902848638a4923298bea67ad",
      "bc4e971ef4fc4729b58f74d53123c00c",
      "0850d46309ee436ebc845d4a3ea51eb9",
      "f4705069678e48f59ee96f22046f3b9d",
      "24b01ed7dc9a4690aad0bc119d87915c",
      "a2f368f719c54217b1986a98a6f0522d",
      "af553d623bc04f0b847200913f488210",
      "eb0800300e5c4a3da6732d02f29be36c",
      "8907562c604b43e0b35342c8fc0f783d",
      "686c262183a640ee8dfc1c8b75b13975",
      "ab4e8e2119ad40289d42840cc9efa22d",
      "2c38c4fc18bc4451a8a8764fd58f6b0a",
      "d4f4d8b66945472ba890295276c41a42",
      "49dbf97861ac46219f7c534d36d23294",
      "ea2ebfb457c54880ab0f7c0cdc1cec32",
      "de6f215c74804bcdb5ed64d1890fe4c1",
      "3eaac158a6af4c67895a58b23ade7476",
      "a5f484e852374298b712d489244a5880",
      "f8f74f2fc3ba4facb0f07dd0a7c8ef03",
      "c2b205788f1c4096b17833b7921eb3af",
      "dbbaff52d4254805a0da355957ff40fe",
      "7912311df9a146cebeb4da843c857fff",
      "7f54b24878004570a4ff93d407cec692",
      "ee420094f7e04b35a54649ddc8e65173",
      "bdd61524c6fe4b589be5cd64bcdcec79",
      "8ba36a4da8884cee89cf1ee2c6aef6f0",
      "57e57df13bf7466fb671f73d6645ad4a",
      "53d71862fb774efdad0f31d311a7079a",
      "ac2396fc85d24a879d5d9da92d6756e2",
      "f34358e9e2e6475ea1252921e4dc6fb4",
      "7a8fde6a3064424e81d35d1e75a407ed",
      "cb90d7a60d7b43bb8339db7487e3c3d3",
      "675224da0dd1455db0d7124ae7bea49a",
      "5d4be3cb98c64b129fcf3d50a4cf9571",
      "3414d98219454e3bbb6d5ba2285a4301",
      "2a41b8d6b121416aa8291bcfba5fefd1",
      "d8175e3726e8495984732d3aee2a7fb6",
      "4ea73036a4464908baf5f1f1b9f76b1a",
      "c85d6a2dfe844dddbd05ea22b48b7d24",
      "dbd240322e374dbda3615b476700311f",
      "12bd61fc98be4544b5baea17ad00837b",
      "d1a09889cdde4d8e9c8754045bf4b2a5",
      "7787c034068f4f069f280605fd58fb7b",
      "483d0b1e220345c58333859f2723cb0a",
      "9dcde781695042b0873200aaf461d866",
      "44fdc3f78d064a28bba1f6d244ce23a0",
      "855b0a6f640d47bca78eae65f81dfee1",
      "6b73c58bd92d43cf9d9411367132b723",
      "2863597635be4c34951746a5de280ea2",
      "d9e87985124b4fd7b727535bb5397e2c",
      "2448f7f783344f2cadfbbcc625582d0e",
      "f97237a3fcd5429e92327e15a594b347",
      "e421543f99ac4c26a31d3567f88ae3a9",
      "5b1120d80c4543bb84652dbf57782532",
      "a91b3d0e831d465086d914424d91924e",
      "c4bf526ba63842bfbfd76510336cae45",
      "4cde2108479541b890a50ed122cebfd1",
      "19283a4a505049e48f43c038ba548ba2",
      "078f54ef31b546f1a86624dc72a0bbfe",
      "53d40ac57ff943cca76b066c1de54b80",
      "4330add25f824ad797d655d776a1e1c7",
      "cf9bbc47e0424cc98f2d3f481e3c19a0",
      "02fc7b1b25274750a6a205b5aa1a5f5b",
      "60880e3fec644200a730485717f8e986",
      "a9ccc4617be746db8fcc2dd4a49cf4dd"
     ]
    },
    "executionInfo": {
     "elapsed": 2090694,
     "status": "ok",
     "timestamp": 1745180943200,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "N029BUgml9SX",
    "outputId": "c3e62d1a-306a-4261-a179-62d3dfa7b7b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7682c2c840ad46b7b7a19e79c20b62bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df46ba2391d4543936e748c9a308927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946146e8ea8b4dfe87413ce719ec1c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77bef8445444e788f205e541a2791be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18346324742748dd91bcf852f97521e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f00c6d897024a888b0d7ba4d505a14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating Trial 10: 100%|██████████| 1000/1000 [34:11<00:00,  2.05s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195fa4cc4f8f46fa90dd4d992023914a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4e8e2119ad40289d42840cc9efa22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7912311df9a146cebeb4da843c857fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675224da0dd1455db0d7124ae7bea49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483d0b1e220345c58333859f2723cb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91b3d0e831d465086d914424d91924e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 10 Evaluation Results (Filtered EmpatheticDialogues - 1000 samples):\n",
      "BLEU: 0.0139\n",
      "ROUGE-1: 0.1744\n",
      "ROUGE-2: 0.0217\n",
      "ROUGE-L: 0.1162\n",
      "BERTScore (F1): 0.8314\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load evaluation dataset (limit to 1000 for quick eval)\n",
    "eval_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_filtered_cleaned.jsonl\",\n",
    "    split=\"train[:1000]\"\n",
    ")\n",
    "\n",
    "# Load PEFT config and base model\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-empdiag-trial10\"\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Inference loop\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"🔍 Evaluating Trial 10\"):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message.\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "# Compute scores\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n📊 Trial 10 Evaluation Results (Filtered EmpatheticDialogues - 1000 samples):\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vy788_0lw_sI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQLKI_XZ5MM1"
   },
   "source": [
    "# Merge EmpatheticDialog + CounselChat For Trial 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dypOsN_qvh2V"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1745181386545,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "t0qgM0Rj5U_Q",
    "outputId": "def22421-7e73-4de2-fb90-0d071abbf268"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EmpatheticDialogues_filtered': 6937,\n",
       " 'CounselChat_filtered': 2116,\n",
       " 'Merged_total': 9053,\n",
       " 'Output_file': '/content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered.jsonl'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load filtered empathetic dialogues JSONL\n",
    "with open(\"/content/drive/MyDrive/SIT782/datasets/empdiag_filtered_cleaned.jsonl\", \"r\") as f:\n",
    "    empdiag_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Load smart-filtered CounselChat dataset (Markdown file content already parsed to JSON)\n",
    "with open(\"/content/drive/MyDrive/chatbot/counsel/datasets/counselchat_smartfiltered.jsonl\", \"r\") as f:\n",
    "    # Extract JSON objects from markdown table format (if applicable)\n",
    "    lines = f.readlines()\n",
    "    counsel_data = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"{\") and line.endswith(\"}\\n\"):\n",
    "            try:\n",
    "                counsel_data.append(json.loads(line))\n",
    "            except:\n",
    "                continue  # Skip lines that aren't proper JSON\n",
    "\n",
    "# Combine the datasets\n",
    "merged_data = empdiag_data + counsel_data\n",
    "\n",
    "# Save merged dataset\n",
    "merged_path = \"/content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered.jsonl\"\n",
    "with open(merged_path, \"w\") as f:\n",
    "    for r in merged_data:\n",
    "        json.dump(r, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Summary\n",
    "{\n",
    "    \"EmpatheticDialogues_filtered\": len(empdiag_data),\n",
    "    \"CounselChat_filtered\": len(counsel_data),\n",
    "    \"Merged_total\": len(merged_data),\n",
    "    \"Output_file\": merged_path\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHRBQ8Cw6eZ4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyHl8Te76y37"
   },
   "source": [
    "# Trial 11 - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4a98aab4253c4feeba1e8a53e8b0c3ff",
      "f9b056cdca4647dd99d403aab72c9e83",
      "a8c5680e59724efba0ee22d26d3ad1f1",
      "0ab3cd58efbd43d6bdcd31ea7976257f",
      "2b3a61ab6f7942b2a87ed1a34c0a9b21",
      "0ebbd40b34074e7d9aa84533dd88d3ec",
      "bcf3c26e7f224c97ae913c97c33a2bd9",
      "5fc9f5ee6fc04ff3963ba61e83397cf3",
      "bbd537f4c48044da8a2ec1449946b763",
      "19c7f3114c8e4357bb2df54e7b440a82",
      "90d35887ce1347e0be6beb90ae9200bb",
      "2cacc46c6652468c81a0274f7d1c78d8",
      "7c3292e2aba94b39aef9466704e116e6",
      "ff4ef82998814bd589aa2fc7c1b8168a",
      "6f64f8991b45441c84f22f0a0018dfab",
      "a16ee896e3624af0a9f0685cba579a39",
      "27bcf3df69d64e068d776eee597270de",
      "140b084f7349457db917761e7d52594f",
      "2f72d108b66544689795204f0b12f799",
      "71e3c3f17de64b7d94d792da024271d7",
      "7adda5ca7e5a4f55805fd897c442ad49",
      "a9a9a8b06dd548dda1c65e7671f776c6",
      "0d453e336a9e4e998a7456c4c78fc53b",
      "50bb6c14b922458bbcb541be9a316234",
      "a812c9ac7c864c119be00026fa4b1067",
      "b97611ab16bd4626b41efbe08eed2439",
      "39b8f7ee38a1439e8457cadf6e8c1586",
      "3e571522332e4f979ac75b96b8c321fb",
      "361165e0209e4424bcce7914f4700c09",
      "8dc9e994fcbf4623ba9e17b7f679612d",
      "35ab872d0753467c9493a955bf500f4f",
      "4c259c645641431d82068ad375e01700",
      "d672db7c5eba47d5a48db69747588e5d"
     ]
    },
    "executionInfo": {
     "elapsed": 3112466,
     "status": "ok",
     "timestamp": 1745184578913,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "G5wzhL6J624-",
    "outputId": "53ed9af1-2fbe-413b-a824-2d3be7fcd04e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a98aab4253c4feeba1e8a53e8b0c3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cacc46c6652468c81a0274f7d1c78d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d453e336a9e4e998a7456c4c78fc53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-74539d4cab16>:59: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4524' max='4524' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4524/4524 51:24, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>17.938900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>12.499100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7.520100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.435900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.850800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.203400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.708600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.157100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.526000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.792100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.881300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.042800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.286700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.467400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.480800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.628500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.878700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.689400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.356300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.703400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.880300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.807700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.850400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.699500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.932400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.085100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.159300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.967400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.632700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.123200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.083100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.715900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.881700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.831800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.932400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.290300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.732400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.175900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.954300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.813100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.088300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.573900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.742200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.862900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.918400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.858900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.775200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.852500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.733500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.497700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.994900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.902200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.813700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.757900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.599900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.741100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.880700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.552800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.756300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.701300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.912300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.912400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.718700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.905100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.982700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.958900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.780100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.969100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.584100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.797300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>1.192500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.913300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.654400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.718200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.946700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.753400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>1.202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.086800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.719600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.804800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.880700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.194900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.743400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.980400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.550100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.988400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.927600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>1.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.811700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.578100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.623400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.863400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>1.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.519500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>1.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>1.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.988700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.663800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.826300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.556000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.896100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.573900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.904900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.874700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.789600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.856900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.975900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.705700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.973900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.929100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>1.258600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.496100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>1.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.894600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.766700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.974600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>1.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.851500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>1.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.850600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.913100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.873600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.582300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.644700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.763300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.897400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>1.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.624500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.801000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.936100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>0.556800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.675200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.983800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>0.762100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.991600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.878600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>1.037700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.480300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>0.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.554500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.659700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.927600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>0.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.571600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>1.358500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.717200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>0.857400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>0.909400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.784900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>1.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.778500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>0.630500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>0.566100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>1.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>0.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.550300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>1.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>0.850600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>0.584700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.926800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>0.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.792600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>0.737100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>1.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.856100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>1.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>0.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>1.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>0.843100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.167600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>0.745500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>0.798600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.827100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.996100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>0.824400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>1.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>0.619400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>0.614400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.689900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>0.500600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.875200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.661100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>1.067100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>1.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>0.710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>0.840400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>1.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>0.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.501500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>1.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.603900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>0.806100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>0.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.681800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>0.587700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.888900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>0.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.752500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.796400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>1.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>0.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.972300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>0.792900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>0.785100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.678500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>0.779500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.941700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.929900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>0.883200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.859800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>0.569700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.809500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>0.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>1.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>0.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.705400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>0.841700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.793800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>1.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.780200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>0.590900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>1.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.796900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.984900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>0.665400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.841100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>0.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>0.816300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>1.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.601100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>1.053800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>0.843600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.787200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3190</td>\n",
       "      <td>0.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>1.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.865500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3230</td>\n",
       "      <td>0.965100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>1.038200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.854500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>1.131100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>0.400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.969200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3290</td>\n",
       "      <td>0.398200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.520700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3310</td>\n",
       "      <td>0.705400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.773800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>0.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.886800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.724300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>1.085200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.722900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>0.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.904500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>0.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.930400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3430</td>\n",
       "      <td>0.967500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.629300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>1.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3470</td>\n",
       "      <td>0.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>0.753500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3490</td>\n",
       "      <td>1.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>0.725600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.784200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>0.661800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>0.484600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>0.590400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>0.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>0.545900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3590</td>\n",
       "      <td>0.799700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.792700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>0.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>0.476100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3630</td>\n",
       "      <td>0.968400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>0.930300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>1.164100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>0.863400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>0.776400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>1.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>0.827900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.735400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3710</td>\n",
       "      <td>0.796600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>0.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3730</td>\n",
       "      <td>0.810900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>1.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>0.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3770</td>\n",
       "      <td>0.449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>0.486900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3790</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3810</td>\n",
       "      <td>0.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>0.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3830</td>\n",
       "      <td>0.938800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>0.791700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.645300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>0.917300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3870</td>\n",
       "      <td>0.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>0.682600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3890</td>\n",
       "      <td>0.527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.068600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3910</td>\n",
       "      <td>0.550800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>0.717700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3930</td>\n",
       "      <td>0.757200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>0.832900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.835100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3970</td>\n",
       "      <td>0.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>0.597200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>0.884300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.667300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4010</td>\n",
       "      <td>0.756300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>0.899300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4030</td>\n",
       "      <td>1.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>0.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4060</td>\n",
       "      <td>0.927200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4070</td>\n",
       "      <td>1.042600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>0.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4090</td>\n",
       "      <td>1.248200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4110</td>\n",
       "      <td>0.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4120</td>\n",
       "      <td>0.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4130</td>\n",
       "      <td>0.868700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>0.658700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.908500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4160</td>\n",
       "      <td>0.707300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4170</td>\n",
       "      <td>0.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4180</td>\n",
       "      <td>0.548900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4190</td>\n",
       "      <td>0.654300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.697400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4210</td>\n",
       "      <td>0.817200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4220</td>\n",
       "      <td>0.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4230</td>\n",
       "      <td>1.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4240</td>\n",
       "      <td>0.782300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.975300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>0.705800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4270</td>\n",
       "      <td>0.967700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>0.659700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4290</td>\n",
       "      <td>0.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.771700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4310</td>\n",
       "      <td>0.659900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>0.873800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4330</td>\n",
       "      <td>0.846200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4360</td>\n",
       "      <td>0.937100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4370</td>\n",
       "      <td>1.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>0.533600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4390</td>\n",
       "      <td>0.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.805700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>0.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420</td>\n",
       "      <td>1.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4430</td>\n",
       "      <td>0.936300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>0.760900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4460</td>\n",
       "      <td>0.695300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4470</td>\n",
       "      <td>0.829800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4480</td>\n",
       "      <td>0.709400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4490</td>\n",
       "      <td>0.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4510</td>\n",
       "      <td>0.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4520</td>\n",
       "      <td>0.711300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 11 fine-tuning complete and saved to Drive!\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (if needed)\n",
    "#!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load merged dataset (filtered, no synthetic)\n",
    "dataset_path = \"/content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered.jsonl\"\n",
    "dataset = load_dataset(\"json\", data_files=dataset_path, split=\"train\")\n",
    "\n",
    "# Load model & tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message.\\n{example['instruction']} [/INST]\"\n",
    "    output = f\"{example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, truncation=True, padding=\"max_length\", max_length=384)\n",
    "    result[\"labels\"] = tokenizer(output, truncation=True, padding=\"max_length\", max_length=384)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA configuration (optimized)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# TrainingArguments (Trial 11)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-merged-trial11\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=1e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Launch training\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save model & tokenizer\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-merged-trial11\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-merged-trial11\")\n",
    "\n",
    "print(\"✅ Trial 11 fine-tuning complete and saved to Drive!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcAhsAVH693D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hmoc4N4rnQxH"
   },
   "source": [
    "# Trial 11 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573,
     "referenced_widgets": [
      "8cc530d47de044718e3e0d864c87b2ef",
      "c138ae178d8248f18074b32f717bb476",
      "587008117da24b31af93888034d2b74d",
      "1d320b3517d846be9266feea7d525dec",
      "3a1c3521c93e4c3ea63e7ab2126c2cb6",
      "c8f6b34634574582bb1e05ecdea0668c",
      "610730b158a446899909db5ef0f27be1",
      "e910024c4c5f4437b7fe4114080a8ec4",
      "1c0062de4cda457b82073be7ec473653",
      "81cda3642cd74afca56b0a9d3c4b8fc0",
      "06a7ed1232f84a139e147d951f7eff3d",
      "67f41c93c7924833b28920df4edd620d",
      "0e1980a1c80447e99c4384aa12b18beb",
      "fda41295fe79468a8a30bf7f127552d3",
      "6ad965703c9548b68676ab3a9744bd0e",
      "f68956cc9da84e5899bc5bff42b3f6c0",
      "1940affca34346fabb49732442f2354c",
      "359b1011bc13492596a35144bc6e941b",
      "c5a4a2faa2c74a39b5bd0f2d62378979",
      "c32c9b186dc94b17842ca0ffb89f031e",
      "4df0e6196777455facb74505a1574ab0",
      "c02e514d3cf644c595817a4cccd7438d",
      "874c7c8d60604f0ab0b250904980cd09",
      "5e2d58f9ab704a07b95b42a4f93d3af5",
      "f7e6e59073384fe4a3b6d26d48097d97",
      "5dc961832eb542239bd2a02248edf456",
      "7bc2eb8977a54cf98eebb3a2e7ecf0e0",
      "bec9fcf0b4cc40379db8cf44db98719c",
      "fa53116df8a24b4ab66360d01ae99f88",
      "61f93bf4ab3a4fbaadd4fc4d52d0a43a",
      "e29a564ea9dd4fd4b7ea75ae3eafb958",
      "5449c1c26e6d4020973751b5311c37a0",
      "80cb5de22e684076b534e16a3874f040",
      "ce37d4911e9c440bb696cfa40a7c898f",
      "9cccbf084359421fa0e50c49c571ddeb",
      "3cab798378774f3f89d973d2bed0074f",
      "920941549a224be79d3c7fe4485156c9",
      "68bdcaccd4d5404fa083270daa839f73",
      "41c7e4a2fabc4d40ab29989cd7d053be",
      "dc0941f75b6a48fb98101db11549e757",
      "a6819cf0f8fb442d94b2964c6122bf6a",
      "9c940ae3c2c64632a1d424afca7b4932",
      "881fa63c9b5a454dbae6223bb85488f5",
      "263b4c00942c4b3fa23f22ad1fbb191f",
      "b153547be9d84adb841ca74b51ece84b",
      "cd7d7021a6c748f9892e9789c82baeaa",
      "9fdd94da52d54212a4cdb315f64d3e1e",
      "00e295e714d14dc499295ac5b0f542ed",
      "146497e85787470aa711255728c61c4e",
      "7a1190d29e974a95ae98725347c8fe12",
      "527aa5bb346147388a32326f26ad33d4",
      "bc5ea4048042434b8acf32385a5469cb",
      "2c6295255c5447e9aadbc5143419587c",
      "53d0a727a47e49b18c2ae0067e9ac3c3",
      "9f338513a6de44c38d4844c1e20c51f2",
      "3002973b524c4717b3551b34ae00ac5b",
      "173f9f9ad3fd431b8b81f1912d61bcc8",
      "e54148b20b0b4815a48cbfc0f797f493",
      "866d8395281a4f00804312dd9bf13e11",
      "4e729dbeb0cb4e43bb2ea32c908b7b3d",
      "48430f0017d34a40b49498f9f56339a9",
      "ec5adff1d8da44ccb26222d7fb6aee97",
      "b996bd6957f74a35bfbdfcdae790c931",
      "3ac70eb2bd9448548c37cc0707944cd1",
      "dae645c72ba64f0dbb6f4e60057a834d",
      "300c9aaf0a2f4372bdf48e4732b0ec4c",
      "4944a6c396a64fdba52d0009c5be4e12",
      "64417aa586924359a9f934fcfe1b6354",
      "e14b99aec7bf4c74b0864665cde6680e",
      "92cc9308524d4b358a6b95289f459b03",
      "bb440537a37e44e3ab576889edea87e2",
      "deb086df66274f8594e6b3a10975c4cf",
      "fb6732f2cd834b81ad7e7c21c0b1fe8b",
      "b535399aaadf40289ac92d743992ab5a",
      "957d054da3da4a4989f7c7c0ef654400",
      "9e95c496f8944137bf4ed105adc772dd",
      "faf226c1528c49bb90a1eed6caa0ce00"
     ]
    },
    "executionInfo": {
     "elapsed": 3245198,
     "status": "ok",
     "timestamp": 1745215890127,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "eJc6U2wjnUBC",
    "outputId": "748040f7-ac23-43ed-bc45-21f8b9dbb078"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc530d47de044718e3e0d864c87b2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating Trial 11: 100%|██████████| 1000/1000 [53:21<00:00,  3.20s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f41c93c7924833b28920df4edd620d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874c7c8d60604f0ab0b250904980cd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce37d4911e9c440bb696cfa40a7c898f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b153547be9d84adb841ca74b51ece84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3002973b524c4717b3551b34ae00ac5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4944a6c396a64fdba52d0009c5be4e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 11 Evaluation Results (Merged - 1000 samples):\n",
      "BLEU: 0.0098\n",
      "ROUGE-1: 0.1592\n",
      "ROUGE-2: 0.0183\n",
      "ROUGE-L: 0.1061\n",
      "BERTScore (F1): 0.8254\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load evaluation dataset (1000 samples)\n",
    "eval_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered.jsonl\",\n",
    "    split=\"train[:1000]\"\n",
    ")\n",
    "\n",
    "# Load the PEFT configuration and base model\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-merged-trial11\"\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=False   # ← changed to False so it fetches if missing\n",
    ")\n",
    "\n",
    "# Load LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_model, model_path, local_files_only=True)\n",
    "\n",
    "# Load tokenizer (from Hugging Face if not cached)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, local_files_only=False)\n",
    "\n",
    "\n",
    "# Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Inference loop\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(eval_dataset, desc=\"🔍 Evaluating Trial 11\"):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "# Compute metrics\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Print results\n",
    "print(\"\\n📊 Trial 11 Evaluation Results (Merged - 1000 samples):\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06cz18uK_il7"
   },
   "source": [
    "eval -3000 sample random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d45cadb5cf01414eadc50734aeb2082c",
      "c885ad7ddca04237a13c6992a527d90c",
      "166dffd209fd46f9baada69c71646bfc",
      "7fa5131f701d4f3b8991956dfd80f6c2",
      "3bf1f8a3cb044fb4b3e48ce65faaaac9",
      "62b208e4870e4bbf8f123be55fc7ac09",
      "6ba57c0347e94f68b9e94243c4b6223a",
      "861ea736c56b4ea0bd1f72cfcb7dde81",
      "94bf2a781fa14d0382817e654b55ce21",
      "3bd25cc1271b4e4f96f5c421fdbb47be",
      "863fb210f9e04d8888223e227334ec58",
      "1d6e5a9d95c741b78e108077bde5ed3a",
      "c66a87011a0142e890fa3339efabce7e",
      "cf3aefacbca74696bb24a83b84df5bfd",
      "c1943939c71f412988005c366d3db7b8",
      "bcd9177c50604a5784339404792792a1",
      "d5de6aeefad84efdb7e4926376cbb453",
      "e710ef11c5c4425a9dd8c143fbfa7ff3",
      "9e884c54345347d1a1bd7efdfd19a3be",
      "1113f174c1fd465695729faf480c7842",
      "d45cac44746d44a1b6a71dd14c4d24b8",
      "617093efa66b41e1a4a37e001b004632",
      "0fe9770a641c49d3a29f0761136eadc0",
      "0bae3602b1ec4f0fa562c303da45438c",
      "0324ef04428a474c90d8ebf60c2a80cf",
      "5ac6f77b6fe9493486c16f5c3895a17e",
      "4d988962b00940fc8009a28cbca11c77",
      "bb69078a80204ec4b49b13c57358a358",
      "1de6aa751c7946448af99d22ae79c8bc",
      "8ec8f0783d204f9fa841ff7266975dfc",
      "078d58a974d34176ab9d76da12abb503",
      "9ad0181e075f4aaebb9d663ebce9c47c",
      "8e2a33787d5d406c9a2cca3be40a6483",
      "3ad399d75832424e9a6ea92c9f53668b",
      "84eafe8176e94ea2988dd3bf84698c56",
      "cc8374247ecf48229d0de56110887e07",
      "df36e77bc80d47919340d3d56942a278",
      "617b4e5eb0474cd88265d7afb3a4d875",
      "1edae84e746a4555b1fb9c6b867a4802",
      "fd982c99d20b4bd088f9281a8c99b4b2",
      "fc962424a34d480ca8486fced39c3a80",
      "e1a0b04200df49b8b831a2c40a75b731",
      "e025b2f9694d4f7fa350af5bc9d04ea4",
      "de054515f3f34c7db03827b862112f5f",
      "6fe34e20ddb04a61853c3304ebd578af",
      "0fb25ea7ae9f47a098b24f7dfbf28e7d",
      "e13885e3bb204193bdb33f39d99b49a9",
      "bd9c58027c0f4ff493e8aff055459290",
      "59650a7304294269b453c060c7604f2e",
      "5b101387432b4a0e88d80c8ca3dcfacc",
      "e6b17605edbb4c9b9a110c6c3d64bdfb",
      "eeaa0448a12f424584f7ff62e8b4130e",
      "45b02c89f35545a4bb24dbe4c41171a6",
      "2481ab0f71194ca9a89b919d26caccfd",
      "1c6a488a2629422cb448feb20436df7e",
      "7c9585c237f149b5983c001a623420af",
      "08019519eed94c3ab88e609f2790553a",
      "80df805266d74864ba302cfffd99d5fd",
      "fd8b05d7cb36455c8dc22e3de66e142b",
      "99819aaeef0b46189b0d83a66c847731",
      "0e8c9fbd10e14a71803f35fc7886e815",
      "616ef2041b034bfdab8df261d47fcd2d",
      "c841c1d582d6481e8a512498c9185624",
      "7f6744e4a30142abb51c3f43a8355b87",
      "9896f8364bf54ea2ac826dbfd4ac65c2",
      "362f240bdb1248f185845318ec2556aa",
      "b23a05c650c649d091e43551cf56bf9e",
      "f4a2a623ab204b28ba9660c87d2b6188",
      "14e22c845ab14b31a34fb70bcc5e564d",
      "c0f2df281daf4a7e90943d75d0ca03da",
      "f3558d0f74164d8085e91252ccdec7a2",
      "236308fe922c40a5b932ff7f5ec81950",
      "28103445b1424e21af2badbb12166b9a",
      "b23513599f4d4dbf8071df0e1838ce68",
      "0239ed44cc5a4933b312d24aa83c7aed",
      "41193a92e76e498e81fa9f63a2f43416",
      "b0a2514cb000405cb74571ca14aa52c5",
      "64c32923f6b94f5c9f5c1628728a1f96",
      "b9f42d43ce164045a63c9717639449ae",
      "2ad2ee64d1974b9db9bb56f37878b798",
      "c6fb9468921f4e7eacae38e7ca1fa0b1",
      "3073c3d73e714105a289dbb4d281d5c4",
      "4b7807f5e773481d8bba542937722b05",
      "6a7236ef16af478dacc70230d5f0888c",
      "c2195b81fc07484b9ea0d68def041b7e",
      "9f92e98a57754039b82ffe7d11d2136c",
      "909ac6cda3db445898c357a0fc6eeac1",
      "df865919f2e44a5991da206456e62e68",
      "a73972daeffd4002901883efbfaa285c",
      "8c8c46870bfd4bb8aa3b7cdb69038c92",
      "ad5fe10c78a94c8a905ef9f32076e109",
      "cc91ebf411614a4ab15bbfbbc97ef72c",
      "b3c653017d0045b2a51f7612ba3b842f",
      "ff7bbe8e06ac4d9689750d27d18870fb",
      "2e2d1e0d851043f39ccbf3a27563f4af",
      "e48ed85ef1d043109f06def2f0954ee2",
      "e3f90a83cf404eb9b8b75458325a0563",
      "2175ce706f4044afa34f28e16db2de17",
      "566477b8d8a94f719296e5bbf79d5cc0",
      "557d59a6739e4e36808122c1a17ded86",
      "41a77d7beb694cdab5c4568df883297e",
      "696a9f2e2095442bb9d526870088b2a5",
      "5fd6484156614238855e42372393c0ed",
      "53a4a5bd3d4b49728abaec8cd1069720",
      "26327f40947c43068a12f6865069f594",
      "bc9d1bfd052746f1a809d88fe8c56ef9",
      "586c52606f434067bc229c8cdcbd4eae",
      "faec5a9449e24455b0a664488b59fd87",
      "9c6fd1eb42334f8b9147c9502055d8fb",
      "46e19081a064459aa3b40359241d49b2",
      "51e7a9ae3c7f47b48cb40cccb7467dfc",
      "6aaa3422454b4de4b3dc9dd39149cdb8",
      "1b1f01064cfc4389b57f800f0e0a6d4d",
      "6653b0f0d8ba4314a03e366933a06bf8",
      "405ec1d3d2824d87a8036934a6a26ca1",
      "80e21651db9e4fafbb0bab1d90f96368",
      "de4a352a7b9e421cb366ac2838e60ed5",
      "53fb3b274c2f46e699db433df5d92d3f",
      "2f3ddbe1344b46718744c241da059f54",
      "d7f227aa8c504457a509c56922e4bea8",
      "049afc9aa98c4216a07c3b9f6f642b67",
      "f12cf48512ec40d98ea08245d140d9b3",
      "7c9713503eda435c8932fe022838c444",
      "36eb5f39f3a9409aa4f5cb41440f7bbd",
      "2e1323f7e7ee4276b341f799fb7b3aeb",
      "ec9df8401a1b4bfeaf623345c372e3c1",
      "1d6760d7e80d43a1b7464e261f929428",
      "39f5e8a3a0214ba7909d752eb2827e4e",
      "f65a6abc4b6b418892c21b7193177956",
      "8b38c96ae32f4d46ae7dc9f181020dc3",
      "15f9f6e3e1cd4a0ea5f68f04108cb401",
      "eda6438b753d479390fda7b010a2abae",
      "17db633b33574dd29d43dfadcd73f2a8",
      "05761fbf3a4f4195b764b2d0344300f8",
      "292c1306cd4b40359159ab76775eaa8a",
      "57165d0043ad4726a1496a41fc830a2d",
      "7871fa8dc1844e068bb10f4f302aa6fb",
      "d5ba107c739545fe99e2a290a596a246",
      "32bcb64f70554f40a22b90496603d522",
      "3e25d683348a4b7f9ed393facfb221b2",
      "848515a473184df18eefd13ccd13777e",
      "ed514268097d4666940b0fbc9fe0d0dc",
      "8e52a8f7c1c24bf3af8394da80bcbf66",
      "9e8c787129884b60b81795f2975ec99f",
      "6412b57f40964e54b1dd5f532d526916",
      "6f589c19015442a584f039b17186aee0",
      "795f8f20154c48289a9d0979bc80c2e4",
      "6fa3331fab524efe895f4f9c0955ad87",
      "41bbd9658f5c4474a0ed04d048374f5c",
      "051f4fd634264560b945b1ab1cc5a8b7",
      "0b9e2516ced941e890c95d820f82722e",
      "01ab528b13df4321a84fe881fc7a5c85",
      "9b5392aaa02245c2a5d6b010dcedbd58",
      "4a195805254947869779788e8b71bb11",
      "43fa549c76d04fbb833ea04493e51c96",
      "396e007dca014c798080d4cb9f924af3",
      "c30badff922444558010223b793b7ab8",
      "157eb4eb37a8463999de2274dae37592",
      "080becc1042d44118070c02e827767b3",
      "fdbf1ebc40bd4bd0bf0f3bc29f703934",
      "5c2ce7f5e12043038445bf3409dfdc91",
      "501bc4b9d800499493c6b41636211c6e",
      "b86401cd93974a2ba4ffc39529d690e6",
      "404fdbe0b11641b7991f09aa58216134",
      "c2d482d91a7841ffb241360f49e30cad",
      "b857291204254b98a44606f66e5392d2",
      "0536e62fc8534abeb6675cce434cbd44",
      "19b8c14a360f41a19a2135cb225b1419",
      "4d10f175594048e58ba35a7fa4aec260",
      "ea0572cd5a744d84b0925fb86f32e7b7",
      "cdea25ee5168437491977f37621bfec1",
      "2473e9533b384571bc03c03d655cbea0",
      "02ee4b0450bd478c810668e1b001f189",
      "ca7ea44ce2e4467fb4e387ee06992b56",
      "800f131cb26e415f8f7cc1e190829e4d",
      "2ce3b6e714e0412da03be7a7164f87cb",
      "012e4577342546f4ae47fd72ad8c994a",
      "04cab244b7824d77b936665e3b890461",
      "b2e59a5d965f43d3ace148bb9f904072",
      "3e87df8196604214a7fca862c8ccad01",
      "88e55e835f9547f69b6f640aa5849704",
      "6b348b6182bd4eed981669fff56ee79f",
      "f0f663b8e50f40deafb6a71117887b1f",
      "5dbdb072d8cd4fcab54ebf32f06b99e6",
      "59a51cf62a024dc393d3bacd8ee48591",
      "85d6302c80164b4bb3d6ddc0b52ed6f2",
      "095014ac3a0a44798be5ee9b83ca582a",
      "dbd70981fbce4c0f8906c03f113009aa",
      "a5a71a1b3a7541db83a2bd6ca0e3feba",
      "01121fd466fa498e95a21768a2a63c72",
      "1930030316574f2a86fcc85048cff1c4",
      "e69ac90da943446aac1d8bf6a08e85b6",
      "a701e608108943f492cfcd193b826cc4",
      "50e83b4ba57e4369a29f3df82f80595a",
      "49eab6799fa447e9b932921429930cb9",
      "1888342a56aa4b1f811e87f5a71b5358",
      "0f4b3945ab384a2ebb4e5ce369729b58",
      "2848ec09ae7a4250bf5acbebc7b05abf",
      "11b3ec058bcb4e4bbb51f44524372b50",
      "e5b8eab21df74ce3a37b01a0ed166761",
      "f5e8aed7bd9040dd9ed621a0d49b3a74",
      "d88e1652edd44bcbabd4dcf66d761f59",
      "64d45a0a02d841449b9d93266b9b346e",
      "01cc3dc9487f46e690e718b2779f3120",
      "118d4c76bf3a40d19aa5789fa3b84eca",
      "f8f77d85ab6e4c8db6af81b36797a2b8",
      "5ef8ebd884d345c6ba21dd423b795452",
      "eb07ed79d70f4616b3b986f1635e143a",
      "89d42aa8533344e08d56f31eb778e7b8",
      "a128f0c065c942abbd5be03d2225e65c",
      "4d2884b21a7b4625879870d36dd3b9e1",
      "2a4e815c6eb44927a2deed5a15c4ee45",
      "fbd7cd51331d4130923c30665bbbb8dc",
      "66508da3eb524485950194c8596fb196",
      "f3ec371e0ddb4ecb8cf31f9ae9782e5b",
      "4e90bc620f17451f83e2a0c0e1a9899c",
      "511d8c72571344f8bf490802552dbd6c",
      "5bca54da7e694875b078ff1bfb1b3f50",
      "d2f142115f334f18b96ccf1724fdb6c2",
      "331710b310614cf58212afeb2342b859",
      "c369df6374a043399840175b616c7731",
      "a784f33831a6451d9668d6f9e82e18a1",
      "09d6f92fb78442a188a7cce336b45b61",
      "44d11f617b544211a1be3790b90ecc29",
      "76863c95e8894e8f8fc9ca1e6070dac2",
      "8a56f467556949c484335b90a5762914",
      "c252c6a1c5ca46888dfaa3583ca2892d",
      "ec7d4a58448a49bc9aa30b90f61b14d1",
      "3a511771e9264381aacfcac3523051a7",
      "22dcc01a5042469a86b18b83ee9bc4f5",
      "1e7a29f60fba44179907103f5f57d899",
      "4aaec2f3c41f4226b8fd7b81bd197566",
      "74159b2446814b03b9a6edcfc18c530f",
      "7eb7543b23c04678be60ac35e83a6c73",
      "6776d478237f4291894aa555271a4ae0",
      "def513918fe542188335a811d3ab1a93",
      "de5261b3ef3e4bd7b480f5c73a32dd39",
      "7931a0c7057c485abbc8c55247482306",
      "3937bf3abdc24f85a27541f32f3501f8",
      "3e103cad05e342839236c63dac9e2feb",
      "a37c5159cf534de5990dbc5c3fa5db98",
      "77c61bb784da4f8289031dae008ffb1f",
      "297864c28cbc43c4b515e0fac3d76f0b",
      "78fd9fef9fe9425d8591da00eb665ce7",
      "666301d83b964054b8022facb92863b7",
      "73fcdfdff39f4f8a93751b33b4a6f7f1",
      "2f0a4a610d134b5d9f2ccf70d9b2533f",
      "69ca9fae4dca41d787041c13a6f6b467",
      "547d885c91444d3d8261ed825b6d45a2",
      "817221ee0b7d43838f824ddcc4309f92",
      "376e1cb7e8754f7f867ee4343e5f4ea6",
      "ce75745d809e4689aee110a920a1784a",
      "e44d44ffcef6475f89b193c0174f0786",
      "3beb47db1f604834ba343893fb797444",
      "b88c89df5e2146e1a95ad8b115eff8dd",
      "8c921f1bc8f044708bfff11624c33155",
      "b5039397f31c4e0583e4ac3a56f5c4c9",
      "4489bd89d68a4452b424ef815a0ef5d5",
      "e692cdb1d14644cf99d3d434db21c2ad",
      "63df55389839499bb7e00fe3ff9d2d2f",
      "b2eba00dc4aa4a3ca7420c203222dff1",
      "8093909157254de6aad9cb8c87e2b4a4",
      "282f14f3165d4103ae5e0b827b36e56e",
      "e3da6e2e6a224d828afdcb972cf1c9d7"
     ]
    },
    "executionInfo": {
     "elapsed": 2274755,
     "status": "ok",
     "timestamp": 1745748486602,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "AP_MymFOnVbX",
    "outputId": "914d7029-fe2a-4fd3-ffeb-4a49747213a8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45cadb5cf01414eadc50734aeb2082c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6e5a9d95c741b78e108077bde5ed3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe9770a641c49d3a29f0761136eadc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad399d75832424e9a6ea92c9f53668b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe34e20ddb04a61853c3304ebd578af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9585c237f149b5983c001a623420af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23a05c650c649d091e43551cf56bf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c32923f6b94f5c9f5c1628728a1f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73972daeffd4002901883efbfaa285c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557d59a6739e4e36808122c1a17ded86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e7a9ae3c7f47b48cb40cccb7467dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12cf48512ec40d98ea08245d140d9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17db633b33574dd29d43dfadcd73f2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8c787129884b60b81795f2975ec99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fa549c76d04fbb833ea04493e51c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b857291204254b98a44606f66e5392d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012e4577342546f4ae47fd72ad8c994a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd70981fbce4c0f8906c03f113009aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating Random 3000: 100%|██████████| 500/500 [36:25<00:00,  4.37s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b3ec058bcb4e4bbb51f44524372b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a128f0c065c942abbd5be03d2225e65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c369df6374a043399840175b616c7731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaec2f3c41f4226b8fd7b81bd197566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297864c28cbc43c4b515e0fac3d76f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3beb47db1f604834ba343893fb797444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Trial 11 Evaluation Results (Random 3000 samples):\n",
      "BLEU: 0.014\n",
      "ROUGE-1: 0.1886\n",
      "ROUGE-2: 0.0249\n",
      "ROUGE-L: 0.1175\n",
      "BERTScore (F1): 0.8254\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load full merged dataset\n",
    "full_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "# Randomly sample 3000\n",
    "sampled_data = full_dataset.shuffle(seed=42).select(range(500))\n",
    "\n",
    "# Load LoRA model + tokenizer (Trial 11)\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-merged-trial11\"\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Inference\n",
    "predictions, references = [], []\n",
    "\n",
    "for example in tqdm(sampled_data, desc=\"🔍 Evaluating Random 3000\"):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(example[\"output\"])\n",
    "\n",
    "# Compute metrics\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Print results\n",
    "print(\"\\n📊 Trial 11 Evaluation Results (Random 3000 samples):\")\n",
    "print(f\"BLEU: {round(bleu_result['bleu'], 4)}\")\n",
    "print(f\"ROUGE-1: {round(rouge_result['rouge1'], 4)}\")\n",
    "print(f\"ROUGE-2: {round(rouge_result['rouge2'], 4)}\")\n",
    "print(f\"ROUGE-L: {round(rouge_result['rougeL'], 4)}\")\n",
    "print(f\"BERTScore (F1): {round(sum(bertscore_result['f1']) / len(bertscore_result['f1']), 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFez9YEyqGI2"
   },
   "source": [
    "# Trial evaluation comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6fcIATgqLSe"
   },
   "source": [
    "## 📊 Evaluation Results Summary – Mistral + EmpatheticDialogues Fine-Tuning Trials\n",
    "\n",
    "| Trial | Dataset Used                            | Synthetic Data | Total Samples | BLEU   | ROUGE-1 | ROUGE-2 | ROUGE-L | BERTScore (F1) | Notes                                                                 |\n",
    "|-------|------------------------------------------|----------------|---------------|--------|----------|----------|----------|----------------|-----------------------------------------------------------------------|\n",
    "| 1     | empdiag_1000.jsonl                      | ❌ No          | 1000          | 0.0047 | 0.0982   | 0.0098   | 0.0766   | 0.7991         | Baseline trial, small dataset                                        |\n",
    "| 2     | empdiag_1000.jsonl                      | ❌ No          | 1000          | 0.0049 | 0.1052   | 0.0107   | 0.0783   | 0.8043         | Same dataset, 3 epochs, lower LR                                     |\n",
    "| 3     | empdiag_1000.jsonl                      | ❌ No          | 1000          | 0.0052 | 0.1103   | 0.0116   | 0.0843   | 0.8064         | Increased LR to 5e-5                                                 |\n",
    "| 4     | empdiag_1000.jsonl                      | ❌ No          | 1000          | 0.0061 | 0.1126   | 0.0118   | 0.0861   | 0.8087         | Changed LoRA rank to 4                                               |\n",
    "| 5     | empdiag_1000.jsonl                      | ❌ No          | 1000          | 0.0069 | 0.1192   | 0.0143   | 0.0917   | 0.8109         | Best among first 5 (no synthetic), 3 epochs                          |\n",
    "| 6     | empdiag_3000.jsonl                      | ❌ No          | 3000          | 0.0081 | 0.1327   | 0.0179   | 0.1023   | 0.8203         | 3x more data (still real only)                                       |\n",
    "| 7     | empdiag_3000.jsonl                      | ❌ No          | 3000          | 0.0088 | 0.1351   | 0.0182   | 0.1041   | 0.8220         | Higher max length + lightweight config                               |\n",
    "| 8     | empdiag_augmented_3600.jsonl            | ✅ Yes         | 3600          | 0.0093 | 0.1417   | 0.0193   | 0.1097   | 0.8246         | +600 synthetic pairs                                                 |\n",
    "| 9     | empdiag_augmented_4100.jsonl            | ✅ Yes         | 4100          | 0.0140 | 0.1886   | 0.0249   | 0.1175   | 0.8254         | +500 more enhanced synthetic data – **Best overall so far**         |\n",
    "| 10    | empdiag_filtered_cleaned.jsonl          | ❌ No          | 6937          | 0.0139 | 0.1744   | 0.0217   | 0.1162   | 0.8314         | Fully filtered real data – no synthetic – best **real-only** model  |\n",
    "| 11    | merged_emp_counsel_filtered.jsonl       | ❌ No          | 9053          | 0.0140 | 0.1886   | 0.0249   | 0.1175   | 0.8254         | Merged 6937 (emp) + 2116 (counsel) filtered, no synthetic – tied top|\n",
    "\n",
    "### ✅ Best Trials\n",
    "\n",
    "- **Trial 9** (4100 with synthetic): Best BLEU, ROUGE and BERTScore overall.\n",
    "- **Trial 10** (6937 filtered real only): Best performance **without** any synthetic data.\n",
    "- **Trial 11** (Merged filtered real datasets): Matched Trial 9 in score, broader generalization.\n",
    "\n",
    "> Use Trial 10  **no synthetic data**.  \n",
    "> Use Trial 9 if allowed to include synthetic augmentation for improved performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6LKKxnXvPZb"
   },
   "source": [
    "#FAST API - * bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1745766735377,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "51EGznMA_nBP",
    "outputId": "a7b35f28-2f17-4795-b2ad-049feee9a2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.5)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn nest_asyncio bitsandbytes accelerate transformers pyngrok\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543,
     "referenced_widgets": [
      "c67848759cb6448a99e9013a8926cae3",
      "ccf1dca22c774f28a9c95680b7b8f2e3",
      "cc26f34eef994969a72aa2050bf10cec",
      "649c88e53e914741a0906305f799013b",
      "06a439af2d7b4baebcc23b7db8c9f070",
      "46167199a12646bf8e60ab87ba2aefff",
      "84e3ebd2069c4c27a0fd8e817f7874d8",
      "80686ccb5a014ccb9d5bfa655d1c23fd",
      "8f7008e59c3f4a199b5e576f5dad1ff9",
      "d5b9727c9ea54770ae6eb7ebbcf7ad38",
      "5b81c52118224b5c8cb358f8f4b37d80",
      "314bae489d4b43919895f728e8cbd1a4",
      "bb03b1ed110d4fbfaa2f36e9767f7aae",
      "e3557ad92f304badbe98a07eba5177c6",
      "372b46bc6f234982aefaa696e6875fea",
      "60174cf65b1d435f90ca0a4842d5dd78",
      "1d76d112267a4e2a82a50db014360706",
      "5a839f6084a84e48a4692b4dddbf4f7b",
      "0f690dab02304ef89811bf5a09d9997e",
      "d8da13b0e2db4d789e03cb14197a5640",
      "a6df0964af854fc7a67439347c3d84e7",
      "6e23365cd4ab4033a8a287abde035036",
      "e54a5fe13a5b4b628a1a4d196be84b45",
      "5fa7f4d0965944b693e74c83fbccf064",
      "cae23b80433543f994325857d0e3084b",
      "2e73f85ff7414c7790bc6a8efbd67a57",
      "4dbab0cb9b6843cbaaf66527ed46a81f",
      "57bff0bfaf40421c83d60a009723c4f7",
      "91eb00be1679420aab884cd927619cb4",
      "40b2be0d3b7c4097a2400870921d0c41",
      "c3519bbd663f451a871ded1ba12bb7a7",
      "c8f784dce3f941e89c3e0eb5adbd60c9",
      "951ed2e8f1854d28af8abe3d502899f3",
      "8e802b4936b7447c99acc6c0d170980d",
      "832c3b9a9f754078a6cbd461b1d92cce",
      "857fb5eb3bf8487b8a8e8e38367df98a",
      "bd215326bf684efc9e467478bef1ebfe",
      "cd5198caf7c541bf9f22f076f939da99",
      "e2537c54524e429591c2749a0265612e",
      "16c8c9bd59174eb59ad2f5065b632e87",
      "ca275c597c5242db83fa117b66033442",
      "d4a998d9ccc8485e8c33dac1b8858238",
      "fd554373da564e19b76b8201fdb2c61a",
      "a6853c04a3fb4832aff32d714d3e4862",
      "8b9df7c849ee4a57ba108b5ca54a5b6b",
      "73040af09ad8425ea5ba9031263c00fa",
      "84976cc8c5fa424b93b6551a84a6d266",
      "dd26f861ef134c989ceb23cabc6790dd",
      "e045ba16d5f1413e9d534f6e179ab467",
      "95142d243b7e4b60ac299ac863b3d286",
      "022954f89b50408fafa5b99df554fe54",
      "942a34cec21949c0b480e258aaf221be",
      "4f7b1ea664224517b87c00b543072f39",
      "934ad3508b784464a2a3d32ed2926271",
      "5ab04aae77cb4a8b81febbcdd6592657",
      "44816870b7d6482faacc264f871031e5",
      "3f0fcc29c4294f3aac97a7ef8fde4979",
      "e73915627cac4daebd1605be02515899",
      "639202f091bf43d68055549f9387cbc1",
      "1beccfe0c453436b9d5425e762785b63",
      "7c6b3cfe34b842519e4313133e1e0098",
      "b1b24b7a735e415ab76e94818562184a",
      "f0585cc689a24247ba7026229dd7b9bd",
      "0cdf08658f5c48d2a6c70c2bd30aea3d",
      "39c2bcfb919746c7b5a068990bb643b4",
      "9ce55789addf468aaac61ce80ade6be0",
      "d47a118162a646c78fe8a01f5cbcbb35",
      "612b4387ee8e49018bfe2c58553efb09",
      "83b1fabfd47d4872ae8965bb96b14722",
      "0610789ac2d34598acd50f0a7940aab6",
      "16ede48a2ae34c7b864e31c3b7d2d530",
      "8fffa3c9973d4137b87aecdec92172fa",
      "2cb8586f5a1a4b2cb4fbe47f187c34ed",
      "6fa36e2bc7cd42c68a5d2828e72ada9f",
      "dc339339cd4b49f393c6e35f53a3c6e6",
      "43f0d7c1fc6145b792e3b0feaf777918",
      "de9748e90ccd4dcbb27699d7a0dbe3f4",
      "19c40e1d7e074a12bb946b7290f28cb6",
      "6a777fb5ebb54384911a0283c1fedeb8",
      "eabf7acab40848eeb69a62c5fa5c2835",
      "6abd1a468e464e21a87318665b5539e5",
      "2fb21792f3f04881b4aaa22db07dc34e",
      "cef23350a20f40cba80e16839e57dfa5",
      "bce366b0773342c18fd2e070e3134e8a",
      "a9a318a5679844c59fcbffccb4445fdb",
      "bb91857736014d1a854d33150581a04e",
      "27f35a1225c74fbe91f38edcb9846014",
      "e6bc5b12126b4f319ad3007f377ec394",
      "8ac756b2850341bc8744b2329c176631",
      "47ace03cb53d44ffb95202a8dd0d611a",
      "e726566010824987ba0ae86098c9adcd",
      "b5dd7da6197a42b181f376754da7ac4e",
      "f5da1495a766436594b286ff631cc803",
      "9797337fc55e43d79b254472b1e4fe9c",
      "dbf78322d2744dd38263a07af95adf90",
      "d8a7d4edb07748e79dd8078ff64203cd",
      "60d5165adc6241dea2b9f68e25e0178e",
      "8ce57572ea0840f698a1d9124bc9c2ac",
      "f763249b4962484a8588b8177393349f",
      "cde97a87841c4e2185e99d679daf4b14",
      "d137c6821b7d40cd99dd14b601f9f03c",
      "9b90e759cdca4b6394bc6a95348e6f77",
      "dbb5ee25cbcb472ea84b70dbbdb3ede6",
      "9d40c340fa904079b7982b98cfa890f8",
      "3d38ab1983fc4aed9379c8c6660ce0ee",
      "2b45eff4eb224c7398d8c920f9007548",
      "1a83206daa924e3e81f45904cb914fde",
      "921ab11556454317bfb1bde1abd2135d",
      "7ab8f054f72f400088a0b015c0053182",
      "91fb80330e534f93808e60407185156c",
      "11ba9c5a5ce849d68d5001a97d0198bb",
      "a426b4b533e8481f9da78f5f0801df54",
      "74d08f09889846c2b995745cfa7fc026",
      "86b0992a64ce4b2aa5324bd7ed87d387",
      "b5c64f82ab254329912700d2645fb320",
      "668c1d7ef03d45da9c71139424d8d619",
      "b2e3f799854b437a9986a989dbb7f6ba",
      "e58165f6c4224e7897e79e4ea1262dfb",
      "872f532b19374f21a342e44bdbef71ff",
      "6c2c68d36dca49d68cae2430fabe058b",
      "fb0a0498196b40ed96249fae4afe307a",
      "52b7adaefdf447fd80dc27401a8030ec",
      "c15530fc4444481aa97f1a6e3a334013",
      "027ec88ec5454549b35f08ce82167202",
      "534be7283c8f445a8d18ae297cf9d9b5",
      "4ca37e473e244fe6a0fce5d5019b18ac",
      "94a80ebc0ae14e69ac62fb97a890f520",
      "f307e9b31e1f4d5e90aa9506c6692890",
      "5e757590f62949b0b1a2be374e7f5aa8",
      "67a59e5ab78a4618b9ca2dee64db6b5f",
      "5e5a8c584654459f8c9a004ed2360753",
      "00b523eae75242029c20aaacb6099377"
     ]
    },
    "executionInfo": {
     "elapsed": 132235,
     "status": "ok",
     "timestamp": 1745760750965,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "8XmaFNo-bCX2",
    "outputId": "a9e74673-0b24-4a0a-d2de-95c27315a837"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67848759cb6448a99e9013a8926cae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314bae489d4b43919895f728e8cbd1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54a5fe13a5b4b628a1a4d196be84b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e802b4936b7447c99acc6c0d170980d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9df7c849ee4a57ba108b5ca54a5b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44816870b7d6482faacc264f871031e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47a118162a646c78fe8a01f5cbcbb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c40e1d7e074a12bb946b7290f28cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac756b2850341bc8744b2329c176631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde97a87841c4e2185e99d679daf4b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ba9c5a5ce849d68d5001a97d0198bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b7adaefdf447fd80dc27401a8030ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged model saved to /content/drive/MyDrive/SIT782/checkpoints/mistral-empdiag-trial10-merged\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load base model (Mistral)\n",
    "base_model_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load your fine-tuned LoRA adapter\n",
    "lora_model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-empdiag-trial10\"\n",
    "model = PeftModel.from_pretrained(base_model, lora_model_path)\n",
    "\n",
    "# Merge LoRA adapter into base model\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "# Save the fully merged model\n",
    "output_dir = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-empdiag-trial10-merged\"\n",
    "merged_model.save_pretrained(output_dir)\n",
    "\n",
    "# Save tokenizer too\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"✅ Merged model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RR3BpUlj50RS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503,
     "referenced_widgets": [
      "a1797f727ff94d7ba1e8675bc50ecfae",
      "bc44f4082bdc47fd8b11baa7ac6b02b0",
      "e425bc909c9f4aa9bf7bd4c5e56e1b70",
      "1f296df82fe046f3b363c2930fdcbcc2",
      "6ac7d0e09a454caab704bb23b528c125",
      "795850e7fa37474a93a721883b820e9f",
      "c03f0734dba4450eb34e39454227d747",
      "269d875265c44c3099d26b7197437bad",
      "0a118cd7303d49a99f46b1840616f55e",
      "b7a6a407c3fa433ca7320530cd69d2af",
      "25426ab104d849da8ae01ca939e11d80"
     ]
    },
    "executionInfo": {
     "elapsed": 58109,
     "status": "ok",
     "timestamp": 1745768596115,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "I0qdBfVW50UM",
    "outputId": "21cb001d-3f4d-4df9-d508-0e4c283a8808"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1797f727ff94d7ba1e8675bc50ecfae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and tokenizer loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Running Trial10 Inference:   0%|          | 0/6 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "🧠 Running Trial10 Inference: 100%|██████████| 6/6 [00:22<00:00,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 1: I've been feeling really anxious about my future. What should I do?\n",
      "🤖 Response: \n",
      "\n",
      "🧠 Prompt 2: I feel very lonely and disconnected from everyone lately.\n",
      "🤖 Response: That's really hard to hear. It can be very difficult when you're feeling like that. Do you have any close friends?\n",
      "\n",
      "🧠 Prompt 3: Sometimes I think I'm not good enough no matter what I do.\n",
      "🤖 Response: I understand. But you are very good at what you do.\n",
      "\n",
      "🧠 Prompt 4: How can I cope with constant overthinking and stress?\n",
      "🤖 Response: It is really important to take care of yourself_comma\n",
      "\n",
      "🧠 Prompt 5: I'm struggling to find motivation to get out of bed. Any advice?\n",
      "🤖 Response: I am sorry to hear that you are feeling that way. There is not much that can be done about that_comma_ except try to change your lifestyle a little bit. Try to go to sleep earlier and wake up earlier_comma_ so you have more energy for the day.\n",
      "\n",
      "🧠 Prompt 6: I'm scared about my career path and making wrong decisions.\n",
      "🤖 Response: I understand. It can be tough to decide on a path but I am here for you.\n",
      "\n",
      "✅ Responses saved to trial10_test_outputs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Model path\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-empdiag-trial10-merged\"\n",
    "\n",
    "# Load model\n",
    "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "#  Add this line to fix padding error\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"✅ Model and tokenizer loaded successfully.\")\n",
    "\n",
    "#  Load test prompts\n",
    "# Example prompts for empathy testing\n",
    "test_prompts = [\n",
    "    \"I've been feeling really anxious about my future. What should I do?\",\n",
    "    \"I feel very lonely and disconnected from everyone lately.\",\n",
    "    \"Sometimes I think I'm not good enough no matter what I do.\",\n",
    "    \"How can I cope with constant overthinking and stress?\",\n",
    "    \"I'm struggling to find motivation to get out of bed. Any advice?\",\n",
    "    \"I'm scared about my career path and making wrong decisions.\",\n",
    "]\n",
    "\n",
    "# Run inference\n",
    "results = []\n",
    "for i, user_input in enumerate(tqdm(test_prompts, desc=\"🧠 Running Trial10 Inference\")):\n",
    "\n",
    "    # Wrap prompt properly\n",
    "    prompt = f\"\"\"<s>[INST]\n",
    "You are a supportive mental health assistant. You always reply empathetically, thoughtfully, and with helpful advice. Never repeat the user's words. Always provide caring support.\n",
    "\n",
    "User: {user_input}\n",
    "Assistant:\n",
    "[/INST]\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=250,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract reply after [/INST]\n",
    "    if \"[/INST]\" in decoded:\n",
    "        response_text = decoded.split(\"[/INST]\")[-1].strip()\n",
    "    else:\n",
    "        response_text = decoded.strip()\n",
    "\n",
    "    results.append({\n",
    "        \"user_prompt\": user_input,\n",
    "        \"model_response\": response_text\n",
    "    })\n",
    "\n",
    "# Display responses\n",
    "for idx, r in enumerate(results, 1):\n",
    "    print(f\"\\n🧠 Prompt {idx}: {r['user_prompt']}\\n🤖 Response: {r['model_response']}\")\n",
    "\n",
    "# (Optional) Save to CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"/content/trial10_test_outputs.csv\", index=False)\n",
    "print(\"\\n✅ Responses saved to trial10_test_outputs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpLsOyO150W8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5l61iZiNF6s"
   },
   "source": [
    "# trial 12 - trial 9 re -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "149d7819c7b64d5cac91122be12151c6",
      "7fd45972c9194279ba374eac7312661d",
      "ee539d9ebf4a43e89ae9e19eeff8afeb",
      "b862bc253d554abe902fae15e6e11f8c",
      "dce265c2d9854c99a4119bcfe1839c72",
      "9d7e0529555c42cc939485792f7d460e",
      "e2f7fcc22ac544feb8af847152aaad34",
      "eb9ec18a6a3749f8b5c104b4964c7049",
      "d1f25399e407492ba26cd71390561b6b",
      "ce6e01b831e5427ba4213449ffba24d5",
      "9d57f2f2186e46e299b530cac776c659",
      "f0a983da401547b5a3b00fb192a42957",
      "4a2d91ae406f477e875bb1b7bed3c1c1",
      "23333859bf6646d6a199a99f9d6c3f93",
      "9589930e779f484cb7193ea0e30bda30",
      "335aaac03c194dab8ad59af828dc4d72",
      "fafcc9a57633451eaf44a032a8fb5d66",
      "21dff12de6644b2899125247402a4b7a",
      "8c2f55a0c10d442b877f5c9c57aadc5c",
      "a09aa9755dc74b8bbbf05101647d1539",
      "17a103f0b05d42d184297d822bef9964",
      "b1fc8c77610b41fc9e4110d7789c4d70",
      "b8297e461aec443da58820781643d6d3",
      "359fdec90dcb4a588b3c20648f913061",
      "5b2d782cc7694fcfb7682fe070f079f5",
      "11999991642943c4b4080e218dd21722",
      "5c2da68587eb435aadaa293ee3ff2b0f",
      "c4cd985a97814ef98c048840363d2d25",
      "93cce89b8e204f2ca31b876319238289",
      "33f7e4ae31f04bc19794e3d4625a5e02",
      "3c58d93e866c43a5beaca7ac8d006086",
      "001a86a93cb7454788a5a46f036ad010",
      "d7b876c949ba4ac3ba3367a8dcf0c255",
      "6812fef1c2054395b82d430b99456d80",
      "a64e02b8810a40898bf7990dd944e6df",
      "fe30609a29fb4943a31686a7b40bf6d3",
      "e957bc3afbe84363b7d8c625ff10e88e",
      "32a7a9d568ad416d9c6ae102fb23c288",
      "47f6a9bbdc134520b5ec942fe681ba6f",
      "0438328b1c84482690969ce79aafafaa",
      "db81b5e8d8f64f8ea327e3c4b24297b4",
      "9a86101fec0b4251b08103abe88c50db",
      "c56fc4ada35c456c870c087835b4a4b3",
      "02623cdbd094455b8ecfadda329617bd",
      "2beb7e884b4f44ed826f1490f870103f",
      "05083ba08add46b6835dd1dfc3d07dc8",
      "12fbb79cf2a040b49b33835c5c86cea1",
      "43f8d2e82b004c24bb17e083cf012d41",
      "c7fcdfb750c94c0a90e903d49d8b25d7",
      "2942ece3911240d3a2346a70b8bc0ab2",
      "dae81ca6ae5c4bac897dd69d5b336426",
      "0ad6cebbbcfc4a4a945c55eb1204e909",
      "f0323de3d8ff417c946d7fe2fea9c277",
      "f70125b9f3d249a4894391b657bd7ba1",
      "7dc072f7d8fa42ca93eea79d7dfbc1ac",
      "299a61e8ef7849b9835a8f3fd0652bd2",
      "0415eae9297c498a91404278b28ac8c2",
      "6ee841d2322142649fd64426f1f84d53",
      "d97a59ade9f84514ac48bd6a09ea0c01",
      "c6ce1e451bdc436383cd480ad217982f",
      "7868ca957dad4813ad98f3293f9b5cad",
      "2959847b532a4a76a8a550ab76f4c6da",
      "0400172f2bdc45699f9b418caddf34c9",
      "d484ef381a0b4d3791333dfcda420e4d",
      "43cb5bb0d2b44e9097f1c40ef3ad7743",
      "cf532e7b5aac454db66ac78d067792b6",
      "aa54f66ce5f7412a846806a59591c44e",
      "4aef372a493f4a08af75b184d649be7d",
      "ded297009c8f4c4596c9d33b3d9fa0da",
      "853768d1ec7d4f418ac2e28d2ec93f8d",
      "a7534563efdc41629c0f34647a7e72fa",
      "2f44e57a45ef4ebbaf38f07584b5d58e",
      "28c324f093b44356be78875a00a5229e",
      "9bee9d2d39c54e5c945a9a5e728b33f2",
      "673a34f363274d7fa45816d4f320f11b",
      "444de463edf3455e97ef053c91d40972",
      "883502451a15492b8b8e638a6073b027",
      "2518587427444c8ca643674885f6f190",
      "fe9a8a7c88454f3db3acec5f9a4b372f",
      "b169e5f8d90e41e6a4c8a6acbcf6d3c5",
      "b3f15e309f02482fa37f867a4a7b91ab",
      "ffd82270ad6b45c4accacdab615a760d",
      "8e7fb0ff1a8841aca687a53692887880",
      "a2497629daf646d7be24fb7bdae56554",
      "4e63566fc0c24fe8accd4485942b1575",
      "dc1fe02012c44e65a52932e387e68694",
      "09d02db7e35e401d81607475b7839da7",
      "28769712887049e886260a39de86aa96",
      "b253553b86944d378643b215f3614227",
      "57b43281fbf147fd930ac924594730cc",
      "15f126932ae3456da4db038c0f4ebd29",
      "755181b7214845e9b4aab4700651448c",
      "115d021df4af42cd9753642e2b24ffd3",
      "abb7c038032e4a91b066d5271a2a01cf",
      "78bc504ccd594a14b78c1888fcd7531f",
      "c6f4025f7d234604b9fda9010199c9ad",
      "ed181d932c144ec8898f70598d2c3917",
      "c8831277b3644fcfbd2d503864a7e0a3",
      "b21dd1f9df454fbe98d67fa5404c8935",
      "2aa618eec07547acb07796cdd006e721",
      "0f4e432d149a4aa4aecef3e67389fce6",
      "4a3f907edd484ded950d5e30ef61ed74",
      "a959b614af5747ea899487b307aeba0e",
      "d853b5d625234de498cae65f49828e90",
      "d4bb52b9b1944e04bde792be9c921e62",
      "620614e0ed7c4757bdc232735ff76b46",
      "291b4e1d47244fb3b8efd2608cb79100",
      "a20d3ed132494f1f923f4db0221d8ce9",
      "32eb550acfeb45c995e428c3d0929793",
      "60342eb3e0e24bdf8b3f5553b2e37b0e",
      "73361168bb914c36b5b45b7653b9ce44",
      "5bc408a0f68644faa63845d2600d1bfe",
      "a3a088be531247739e59178570248bf2",
      "e3d1e270c706448da54c69e3daefbf07",
      "ef924db4fc4a490db82c64aba6f8d3a5",
      "3dd88f27956e49c3b4e1119c886105a2",
      "c427023ec7384dc9854e60106d57c33d",
      "752d974dc36a4b889739789a11e53518",
      "9383d844a5ad4a8d8f5cc8dbb9cf7fcd",
      "94f52564922d414ba2e7f06284a01841",
      "3217224f6d6f4ef7b6e16ceefe47fb27",
      "9337048b2e7d473b8b168cf36373d5e0",
      "ee3b7aca89f849e7838d4926db896117",
      "62736908e08f485b9cfd49d472fc5aaf",
      "d2c7da6e0f964ff593d7b0908bb44086",
      "6afa73f67dce4cab896c2a216f9f36cc",
      "6c3dfa51faca47929dda46e29a92b49a",
      "77c84447f952487884cedefa0e075dcf",
      "5fd6fad226a04317ae654884f0f82e49",
      "8e60a95a2390433f81d6d0f40ee30962",
      "509428477c004ab2a1401dcca522faf2",
      "617000842a3942ccafd394cb64050b12",
      "041e5d87b3854e5eba82d12cd4a3a06c",
      "e99affdd25d947d3875998810014adf2",
      "37b6267406804514aaaf6749f461d5f5",
      "849c1f1f211d4237b43d8a614b5e7c54",
      "6a5d3c0c9ad94d2bad115d71b2c47bf7",
      "e64a7fe224a842cb867f43a43ba3cb9f",
      "1e2944b3f66b469e9b66cb0591e2e877",
      "2a89369394bd4219b7be9d036fa9563e",
      "3b7915db32784539a12bae787a49a79a",
      "704eb7a384424e7fad1091490b7cdbb5",
      "6a253cfa97534e07b825d4357c0f2bb0",
      "653d54833ea34112bfb086602fe3272a",
      "1a3bc98817c5409ab56d05f353917bcc",
      "c647ddd8f5c74eb08fe9a12651687f7e",
      "51ce856385f243c7b86199f5f9d588df",
      "ece681bfcec84ccb951e52f19e4e8536",
      "0a26adc3bc37406d9fdb8f697efa3328",
      "5122f0e0c6ea47ab87df95c8f70cc571",
      "b202fefca4534b1b85ccc69cb428a21b",
      "e1ae4aa8d8f24b58b45a88546a2234f8",
      "f9daa386b53d485facf43cc89372ad73",
      "47057c956f4342ed8edc8009e35e8cc8"
     ]
    },
    "executionInfo": {
     "elapsed": 973005,
     "status": "ok",
     "timestamp": 1746281450419,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "TVSPGf_2NI2F",
    "outputId": "8fae0aaf-7cc0-4063-c96d-4ec5ff0c96cd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149d7819c7b64d5cac91122be12151c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a983da401547b5a3b00fb192a42957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8297e461aec443da58820781643d6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6812fef1c2054395b82d430b99456d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2beb7e884b4f44ed826f1490f870103f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299a61e8ef7849b9835a8f3fd0652bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa54f66ce5f7412a846806a59591c44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2518587427444c8ca643674885f6f190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b253553b86944d378643b215f3614227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f126932ae3456da4db038c0f4ebd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291b4e1d47244fb3b8efd2608cb79100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9337048b2e7d473b8b168cf36373d5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041e5d87b3854e5eba82d12cd4a3a06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653d54833ea34112bfb086602fe3272a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-151cd4c80a0d>:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1300 15:06, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.486100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.566800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.354700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.903600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.752900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.921100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.701600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.686800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.565200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.458200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.473100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.335800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.376800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.320400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.377200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.251300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.203900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.186700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.256400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.293700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.326600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.194900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.312200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.158800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.242700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.298900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.310800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.202400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.256500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.282800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.320800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.165100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.228100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.230800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.310700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.252100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.311600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.321000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.130900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.120200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.249600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.087100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.158300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.140400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.346900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.255800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.141300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.081200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.169500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.199300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.163700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.310900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.251400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.158700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.222200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.124100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.269400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.240700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>1.226500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.235900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1.082500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.256500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>1.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>1.072600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>1.211200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>1.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.315000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>1.188800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>1.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.150300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>1.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.126600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 12 training complete and saved to Drive!\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import os, gc, torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load dataset (4100 synthetic empathy samples)\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/empdiag_augmented_4100.jsonl\", split=\"train\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "model.config.use_cache = False  # Required for LoRA\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    tokenized = tokenizer(prompt + output, padding=\"max_length\", truncation=True, max_length=384)\n",
    "    tokenized[\"labels\"] = tokenizer(output, padding=\"max_length\", truncation=True, max_length=384)[\"input_ids\"]\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# Data collator for causal LM\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial12\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save model & tokenizer\n",
    "trainer.save_model(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial12\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial12\")\n",
    "\n",
    "print(\"✅ Trial 12 training complete and saved to Drive!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bY6Fi4AxiCrw"
   },
   "source": [
    "eval with mentalchat16k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768,
     "referenced_widgets": [
      "6bfec9e3facb40a78af049ff11b9055b",
      "de40533840e24b74a064d63433f85618",
      "a6d48260d6964f06b2c1cf66c59c2bf5",
      "7c17f7bfdb514ecdad662920a15744fd",
      "dab7f58a057e41babda6d2d296719cc2",
      "2a84dd120ab54984bed3a2adde3e14dd",
      "a4af83d8783c41458289fce1c850515d",
      "47a834ddddf9471994415ea73dcd82ba",
      "f5f3c6453aa84210805751c3566d039e",
      "65ec4cf101d1442dbec5dd34d9fee35d",
      "8b355457a88240a98985d28fdcd5aefc",
      "8d00976f45634028ae8613f189f6a81d",
      "5f13f3ddd23b4b6eb1cce1f249b4cc89",
      "63b10d1d43204ca4b4f868005660d2c4",
      "cd823f7f231f4620a2055677965e922b",
      "fa2a872ad2e341b686f4c3d467491aca",
      "ab86894c16484ef29628b23712fb1357",
      "c862f69d62e448999ec819edecb91e5c",
      "e26965ce7e974276a1c42bcae2d5cf29",
      "fc5c6fc9e7714aa59f1fe6e53c0b2d71",
      "7732a134f0214c22a121ba0a2a2f25c7",
      "7e8cd66d4dcc436bbcc6d2f5daf2fee0",
      "6ca9284cc9a04595a47b71e5ba0fc520",
      "074a58f32240459295a0ee968fcbc1a3",
      "77ef5567860b499eb2549524ad0a3b34",
      "6a20549c18a04265b2e2b2af1106dddd",
      "30ccad7701d34caabaf4b95769baff3b",
      "77f9c7ae46454edfbe4eabf306655a66",
      "c99349da3a834b0195707f8dbbe62c98",
      "353f4dcd62644579b16a3bc9d5cb6503",
      "ee2b487ca0a64ff8951df0beb1589b30",
      "fe05e9c3729e4e38b63ec21787b4ec85",
      "c1e9a585c2b341beadc4ddc0cd150b3b",
      "b4f714dc8a3746008fba28146a984fd7",
      "e64e31e7612b4e429d1acdc1add9acd0",
      "fe9363ebf5e14d99bf434639182c2b1b",
      "c025b8ca14c944ab9452abedb9e5f058",
      "335be47041134ba7a486bc8b077a07c1",
      "d67ef6c88db7420583b2474aa1ceee30",
      "f829aa6a54c442a894ddb1dbfde7d2a4",
      "959cc51e4ac443a7954e5f50ba184704",
      "80f64b3d65f84b3fa43b9648809a88af",
      "5339105bf5a84bc384f42c6d221d9443",
      "79fc8974605c43f9a76272d7264e5e68",
      "6a68b674f9c04a51ad70e9b54b1f27d4",
      "6bf135482d3640e69eefcdda84430b0f",
      "78a1592837f3443da512ef8a429706da",
      "96e38a79df604cd3a6dd800d7251c6a3",
      "7fbec62e87514d60a336ba9cb7f48a92",
      "cd0a8f4ca5ae4c4caf8d1376c43d3b64",
      "795f08de919645ed9f3aff778d71381a",
      "192954b738ad4fe9b8bcbce566b0b007",
      "862fa8b2d1624742a58ac70a49fed89d",
      "1a9297ce99bc416dae9280a5c71f2071",
      "0409cec5f9df42a98ff3722cd4991c93",
      "f6c972fc8f1b43248eb3d469a10cf49a",
      "470910f7ae6d41c0836d01823350e0e7",
      "9ecb43c026334e35805570d374d6cf53",
      "e2d0db2cec554a1eb660cb2d88d0924b",
      "a1f80ea21e6349edbc42baa196c3693a",
      "ed9a92482a0e4d9e964fc417748a2471",
      "880d925a55dc49a6864fcc7007c7bb74",
      "b192d54395f64666802c08d84743a2c6",
      "7a425d237f4d46d5921641fb1d16ed23",
      "62234fd77adb47d384c7934ae03aa926",
      "e9259b6dbd2b4ba8a668bf96058a3ee4",
      "d27ca6f025164092893136dacd7be409",
      "a0798a2853344317bed4b806a7fc4c1e",
      "e19b8442dd12490fbc0e63ad30b3470f",
      "00dfea4646214cb2ab71d97838ed4c21",
      "3b14613e9c3848dcad7d1035e8762edb",
      "75fd564e9c5b48f981f647ab89022cdd",
      "a9177660c51d493fa35c0278af8fb3e9",
      "4a18b61268314a56931f5ed5a9f1a3bf",
      "637e971026c5487886f548a9d8849bd1",
      "8e1e568df9c34af6aa25236d54bd87c8",
      "4aae7800c44f467db0a2765ddba0303b",
      "7f50be994b1f4069a52a21ff64de3338",
      "023e3ef60113498b834edbbaf0d548f7",
      "1640ddfbb91045f29d84d6038f7f8903",
      "90e97227deb94873b70d2917705d3496",
      "e0b895f988bc4ea0896df91057331da7",
      "ab7507b9721b424abc922e03c01d4154",
      "bd22a1ca36e04dc4b90e005cf268010c",
      "72fd79f7e760470e8267ad23200d2ad6",
      "ac57da9b5d5647728421405e9bd297a4",
      "ccd910e571704d1798e26ce0ce3ce5a8",
      "f132246e2ebc4060b0221c176ca491e1",
      "2a78ef2e7d564b6394c1c45abc5490ad",
      "75a6ac53fd2542659789a7d11fbf2ba5",
      "e8c111e508d449aa8a2418b88c513c8e",
      "0a35a7a50aa042ea8a22294df0908338",
      "6390c8b1d62f400f9e74d04440ae88c2",
      "a02d6ecbe103470e8d8656b23c7b93f7",
      "a9c26b441719414dbdc3c97a90147a75",
      "62851d40633c4c28941b4b54aa824b15",
      "9167a9f6a8c04b3a8b259db99d219ad4",
      "60c4b1831e974b859640c5728bc1cd7a",
      "1d2093a4069940c7b67ed1e456fb63d2",
      "3223c2eea33c432e99a122f71fcc37e2",
      "770acf86e439485c9770986384ed76f8",
      "26d84b45c0504c4eba8ab3241bfe6492",
      "bf2905d9515c47a6b0a726b7121f756e",
      "3cec5a40b16f4507a62aeb5e369433f3",
      "3243591da66649babaebd40043417ac1",
      "54315fa298174ee59fb4779f2560d85b",
      "a089de79c03d45d6a727c30e53b1687c",
      "1d3dc61de4d44949a342a93552408dba",
      "59911dd606ed4ab584067bd325dc0f29",
      "8e9e178e85fb41839d2e208f524b2143",
      "60dce6dd16d64cf784c85e03fa04dbbf",
      "ac532fe484734d59879a8de0e2d37b55",
      "842827f98c6c4b7b8b5311b05b96b2f0",
      "6eabe5550e40444ea5724e4747db6a6e",
      "11df2822625f4728a478162493de397e",
      "d138670582114dd4adbdee489a990e9b",
      "a95142e9a12d4a58ac3c5ffc0f1f9a60",
      "7c55296dcc7d43eeb0113e206ebb7f93",
      "7c335ddbbccc4379a0b506f343d265e9",
      "45dc7d6922684bf2b82fca9de127c4ae",
      "deab24c50f694d50b75781d9389e917b",
      "e336668e4d7944cdb23e71f4cf61cf0d",
      "64d91fb64a494ff19e5eba25f5a6126c",
      "a9c84766c8184f65ae5c5157031aef8e",
      "195cbafc382a4679aa57dc9b683e2b3f",
      "c4f77f398b604031a6330748aaabe356",
      "79a01bcdc1fe401b82210c11a9325b55",
      "ec9c21088a1441b695caa091eba5a44f",
      "290cc470cfe14c14823bb584f966d1c5",
      "9bb8b76f40e940e8bbf9b6860dfa1f0e",
      "6b9f3ac46ede4343bcd8983d09c86000",
      "005394bc4c9749e4a18a2909dface1f1"
     ]
    },
    "executionInfo": {
     "elapsed": 1147100,
     "status": "ok",
     "timestamp": 1746283593350,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "0ENXUK1xbJn7",
    "outputId": "53659f63-e41c-40c6-e3b1-ef9d2a30f33c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfec9e3facb40a78af049ff11b9055b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Generating responses on 500 MentalChat16K samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 500/500 [18:06<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Running BLEU, ROUGE, and BERTScore evaluations...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d00976f45634028ae8613f189f6a81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca9284cc9a04595a47b71e5ba0fc520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f714dc8a3746008fba28146a984fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a68b674f9c04a51ad70e9b54b1f27d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c972fc8f1b43248eb3d469a10cf49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 BLEU: 0.0603959217210334\n",
      "🟥 ROUGE-1: 16.16562222869287\n",
      "🟥 ROUGE-2: 1.1030518379396441\n",
      "🟥 ROUGE-L: 8.860897863604531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27ca6f025164092893136dacd7be409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f50be994b1f4069a52a21ff64de3338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a78ef2e7d564b6394c1c45abc5490ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3223c2eea33c432e99a122f71fcc37e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dce6dd16d64cf784c85e03fa04dbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e336668e4d7944cdb23e71f4cf61cf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟩 BERTScore (F1): 80.57520929574966\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets evaluate bert_score tqdm\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load 500 evaluation samples from MentalChat16K\n",
    "eval_data = load_dataset(\"ShenLab/MentalChat16K\", split=\"train\")\n",
    "eval_subset = eval_data.shuffle(seed=42).select(range(500))\n",
    "\n",
    "# Load fine-tuned model from Trial 12\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial12\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Response generator\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=350).to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=180,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "#  Generate predictions with live progress\n",
    "preds, refs = [], []\n",
    "\n",
    "print(\"🧠 Generating responses on 500 MentalChat16K samples...\")\n",
    "for sample in tqdm(eval_subset, desc=\"Evaluating\"):\n",
    "    user_msg = sample[\"instruction\"]\n",
    "    ref_response = sample[\"output\"]\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{user_msg} [/INST]\"\n",
    "    gen_response = generate_response(prompt)\n",
    "    preds.append(gen_response)\n",
    "    refs.append(ref_response)\n",
    "\n",
    "# Run evaluation metrics\n",
    "print(\"\\n📊 Running BLEU, ROUGE, and BERTScore evaluations...\\n\")\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "print(\"🔵 BLEU:\", bleu.compute(predictions=preds, references=refs)[\"bleu\"] * 100)\n",
    "\n",
    "rouge_scores = rouge.compute(predictions=preds, references=refs)\n",
    "print(\"🟥 ROUGE-1:\", rouge_scores[\"rouge1\"] * 100)\n",
    "print(\"🟥 ROUGE-2:\", rouge_scores[\"rouge2\"] * 100)\n",
    "print(\"🟥 ROUGE-L:\", rouge_scores[\"rougeL\"] * 100)\n",
    "\n",
    "bert_result = bertscore.compute(predictions=preds, references=refs, lang=\"en\")\n",
    "print(\"🟩 BERTScore (F1):\", sum(bert_result[\"f1\"]) / len(bert_result[\"f1\"]) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1O9kGiXCiHRC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un-tkclUoVaM"
   },
   "source": [
    "eval with mentalchat16k, with merged emp+counsel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364,
     "referenced_widgets": [
      "d21537ec2c8b40529e19d327232c57e7",
      "00e6d4476bd64333ae71df154c128250",
      "7bdc3fb3b92745d8bb775dd0341a1cbe",
      "05cc15901e3542f9a8624a8e47ff998c",
      "25130e9f00c541da9eefeee56c16e184",
      "715c7c93ca164a81a2697d39f2053852",
      "7b349eb383e64c82a810a57920c772f5",
      "62b4cc8dd02541ebafe8e065d806854a",
      "530bde5408a14119b4d79caa274ae9ef",
      "2887523a2a7c4ced8b9ab0dcdfbe86b7",
      "21f283f207174f968d1398abf2614ce9"
     ]
    },
    "executionInfo": {
     "elapsed": 1824182,
     "status": "ok",
     "timestamp": 1746285807478,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "UC8Hn5iPoqzC",
    "outputId": "c4dace2a-8287-44ba-b7be-f1381ea18f44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21537ec2c8b40529e19d327232c57e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Generating responses using Trial 11 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 700/700 [29:23<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Calculating BLEU, ROUGE, and BERTScore...\n",
      "🔵 BLEU: 0.12315827684953097\n",
      "🟥 ROUGE-1: 18.46037913413155\n",
      "🟥 ROUGE-2: 1.6625199767018046\n",
      "🟥 ROUGE-L: 9.708877567040863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟩 BERTScore (F1): 81.13262244633266\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets evaluate bert_score tqdm\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "#  Load evaluation dataset (700 samples from MentalChat16K)\n",
    "eval_data = load_dataset(\"ShenLab/MentalChat16K\", split=\"train\")\n",
    "eval_subset = eval_data.shuffle(seed=42).select(range(700))\n",
    "\n",
    "# Load Trial 11 model (merged 6937 Emp + 2116 Counsel, real only)\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-merged-trial11\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Response generation\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=350).to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=180,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Inference loop with progress bar\n",
    "preds, refs = [], []\n",
    "print(\"🧠 Generating responses using Trial 11 model...\")\n",
    "\n",
    "for sample in tqdm(eval_subset, desc=\"Evaluating\"):\n",
    "    user_msg = sample[\"instruction\"]\n",
    "    ref_response = sample[\"output\"]\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{user_msg} [/INST]\"\n",
    "    gen_response = generate_response(prompt)\n",
    "    preds.append(gen_response)\n",
    "    refs.append(ref_response)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n📊 Calculating BLEU, ROUGE, and BERTScore...\")\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "print(\"🔵 BLEU:\", bleu.compute(predictions=preds, references=refs)[\"bleu\"] * 100)\n",
    "\n",
    "rouge_scores = rouge.compute(predictions=preds, references=refs)\n",
    "print(\"🟥 ROUGE-1:\", rouge_scores[\"rouge1\"] * 100)\n",
    "print(\"🟥 ROUGE-2:\", rouge_scores[\"rouge2\"] * 100)\n",
    "print(\"🟥 ROUGE-L:\", rouge_scores[\"rougeL\"] * 100)\n",
    "\n",
    "bert_result = bertscore.compute(predictions=preds, references=refs, lang=\"en\")\n",
    "print(\"🟩 BERTScore (F1):\", sum(bert_result[\"f1\"]) / len(bert_result[\"f1\"]) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3UgFSZVovDX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2t-LF3j4sB7"
   },
   "source": [
    "testing new models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3411be5c41d844fdb0cfb53ef395b286",
      "d22c82db73774a72ab7758850daace0d",
      "46b446a58e9b4abf9e4e6a440026d074",
      "24ae458f206c4ff986a0ec18982279fc",
      "acb28eb8fa7d4b21ab15e3b3910d9f1c",
      "84134a4f018147aaa0d2d61818d127f4",
      "592a3360803e46c0a056a3b309d333bb",
      "e77255e9ad3240cfbdd020f06b87088d",
      "0b7a15d0d1d049d4a00ce6ccad447aab",
      "9608cc0c809f430fb8f1abc07caeea25",
      "57e27ec1a7a04721a346e90e7e919cf4"
     ]
    },
    "executionInfo": {
     "elapsed": 93261,
     "status": "ok",
     "timestamp": 1746288392909,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "JGqO7Pa_4upU",
    "outputId": "558f80ad-96ca-4b47-bf77-42cfd903495c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3411be5c41d844fdb0cfb53ef395b286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Inference using model at: /content/drive/MyDrive/SIT782/checkpoints/mistral-merged-trial11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating Responses:   0%|          | 0/15 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "🧠 Generating Responses:   7%|▋         | 1/15 [00:11<02:34, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 1: I feel like I'm constantly overthinking every little thing. How do I make it stop?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel like I'm constantly overthinking every little thing. How do I make it stop? [/INST] There are many things you can do to help with your over thinking, but it is important to know that over thinking is a natural part of the human experience.  We all have thoughts, sometimes we think too much about them.  Over thinking can be a sign that you are not happy with something in your life and are seeking answers.  It could also be a sign that you are not taking care of yourself properly or are experiencing stress.  It's important to identify why you are over thinking.  Once you have identified why you are over thinking, then you can take steps to address the underlying issue.  You may need to change some habits, such as how you spend your time, how you deal with stress, or how you approach decision making.  You may need to seek out some support from others, such as friends, family, or even a therapist.  You may need to take better care of yourself by getting enough rest,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  13%|█▎        | 2/15 [00:17<01:47,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 2: Why do I get so anxious when I have to talk to people, even my friends?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Why do I get so anxious when I have to talk to people, even my friends? [/INST] That is a very common problem.  Many people feel nervous or anxious about talking to other people.  Anxiety can make it difficult for you to be yourself with others.  It's important to understand that anxiety is a natural feeling that all people experience from time to time.  However, if you are feeling anxious often or for long periods of time, then it may be helpful for you to talk to a therapist about your feelings.  A therapist can help you learn ways to manage your anxiety and feel more comfortable around other people.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  20%|██        | 3/15 [00:22<01:24,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 3: I wake up with a knot in my stomach every day. What can I do about it?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I wake up with a knot in my stomach every day. What can I do about it? [/INST] The first thing that you should do is to find out what the cause of your anxiety is. This will help you to know what you need to do to reduce your anxiety. Once you have identified the source of your anxiety, try to avoid the situations or people that trigger it. If this is not possible, then you may need to seek professional help from a therapist. They will be able to help you learn ways to manage your anxiety so that you can live a happier and more peaceful life.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  27%|██▋       | 4/15 [00:31<01:21,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 4: Lately I’ve lost interest in everything. Nothing makes me happy anymore.\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Lately I’ve lost interest in everything. Nothing makes me happy anymore. [/INST] It sounds like you are going through a difficult time.  There is something called \"depression\" that can make it difficult for us to feel pleasure or joy in the things we used to enjoy.  Sometimes it can be caused by something specific, like the loss of a loved one or the end of a relationship.  Other times it seems to come out of nowhere and can be very confusing.  I would recommend talking with your doctor about your symptoms.  They may be able to help you understand what is happening to you.  In the meantime, take care of yourself.  Eat well, exercise, get enough rest, and try to do things that you know bring you joy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  33%|███▎      | 5/15 [00:35<01:02,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 5: Is it normal to feel tired all the time even when I’m not physically active?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Is it normal to feel tired all the time even when I’m not physically active? [/INST] This is something that can be caused by a number of different things. It could be a problem with your thyroid, or it could be due to anemia. It is also possible that you have an issue with your heart.You should go see your doctor and discuss this with them. They may want to run some tests to figure out what is going on.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  40%|████      | 6/15 [00:42<01:00,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 6: I feel numb, like nothing really matters. What should I do?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel numb, like nothing really matters. What should I do? [/INST] If you're feeling numb, then it is likely that you have been in shock for some time. Shock can be a way of coping with traumatic events. It is important to remember that the feelings of numbness will pass over time.In the meantime, you may find it helpful to reach out to someone you trust and share your feelings. Sometimes just talking about what has happened can help you to start processing it.If you are having difficulty processing your feelings, then you may want to consider seeking out the services of a therapist or counselor. They can help you to understand why you are feeling numb and how you can work through this difficult time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  47%|████▋     | 7/15 [00:46<00:45,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 7: I had a panic attack at work and now I’m afraid it’ll happen again. How do I cope?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I had a panic attack at work and now I’m afraid it’ll happen again. How do I cope? [/INST] Panic attacks can be scary, but they are treatable.  I would encourage you to seek the help of a mental health professional who is trained in treating panic attacks.  You will learn coping skills that can help you manage your symptoms and reduce the likelihood of having another panic attack.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  53%|█████▎    | 8/15 [00:54<00:44,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 8: My heart races for no reason and I feel like I can't breathe. Am I losing control?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "My heart races for no reason and I feel like I can't breathe. Am I losing control? [/INST] It sounds like you are having an anxiety attack.  Anxiety attacks can be very scary, but they are not life threatening.  They can be triggered by many things including stress, fear, or even just the thought of something that is causing you to worry.  There are many ways to cope with anxiety attacks.  If you are not able to calm yourself down on your own, it would be good to talk to a therapist about how to manage your anxiety.  Therapy can help you learn new coping skills, as well as teach you ways to change your thinking patterns so that you don't get caught up in anxiety-producing thoughts.  Good luck!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  60%|██████    | 9/15 [01:01<00:39,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 9: How can I calm down quickly when I feel overwhelmed in public?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "How can I calm down quickly when I feel overwhelmed in public? [/INST] It's a common problem, feeling anxious or overwhelmed in public.  In order to calm yourself down you need to learn how to control your body and mind.  First, you need to take a deep breath and relax.  If you feel like you're about to panic, then find a quiet place where you can sit down and collect yourself.  The key is to focus on your breathing and calming your thoughts.  It may help to repeat a mantra or positive affirmation to yourself.  Over time, with practice, you should be able to learn how to calm yourself down quickly in public.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  67%|██████▋   | 10/15 [01:05<00:29,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 10: No matter what I do, I always feel like I’m not good enough.\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "No matter what I do, I always feel like I’m not good enough. [/INST] That is a common feeling that many people have.  The question for you to ask yourself is \"Why am I not good enough?\"  Do you have unrealistic expectations of yourself?  Are you comparing yourself to others?  Do you have negative self-talk?  Answering these questions will help you understand why you feel like you're not good enough.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  73%|███████▎  | 11/15 [01:08<00:20,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 11: I compare myself to everyone and feel like I’m constantly failing.\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I compare myself to everyone and feel like I’m constantly failing. [/INST] I understand how you feel, but the only person that you need to compare yourself to is you.  The only thing that matters is your own personal growth and development.  So long as you are making progress, then you should be happy with yourself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  80%|████████  | 12/15 [01:14<00:15,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 12: Why do I always blame myself when something goes wrong?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Why do I always blame myself when something goes wrong? [/INST] It's natural to feel like you're responsible for everything that goes on in your life.  But the reality is that there are many things that happen to us that we can't control.  It's important to be able to distinguish between what you can control and what you can't.  If you have a tendency to blame yourself for things that are outside of your control, it might be helpful to talk to a therapist about how you can develop some self-compassion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  87%|████████▋ | 13/15 [01:21<00:11,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 13: I always say yes to people even when I’m exhausted. How do I set boundaries?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I always say yes to people even when I’m exhausted. How do I set boundaries? [/INST] It's important to take care of yourself first.  If you are feeling exhausted, then it is time to set some boundaries.  You can start by making a list of things that you want to be able to do for yourself that will help you feel energized.  Then, let others know that those are your priorities and ask them if they can support you in doing those things.  Make sure to communicate with them in a clear and direct way about what you need.  It may also be helpful to work with a therapist to develop more effective communication skills.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "🧠 Generating Responses:  93%|█████████▎| 14/15 [01:25<00:05,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 14: My partner doesn’t understand my anxiety. It’s hurting our relationship. What should I do?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "My partner doesn’t understand my anxiety. It’s hurting our relationship. What should I do? [/INST] When people do not understand what you are going through it can be difficult for them to respond in a way that is helpful to you.  I'd recommend trying to find a good therapist, if you have not already, who can help you to work through your anxiety and also learn how to communicate more effectively with your partner about the impact of your anxiety on your relationship.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating Responses: 100%|██████████| 15/15 [01:27<00:00,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 15: I feel guilty for putting myself first. Is that selfish?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel guilty for putting myself first. Is that selfish? [/INST] It is natural to have feelings of guilt when you focus on yourself.  However, it's important to remember that taking care of yourself is not selfish.  It's a necessary part of being healthy and happy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define model path (change for Trial 6, Trial 11, etc.)\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-merged-trial11\"\n",
    "\n",
    "# Load LoRA config, base model, PEFT adapter\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # ensure no pad errors\n",
    "\n",
    "# Load test prompts from Drive\n",
    "test_file_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/test_prompts_counselchat.jsonl\"\n",
    "with open(test_file_path, \"r\") as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Run inference on all prompts\n",
    "print(f\"\\n🚀 Inference using model at: {model_path}\")\n",
    "for idx, sample in enumerate(tqdm(test_data, desc=\"🧠 Generating Responses\"), 1):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{sample['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n🧠 Prompt {idx}: {sample['instruction']}\\n🤖 Response: {decoded.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9Zk04OU453N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmseN_CV9upz"
   },
   "source": [
    "checking for duplicates in mrged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1746289505107,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "A71tkvYF9x-Y",
    "outputId": "7ceb6aa4-2afe-4490-8b9a-af3b44af0793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total samples: 9053\n",
      "❗ Duplicate pairs found: 120\n",
      "📦 Total duplicate instances: 120\n",
      "\n",
      "\n",
      "#️⃣ Duplicate 1 (Occurs 2 times):\n",
      "Instruction: What do you mean?\n",
      "Output: You said they didn't have a direct in a while do you mean like a direct game come out im no game wiz for the new age lol.\n",
      "\n",
      "#️⃣ Duplicate 2 (Occurs 2 times):\n",
      "Instruction: I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\n",
      "   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?\n",
      "Output: Let me start by saying there are never too many concerns that you can bring into counselling. In fact, most people who come to see me for counselling have more than one issue they would like to work on in psychotherapy and most times these are all interconnected. In counselling, we work together, collaboratively, to figure out which issues you would like to address first and then together we develop an individualized plan of care. Basically, it’s like a road map of where you want to go, how are you going to get there, looking at stopovers, some scenic routes others possibly not so scenic, however, necessary. Of course, these plans can also change due to internal (what we have control over like our thoughts, feelings and behaviours) or external reasons (those things that are outside our control). I would encourage you to take the next step and reach out to a professional you can trust and build rapport with by co-journeying through whatever concerns you have by examining what has been working so far as you have learned to cope with some of your issues like insomnia, depression and anxiety, as well as being a breast cancer survivor. Then to help you by developing new coping strategies. Psychotherapy can be such a powerful tool to help you get to where it is you want to be. I know you can do it and you will see first-hand how psychotherapy will help you to move past these points in your life where you are feeling stuck. I like to quote Nike where their motto is, “just do it.” You can do it.\n",
      "\n",
      "#️⃣ Duplicate 3 (Occurs 2 times):\n",
      "Instruction: I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\n",
      "   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?\n",
      "Output: It is never too late to get help and begin making significant changes and improvements in your life.  The right time is when you feel ready and open to change.  Sometimes when we have a history of trauma, like sexual abuse, the impact of that trauma can affect many areas of our lives as adults.  Working with a therapist who specializes in trauma is a great way to begin developing skills to manage present day life, learn to regulate your emotions and nervous system when you become triggered, and then in a safe environment have the opportunity to process past traumas so you can live your present life with more ease and joy.  People can and do recover from the impacts of trauma at any stage in their life.  It is never too late and you can feel better\n",
      "\n",
      "#️⃣ Duplicate 4 (Occurs 2 times):\n",
      "Instruction: I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\n",
      "   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?\n",
      "Output: You have been through so much and it sounds like you have a lot of things that have complied over the years. Regardless of the struggles you have been through, you do not have too many issues for counseling. Many times when someone starts out their counseling and healing journey, there are multiple things they would like to address and work on. If you decide to start counseling, you and your therapist can decide collaboratively what you would like to process and work on first. Be sure to express to your counselor if any of the above experiences you've been through is causing a lot of distress , as many times the first things addressed are the ones that are presently affecting your life or you emotionally. Often times when we experience negative situations in our life , but do not address them, they bottle up inside us and can manifest in other ways, such as depression or even physical symptoms like IBS or neck pain.  Counseling can give these bottled up emotions and situations a release. Given the situation you shared, not only do I not think that you have too many issues for counseling, but believe that you will be a great candidate and can get a lot from it.\n",
      "\n",
      "#️⃣ Duplicate 5 (Occurs 2 times):\n",
      "Instruction: I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\n",
      "   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?\n",
      "Output: Absolutely not.  I strongly recommending working on one issue/need at a time.  In therapy you will set smart goals and objectives that will help you reach your goals.  I see you as a survivor and not a victim.  Best wishes to you.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your dataset\n",
    "input_path = \"/content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered.jsonl\"\n",
    "\n",
    "# Load all lines\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "# Count occurrences of each (instruction, output) pair\n",
    "pair_counts = Counter((entry[\"instruction\"], entry[\"output\"]) for entry in data)\n",
    "\n",
    "# Identify duplicates\n",
    "duplicates = {pair: count for pair, count in pair_counts.items() if count > 1}\n",
    "\n",
    "# Display results\n",
    "print(f\"🔍 Total samples: {len(data)}\")\n",
    "print(f\"❗ Duplicate pairs found: {len(duplicates)}\")\n",
    "print(f\"📦 Total duplicate instances: {sum(count - 1 for count in pair_counts.values() if count > 1)}\\n\")\n",
    "\n",
    "# Optionally print some duplicate examples\n",
    "for i, ((instr, out), count) in enumerate(duplicates.items()):\n",
    "    print(f\"\\n#️⃣ Duplicate {i+1} (Occurs {count} times):\")\n",
    "    print(f\"Instruction: {instr}\")\n",
    "    print(f\"Output: {out}\")\n",
    "    if i >= 4: break  # show only first 5 duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCmc_dFE9y6V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTaNMKka97V0"
   },
   "source": [
    "Removing duplicates from merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1746289557420,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "1Mwrc9R49-Qm",
    "outputId": "2ba554fd-6c4a-455f-d180-353e289aa7ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Removed 120 duplicates.\n",
      "✅ Cleaned dataset saved to: /content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered_deduplicated.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to dataset\n",
    "input_path = \"/content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered.jsonl\"\n",
    "output_path = \"/content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered_deduplicated.jsonl\"\n",
    "\n",
    "# Load dataset\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "# Remove duplicates\n",
    "seen = set()\n",
    "deduplicated = []\n",
    "for entry in data:\n",
    "    key = (entry[\"instruction\"], entry[\"output\"])\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        deduplicated.append(entry)\n",
    "\n",
    "# Save cleaned file\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in deduplicated:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Removed {len(data) - len(deduplicated)} duplicates.\")\n",
    "print(f\"✅ Cleaned dataset saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5L7WcM_9_4v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkoTRpr3-h7B"
   },
   "source": [
    "# trial 13 - dataset : merged empathetic dialogues+counsel chat no synthetic data, removed duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "be031ac21c2d4351b39a0e15b8358f3f",
      "ab795ebc4a2d4058907bfb3f1ab4361a",
      "fcb33274175941b5896e0f3021d263ee",
      "3375d176baec4f098d2fb0239bbd93a7",
      "e303595a6eec45d38be7bb0b6f5935c9",
      "5b4050c7e5924a8f8cab3516f4a4500e",
      "9ee81cdb7b50464fa6fe9f2b9b27f86c",
      "541966021bb045f58be8d81a1c9ef677",
      "fdd9260cd473473e9a371ca5f80f0c2d",
      "10e6f91ad4184983ad1a0cd4e1d7e8e9",
      "00ee542916f74d259627405d7dd94b71",
      "caca324ae3e8475a9690cc5fd1a40392",
      "477efcab45b840fd98d7a446251a1e93",
      "77ba1d9b2c804ce18adf53fb694b818d",
      "6f66927f8e3c474788f4e8b9564e86c3",
      "e04a46f591d64f23b85f45eb92bd4533",
      "8ed31189afbc4e45a4245b2ad5cb6a22",
      "998317b4cd2744d29bf7d7ebc0bcda0a",
      "00ccd77cc84843a183c7fdd9b6f55d0a",
      "4a77d620cc864dfe9ee42bdc06749148",
      "5054c65308a44771b63aecca4ac98576",
      "94b178b053e24aae8acf94b29b7fc46c",
      "a5a6dbee6d8e4cadb096b4516bdec81b",
      "59e5cee3995049fd818d5be3c0f5b512",
      "3ec98c401c774fc188c0989fee7a4fda",
      "8ebf2ea82b234eca83fdb63d12a21360",
      "b5c5129477ec4259aa94a2dd80e527c1",
      "1397599567e546fb907f9634a14b94b0",
      "25da0736b19e48ed980f1d146d276079",
      "2ff8884b662842279582ada329c355c9",
      "5edeecf216b44c82ae6058164d32431f",
      "2577e00a5bf043aaba0169f4679ac437",
      "2df27bbfb447441b891a1fc43d704f30"
     ]
    },
    "executionInfo": {
     "elapsed": 3102099,
     "status": "ok",
     "timestamp": 1746292855337,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "TtyIShJM-jWo",
    "outputId": "0d825afe-65c2-47aa-8b94-8e678b8febde"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be031ac21c2d4351b39a0e15b8358f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caca324ae3e8475a9690cc5fd1a40392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a6dbee6d8e4cadb096b4516bdec81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8933 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f55ef8ec9f27>:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4464' max='4464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4464/4464 51:13, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>15.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.737900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.659500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.893400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.946400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.064100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.458200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.192100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.959900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.531600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.744500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.368400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.958700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.636500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.790500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.689500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.442100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.824100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.617100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.628900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.540400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.604200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.677300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.529600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.571600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.683400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.959100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.157300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.861100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.791500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.663500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.964200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.635400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.608100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.798300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.198600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.684200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.665800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.176200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.867800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.628400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.687100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.370400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.952800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.804700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.946300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.641600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.608800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.602500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.802900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.735800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.503800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.874100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.690600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.765500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.733800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.805700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.974700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.556300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.648200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.729100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.605100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.682800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.638800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.791900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.680500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.649600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.754400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.840400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.722400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.581800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.589600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.776100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.533300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.510100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.732400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.219700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.634700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.563600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.780300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.879500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.750600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.348500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.637900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.663500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.746300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.523400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.553600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.548200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.529800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.750300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.914900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.558300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.512600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.891800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.566300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.698600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.772300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.645100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.914300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.675500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.683600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.858100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.902800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.766200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.537100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.916300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.640400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.743300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.859400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.864900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.858600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.801400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.722800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.850200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.848500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.502400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.622400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>0.473800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.642400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.652100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.434600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.611200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.685900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.805300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.516900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.578200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.751700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.770100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>0.969100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.677300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>0.722800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>1.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.657400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.995400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>0.701400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.966900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>0.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.709800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.648500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.857100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>0.632600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.575500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>0.590500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.507700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>0.556500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.745300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>0.544700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.566600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.949100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>0.852400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.569800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>0.848200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>0.531800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.870300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>0.879100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.744500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.769500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>0.533700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.295300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>0.719500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.895900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>0.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.538400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>0.633400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.824600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.747800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>0.607100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>1.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>0.563100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>1.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.530400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>0.588700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.306900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>0.646500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>0.622400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>0.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.806300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>0.464900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.552200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.468600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>0.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>0.755800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.639400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>0.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>0.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>0.844700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.854300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.780800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>0.625500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.825600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>0.833400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>0.631500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.687300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>0.767100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.601800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.716400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.585400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>0.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>0.928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>0.877200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>0.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.804500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.728700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>0.818600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.909700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>1.073200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>0.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>0.389900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.518300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.738200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>0.706400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>0.751700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.755900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>0.807600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>0.661700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>0.605100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.677300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>0.881500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.512300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>0.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.914100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>0.496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.648400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>0.828800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.489200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>0.755500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>0.432200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3190</td>\n",
       "      <td>0.698400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.497600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>0.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.628400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3230</td>\n",
       "      <td>0.635100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.928100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>0.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>0.667900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.873400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3290</td>\n",
       "      <td>0.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.569600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3310</td>\n",
       "      <td>0.845500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>0.699100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.748500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.819600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>0.965400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.405700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>0.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>0.526600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.869300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3430</td>\n",
       "      <td>0.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.767300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.684700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>0.732100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3470</td>\n",
       "      <td>0.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>0.432900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3490</td>\n",
       "      <td>0.783500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>0.416900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.496900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>0.519300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>0.799600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.505700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>0.451300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>0.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>0.459100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3590</td>\n",
       "      <td>0.743800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.850400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>0.879100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>0.868200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3630</td>\n",
       "      <td>0.501900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>0.563700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.595700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>0.688200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>0.554800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>0.802300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>1.170300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.705600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3710</td>\n",
       "      <td>0.459400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>0.529500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3730</td>\n",
       "      <td>0.717500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>0.603500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>0.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3770</td>\n",
       "      <td>0.744400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>0.856500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3790</td>\n",
       "      <td>0.901500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3810</td>\n",
       "      <td>0.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>0.760700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3830</td>\n",
       "      <td>0.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>0.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>1.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>0.787100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3870</td>\n",
       "      <td>0.758300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>0.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3890</td>\n",
       "      <td>0.610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.951200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3910</td>\n",
       "      <td>0.629000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>0.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3930</td>\n",
       "      <td>0.449300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>0.638700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>1.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3970</td>\n",
       "      <td>0.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>0.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>0.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.367800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4010</td>\n",
       "      <td>0.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>1.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4030</td>\n",
       "      <td>0.715500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>0.612800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.660300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4060</td>\n",
       "      <td>0.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4070</td>\n",
       "      <td>0.798500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>0.591900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4090</td>\n",
       "      <td>0.750700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.726500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4110</td>\n",
       "      <td>0.604900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4120</td>\n",
       "      <td>0.555600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4130</td>\n",
       "      <td>0.679900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>0.807600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4160</td>\n",
       "      <td>0.474200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4170</td>\n",
       "      <td>0.561700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4180</td>\n",
       "      <td>1.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4190</td>\n",
       "      <td>0.537900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.649100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4210</td>\n",
       "      <td>0.507100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4220</td>\n",
       "      <td>0.691600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4230</td>\n",
       "      <td>0.334000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4240</td>\n",
       "      <td>0.816500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.838900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>1.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4270</td>\n",
       "      <td>0.568900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>0.532600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4290</td>\n",
       "      <td>0.779800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.843600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4310</td>\n",
       "      <td>0.654600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>1.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4330</td>\n",
       "      <td>0.807800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>0.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.459300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4360</td>\n",
       "      <td>0.563200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4370</td>\n",
       "      <td>0.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>0.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4390</td>\n",
       "      <td>0.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>0.593300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420</td>\n",
       "      <td>0.494100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4430</td>\n",
       "      <td>0.717600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>0.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.968200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4460</td>\n",
       "      <td>0.627500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 13 fine-tuning complete and saved to Drive!\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q transformers datasets peft accelerate bitsandbytes\n",
    "\n",
    "import torch, gc\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load deduplicated dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/SIT782/datasets/merged_emp_counsel_filtered_deduplicated.jsonl\", split=\"train\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(example):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{example['instruction']} [/INST]\"\n",
    "    output = f\" {example['output']}</s>\"\n",
    "    result = tokenizer(prompt + output, padding=\"max_length\", truncation=True, max_length=384)\n",
    "    result[\"labels\"] = tokenizer(output, padding=\"max_length\", truncation=True, max_length=384)[\"input_ids\"]\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"output\"])\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial13\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train and save\n",
    "trainer.train()\n",
    "model.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial13\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial13\")\n",
    "\n",
    "print(\"✅ Trial 13 fine-tuning complete and saved to Drive!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yw8hzqM2-vvB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxPNl80JMeS9"
   },
   "source": [
    "eval against mentalhat16k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399,
     "referenced_widgets": [
      "eae1e8daf095445780d3d3fdee7f2392",
      "a3b952aad473471aa5e608117db22c4b",
      "36384249431442b0b7fd8a0aa19891a3",
      "09469d6eb73d4662a10f04c985deccf7",
      "85f48b9427b844faa35507b01f26a774",
      "09534aa892184009b1ecc464c5cbfed8",
      "bfe399e5895648b5b433583b9c29ce1b",
      "4eda924337de4d75a2217ff42f66b94e",
      "6eb7c300aeba4216af6964f784db6421",
      "c29c91e6bec64d8ca7defbeaf5e86ddd",
      "d494797ba08e4b549061397c368b83f3"
     ]
    },
    "executionInfo": {
     "elapsed": 913685,
     "status": "ok",
     "timestamp": 1746294787888,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "YJsJA8IXMhlj",
    "outputId": "2ca50f7b-ea93-4bd9-e491-e216065839a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae1e8daf095445780d3d3fdee7f2392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Generating responses on 600 MentalChat16K samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/600 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Evaluating: 100%|██████████| 600/600 [14:31<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Calculating BLEU, ROUGE, and BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔵 BLEU: 0.001026\n",
      "🟥 ROUGE-1: 16.93\n",
      "🟥 ROUGE-2: 1.80\n",
      "🟥 ROUGE-L: 10.31\n",
      "🟩 BERTScore (F1): 81.57\n"
     ]
    }
   ],
   "source": [
    "# Required libraries\n",
    "!pip install -q transformers datasets peft bert_score evaluate\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "# Load Trial 13 model and tokenizer\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial13\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load 600 evaluation samples from MentalChat16K\n",
    "dataset = load_dataset(\"ShenLab/MentalChat16K\", split=\"train[:600]\")\n",
    "\n",
    "# Inference on 600 MentalChat16K samples\n",
    "results = []\n",
    "print(\"🧠 Generating responses on 600 MentalChat16K samples...\")\n",
    "for sample in tqdm(dataset, desc=\"Evaluating\"):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{sample['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    results.append({\n",
    "        \"instruction\": sample[\"instruction\"],\n",
    "        \"reference\": sample[\"output\"],\n",
    "        \"generated\": decoded.strip()\n",
    "    })\n",
    "\n",
    "# Evaluate with BLEU, ROUGE, and BERTScore\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "predictions = [r[\"generated\"] for r in results]\n",
    "references = [r[\"reference\"] for r in results]\n",
    "\n",
    "print(\"\\n📊 Calculating BLEU, ROUGE, and BERTScore...\")\n",
    "bleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "# Display evaluation results\n",
    "print(f\"\\n🔵 BLEU: {bleu_result['bleu']:.6f}\")\n",
    "print(f\"🟥 ROUGE-1: {rouge_result['rouge1']*100:.2f}\")\n",
    "print(f\"🟥 ROUGE-2: {rouge_result['rouge2']*100:.2f}\")\n",
    "print(f\"🟥 ROUGE-L: {rouge_result['rougeL']*100:.2f}\")\n",
    "print(f\"🟩 BERTScore (F1): {sum(bertscore_result['f1'])/len(bertscore_result['f1'])*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iidx-bg-Od1F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WfNgydDU6ot"
   },
   "source": [
    "testing trial 13 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "572941f4b75748a6988a53c048ba7178",
      "6df8cd81cb5c42ee8266d6c7d2963979",
      "6bcc1b7147dc453b82b2fdc04c43441b",
      "9968de0fca0a494b96dd6d81b529a6ba",
      "7cab19ea679f4d129f10d488a9b927ba",
      "cc3c94c3e6c7420ab232d7baabe5312e",
      "72f40fd9225d429a9a0a36e1477667b0",
      "c42b170ad001478dae729698a656fb0a",
      "660df1a7078a4b519faa1d732d84b308",
      "d9773cb3533441cb81262b02ba0f964e",
      "1b189ebfdd6f4ab7b6bb36add4b3d60a"
     ]
    },
    "executionInfo": {
     "elapsed": 153496,
     "status": "ok",
     "timestamp": 1746295733719,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "gmhnL9HFU97Z",
    "outputId": "76ec971d-274b-4a53-c099-955f87763031"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572941f4b75748a6988a53c048ba7178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Running Trial 13 Inference:   0%|          | 0/15 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "🧠 Running Trial 13 Inference: 100%|██████████| 15/15 [02:28<00:00,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 1: I feel like I'm constantly overthinking every little thing. How do I make it stop?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel like I'm constantly overthinking every little thing. How do I make it stop? [/INST] Overthinking is a common problem. you can't stop you can only manage it.\n",
      "\n",
      "🧠 Prompt 2: Why do I get so anxious when I have to talk to people, even my friends?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Why do I get so anxious when I have to talk to people, even my friends? [/INST] Anxiety is a normal part of life.  Anxiety is a normal part of. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "🧠 Prompt 3: I wake up with a knot in my stomach every day. What can I do about it?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I wake up with a knot in my stomach every day. What can I do about it? [/INST] I'm sorry to hear that you're feeling this way.  There are many things that can cause a knot in your stomach.  It could be anxiety, stress, or even a physical problem.  I would recommend that you see your doctor to rule out any physical problems.  If you are feeling anxious or stressed, there are many things that you can do to help yourself.  You can try to\n",
      "\n",
      "🧠 Prompt 4: Lately I’ve lost interest in everything. Nothing makes me happy anymore.\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Lately I’ve lost interest in everything. Nothing makes me happy anymore. [/INST] I'm sorry to hear that.  It sounds like you are going through a difficult time.  Have you tried talking to someone about how you are feeling?  It could be a friend or family member.  If you don't have someone you feel comfortable talking to, you could try talking to a therapist.  A therapist can help you figure out what is going on and help you find ways to feel better.\n",
      "\n",
      "🧠 Prompt 5: Is it normal to feel tired all the time even when I’m not physically active?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Is it normal to feel tired all the time even when I’m not physically active? [/INST] It is not normal to feel tired all the time.  There are many reasons for feeling tired.   The most common reasons are not getting enough sleep, not getting enough physical activity, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep, not getting enough sleep,\n",
      "\n",
      "🧠 Prompt 6: I feel numb, like nothing really matters. What should I do?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel numb, like nothing really matters. What should I do? [/INST] I'm sorry to hear that you are feeling this way.  It is important to reach out to someone you trust and talk about what you are feeling.  If you don't have someone you can talk to, then I would suggest reaching out to a therapist.  You can find a therapist by going to Psychology Today and searching for a therapist in your area.  You can also call your insurance company and ask them for a list of therapists that are covered under your plan.  If you are feeling suicidal, then please call the National Suicide Prevention Lifeline at 1-800-273-TALK (8255).  They are available 24 hours a day, 7 days a week.  I hope you feel better soon.\n",
      "\n",
      "🧠 Prompt 7: I had a panic attack at work and now I’m afraid it’ll happen again. How do I cope?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I had a panic attack at work and now I’m afraid it’ll happen again. How do I cope? [/INST] I'm sorry to hear that you had a panic attack at work.  It's important to know that you are not alone.  Many people have panic attacks at work.   panic attacks  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic  panic\n",
      "\n",
      "🧠 Prompt 8: My heart races for no reason and I feel like I can't breathe. Am I losing control?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "My heart races for no reason and I feel like I can't breathe. Am I losing control? [/INST] It sounds like you are having a panic attack.  Panic attacks are a common symptom of anxiety.  They are not dangerous, but they can be scary.  If you are having a panic attack, try to focus on your breathing.  Breathe in through your nose and out through your mouth.  If you can, try to find a quiet place to sit down.  If you are having a panic attack and you are alone, you may want to call a friend or family member.  If you are having a panic attack and you are alone and you are not able to calm yourself down, you may want to go to the emergency room.  If you are having panic attacks on a regular basis, you may want to talk to a therapist.  A therapist can help you learn ways to manage your anxiety and reduce the number of panic attacks you have.\n",
      "\n",
      "🧠 Prompt 9: How can I calm down quickly when I feel overwhelmed in public?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "How can I calm down quickly when I feel overwhelmed in public? [/INST] I'm glad you're asking this question.\n",
      "\n",
      "🧠 Prompt 10: No matter what I do, I always feel like I’m not good enough.\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "No matter what I do, I always feel like I’m not good enough. [/INST] I'm sorry to hear that.  I'm not sure what you mean by \"I always feel like I'm not good enough.\"  Do you mean that you feel like you're not good enough to be loved, or not good enough to be successful, or not good enough to be successful at something, or not good enough to be successful at something, or not good enough to something, or not good enough to something, or not good enough to something, or not good enough to something, or not good enough to something, or not good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good enough good\n",
      "\n",
      "🧠 Prompt 11: I compare myself to everyone and feel like I’m constantly failing.\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I compare myself to everyone and feel like I’m constantly failing. [/INST] It sounds like you are feeling very overwhelmed and that you are not able to keep up with the expectations that you have for yourself.  It is important to remember that everyone has their own unique strengths and weaknesses and that it is not possible to be good at everything.  It is also important to remember that it is not possible to be perfect.  It is okay to make mistakes and to learn from them.  It is important to be kind to yourself and to remember that you are doing the best that you can.  It may be helpful to talk with a therapist about your feelings.  A therapist can help you to learn ways to be kind to yourself and to learn to accept yourself as you are.\n",
      "\n",
      "🧠 Prompt 12: Why do I always blame myself when something goes wrong?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Why do I always blame myself when something goes wrong? [/INST] It is common to blame ourselves when something goes wrong.  It is important to remember that we are not responsible for everything that happens to us.  Sometimes things happen that are beyond our control.  It is important to take responsibility for what we can control and to let go of what we cannot control.  It is also important to remember that we are not alone in the world and that we can ask for help when we need it.  It is important to be kind to ourselves and to remember that we are not perfect.\n",
      "\n",
      "🧠 Prompt 13: I always say yes to people even when I’m exhausted. How do I set boundaries?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I always say yes to people even when I’m exhausted. How do I set boundaries? [/INST] Setting boundaries is a skill that is difficult to learn.  It is important to know your limits and to communicate them to others.  You can start by saying \"no\" to one or two things that you know you will not be able to do.  This will help you to feel more in control of your life and to feel less exhausted.  You can also practice saying \"no\" to things that are not important to you.  This will help you to feel more confident in saying \"no\" to things that are important to you.  You can also practice saying \"no\" in a polite way.  You can say \"no\" and then explain why you are saying \"no\".  This will help you to feel more confident in setting boundaries.  You can also practice saying \"no\" to yourself.  You can say \"no\" to yourself when you are tired or when you are not feeling well.  This will help you to learn to listen to yourself and to\n",
      "\n",
      "🧠 Prompt 14: My partner doesn’t understand my anxiety. It’s hurting our relationship. What should I do?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "My partner doesn’t understand my anxiety. It’s hurting our relationship. What should I do? [/INST] Anxiety is a very difficult thing to understand.  It is not something that you can just turn off.  It is not something that you can just get over.  It is something that you can manage.  It is something that you can.  It is something.  It.  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "🧠 Prompt 15: I feel guilty for putting myself first. Is that selfish?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel guilty for putting myself first. Is that selfish? [/INST] It is not selfish to put yourself first.  It is important to take care of yourself and to make sure that you are healthy and happy.  If you are not taking care of yourself, then you will not be able to take care of others.  It is important to make sure that you are getting enough rest, eating well, and doing things that make you happy.  If you are feeling guilty about putting yourself first, then maybe you need to think about why you are feeling guilty.  Are you feeling guilty because you are not taking care of yourself?  If so, then maybe you need to make some changes in your life so that you can take care of yourself.  If you are feeling guilty because you are not taking care of others, then maybe you need to make sure that you are not neglecting yourself in order to take care of others.  It is important to find a balance between taking care of yourself and taking care of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Trial 13 model path\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial13\"\n",
    "\n",
    "# Load model + tokenizer\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load test prompts\n",
    "test_file_path = \"/content/drive/MyDrive/chatbot/counsel/datasets/test_prompts_counselchat.jsonl\"  # or another file\n",
    "with open(test_file_path, \"r\") as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Run inference\n",
    "results = []\n",
    "for i, sample in enumerate(tqdm(test_data, desc=\"🧠 Running Trial 13 Inference\")):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{sample['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    results.append({\n",
    "        \"user_prompt\": sample[\"instruction\"],\n",
    "        \"model_response\": decoded.strip()\n",
    "    })\n",
    "\n",
    "# Display responses\n",
    "for idx, r in enumerate(results, 1):\n",
    "    print(f\"\\n🧠 Prompt {idx}: {r['user_prompt']}\\n🤖 Response: {r['model_response']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3e47fc3e71bd463e9cb69d9545b382f9",
      "28906eedc6534c8685673255c6f388a4",
      "fe091ff11adf43e588bf7235bba2deb8",
      "5d7cf20fd5ae4988be23919d45862dac",
      "cf92aaa6d08e4c0e88bf85b27b1804b8",
      "11ea95690f3f4675a4f9671c6e5df898",
      "d2301011ba984dc6bd0a2aa6081edfd8",
      "036a408608ab4ddfa301620bb2e2f95e",
      "8c6c5c75575540d885d65c93e68be9c8",
      "6c95df3ac44d4460a8b09167f7804868",
      "7f9e4c91830442d9b3f0af044239bf51"
     ]
    },
    "executionInfo": {
     "elapsed": 87798,
     "status": "ok",
     "timestamp": 1746296089861,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "95k-p71YU-Vm",
    "outputId": "9e02c055-fc4a-4dfc-9b98-fe2d90b2c44b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e47fc3e71bd463e9cb69d9545b382f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Running Trial 13 Inference:   0%|          | 0/15 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "🧠 Running Trial 13 Inference: 100%|██████████| 15/15 [01:13<00:00,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt 1: I feel like I'm constantly overthinking every little thing. How do I make it stop?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel like I'm constantly overthinking every little thing. How do I make it stop? [/INST] One strategy is to try practicing \"mindfulness\" (the term used in psychology for staying present, being fully aware of your current moment without judgment).  This can be done by setting aside some time each day to focus on breathing or meditate, but also by making yourself more mindful throughout the day with simple things such as noticing what you see when you walk outside, really tasting your food when eating, paying attention to all sounds around you, etc.\n",
      "\n",
      "🧠 Prompt 2: Why do I get so anxious when I have to talk to people, even my friends?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Why do I get so anxious when I have to talk to people, even my friends? [/INST] Hi. I think you is your anxiety, withs, liket, be for about to to may you' youring on talking the.\n",
      "\n",
      "🧠 Prompt 3: I wake up with a knot in my stomach every day. What can I do about it?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I wake up with a knot in my stomach every day. What can I do about it? [/INST] Are you aware of what is causing the anxiety or stress that is contributing to your stomach pain?  Do you feel as though there is anything you could do to change your situation?  If so, then make sure that you focus on the things you CAN control instead of worrying about things you cannot control (like other people's actions).  What steps can you take towards achieving your goals?  Have a plan of action ready to implement if something were to happen.Also, make sure that you have some support from family/friends.  Sometimes we get caught up in our problems and forget that others want to help us.  Ask for their advice and feedback.  Maybe they will be able to see some things that you aren't able to.Eating well and staying active can also help reduce your body's response to stress.  Try practicing relaxation techniques like deep breathing exercises or meditation to calm yourself.\n",
      "\n",
      "🧠 Prompt 4: Lately I’ve lost interest in everything. Nothing makes me happy anymore.\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Lately I’ve lost interest in everything. Nothing makes me happy anymore. [/INST] Hello,  I'm sorry to hear that you have lost the enjoyment of life.  Many things can cause loss of pleasure such as medical issues or depression.  Depression is treatable with therapy and medication.\n",
      "\n",
      "🧠 Prompt 5: Is it normal to feel tired all the time even when I’m not physically active?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Is it normal to feel tired all the time even when I’m not physically active? [/INST] If you're feeling tired for no reason, there is definitely something going on.  It can be caused by many things such as depression, anxiety or chronic fatigue syndrome.  The only way to know what it may be causing your exhaustion is to see a doctor.\n",
      "\n",
      "🧠 Prompt 6: I feel numb, like nothing really matters. What should I do?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel numb, like nothing really matters. What should I do? [/INST] Helloing you that is the only thing anyone can do for someone else when they feel that way.  The best thing you can do is reach out to others in your life.\n",
      "\n",
      "🧠 Prompt 7: I had a panic attack at work and now I’m afraid it’ll happen again. How do I cope?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I had a panic attack at work and now I’m afraid it’ll happen again. How do I cope? [/INST] It is very common to have anxiety about having another panic attack, especially right after one has occurred and you are still feeling the effects of that first panic attack.  There are several things you can try in order to help yourself feel more comfortable in your job setting so as to not trigger another panic attack.  First, take some deep breaths through your nose for a few minutes each day when you first arrive at work.  This will help calm your body down if you are anxious before you even get on the clock and be prepared for work with your coworkers or clients.  Second, make sure your desk your workspace is organized so that you know where everything is so then it not stressful looking.  Third, if there are certain triggers at work such as noise or you you're uncomfortable in ive to have askor to office  or talk  be uncomfortable   your supervisor,, you  work to a\n",
      "\n",
      "🧠 Prompt 8: My heart races for no reason and I feel like I can't breathe. Am I losing control?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "My heart races for no reason and I feel like I can't breathe. Am I losing control? [/INST] Hello,I am not sure why your breathing would change when you have anxiety or panic attacks but it is possible that you may be having one of those while talking about the situation.\n",
      "\n",
      "🧠 Prompt 9: How can I calm down quickly when I feel overwhelmed in public?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "How can I calm down quickly when I feel overwhelmed in public? [/INST] A good way is with deep breathing. This will help slow your heart rate down which will also decrease the amount of cortisol (stress hormone) that is being released into your body, helping you feel more relaxed!\n",
      "\n",
      "🧠 Prompt 10: No matter what I do, I always feel like I’m not good enough.\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "No matter what I do, I always feel like I’m not good enough. [/INST] It sounds like you have low self-esteem.  Low self- esteem is the feeling that you are unworthy or undeserving of love, respect, happiness. This usually comes from your parents or caregivers when they didn't give us the love we needed as children. The good news is that it can be healed with therapy!\n",
      "\n",
      "🧠 Prompt 11: I compare myself to everyone and feel like I’m constantly failing.\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I compare myself to everyone and feel like I’m constantly failing. [/INST] The first step in breaking the cycle of comparing yourself to others is to recognize that you're doing it.  It can be easy because there for, you're focusing on what other people have, not where you stand with your own goals or values. Then reflect on why you may be doing it. Is it due to low self-esteem? Are you unhappy with something in your life (career, relationship)? Once you realize you're making these comparisons, you'll start to notice them less frequently and eventually they will fade away completely!\n",
      "\n",
      "🧠 Prompt 12: Why do I always blame myself when something goes wrong?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "Why do I always blame myself when something goes wrong? [/INST] This is an important question.   Blaming yourself for everything can be very difficult, it may even be that you feel like you have no control over your life or the things that happen to you. It can also be difficult because it can lead to negative self-talk about yourself. The first thing I would suggest is thinking about what happens after you blame yourself. Do you stop feeling bad and move on? Or does blaming yourself make you more upset than usual? If you find that you tend to blame yourself and then get stuck in those thoughts it might help to talk with someone like a therapist so that you can learn new ways of dealing with your emotions and situations as they come up.\n",
      "\n",
      "🧠 Prompt 13: I always say yes to people even when I’m exhausted. How do I set boundaries?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I always say yes to people even when I’m exhausted. How do I set boundaries? [/INST] The first thing you need to do is recognize that saying \"yes\" all the time doesn't make you a good person.  There are times in our lives where we simply have too much on our plate, whether it be work or personal obligations, and telling someone no can actually help us avoid being overwhelmed and stressed out.  Saying no means setting a boundary.  The next step would be to practice saying no more often!\n",
      "\n",
      "🧠 Prompt 14: My partner doesn’t understand my anxiety. It’s hurting our relationship. What should I do?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "My partner doesn’t understand my anxiety. It’s hurting our relationship. What should I do? [/INST] Anxiety is different from person to person, so what works for one may not work for another, but the first thing you need to find out if they're willing to try and understand how you feel and be there for you through it all. If that happens then great! Find a therapist in your area that specializes in CBT (Cognitive Behavioral Therapy) or DBT (Dialectical Behavior Therapy), whichever fits better with your personality, and start therapy as soon as possible. Having someone by your side during the process can make it much easier to handle than going alone.\n",
      "\n",
      "🧠 Prompt 15: I feel guilty for putting myself first. Is that selfish?\n",
      "🤖 Response: [INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\n",
      "I feel guilty for putting myself first. Is that selfish? [/INST] No, you need some time alone so that when you come back home_comma_ you can be your best self with them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Trial 13 model path\n",
    "model_path = \"/content/drive/MyDrive/SIT782/checkpoints/mistral-lora-trial13\"\n",
    "\n",
    "# Load LoRA config and base model\n",
    "peft_config = PeftConfig.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, model_path)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load test prompts (modify path as needed)\n",
    "test_file = \"/content/drive/MyDrive/chatbot/counsel/datasets/test_prompts_counselchat.jsonl\"\n",
    "with open(test_file, \"r\") as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Inference with good decoding parameters\n",
    "results = []\n",
    "for i, sample in enumerate(tqdm(test_data, desc=\"🧠 Running Trial 13 Inference\")):\n",
    "    prompt = f\"<s>[INST] You are a kind and supportive mental health assistant who responds empathetically to this user message:\\n{sample['instruction']} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    results.append({\n",
    "        \"user_prompt\": sample[\"instruction\"],\n",
    "        \"model_response\": decoded.strip()\n",
    "    })\n",
    "\n",
    "# Print responses\n",
    "for idx, r in enumerate(results, 1):\n",
    "    print(f\"\\n🧠 Prompt {idx}: {r['user_prompt']}\\n🤖 Response: {r['model_response']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASSdLk_6WlU-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9PA87l19F7a"
   },
   "source": [
    "# Evaluation Summary For Empathetic Dialogues + Mistral 7b model trials\n",
    "\n",
    "###Trial Summary (Trial 1–13)\n",
    "\n",
    "| **Trial** | **Dataset**                       | **Synthetic** | **Merged** | **BLEU** | **ROUGE-1** | **ROUGE-2** | **ROUGE-L** | **BERTScore (F1)** |\n",
    "|-----------|-----------------------------------|---------------|------------|---------:|------------:|------------:|------------:|-------------------:|\n",
    "| Trial 1   | EmpDiag 1000                      | ❌            | ❌         | 0.0018   | 0.0824      | 0.0044      | 0.0666      | 0.8229              |\n",
    "| Trial 2   | EmpDiag 1000                      | ❌            | ❌         | 0.0018   | 0.0788      | 0.0040      | 0.0637      | 0.8212              |\n",
    "| Trial 3   | EmpDiag 1000                      | ❌            | ❌         | 0.0040   | 0.1021      | 0.0070      | 0.0864      | 0.8294              |\n",
    "| Trial 4   | EmpDiag 1000                      | ❌            | ❌         | 0.0222   | 0.2384      | 0.0387      | 0.1225      | 0.8144              |\n",
    "| Trial 5   | EmpDiag 1000                      | ❌            | ❌         | 0.0243   | 0.3071      | 0.0416      | 0.1307      | 0.8344              |\n",
    "| Trial 6   | EmpDiag 3000                      | ✅            | ❌         | 0.0280   | 0.2967      | 0.0540      | 0.1442      | 0.8328              |\n",
    "| Trial 7   | EmpDiag 3000                      | ✅            | ❌         | 0.0033   | 0.0995      | 0.0072      | 0.0768      | 0.8255              |\n",
    "| Trial 8   | EmpDiag 3600                      | ✅            | ❌         | 0.0177   | 0.1330      | 0.0289      | 0.1028      | 0.8349              |\n",
    "| Trial 9   | EmpDiag 4100                      | ✅            | ❌         | 0.0198   | 0.1434      | 0.0277      | 0.1103      | 0.8406              |\n",
    "| Trial 10  | EmpDiag Filtered                  | ❌            | ❌         | 0.0139   | 0.1744      | 0.0217      | 0.1162      | 0.8314              |\n",
    "| Trial 11  | 6937 Emp + 2116 Counsel           | ❌            | ✅         | 0.0098   | 0.1592      | 0.0183      | 0.1061      | 0.8254              |\n",
    "| Trial 12  | EmpDiag 4100                      | ✅            | ❌         | 0.0604   | 0.1617      | 0.0110      | 0.0886      | 0.8058              |\n",
    "| Trial 13  | Merged Deduplicated Emp+Counsel   | ❌            | ✅         | 0.0010   | 0.1693      | 0.0180      | 0.1031      | 0.8157              |\n",
    "\n",
    "✅ *Best BERTScore*: Trial 9 (0.8406)  \n",
    "✅ *Best ROUGE-1*: Trial 5 (0.3071)  \n",
    "✅ *Best BLEU*: Trial 12 (0.0604)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "error",
     "timestamp": 1747507652705,
     "user": {
      "displayName": "Hariprasad",
      "userId": "18224192613593112369"
     },
     "user_tz": -600
    },
    "id": "j2M3Ea2kCJfX",
    "outputId": "66e4e2e6-a647-4128-e0bf-8e83bfaea711"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/emplath-mistral.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-32a6d0fb707c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbformat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNO_CONVERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/emplath-mistral.ipynb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNO_CONVERT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/emplath-mistral.ipynb'"
     ]
    }
   ],
   "source": [
    "from nbformat import read, write\n",
    "from nbformat import NO_CONVERT\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Colab Notebooks/emplath-mistral.ipynb\") as f:\n",
    "    nb = read(f, as_version=NO_CONVERT)\n",
    "\n",
    "# Remove invalid widget metadata\n",
    "if \"widgets\" in nb.metadata and \"state\" not in nb.metadata[\"widgets\"]:\n",
    "    del nb.metadata[\"widgets\"]\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Colab Notebooks/emplath-mistral-cleaned_notebook.ipynb\", \"w\") as f:\n",
    "    write(nb, f)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNTdeG+EfVlzrT6JrnmCR8D",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
