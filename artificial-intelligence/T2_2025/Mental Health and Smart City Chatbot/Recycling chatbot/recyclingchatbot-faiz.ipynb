{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ8tCCeWVsJp",
        "outputId": "a7cb6e7f-8104-481d-c7df-d2bf5347eb6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique categories:\n",
            "- Chemicals\n",
            "- E-waste\n",
            "- Food packaging\n",
            "- Garden waste\n",
            "- Hard waste\n",
            "- Hazardous waste\n",
            "- Household items\n",
            "- Household waste\n",
            "- Medical waste\n",
            "- Organic waste\n",
            "- Packaging\n",
            "- Paper\n",
            "- Soft plastics\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load the dataset\n",
        "with open('waste_disposal_dataset.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract all unique categories\n",
        "unique_categories = sorted(set(item[\"category\"] for item in data))\n",
        "\n",
        "# Print them\n",
        "print(\"Unique categories:\")\n",
        "for category in unique_categories:\n",
        "    print(\"-\", category)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = 0\n",
        "for i in range(len(data)):\n",
        "  x = (data[i]['item'])\n",
        "  print(x)\n",
        "\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3TgCsf5NFso",
        "outputId": "a1adf5fa-1373-458f-e6ae-6194a64c8f81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aerosol cans\n",
            "Adhesive strips (band aids)\n",
            "Aluminium cans\n",
            "Aluminium foil\n",
            "Aluminium trays\n",
            "Anti-freeze\n",
            "Asbestos\n",
            "Australia Post satchels\n",
            "Baby items\n",
            "Balloons\n",
            "Baskets\n",
            "Batteries (car)\n",
            "Batteries (household)\n",
            "Bicycles\n",
            "Biscuit trays\n",
            "Blankets and bedding\n",
            "Blister packs (medicinal)\n",
            "Bottles (glass, plastic, metal)\n",
            "Branches\n",
            "Bread bags\n",
            "Bubble wrap\n",
            "Cables (computer, charging, electronic)\n",
            "Cameras\n",
            "Cans (steel, aluminium)\n",
            "Car parts and bodies\n",
            "Cardboard\n",
            "Cartons (milk and juice)\n",
            "Carpet\n",
            "Cassette tapes\n",
            "CDs\n",
            "Ceramics (vases, pots, etc)\n",
            "Cellophane\n",
            "Chargers\n",
            "Chemicals\n",
            "Chip packets\n",
            "Chlorine\n",
            "Christmas trees\n",
            "Cigarette butts\n",
            "Cling wrap\n",
            "Clothing and shoes\n",
            "Coffee cups and lids (single use)\n",
            "Coffee pods / capsules\n",
            "Coffee machines\n",
            "Computers and accessories\n",
            "Cooking oil\n",
            "Crockery\n",
            "Cutlery (metal)\n",
            "Cutlery (plastic)\n",
            "Cupboards\n",
            "Detergent bottles (plastic)\n",
            "Deodorant cans, roll-ons, sprays\n",
            "Diabetic testing strip\n",
            "Dishwasher\n",
            "Disposable coffee cups\n",
            "Dog faeces\n",
            "Door mat\n",
            "Dryer\n",
            "DVDs\n",
            "DVD player\n",
            "E-waste\n",
            "Fabric\n",
            "Fire extinguishers\n",
            "Fluorescent tubes and compact fluorescent light globes (CFLs)\n",
            "Foam\n",
            "Food pouches\n",
            "Food scraps\n",
            "Formula tins\n",
            "Fridge / freezer\n",
            "Frozen food bags\n",
            "Fruit tree netting\n",
            "Fuels\n",
            "Furniture\n",
            "Garden waste\n",
            "Gas cylinders and bottles\n",
            "Glass bottles and jars\n",
            "Glass windows, cups, mirrors and table tops\n",
            "Hard waste\n",
            "Hair dryers or straighteners\n",
            "Household chemicals\n",
            "Ice cream containers\n",
            "Insect spray bottles and cans\n",
            "Iron\n",
            "Jars and lids\n",
            "Juice boxes and containers\n",
            "Kettles\n",
            "Keyboards\n",
            "Kitchenware\n",
            "Kitty litter\n",
            "Laptops\n",
            "Laminated paper\n",
            "Light globes\n",
            "Linen\n",
            "Lolly wrappers\n",
            "Magazines\n",
            "Mattresses\n",
            "Medicines\n",
            "Metal scraps\n",
            "Microwaves\n",
            "Mirrors\n",
            "Monitors (computer)\n",
            "Motor oil\n",
            "Nappies\n",
            "Netting (fruit trees)\n",
            "Netting produce bags\n",
            "Newspapers\n",
            "Nitrous oxide canisters\n",
            "Oils - cooking\n",
            "Oils – motor\n",
            "Oven\n",
            "Oven cleaner\n",
            "Paint and paint stripper\n",
            "Paint tins\n",
            "Paper and cardboard\n",
            "Paper towel\n",
            "Pens and markers\n",
            "Pet food bags\n",
            "Plant pots\n",
            "Plasterboard\n",
            "Plastic bags\n",
            "Plastic containers and bottles\n",
            "Plastic film\n",
            "Plastic sachets\n",
            "Plastic strapping, packing tape\n",
            "Polystyrene\n",
            "Potting mix bags\n",
            "Power tools\n",
            "Printer cartridges\n",
            "Prunings\n",
            "Pyrex\n",
            "Radios\n",
            "Rat poison\n",
            "Refrigerators\n",
            "Remote control\n",
            "Reusable shopping bags\n",
            "Scrap metal\n",
            "Shoes\n",
            "Smoke detectors (household)\n",
            "Soft plastics\n",
            "Solvents\n",
            "Sporting equipment\n",
            "Steel cans\n",
            "Stoves\n",
            "Tables\n",
            "Tea bags\n",
            "Tetra Paks\n",
            "Timber\n",
            "Tissues\n",
            "Toaster\n",
            "Tools\n",
            "Toothbrushes\n",
            "Toothbrushes (electric)\n",
            "Towels\n",
            "Toys (no batteries)\n",
            "Toys (with plug, cord or battery)\n",
            "Transmission fluid\n",
            "TV units\n",
            "Tupperware\n",
            "Tyres\n",
            "Vacuum cleaners\n",
            "Vacuum cleaner dust\n",
            "Vapes\n",
            "VHS / Cassette tapes\n",
            "Wardrobes\n",
            "Watches\n",
            "Washing machines\n",
            "Waxed cardboard\n",
            "Whitegoods\n",
            "Window glass\n",
            "Wood pallets\n",
            "X-rays\n",
            "Yoghurt containers\n",
            "Zip lock bags\n",
            "172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "MyQO7Dob_5YC",
        "outputId": "fd284626-8aa0-4f71-9dda-91ce9a79107c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install openai pandas\n"
      ],
      "metadata": {
        "id": "h_4b8R5dfSvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0812f2ea-2c12-418f-8b51-1c3561632ee0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📦 Import Libraries\n",
        "import json\n",
        "import urllib.parse  # ✅ Add this line\n",
        "from openai import OpenAI\n"
      ],
      "metadata": {
        "id": "u-Jniqw2B1-o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load your API key here\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\")  # Replace with your API key\n",
        "\n",
        "# Load dataset\n",
        "with open('/content/waste_disposal_dataset.json') as f:\n",
        "    waste_data = json.load(f)\n",
        "\n",
        "# Additional info per category\n",
        "additional_notes = {\n",
        "    \"Hard waste\": \"\"\"\n",
        "🏠 **City of Melbourne Hard Waste Collection**\n",
        "\n",
        "Residents are entitled to **one free hard waste collection per financial year** (maximum volume: 1 cubic metre – 1m x 1m x 1m). If you live in a high-rise, contact your building manager to organize the booking.\n",
        "\n",
        "📦 **Accepted Items Include**:\n",
        "- Scrap iron, steel, and metal items (e.g., old barbecues)\n",
        "- Pottery and chinaware\n",
        "- Securely wrapped sheet glass clearly marked as 'glass'\n",
        "- Mattresses, small rugs (max 1.5m length), tied and rolled\n",
        "- All sizes of e-waste (TVs, computers, etc.)\n",
        "- Whitegoods and appliances (fridges, stoves, dishwashers – **doors must be removed**)\n",
        "- Household furniture, tools, sporting goods, toys, bicycles\n",
        "- Timber < 1m in length (max 10 pieces)\n",
        "- Hot water units\n",
        "\n",
        "📅 **Collection Rules**:\n",
        "- Bookings are essential and can be made up to 2 months in advance\n",
        "- Place items at the kerb **the day before** your collection\n",
        "- Collection trucks **will not enter private property**\n",
        "\n",
        "🔗 Book here: https://cityofmelbourne-hardwaste.cleanaway.com.au/\n",
        "🔁 Items not accepted? Consider donating, or use Dynon Road Recycling Centre (fees may apply)\n",
        "\"\"\",\n",
        "\n",
        "    \"Hazardous waste\": \"\"\"\n",
        "☣️ **Hazardous & Chemical Waste Disposal**\n",
        "\n",
        "Do **not** place any chemicals in your landfill or recycling bins.\n",
        "\n",
        "✅ **Safe Disposal Option**:\n",
        "Drop off household chemicals for free at your closest **Detox Your Home** collection site, organized by **Sustainability Victoria**.\n",
        "\n",
        "🧪 **Accepted Items**:\n",
        "- Paint, solvents, motor oil, cleaning products, garden chemicals, etc.\n",
        "\n",
        "⚠️ **Safety Guidelines**:\n",
        "- Max size per container: **20kg or 20L**\n",
        "- **Do not decant**; bring chemicals in **sealed disposable containers**\n",
        "- Some chemicals may be restricted (check their website before attending)\n",
        "\n",
        "🚛 **Mobile collection service** is also available with broader acceptance range.\n",
        "\n",
        "🔗 More info & locations: https://www.sustainability.vic.gov.au/detoxyourhome\n",
        "\"\"\",\n",
        "\n",
        "    \"E-waste\": \"\"\"\n",
        "🔌 **Electronic Waste (E-Waste) Disposal**\n",
        "\n",
        "E-waste must **not be placed in household bins**. It includes anything with a plug, battery, or cord.\n",
        "\n",
        "📏 **Categories**:\n",
        "- **Small E-waste**: Mobile phones, power banks, charging cables, household batteries\n",
        "  → Drop-off at:\n",
        "    - North Melbourne Library (66 Errol St)\n",
        "    - Boyd Community Hub (207 City Rd)\n",
        "    - East Melbourne Library\n",
        "    - Library at The Dock\n",
        "    - Kathleen Syme Library\n",
        "    - Kensington Town Hall\n",
        "    - Dynon Road Waste & Recycling Centre\n",
        "\n",
        "- **Medium E-waste**: Monitors, small TVs, vacuums, kettles, microwaves\n",
        "  → Drop-off at:\n",
        "    - Dynon Road Recycling Centre\n",
        "    - Kathleen Syme Library\n",
        "    - Library at The Dock\n",
        "\n",
        "- **Large E-waste**: TVs, washing machines, computers (large)\n",
        "  → **Book free hard waste collection**:\n",
        "    https://hardwastecom.citywide.com.au/\n",
        "\n",
        "🛑 **Never dispose of e-waste in landfill or recycling bins.**\n",
        "\"\"\"\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "6uHP8bAAWmKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to call LLM\n",
        "def call_llm(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are a helpful assistant for the City of Melbourne's waste and recycling guide. \"\n",
        "                    \"Based on the item information below, provide a friendly and informative response to a user \"\n",
        "                    \"asking how to dispose of this item. Include details like drop-off instructions, recycling advice, \"\n",
        "                    \"and any important conditions. If additional notes are provided, summarize them clearly. \"\n",
        "                    \"Avoid repeating labels like 'Item:' or 'Category:' in your answer. \"\n",
        "                    \"If a Google Maps link is provided, show it clearly as a separate line in the response.\"\n",
        "                )\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Main recycling info handler\n",
        "def get_recycling_info(user_query):\n",
        "    user_query = user_query.lower()\n",
        "\n",
        "    for item in waste_data:\n",
        "        keywords = [item[\"item\"].lower()] + [alias.lower() for alias in item.get(\"aliases\", [])]\n",
        "        if any(kw in user_query for kw in keywords):\n",
        "            base_info = f\"\"\"\n",
        "Item: {item['item']}\n",
        "Category: {item['category']}\n",
        "Bin Type: {item['bin_type'] or 'Not specified'}\n",
        "Recyclable: {'Yes' if item['recyclable'] else 'No'}\n",
        "Instructions: {item['instructions']}\n",
        "\"\"\"\n",
        "\n",
        "            map_links = []\n",
        "\n",
        "            if item.get(\"drop_off_required\") and item.get(\"drop_off_locations\"):\n",
        "                locations = []\n",
        "                for loc in item[\"drop_off_locations\"]:\n",
        "                    name = loc[\"name\"]\n",
        "                    address = loc[\"address\"]\n",
        "                    suburb = loc[\"suburb\"]\n",
        "                    if \"see website\" not in address.lower() and \"online\" not in address.lower():\n",
        "                        query = f\"{address} {suburb}\".strip().replace(\" \", \"+\")\n",
        "                        maps_link = f\"https://www.google.com/maps/search/?api=1&query={query}\"\n",
        "                        location_str = f\"- {name}, {address}\" + (f\" ({suburb})\" if suburb else \"\") + f\"\\n  Google Maps: {maps_link}\"\n",
        "                        map_links.append(f\"{name}: {maps_link}\")\n",
        "                    else:\n",
        "                        location_str = f\"- {name}, {address}\" + (f\" ({suburb})\" if suburb else \"\")\n",
        "                    locations.append(location_str)\n",
        "                base_info += f\"\\nDrop-off Locations:\\n\" + \"\\n\".join(locations) + \"\\n\"\n",
        "\n",
        "            if item.get(\"extra_notes\"):\n",
        "                base_info += f\"\\nExtra Notes:\\n{item['extra_notes'].strip()}\\n\"\n",
        "\n",
        "            if item[\"category\"] in additional_notes:\n",
        "                base_info += f\"\\nCategory Info:\\n{additional_notes[item['category']].strip()}\"\n",
        "\n",
        "            prompt = f\"\"\"A user asked how to dispose of: {item['item']}.\n",
        "\n",
        "Here is the relevant information:\n",
        "{base_info.strip()}\n",
        "\n",
        "Please explain this in a clear and helpful way.\"\"\"\n",
        "\n",
        "            response = call_llm(prompt)\n",
        "\n",
        "            # Print LLM response\n",
        "            print(response)\n",
        "\n",
        "            # Print Google Maps links clearly\n",
        "            if map_links:\n",
        "                print(\"\\n📍 Google Maps Links:\")\n",
        "                for link in map_links:\n",
        "                    print(link)\n",
        "\n",
        "            return  # Don't return LLM response — already printed\n",
        "\n",
        "    print(\"Sorry, I couldn't find recycling information for that item.\")\n"
      ],
      "metadata": {
        "id": "2Gvkv4mMd6os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"carpets\"  # Try: \"TV units\", \"Tupperware\", \"Chemicals\", etc.\n",
        "get_recycling_info(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij-bKGaJ-2Sj",
        "outputId": "2b32c6fd-f612-4c15-b81c-077856112ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To dispose of carpet, you can take it to the Dynon Road Waste and Recycling Centre located at 437 Dynon Road in West Melbourne. Charges may apply for drop-off, so it's good to keep that in mind.\n",
            "\n",
            "City of Melbourne offers residents one free hard waste collection per financial year. When disposing of items like carpet at the drop-off location, make sure you comply with the rules such as securely wrapping the carpet and taking it to the designated facility.\n",
            "\n",
            "If you need to schedule a hard waste collection, you can book it online up to two months in advance and place the items at the kerb the day before collection. Remember that trucks will not enter private property for collection.\n",
            "\n",
            "For more details and to schedule a collection, you can visit: https://cityofmelbourne-hardwaste.cleanaway.com.au/ \n",
            "\n",
            "If you have other items that are not accepted, consider donating them or utilizing the Dynon Road Recycling Centre for disposal (fees may apply). \n",
            "\n",
            "Drop-off Location:\n",
            "- Dynon Road Waste and Recycling Centre\n",
            "  437 Dynon Road, West Melbourne\n",
            "  Google Maps: [437 Dynon Road, West Melbourne](https://www.google.com/maps/search/?api=1&query=437+Dynon+Road+West+Melbourne)\n",
            "\n",
            "📍 Google Maps Links:\n",
            "Dynon Road Waste and Recycling Centre: https://www.google.com/maps/search/?api=1&query=437+Dynon+Road+West+Melbourne\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96dcc1f2"
      },
      "source": [
        "After mounting your drive, you can access your files at `/content/drive/MyDrive/`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMhvA90mRT6f",
        "outputId": "a1410968-7598-4526-d01c-0d527e96d8c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rapidfuzz import fuzz\n",
        "\n",
        "def get_recycling_info(user_query, threshold=70):\n",
        "    user_query = user_query.lower()\n",
        "    found_items = []\n",
        "\n",
        "    for item in waste_data:\n",
        "        keywords = [item[\"item\"].lower()] + [alias.lower() for alias in item.get(\"aliases\", [])]\n",
        "\n",
        "        for kw in keywords:\n",
        "            score = fuzz.partial_ratio(user_query, kw)  # partial match works better for long queries\n",
        "            if score >= threshold:\n",
        "                found_items.append((item, score))\n",
        "                break  # stop after first good alias match for this item\n",
        "\n",
        "    if not found_items:\n",
        "        print(\"Sorry, I couldn't find recycling information for that item.\")\n",
        "        return\n",
        "\n",
        "    for item, score in found_items:\n",
        "        base_info = f\"\"\"\n",
        "Item: {item['item']}\n",
        "Category: {item['category']}\n",
        "Bin Type: {item['bin_type'] or 'Not specified'}\n",
        "Recyclable: {'Yes' if item['recyclable'] else 'No'}\n",
        "Instructions: {item['instructions']}\n",
        "\"\"\"\n",
        "\n",
        "        if item.get(\"extra_notes\"):\n",
        "            base_info += f\"\\nExtra Notes:\\n{item['extra_notes'].strip()}\\n\"\n",
        "\n",
        "        if item[\"category\"] in additional_notes:\n",
        "            base_info += f\"\\nCategory Info:\\n{additional_notes[item['category']].strip()}\"\n",
        "\n",
        "        # LLM response\n",
        "        prompt = f\"\"\"A user asked: \"{user_query}\".\n",
        "\n",
        "Here is the relevant information:\n",
        "{base_info.strip()}\n",
        "\n",
        "Please explain this in a clear and helpful way.\"\"\"\n",
        "\n",
        "        response = call_llm(prompt)\n",
        "\n",
        "        print(\"🟢 Match found:\", item['item'], f\"(confidence {score}%)\")\n",
        "        print(response)\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "1dZ46O_PSSuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"where to dispose of carpets\"\n",
        "get_recycling_info(query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WhxR0oLSaI6",
        "outputId": "8e242ac5-88ef-4c72-eb19-ab09191200e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟢 Match found: Carpet (confidence 100.0%)\n",
            "You can dispose of carpets as hard waste by utilizing the City of Melbourne's hard waste collection service. Simply book a collection using the link provided, ensuring that the carpet is neatly bundled and within the maximum volume limit of 1 cubic meter. Place the carpet at the kerb the day before your scheduled collection. Note that charges may apply for drop-off.\n",
            "\n",
            "📍 Drop-off: City of Melbourne Hard Waste Collection  \n",
            "🔗 Book here: [City of Melbourne Hard Waste Collection Booking](https://cityofmelbourne-hardwaste.cleanaway.com.au/)\n",
            "\n",
            "==================================================\n",
            "\n",
            "🟢 Match found: Coffee cups and lids (single use) (confidence 70.0%)\n",
            "You can dispose of coffee cups and lids in the following way:\n",
            "\n",
            "1. Remove the lid and place it in the recycling (yellow lid) bin.\n",
            "2. Place the cup in the general waste (red lid) bin or drop it off at 7/11 stores for recycling.\n",
            "\n",
            "7/11 partners with Simply Cups for recycling coffee cups. You can find the nearest 7/11 store by using the following Google Maps link: [Find nearest 7/11 store for recycling](insert Google Maps link here).\n",
            "\n",
            "==================================================\n",
            "\n",
            "🟢 Match found: Disposable coffee cups (confidence 70.0%)\n",
            "You can dispose of disposable coffee cups by removing the lid and placing it in the recycling (yellow lid) bin, and putting the cup itself in the general waste (red lid) bin. Remember to separate the lid for recycling.\n",
            "\n",
            "If you'd like to recycle the cups, you can take them to 7/11 stores through the Simply Cups program.\n",
            "\n",
            "Here is a Google Maps link to help you find the nearest 7/11 store for cup recycling: [Find 7/11 store for cup recycling](insert Google Maps link).\n",
            "\n",
            "==================================================\n",
            "\n",
            "🟢 Match found: Juice boxes and containers (confidence 71.42857142857143%)\n",
            "You can dispose of carpets by taking them to your local waste disposal or recycling center. Carpets cannot be recycled, so please place them in the general waste bin. If your carpet is too large for your bin, you may need to arrange a special collection with your local council. Here is a link to help you find the closest drop-off location: [Find a recycling center near you](insert Google Maps link).\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install deps (Colab)\n",
        "!pip -q install rapidfuzz gradio pandas openai\n",
        "\n",
        "import re, json, math, urllib.parse\n",
        "from collections import defaultdict\n",
        "from rapidfuzz import process, fuzz\n",
        "import pandas as pd\n",
        "\n",
        "# --- Load your dataset ---\n",
        "with open('/content/waste_disposal_dataset.json') as f:\n",
        "    waste_data = json.load(f)\n",
        "\n",
        "# --- Optional: your additional notes dict (reuse yours as-is) ---\n",
        "additional_notes = {\n",
        "    \"Hard waste\": \"\"\"\n",
        "🏠 **City of Melbourne Hard Waste Collection**\n",
        "\n",
        "Residents are entitled to **one free hard waste collection per financial year** (maximum volume: 1 cubic metre – 1m x 1m x 1m). If you live in a high-rise, contact your building manager to organize the booking.\n",
        "\n",
        "📦 **Accepted Items Include**:\n",
        "- Scrap iron, steel, and metal items (e.g., old barbecues)\n",
        "- Pottery and chinaware\n",
        "- Securely wrapped sheet glass clearly marked as 'glass'\n",
        "- Mattresses, small rugs (max 1.5m length), tied and rolled\n",
        "- All sizes of e-waste (TVs, computers, etc.)\n",
        "- Whitegoods and appliances (fridges, stoves, dishwashers – **doors must be removed**)\n",
        "- Household furniture, tools, sporting goods, toys, bicycles\n",
        "- Timber < 1m in length (max 10 pieces)\n",
        "- Hot water units\n",
        "\n",
        "📅 **Collection Rules**:\n",
        "- Bookings are essential and can be made up to 2 months in advance\n",
        "- Place items at the kerb **the day before** your collection\n",
        "- Collection trucks **will not enter private property**\n",
        "\n",
        "🔗 Book here: https://cityofmelbourne-hardwaste.cleanaway.com.au/\n",
        "🔁 Items not accepted? Consider donating, or use Dynon Road Recycling Centre (fees may apply)\n",
        "\"\"\",\n",
        "\n",
        "    \"Hazardous waste\": \"\"\"\n",
        "☣️ **Hazardous & Chemical Waste Disposal**\n",
        "\n",
        "Do **not** place any chemicals in your landfill or recycling bins.\n",
        "\n",
        "✅ **Safe Disposal Option**:\n",
        "Drop off household chemicals for free at your closest **Detox Your Home** collection site, organized by **Sustainability Victoria**.\n",
        "\n",
        "🧪 **Accepted Items**:\n",
        "- Paint, solvents, motor oil, cleaning products, garden chemicals, etc.\n",
        "\n",
        "⚠️ **Safety Guidelines**:\n",
        "- Max size per container: **20kg or 20L**\n",
        "- **Do not decant**; bring chemicals in **sealed disposable containers**\n",
        "- Some chemicals may be restricted (check their website before attending)\n",
        "\n",
        "🚛 **Mobile collection service** is also available with broader acceptance range.\n",
        "\n",
        "🔗 More info & locations: https://www.sustainability.vic.gov.au/detoxyourhome\n",
        "\"\"\",\n",
        "\n",
        "    \"E-waste\": \"\"\"\n",
        "🔌 **Electronic Waste (E-Waste) Disposal**\n",
        "\n",
        "E-waste must **not be placed in household bins**. It includes anything with a plug, battery, or cord.\n",
        "\n",
        "📏 **Categories**:\n",
        "- **Small E-waste**: Mobile phones, power banks, charging cables, household batteries\n",
        "  → Drop-off at:\n",
        "    - North Melbourne Library (66 Errol St)\n",
        "    - Boyd Community Hub (207 City Rd)\n",
        "    - East Melbourne Library\n",
        "    - Library at The Dock\n",
        "    - Kathleen Syme Library\n",
        "    - Kensington Town Hall\n",
        "    - Dynon Road Waste & Recycling Centre\n",
        "\n",
        "- **Medium E-waste**: Monitors, small TVs, vacuums, kettles, microwaves\n",
        "  → Drop-off at:\n",
        "    - Dynon Road Recycling Centre\n",
        "    - Kathleen Syme Library\n",
        "    - Library at The Dock\n",
        "\n",
        "- **Large E-waste**: TVs, washing machines, computers (large)\n",
        "  → **Book free hard waste collection**:\n",
        "    https://hardwastecom.citywide.com.au/\n",
        "\n",
        "🛑 **Never dispose of e-waste in landfill or recycling bins.**\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# ---------- Text utils ----------\n",
        "_word_re = re.compile(r\"[a-z0-9]+\")\n",
        "\n",
        "def normalize(s: str) -> str:\n",
        "    s = s.lower()\n",
        "    return \" \".join(_word_re.findall(s))\n",
        "\n",
        "def maybe_singular(pl: str) -> str:\n",
        "    # very light heuristic\n",
        "    return pl[:-1] if pl.endswith('s') and len(pl) > 3 else pl\n",
        "\n",
        "def split_multi_query(q: str):\n",
        "    # split on commas or \" and \"\n",
        "    parts = re.split(r\",| and \", q, flags=re.I)\n",
        "    return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "# ---------- Build searchable index ----------\n",
        "# We give weights to different fields so item name/alias outranks category hits.\n",
        "INDEX = []     # list of (index_key, item_idx, field, weight)\n",
        "INDEX_KEYS = []  # just the strings for vectorized matching\n",
        "\n",
        "FIELD_WEIGHTS = {\n",
        "    \"item\": 1.0,\n",
        "    \"alias\": 0.95,\n",
        "    \"category\": 0.65,\n",
        "}\n",
        "\n",
        "for idx, it in enumerate(waste_data):\n",
        "    # item name\n",
        "    key = normalize(it[\"item\"])\n",
        "    INDEX.append((key, idx, \"item\", FIELD_WEIGHTS[\"item\"]))\n",
        "    INDEX_KEYS.append(key)\n",
        "\n",
        "    # aliases\n",
        "    for al in it.get(\"aliases\", []):\n",
        "        k = normalize(al)\n",
        "        INDEX.append((k, idx, \"alias\", FIELD_WEIGHTS[\"alias\"]))\n",
        "        INDEX_KEYS.append(k)\n",
        "\n",
        "    # category (helps queries like \"chemicals\", \"e-waste\")\n",
        "    if it.get(\"category\"):\n",
        "        k = normalize(it[\"category\"])\n",
        "        INDEX.append((k, idx, \"category\", FIELD_WEIGHTS[\"category\"]))\n",
        "        INDEX_KEYS.append(k)\n",
        "\n",
        "# For speed, keep a parallel list of metadata for the INDEX rows:\n",
        "INDEX_META = [{\"item_idx\": idx, \"field\": fld, \"weight\": w} for (_, idx, fld, w) in INDEX]\n",
        "\n",
        "# ---------- Core search ----------\n",
        "def score_one_subquery(subq_norm: str, score_cutoff=60, top_k=50):\n",
        "    \"\"\"\n",
        "    Returns a dict: item_idx -> {\"score\": aggregated_score, \"hits\": [(index_row, score, method), ...]}\n",
        "    We ensemble two scorers and keep the max per index row, then aggregate to item.\n",
        "    \"\"\"\n",
        "    # Vectorized matching over INDEX_KEYS\n",
        "    # 1) token_set_ratio (handles word order & duplicates well)\n",
        "    hits_a = process.extract(\n",
        "        subq_norm, INDEX_KEYS,\n",
        "        scorer=fuzz.token_set_ratio,\n",
        "        score_cutoff=score_cutoff,\n",
        "        limit=top_k\n",
        "    )\n",
        "    # 2) partial_ratio (good for substrings)\n",
        "    hits_b = process.extract(\n",
        "        subq_norm, INDEX_KEYS,\n",
        "        scorer=fuzz.partial_ratio,\n",
        "        score_cutoff=score_cutoff,\n",
        "        limit=top_k\n",
        "    )\n",
        "\n",
        "    # Merge hits: keep max score per INDEX row\n",
        "    merged = {}\n",
        "    for (idx_key, score, pos) in hits_a:\n",
        "        merged[pos] = (\"token_set_ratio\", score)\n",
        "    for (idx_key, score, pos) in hits_b:\n",
        "        prev = merged.get(pos)\n",
        "        if (not prev) or (score > prev[1]):\n",
        "            merged[pos] = (\"partial_ratio\", score)\n",
        "\n",
        "    # Aggregate to items with weights + small bonuses\n",
        "    by_item = defaultdict(lambda: {\"score\": 0.0, \"hits\": []})\n",
        "\n",
        "    for pos, (method, base_score) in merged.items():\n",
        "        meta = INDEX_META[pos]\n",
        "        row_text = INDEX_KEYS[pos]\n",
        "        weight = meta[\"weight\"]\n",
        "        item_idx = meta[\"item_idx\"]\n",
        "\n",
        "        # Bonuses for high-precision signals\n",
        "        bonus = 0.0\n",
        "        if row_text in subq_norm:\n",
        "            bonus += 5.0  # substring present\n",
        "        if subq_norm.startswith(row_text[: max(3, len(row_text)//2)]):\n",
        "            bonus += 2.0  # prefix-ish\n",
        "\n",
        "        # Weighted score\n",
        "        wscore = (base_score * weight) + bonus\n",
        "\n",
        "        # Keep the best contribution from this index row\n",
        "        by_item[item_idx][\"score\"] = max(by_item[item_idx][\"score\"], wscore)\n",
        "        by_item[item_idx][\"hits\"].append((pos, INDEX[pos][0], meta[\"field\"], base_score, weight, method, bonus))\n",
        "\n",
        "    return by_item\n",
        "\n",
        "def search_items(user_query: str, threshold=70, max_results=8):\n",
        "    \"\"\"\n",
        "    Splits multi-item queries, scores each sub-query, aggregates across sub-queries.\n",
        "    Returns sorted list of (item, agg_score, debug_rows)\n",
        "    \"\"\"\n",
        "    parts = split_multi_query(user_query.lower())\n",
        "    if not parts:\n",
        "        parts = [user_query.lower()]\n",
        "    parts_norm = [normalize(p) for p in parts]\n",
        "\n",
        "    agg = defaultdict(lambda: {\"score\": 0.0, \"reasons\": []})\n",
        "\n",
        "    for sub in parts_norm:\n",
        "        sub_scores = score_one_subquery(sub, score_cutoff=max(40, threshold-20), top_k=80)\n",
        "        for item_idx, data in sub_scores.items():\n",
        "            # Aggregate: use softplus to reward multiple sub-query hits without linear explosion\n",
        "            # softplus(x)=ln(1+e^(x/20))*20, so ~linear around normal score ranges but tempered\n",
        "            sp = math.log1p(math.exp(data[\"score\"]/20.0)) * 20.0\n",
        "            agg[item_idx][\"score\"] += sp\n",
        "            agg[item_idx][\"reasons\"].extend(data[\"hits\"])\n",
        "\n",
        "    # Convert to ranked list\n",
        "    ranked = []\n",
        "    for item_idx, data in agg.items():\n",
        "        # small boost if the canonical item name is in the original raw query\n",
        "        name = waste_data[item_idx][\"item\"].lower()\n",
        "        boost = 6.0 if name in user_query.lower() else 0.0\n",
        "        final = data[\"score\"] + boost\n",
        "        ranked.append((item_idx, final, data[\"reasons\"]))\n",
        "\n",
        "    ranked.sort(key=lambda x: x[1], reverse=True)\n",
        "    # Filter by a practical threshold (post-aggregation)\n",
        "    ranked = [r for r in ranked if r[1] >= threshold]\n",
        "    ranked = ranked[:max_results]\n",
        "\n",
        "    results = []\n",
        "    for item_idx, final_score, reasons in ranked:\n",
        "        results.append((waste_data[item_idx], round(final_score, 1), reasons))\n",
        "    return results\n",
        "\n",
        "# ---------- Utilities to render info ----------\n",
        "def build_maps_links(dropoff_list):\n",
        "    links = []\n",
        "    rendered_lines = []\n",
        "    for loc in dropoff_list:\n",
        "        name = loc.get(\"name\", \"\").strip()\n",
        "        address = (loc.get(\"address\") or \"\").strip()\n",
        "        suburb = (loc.get(\"suburb\") or \"\").strip()\n",
        "        show_line = f\"- {name}\" if name else \"- Location\"\n",
        "        if address:\n",
        "            show_line += f\", {address}\"\n",
        "        if suburb:\n",
        "            show_line += f\" ({suburb})\"\n",
        "        rendered_lines.append(show_line)\n",
        "\n",
        "        # Only make GMaps link when we have a mappable address\n",
        "        if address and (\"see website\" not in address.lower()) and (\"online\" not in address.lower()):\n",
        "            q = urllib.parse.quote_plus(f\"{address} {suburb}\".strip())\n",
        "            links.append((name or \"Location\", f\"https://www.google.com/maps/search/?api=1&query={q}\"))\n",
        "    return rendered_lines, links\n",
        "\n",
        "def render_item_markdown(it, category_notes: dict):\n",
        "    lines = []\n",
        "    lines.append(f\"### {it['item']}\")\n",
        "    if it.get(\"category\"):\n",
        "        lines.append(f\"**Category:** {it['category']}\")\n",
        "    lines.append(f\"**Bin Type:** {it.get('bin_type') or 'Not specified'}\")\n",
        "    lines.append(f\"**Recyclable:** {'Yes' if it.get('recyclable') else 'No'}\")\n",
        "\n",
        "    if it.get(\"instructions\"):\n",
        "        lines.append(f\"**What to do:** {it['instructions']}\")\n",
        "\n",
        "    if it.get(\"drop_off_required\") and it.get(\"drop_off_locations\"):\n",
        "        rendered, links = build_maps_links(it[\"drop_off_locations\"])\n",
        "        if rendered:\n",
        "            lines.append(\"**Drop-off locations:**\")\n",
        "            lines.extend(rendered)\n",
        "        if links:\n",
        "            lines.append(\"\\n**📍 Google Maps Links:**\")\n",
        "            for name, url in links:\n",
        "                lines.append(f\"- [{name}]({url})\")\n",
        "\n",
        "    if it.get(\"extra_notes\"):\n",
        "        lines.append(f\"\\n**Notes:** {it['extra_notes'].strip()}\")\n",
        "\n",
        "    if it.get(\"category\") in category_notes:\n",
        "        lines.append(\"\\n**Category Info:**\")\n",
        "        lines.append(category_notes[it[\"category\"]].strip())\n",
        "\n",
        "    return \"\\n\\n\".join(lines)\n",
        "\n",
        "# ---------- Optional LLM wrapper (uses your prompt style) ----------\n",
        "from typing import Optional\n",
        "\n",
        "def explain_with_llm(item_md: str, api_key: Optional[str] = None) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    If api_key provided, use OpenAI Chat Completions to rewrite the markdown into\n",
        "    a friendly paragraph. Otherwise return None.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return None\n",
        "\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=\"\")\n",
        "\n",
        "    sys_prompt = (\n",
        "        \"You are a helpful assistant for the City of Melbourne's waste and recycling guide. \"\n",
        "        \"Rewrite the provided info into a friendly, concise explanation with clear steps. \"\n",
        "        \"Keep links on their own lines. Avoid prefixes like 'Item:'/'Category:'; just explain.\"\n",
        "    )\n",
        "    user_prompt = \"Please explain the following guidance clearly for a resident:\\n\\n\" + item_md\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\":\"system\",\"content\":sys_prompt},\n",
        "                  {\"role\":\"user\",\"content\":user_prompt}],\n",
        "        temperature=0.4,\n",
        "    )\n",
        "    return resp.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "d5zjtyYYSlaU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gradio as gr\n",
        "\n",
        "def app_search(user_query, threshold, api_key, show_debug):\n",
        "    if not user_query or not user_query.strip():\n",
        "        return \"Type something like: `where do I dispose of carpets and batteries?`\", pd.DataFrame()\n",
        "\n",
        "    results = search_items(user_query, threshold=threshold, max_results=8)\n",
        "\n",
        "    if not results:\n",
        "        # fallback: show top suggestions even if below threshold\n",
        "        sugg = search_items(user_query, threshold=max(0, threshold-25), max_results=5)\n",
        "        if not sugg:\n",
        "            return \"Sorry, I couldn't find recycling information for that item.\", pd.DataFrame()\n",
        "        df = pd.DataFrame([{\n",
        "            \"Suggested Item\": r[0][\"item\"],\n",
        "            \"Category\": r[0].get(\"category\",\"\"),\n",
        "            \"Score\": r[1],\n",
        "        } for r in sugg])\n",
        "        return (\"I couldn't find a strong match. Here are some close suggestions you can try:\\n\" +\n",
        "                \"\\n\".join(f\"- {row['Suggested Item']} ({row['Category']})\"\n",
        "                          for _, row in df.iterrows())), df\n",
        "\n",
        "    # Build markdown for the best 1–3 matches\n",
        "    top_to_render = results[:3]\n",
        "    out_sections = []\n",
        "    table_rows = []\n",
        "\n",
        "    for it, sc, reasons in results:\n",
        "        table_rows.append({\n",
        "            \"Item\": it[\"item\"],\n",
        "            \"Category\": it.get(\"category\",\"\"),\n",
        "            \"Score\": sc\n",
        "        })\n",
        "\n",
        "    for it, sc, reasons in top_to_render:\n",
        "        md = render_item_markdown(it, additional_notes)\n",
        "        llm_text = explain_with_llm(md, api_key=api_key)\n",
        "        if llm_text:\n",
        "            out_sections.append(f\"## {it['item']}  \\n*(confidence {sc})*\\n\\n{llm_text}\")\n",
        "        else:\n",
        "            out_sections.append(f\"## {it['item']}  \\n*(confidence {sc})*\\n\\n{md}\")\n",
        "\n",
        "        if show_debug:\n",
        "            # Show top contributing matches for transparency\n",
        "            dbg = sorted(reasons, key=lambda r: (r[3]*r[4]), reverse=True)[:6]\n",
        "            lines = [\"\\n<details><summary>Why this matched</summary>\\n\\n| Matched Text | Field | Base Score | Weight | Method | Bonus |\",\n",
        "                     \"|---|---:|---:|---:|---|---:|\"]\n",
        "            for (pos, text, field, base, wt, method, bonus) in dbg:\n",
        "                lines.append(f\"| `{text}` | {field} | {base:.1f} | {wt:.2f} | {method} | {bonus:.1f} |\")\n",
        "            lines.append(\"</details>\")\n",
        "            out_sections.append(\"\\n\".join(lines))\n",
        "\n",
        "    df = pd.DataFrame(table_rows).sort_values(\"Score\", ascending=False)\n",
        "    return \"\\n\\n---\\n\\n\".join(out_sections), df\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"City of Melbourne – Recycling Helper\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # ♻️ City of Melbourne – Recycling Helper\n",
        "        Type what you want to dispose of (you can list multiple, e.g. **\"carpets, batteries and TV\"**).\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        query = gr.Textbox(lines=2, label=\"What do you want to dispose of?\", placeholder=\"e.g., where to dispose of carpets and batteries\")\n",
        "    with gr.Row():\n",
        "        threshold = gr.Slider(40, 120, value=80, step=1, label=\"Match confidence (higher = stricter)\")\n",
        "        api_key = gr.Textbox(label=\"OpenAI API key (optional – for friendlier explanations)\", type=\"password\")\n",
        "        show_debug = gr.Checkbox(label=\"Show match debug (why it matched)\", value=False)\n",
        "\n",
        "    go = gr.Button(\"Search\")\n",
        "    out_md = gr.Markdown()\n",
        "    out_df = gr.Dataframe(interactive=False, label=\"Matched Items\", wrap=True)\n",
        "\n",
        "    go.click(app_search, inputs=[query, threshold, api_key, show_debug], outputs=[out_md, out_df])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "Ol1sjL1CgsHt",
        "outputId": "262bc68c-b022-4cd5-d00c-2cc93db736ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fd45ec7b45353289f5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fd45ec7b45353289f5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ds43cI2Qgz2G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}