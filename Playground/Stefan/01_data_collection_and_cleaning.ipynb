{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3936601-51ef-4b78-8c17-c22172895af8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Smart Street Parking Assistant\n",
    "\n",
    "**Author:** Stefan Cucos  \n",
    "**Student ID:** 214397647  \n",
    "**Email:** cucoss@deakin.edu.au  \n",
    "**Project Title:** Smart Street Parking Assistant  \n",
    "**Branch:** Data Science Portfolio – Project B Deakin  \n",
    "**GitHub Repository:** [Insert after pushing to repo]  \n",
    "**Notebook Name:** `01_data_collection_and_cleaning.ipynb`  \n",
    "**Environment:** `smartpark`  \n",
    "**Date:** 10 April 2025\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f919da-0be0-4725-b2e4-7e81ff6a4ba4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1 — Data Source Planning\n",
    "\n",
    "This section outlines the data sources required to build the Smart Street Parking Assistant.  \n",
    "The objective is to identify available open datasets that provide:\n",
    "\n",
    "- Real-time or historical parking information  \n",
    "- Accepted payment methods  \n",
    "- Applicable parking rules in urban areas\n",
    "\n",
    "---\n",
    "\n",
    "### Desired Data Features\n",
    "\n",
    "- On-street parking zone information (location, type, restrictions)  \n",
    "- Time limits (e.g., 1P, 2P, etc.)  \n",
    "- Cost per hour (if applicable)  \n",
    "- Accepted payment methods (App, Card, Cash)  \n",
    "- Availability data (if possible – even simulated)\n",
    "\n",
    "---\n",
    "\n",
    "### Potential Data Sources\n",
    "\n",
    "- Australian or local council Open Data portals  \n",
    "  (e.g., City of Melbourne Open Data)  \n",
    "- GTFS feeds with parking metadata (if available)  \n",
    "- Sample or mock datasets for early testing\n",
    "\n",
    "---\n",
    "\n",
    "The final list of confirmed datasets will be documented in the next step  \n",
    "and stored locally in the `data` folder.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d05a57-19f2-463d-888b-0df67bf06b22",
   "metadata": {},
   "source": [
    "## Step 1.1 — Preview and Choose an Initial Dataset\n",
    "\n",
    "In this step, we select a real-world dataset to support the development of the **Smart Street Parking Assistant**.\n",
    "\n",
    "Our objective is to find and download an open dataset that can be used for local analysis and early prototype testing.\n",
    "\n",
    "After reviewing several options, we chose a dataset from the **City of Melbourne Open Data** platform:\n",
    "\n",
    "> **Dataset:** `On-street Parking Bay Sensors`  \n",
    "> **Source:** data.melbourne.vic.gov.au  \n",
    "> **Type:** Real-time sensor data (updated every 2 minutes)  \n",
    "> **Features:** Includes bay ID, sensor status (occupied or not), spatial coordinates, and timestamps\n",
    "\n",
    "**Note:**  \n",
    "This dataset may experience temporary outages and is unavailable on public holidays or in construction zones.  \n",
    "Please monitor the `lastupdated` column to ensure data freshness.\n",
    "\n",
    "The dataset has been saved locally in the `data/` folder for this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43579fe6-f9f1-4f5f-9c89-2451ae10904a",
   "metadata": {},
   "source": [
    "## Step 1.2 — Load and Preview the Dataset\n",
    "\n",
    "In this step, we will load the downloaded dataset into the notebook to explore its structure and get an initial understanding of the data.\n",
    "\n",
    "The goal is to:\n",
    "- Load the dataset using `pandas`\n",
    "- Preview the first few rows\n",
    "- Check for column names, data types, and general structure\n",
    "\n",
    "We will read the CSV file saved in the `data/` folder under the name:  \n",
    "`on-street-parking-bay-sensors.csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66a8645b-f1bb-42e8-a6d4-27c0e1c0a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (3307, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lastupdated</th>\n",
       "      <th>Status_Timestamp</th>\n",
       "      <th>Zone_Number</th>\n",
       "      <th>Status_Description</th>\n",
       "      <th>KerbsideID</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-21T14:42:37+11:00</td>\n",
       "      <td>2025-01-21T12:37:41+11:00</td>\n",
       "      <td>7053.0</td>\n",
       "      <td>Unoccupied</td>\n",
       "      <td>10286</td>\n",
       "      <td>-37.79493418293051, 144.97155131195115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-21T14:42:37+11:00</td>\n",
       "      <td>2025-01-21T07:40:01+11:00</td>\n",
       "      <td>7053.0</td>\n",
       "      <td>Unoccupied</td>\n",
       "      <td>10279</td>\n",
       "      <td>-37.79506794595409, 144.97277440018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-21T14:42:37+11:00</td>\n",
       "      <td>2025-01-20T16:57:00+11:00</td>\n",
       "      <td>7053.0</td>\n",
       "      <td>Present</td>\n",
       "      <td>10280</td>\n",
       "      <td>-37.79502666258857, 144.97240204442983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-21T14:42:37+11:00</td>\n",
       "      <td>2025-01-20T21:25:07+11:00</td>\n",
       "      <td>7049.0</td>\n",
       "      <td>Present</td>\n",
       "      <td>10288</td>\n",
       "      <td>-37.79508290762313, 144.9712217164565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-21T14:42:37+11:00</td>\n",
       "      <td>2025-01-19T10:01:01+11:00</td>\n",
       "      <td>7049.0</td>\n",
       "      <td>Unoccupied</td>\n",
       "      <td>10290</td>\n",
       "      <td>-37.79511384563001, 144.97151325560708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Lastupdated           Status_Timestamp  Zone_Number  \\\n",
       "0  2025-01-21T14:42:37+11:00  2025-01-21T12:37:41+11:00       7053.0   \n",
       "1  2025-01-21T14:42:37+11:00  2025-01-21T07:40:01+11:00       7053.0   \n",
       "2  2025-01-21T14:42:37+11:00  2025-01-20T16:57:00+11:00       7053.0   \n",
       "3  2025-01-21T14:42:37+11:00  2025-01-20T21:25:07+11:00       7049.0   \n",
       "4  2025-01-21T14:42:37+11:00  2025-01-19T10:01:01+11:00       7049.0   \n",
       "\n",
       "  Status_Description  KerbsideID                                Location  \n",
       "0         Unoccupied       10286  -37.79493418293051, 144.97155131195115  \n",
       "1         Unoccupied       10279  -37.79506794595409, 144.97277440018868  \n",
       "2            Present       10280  -37.79502666258857, 144.97240204442983  \n",
       "3            Present       10288   -37.79508290762313, 144.9712217164565  \n",
       "4         Unoccupied       10290  -37.79511384563001, 144.97151325560708  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1.2 — Load and preview the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Full file path to the downloaded dataset\n",
    "file_path = r\"C:\\Projects\\SmartParkingAssistant\\data\\on-street-parking-bay-sensors.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf3112-2d54-4a9e-b6f5-f2441844e6bd",
   "metadata": {},
   "source": [
    "### Output Summary – Step 1.2\n",
    "\n",
    "The dataset has been successfully loaded and contains **3,307 rows** and **6 columns**.  \n",
    "\n",
    "Each row represents a parking bay sensor reading, and the columns provide:\n",
    "\n",
    "- `Lastupdated`: When the data snapshot was taken\n",
    "- `Status_Timestamp`: When the occupancy status was last updated\n",
    "- `Zone_Number`: Identifier for the parking zone\n",
    "- `Status_Description`: Indicates if the bay is *Occupied* or *Unoccupied*\n",
    "- `KerbsideID`: ID used for spatial mapping or joining datasets\n",
    "- `Location`: Latitude and longitude of the parking sensor\n",
    "\n",
    "These variables will be crucial in visualising occupancy, identifying patterns, and simulating smart parking assistance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ff6b8-b05f-4119-9fe8-1db215746119",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1.3 — Clean and Inspect Dataset Structure\n",
    "\n",
    "In this step, we will examine the structure and quality of the loaded data to prepare it for analysis.\n",
    "\n",
    "The key objectives are to:\n",
    "\n",
    "- Identify missing values or duplicates\n",
    "- Inspect column data types\n",
    "- Check for inconsistent formatting or outliers\n",
    "\n",
    "This process ensures that the dataset is clean, well-structured, and ready for further transformation and modelling.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "270a521f-1e5f-462a-8ebd-5dfd16e3e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Lastupdated             0\n",
      "Status_Timestamp        0\n",
      "Zone_Number           225\n",
      "Status_Description      0\n",
      "KerbsideID              0\n",
      "Location                0\n",
      "dtype: int64\n",
      "\n",
      "Data Types:\n",
      " Lastupdated            object\n",
      "Status_Timestamp       object\n",
      "Zone_Number           float64\n",
      "Status_Description     object\n",
      "KerbsideID              int64\n",
      "Location               object\n",
      "dtype: object\n",
      "\n",
      "Number of Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3 — Clean and Inspect Dataset Structure\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Check data types\n",
    "data_types = df.dtypes\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_count = df.duplicated().sum()\n",
    "\n",
    "# Display all checks\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "print(\"\\nData Types:\\n\", data_types)\n",
    "print(f\"\\nNumber of Duplicate Rows: {duplicate_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd981ff1-b24f-4a1e-af01-96665304f6ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1.3 — Clean and Inspect Dataset Structure\n",
    "\n",
    "After loading the dataset, we performed three key checks:\n",
    "\n",
    "- **Missing Values**  \n",
    "  All columns are complete except for `Zone_Number`, which has 225 missing entries. This may need to be addressed in later cleaning steps depending on how critical zone information is for our model.\n",
    "\n",
    "- **Data Types**  \n",
    "  - `Lastupdated`, `Status_Timestamp`, `Status_Description`, and `Location` are stored as object (string) types.  \n",
    "  - `Zone_Number` is a float64, likely due to missing values.  \n",
    "  - `KerbsideID` is an int64.\n",
    "\n",
    "  Some of these columns — particularly timestamps — will need to be converted to appropriate datetime types before further use.\n",
    "\n",
    "- **Duplicate Rows**  \n",
    "  There are 0 duplicate rows, which is ideal.\n",
    "\n",
    "This structure check confirms that the dataset is mostly clean and ready for transformation, with only a few minor adjustments needed.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86348e79-6b44-415b-b017-06df57e162c6",
   "metadata": {},
   "source": [
    "## Step 1.4 — Parse and Format the Timestamps\n",
    "\n",
    "In this step, we will convert the string-based datetime columns into proper `datetime` objects using `pandas`.\n",
    "\n",
    "This is essential because:\n",
    "\n",
    "- It enables accurate **sorting, filtering, and time-based grouping**\n",
    "- It allows us to calculate **durations**, identify **patterns**, and build **time series models**\n",
    "- Misformatted timestamps are a common cause of **reporting errors** and **failed visualizations**\n",
    "\n",
    "We will convert:\n",
    "\n",
    "- `Lastupdated` → precise moment when the data was refreshed\n",
    "- `Status_Timestamp` → when the bay status (e.g., Present/Unoccupied) was recorded\n",
    "\n",
    "Both columns will be converted using `pd.to_datetime()` and displayed to verify success.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b51723a9-b44b-4c19-a948-3f44bb0629f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Timestamp Columns:\n",
      "\n",
      "                Lastupdated          Status_Timestamp\n",
      "0 2025-01-21 03:42:37+00:00 2025-01-21 01:37:41+00:00\n",
      "1 2025-01-21 03:42:37+00:00 2025-01-20 20:40:01+00:00\n",
      "2 2025-01-21 03:42:37+00:00 2025-01-20 05:57:00+00:00\n",
      "3 2025-01-21 03:42:37+00:00 2025-01-20 10:25:07+00:00\n",
      "4 2025-01-21 03:42:37+00:00 2025-01-18 23:01:01+00:00\n"
     ]
    }
   ],
   "source": [
    "# Step 1.4 — Parse and Format the Timestamps\n",
    "\n",
    "# Convert 'Lastupdated' and 'Status_Timestamp' columns to datetime format (UTC)\n",
    "df['Lastupdated'] = pd.to_datetime(df['Lastupdated'], errors='coerce', utc=True)\n",
    "df['Status_Timestamp'] = pd.to_datetime(df['Status_Timestamp'], errors='coerce', utc=True)\n",
    "\n",
    "# Display the converted columns to verify success\n",
    "print(\"Converted Timestamp Columns:\\n\")\n",
    "print(df[['Lastupdated', 'Status_Timestamp']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433a6be-76e1-44a9-bec4-cabc4c1f2e09",
   "metadata": {},
   "source": [
    "The output confirms that both `Lastupdated` and `Status_Timestamp` columns were successfully parsed as datetime objects.\n",
    "\n",
    "By including `utc=True`, we’ve standardized the timestamps to Coordinated Universal Time (UTC), which avoids potential issues caused by inconsistent time zone formatting.\n",
    "\n",
    "This ensures that all future operations involving date comparison, sorting, or time series analysis will behave consistently across the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20931f96-7fd1-4c26-a45c-01a99f78ad0d",
   "metadata": {},
   "source": [
    "## Step 1.5 — Extract Temporal Features\n",
    "\n",
    "In this step, we extract new time-related features from the cleaned `Status_Timestamp` column to help us understand patterns of parking occupancy over time.\n",
    "\n",
    "The following temporal features were created:\n",
    "\n",
    "- **day_of_week**: Numerical day of the week (0=Monday, 6=Sunday)\n",
    "- **hour**: Hour of the day (0–23)\n",
    "- **date**: Calendar date (YYYY-MM-DD format)\n",
    "\n",
    "These features will allow us to:\n",
    "- Group or filter data by **specific days or hours**\n",
    "- Build **usage profiles** based on time of day and weekday/weekend\n",
    "- Support **time-based analysis** in later stages of the project\n",
    "\n",
    "Below is a preview of the extracted features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "105027e2-67f2-4dcc-a7b9-e72f66cb21aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status_Timestamp</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-21 01:37:41+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-20 20:40:01+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-20 05:57:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-20 10:25:07+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-18 23:01:01+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>2025-01-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Status_Timestamp  day_of_week  hour        date\n",
       "0 2025-01-21 01:37:41+00:00            1     1  2025-01-21\n",
       "1 2025-01-20 20:40:01+00:00            0    20  2025-01-20\n",
       "2 2025-01-20 05:57:00+00:00            0     5  2025-01-20\n",
       "3 2025-01-20 10:25:07+00:00            0    10  2025-01-20\n",
       "4 2025-01-18 23:01:01+00:00            5    23  2025-01-18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1.5 — Extract Temporal Features\n",
    "\n",
    "# Extract new time-related columns\n",
    "df['day_of_week'] = df['Status_Timestamp'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['hour'] = df['Status_Timestamp'].dt.hour\n",
    "df['date'] = df['Status_Timestamp'].dt.date\n",
    "\n",
    "# Display a preview of the new columns\n",
    "df[['Status_Timestamp', 'day_of_week', 'hour', 'date']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb7998-e1a3-4683-b358-0163b2d7a947",
   "metadata": {},
   "source": [
    "We have successfully extracted three useful time-based features from the `Status_Timestamp` column:\n",
    "\n",
    "- `day_of_week`: Indicates the day of the week (0 = Monday, 6 = Sunday)\n",
    "- `hour`: Extracted hour (0 to 23), useful for hourly trend analysis\n",
    "- `date`: Simplified calendar date for grouping and filtering\n",
    "\n",
    "These features will allow us to perform time-based aggregations, such as:\n",
    "\n",
    "- **Identifying peak parking hours** during weekdays or weekends\n",
    "- **Grouping patterns by day** to compare weekdays vs weekends\n",
    "- **Building time series models** using daily or hourly aggregates\n",
    "\n",
    "This marks the completion of our initial data cleaning and temporal feature engineering phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f9c5a-4ee5-4ac7-872a-7578ef28e492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
