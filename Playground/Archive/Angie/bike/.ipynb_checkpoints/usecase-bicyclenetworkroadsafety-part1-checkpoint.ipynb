{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".usecase-title, .usecase-duration, .usecase-section-header {\n",
       "    padding-left: 15px;\n",
       "    padding-bottom: 10px;\n",
       "    padding-top: 10px;\n",
       "    padding-right: 15px;\n",
       "    background-color: #0f9295;\n",
       "    color: #fff;\n",
       "}\n",
       "\n",
       ".usecase-title {\n",
       "    font-size: 1.7em;\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       ".usecase-authors, .usecase-level, .usecase-skill {\n",
       "    padding-left: 15px;\n",
       "    padding-bottom: 7px;\n",
       "    padding-top: 7px;\n",
       "    background-color: #baeaeb;\n",
       "    font-size: 1.4em;\n",
       "    color: #121212;\n",
       "}\n",
       "\n",
       ".usecase-level-skill  {\n",
       "    display: flex;\n",
       "}\n",
       "\n",
       ".usecase-level, .usecase-skill {\n",
       "    width: 50%;\n",
       "}\n",
       "\n",
       ".usecase-duration, .usecase-skill {\n",
       "    text-align: right;\n",
       "    padding-right: 15px;\n",
       "    padding-bottom: 8px;\n",
       "    font-size: 1.4em;\n",
       "}\n",
       "\n",
       ".usecase-section-header {\n",
       "    font-weight: bold;\n",
       "    font-size: 1.5em;\n",
       "}\n",
       "\n",
       ".usecase-subsection-header, .usecase-subsection-blurb {\n",
       "    font-weight: bold;\n",
       "    font-size: 1.2em;\n",
       "    color: #121212;\n",
       "}\n",
       "\n",
       ".usecase-subsection-blurb {\n",
       "    font-size: 1em;\n",
       "    font-style: italic;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DELETE BEFORE PUBLISHING\n",
    "# This is just here so you can preview the styling on your local machine\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".usecase-title, .usecase-duration, .usecase-section-header {\n",
    "    padding-left: 15px;\n",
    "    padding-bottom: 10px;\n",
    "    padding-top: 10px;\n",
    "    padding-right: 15px;\n",
    "    background-color: #0f9295;\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".usecase-title {\n",
    "    font-size: 1.7em;\n",
    "    font-weight: bold;\n",
    "}\n",
    "\n",
    ".usecase-authors, .usecase-level, .usecase-skill {\n",
    "    padding-left: 15px;\n",
    "    padding-bottom: 7px;\n",
    "    padding-top: 7px;\n",
    "    background-color: #baeaeb;\n",
    "    font-size: 1.4em;\n",
    "    color: #121212;\n",
    "}\n",
    "\n",
    ".usecase-level-skill  {\n",
    "    display: flex;\n",
    "}\n",
    "\n",
    ".usecase-level, .usecase-skill {\n",
    "    width: 50%;\n",
    "}\n",
    "\n",
    ".usecase-duration, .usecase-skill {\n",
    "    text-align: right;\n",
    "    padding-right: 15px;\n",
    "    padding-bottom: 8px;\n",
    "    font-size: 1.4em;\n",
    "}\n",
    "\n",
    ".usecase-section-header {\n",
    "    font-weight: bold;\n",
    "    font-size: 1.5em;\n",
    "}\n",
    "\n",
    ".usecase-subsection-header, .usecase-subsection-blurb {\n",
    "    font-weight: bold;\n",
    "    font-size: 1.2em;\n",
    "    color: #121212;\n",
    "}\n",
    "\n",
    ".usecase-subsection-blurb {\n",
    "    font-size: 1em;\n",
    "    font-style: italic;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-title\">Melbourne Bicycle Network Routes and Road Safety: Part 1</div>\n",
    "\n",
    "<div class=\"usecase-authors\"><b>Authored by: </b> Bree McLennan and Anugra Sara Thomas</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-duration\"><b>Duration:</b> 120 mins</div>\n",
    "\n",
    "<div class=\"usecase-level-skill\">\n",
    "    <div class=\"usecase-level\"><b>Level: </b>Intermediate</div>\n",
    "    <div class=\"usecase-skill\"><b>Pre-requisite Skills: </b>Python, Data engineering and analysis</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Scenario</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. As a cyclist, I want a safe transport journey in the city of Melbourne. Which roads are safest to cycle on?** \n",
    "\n",
    "From a cyclist road users' perspective, I want a safe transport journey in Melbourne. \n",
    "I seek to understand which sections of bicycle road network are the safest and which have the highest occurrence of accidents so that I can use this insight to plan the safest possible journey.\n",
    "\n",
    "**2. As a council, we seek to invest in road safety initiatives which reduce the occurrences of accidents resulting in serious injuries of citizens using our road network. Where are accident hotspots for cyclists occurring?**\n",
    "\n",
    "From a leadership & strategic perspective, as a council, we seek to invest in road safety initiatives which can effectively reduce the occurrences of accidents resulting in serious injuries and fatalities of citizens using our road network. \n",
    "\n",
    "Where are accident hot spots for cyclists (and other road users) occurring?\n",
    "\n",
    "Are our current approaches to road and bicycle network design working and having the impact we expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Objectives for the Exploratory Data Analysis</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the power of data aggregation, we can combine Melbourne Open datasets such as transport networks and events\n",
    "With open government datasets including traffic accident ‘crash stats’ from Victoria Police and traffic event data from VicRoads and begin to observe, analyze and report on geographical patterns between these datasets.\n",
    "\n",
    "We can ask questions such as:\n",
    "\n",
    "1. Are accidents which involve cyclists occurring on designated bicycle network paths or on different roads? Where, specifically?\n",
    "2. What are the traffic accident circumstances? Are cyclists colliding with open car doors an increasing or decreasing problem?\n",
    "3. Do accidents co-occur with road-works, weather events or other disruptive events?\n",
    "\n",
    "Goals for exploratory data analysis:\n",
    "\n",
    "1. Analyse the frequency, timing and characteristics of traffic accidents involving cyclists in Melbourne\n",
    "2. Analyse the geographical location of these accidents and compare to the locations of the bicycle path network\n",
    "3. Report on sections of roadway where higher accident rates are observed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Strategic benefits for City of Melbourne</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This use case and exploratory data analysis project can support the City of Melbourne in the following ways:\n",
    "\n",
    "1. Support for the ‘Safety and Well-being’ strategic vision and goals\n",
    "\n",
    "2. Influence the creation of a ‘key risk indicator’ to monitor progress on the reduction of the 'Number of transport-related injuries and fatalities’ on Melbourne roads\n",
    "\n",
    "3. Support further discussion between City of Melbourne and Victorian Road Safety partner agencies to improve road network design and infrastructure programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Background on Related Road Safety Initiatives in Victoria</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach to aggregating key data sources and analysing geographical attributes is currently used by the TAC (Transport Accident Commission) in Victoria when analysing accident hot-spots and reviewing whether the design of the road could be improved to reduce road trauma. \n",
    "    \n",
    "This type of analysis was used by TAC in recent years to assess fatal accident hotspots in Geelong.\n",
    "\n",
    "The TAC in partnership with the Victorian Road Safety partnering agencies discovered a cluster of fatal accidents occurring over a 5-year period along a specific stretch of road at Thompsons Road, North Geelong.\n",
    "    \n",
    "The analysis informed a strategic decision for road safety partners (Victoria Police, VicRoads, City of Greater Geelong, TAC) to re-design the road to make it safer.\n",
    "    \n",
    "The road re-design has resulted in a substantial reduction in road trauma along Thompsons Road in North Geelong.\n",
    "\n",
    "A similar analysis technique and approach could be applied to the City of Melbourne road network\n",
    "\n",
    "\n",
    "**REFERENCE:**\n",
    "\n",
    "[1] https://regionalroads.vic.gov.au/map/barwon-south-west-improvements/thompson-road-safety-improvements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Exploratory Data Analysis Worflow Steps</div>\n",
    "\n",
    "1. Document the data considerations and risk assessments\n",
    "\n",
    "2. Prepare the Traffic Accident 'crash-stats' source data (this is handled by a separate python notebook)\n",
    "\n",
    "3. Access and read-in the Melbourne Bicycle Network dataset via the CoM API\n",
    "\n",
    "4. Explore the Melbourne Bicycle Network dataset\n",
    "\n",
    "5. Read-in the pre-processed Traffic Accident 'crash-stats' dataset\n",
    "\n",
    "6. Explore the Traffic Accident 'crash-stats' dataset\n",
    "\n",
    "7. Visualise the geographical features of the Melbourne Bicycle Network overlaid with Traffic Accident 'crash-stats' dataset\n",
    "\n",
    "**Dataset list:**\n",
    "1. Melbourne Open Data Bicycle-Network\n",
    "2. VicRoads Accident data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Data Considerations</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Information Security and Sensitivity**\n",
    "\n",
    "For the purpose of analysis, the analysis datasets contain de-identified data. No personally identifyable names or contact details are used or included.\n",
    "\n",
    "**2. Converting raw traffic accident 'crash-stats' data into useful dataset**\n",
    "\n",
    "After initial observation of the traffic accident data in its raw form, the raw data was prepared and converted into a working ‘.csv’ file and imported into this notebook for further analysis.\n",
    "\n",
    "The following process was used for converting the raw data into a working dataset:\n",
    "\n",
    "1. The accident context domains 'person', 'accident' and 'node' were used to form the foundation of the working dataset\n",
    "\n",
    "    - From the domain 'person', the variable 'road user type' was used to identify 'Bicyclists'\n",
    "    - From the domain 'accident', the variable 'accidentdate' was used to filter for accident records on and after '1st Jan 2017'    \n",
    "    - From the domain 'node', the variable 'lga_name' was used to identify the broad geographical area of 'MELBOURNE' city\n",
    "    \n",
    "    \n",
    "2. A series of two inner merges were then performed to construct the working dataset\n",
    "\n",
    "    - First inner merge on the filtered 'accident' domain and filtered 'person' domain using the primary key 'accident_no'\n",
    "    - Second inner merge on the output from the step described above, and on the filtered 'node' domain, using 'accident_no'\n",
    "    \n",
    "    \n",
    "3. To obtain additional traffic accident descriptive features, five additional data domains were left joined in sequence\n",
    "\n",
    "    - 'surface conditions' using the primary key 'accident_no' to join\n",
    "    - 'SUB DCA' using the primary key 'accident_no' to join\n",
    "    - 'Atmospheric Conditions' using the primary key 'accident_no' to join\n",
    "    - 'Accident Location' using the primary key 'accident_no' to join\n",
    "    - 'Accident Event' using the primary key 'accident_no' to join\n",
    "\n",
    "4. Variable naming conventions were applied\n",
    "\n",
    "Variable features which were created in the working dataset use a three-letter acronym prefix to denote the expected general data type values:\n",
    "\n",
    "- NUM: Numeric values which have a range beyond binary format, may include NA (Missing/Null).\n",
    "- BIN: Binary values. 1 and 0 only.\n",
    "- CAT: Categorical value. Structured and consistent groupings.\n",
    "- TXT: Free/unstructured text.\n",
    "- TIM: Time values. Specifically formatted as HH:MM:SS.ss.\n",
    "- DAT: Date values. Specifically formatted as Y-M-D.\n",
    "- KEY: Primary Key values. Features which uniquely identify the context and records.\n",
    "\n",
    "A suffix beginning with an underscore was also used to denote the context data domain origin for each feature. For example \"_person\" denotes a variable which originated from the accident person domain dataset.\n",
    "\n",
    "Manual data inspection notes:\n",
    "- The resulting working dataset contains 735 records and 34 features (columns)\n",
    "- The working dataset records represents 735 bicyclists who have experienced accidents in the city of Melbourne between 1st January 2017 and 31st March 2020\n",
    "- The primary keys for the working dataset are 'KEYAccidentNumber' and 'KEYPersonID'. The reason for the combination is an accident record can describe multiple bicyclists involved in the accident event, therefore the accident number can be 'duplicated' but differentiated by using the person ID.\n",
    "- The geographical longitude and latitudes are recorded consistently as part of the work practice when recording accidents in the source system\n",
    "\n",
    "\n",
    "After creating the working dataset, data opportunities were discovered to create new variables to assist with the analysis:\n",
    "\n",
    "- Concatenate accident day of week with accident hour\n",
    "- Concatenate accident road name and type\n",
    "- Create an accident hour grouping and concatenate with accident day of week\n",
    "\n",
    "**3. Data cleaning & pre processing**\n",
    "\n",
    "Excess text whitespace characters were detected in variables 'TIMAccidentTime_accident' and 'CATDCADesc_accident', these were removed.\n",
    "\n",
    "**4. Geographical Location Data**\n",
    "\n",
    "In order to answer queries on geographical locations for accidents, the analysis dataset requires longitude and latitude data in order to instruct geographical mapping tools and visualisations. The longitude and latitude data is captured when accident records are entered into the source system.\n",
    "\n",
    "**5. Additional Data**\n",
    "\n",
    "None identified.\n",
    "\n",
    "**6. Data Integrity Checks and Filtering**\n",
    "\n",
    "- No duplicated data or records were identified\n",
    "- All records contain a primary key value and less than 10 records were removed due to missing geographical identifies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Setting Up for Analysis</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin the analysis we first import the necessary libraries to support our exploratory data analysis using Melbourne Open data.\n",
    "\n",
    "The following are core packages required for this exercise:\n",
    "\n",
    "- json // Assists with parsing JSON (JavaScript Object Notation) from strings or files.\n",
    "- folium // Assists with visualising data that's been manipulated in Python on an interactive leaflet map.\n",
    "- seaborn // Assists with visualization of data. It provides a high-level interface for drawing attractive and informative statistical graphics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in d:\\programs\\anaconda\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in d:\\programs\\anaconda\\lib\\site-packages (from geopy) (2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c1d082bb2518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMarkerCluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\seaborn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmiscplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# but still use the older Histogram for bivariate computation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_statistics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mECDF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHistogram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKDE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m from .axisgrid import (\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\seaborn\\_stats\\counting.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGroupBy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscales\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mScale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# Libraries used for this use case and exploratory data analysis\n",
    "###################################################################\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, shape\n",
    "\n",
    "import json\n",
    "import plotly.express as px\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the Melbourne Open Data Portal we must establish a connection using their API specifiying the dataset, for larger datasets an application access token which can be requested from the City of Melbourne Open Data portal by registering __[here](https://data.melbourne.vic.gov.au/signup)__\n",
    "\n",
    "For this exercise we will access the domain without an application token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Accessing the Melbourne City Bicycle Network Dataset\n",
    "########################################################\n",
    "\n",
    "BASE_URL = 'https://data.melbourne.vic.gov.au/api/v2/catalog/datasets/'\n",
    "NUMBER_OF_RECORDS = 300\n",
    "\n",
    "FILTERS = f'exports/json?limit={NUMBER_OF_RECORDS}&offset=0&timezone=UTC'\n",
    "BIKE_ROUTES_ID = 'bicycle-routes-including-informal-on-road-and-off-road-routes'\n",
    "BIKE_ROUTES_URL = f'{BASE_URL}{BIKE_ROUTES_ID}/{FILTERS}'\n",
    "BIKE_ROUTES_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Exploring the Melbourne Bicycle Network Dataset</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will look at the **Bicycle-Network** dataset, to better understand its structure and how we can use it.\n",
    "\n",
    "Our data requirements from this use case include the following:\n",
    "- Visualising the bicycle network to learn where the bicycle paths are located\n",
    "\n",
    "For this exercise, we start by examining the **Bicycle-Network** dataset.\n",
    "Each dataset in the Melbourne Open Data Portal has a unique identifier which can be used to retrieve the dataset using the sodapy library.\n",
    "\n",
    "The **Bicycle-Network** dataset unique identifier is **bicycle-routes-including-informal-on-road-and-off-road-routes**.\n",
    "We pass this identifier to the API to retrieve this data.\n",
    "\n",
    "This dataset is placed in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with the Melbourne Bicycle Network Routes Datase**\n",
    "\n",
    "The code below describes how to access the **Bicycle Network** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API URL \n",
    "print(f'URL: {BIKE_ROUTES_URL}')\n",
    "\n",
    "# Call the API and save the output as a json object\n",
    "result = requests.get(BIKE_ROUTES_URL)\n",
    "result_json = result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe\n",
    "bicyclepath = pd.DataFrame(result_json)\n",
    "\n",
    "bicyclepath.rename(columns={'geo_shape':'features'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing the first record in the geoJSON file**\n",
    "\n",
    "To observe the type of data and values stored within the geoJSON file we can use the following code to observe the first record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_json[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observing the geoJSON Full Structure and Properties**\n",
    "\n",
    "By calling the variable 'bicyclepath' we can observe the full structure, properties and values of the geoJSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bicyclepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Navigating the geoJSON File Structure**\n",
    "\n",
    "When you load a GeoJSON file using the json library, you get a dictionary that contains an entry 'features', \n",
    "which contains the list of features. Each feature in turn consists of a dictionary, which, contains an entry 'geometry'. \n",
    "\n",
    "The geometry is a dictionary containing the entries 'type' and 'coordinates'.\n",
    "\n",
    "The GeoJSON file can be traversed or navigated using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in bicyclepath['features'][:3]:\n",
    "    print (feature['geometry']['type'])\n",
    "    print (feature['geometry']['coordinates'][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualising the Melbourne Bicycle Network on a Map**\n",
    "\n",
    "To visualise the geoJSON file containing the Melbourne Bicycle Network we can use the 'folium' and 'json' packages and the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the base layer map\n",
    "m = folium.Map(\n",
    "    location=[-37.81368709240999, 144.95738102347036], #Coordinates are in the Melbourne CBD block\n",
    "    tiles=\"cartodbpositron\",\n",
    "    zoom_start=13, \n",
    "    control_scale=True,\n",
    "    prefer_canvas=True, \n",
    "    width=800, \n",
    "    height=580\n",
    ")\n",
    "\n",
    "style = {'fillColor': '#08af64', 'color': '#08af64'}\n",
    "\n",
    "# iterate through the features in the bicyclepath DataFrame column\n",
    "for i in range(bicyclepath.shape[0]):\n",
    "    feature = bicyclepath[\"features\"].loc[i]\n",
    "    \n",
    "    # get the coordinates of the feature\n",
    "    coords = feature[\"geometry\"][\"coordinates\"]\n",
    "    coords = [[y, x] for x,y in coords[0]]\n",
    "\n",
    "    # create a PolyLine object from the coordinates\n",
    "    line = folium.PolyLine(coords, color='blue', weight=2)\n",
    "    lon, lat = bicyclepath['geo_point_2d'].loc[i].values()\n",
    "    \n",
    "    name,direction,b_type,info,status,notes= bicyclepath.loc[i][['name','direction','type','info','status','notes']]\n",
    "\n",
    "    iframe = folium.IFrame(f'<h4>{name}</h4><br>Directions: {direction}<br>Notes: {notes}<br>Info: {info}<br>Status: {status}')\n",
    "    popup = folium.Popup(iframe, min_width=300, max_width=300)\n",
    "    marker = folium.Marker(location=[lat,lon], icon=folium.Icon(icon='map-marker', prefix='fa'), popup=popup)\n",
    "\n",
    "\n",
    "    # add the PolyLine to the map\n",
    "    m.add_child(line)\n",
    "    m.add_child(marker)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Exploring the Traffic Accident 'Crash-Stats' Dataset</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section focuses on setting up the Traffic Accident 'Crash-Stats' dataset and preparing it for use in the exploratory data analysis alongside the Melbourne Bicycle Network dataset.\n",
    "\n",
    "The raw input dataset contains the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the dataset\n",
    "raw_accidents_bicyclists = pd.read_csv('bicyclenetworkroadsafety-part1/dependencies/Accidents_Bicyclists_Melbourne_2017to2020.csv', parse_dates=['DATAccidentDate_accident'])\n",
    "raw_accidents_bicyclists.info() # see summary information of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up the Working Accident 'Crash-Stats' Dataset**\n",
    "\n",
    "The working dataset will have the following structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create a copy of the raw source dataset\n",
    "wrk_accident_bicyclists = raw_accidents_bicyclists.copy()\n",
    "\n",
    "#Create new features from the accident date variable such as a numerical representation of weekday name, week of the year\n",
    "#day of the year and a separate variable to hold the year of accident.\n",
    "wrk_accident_bicyclists['NUMDayOfWeek'] = wrk_accident_bicyclists['DATAccidentDate_accident'].dt.strftime('%w')\n",
    "wrk_accident_bicyclists['NUMWeekOfYear'] = wrk_accident_bicyclists['DATAccidentDate_accident'].dt.strftime('%W')\n",
    "wrk_accident_bicyclists['NUMDayOfYear'] = wrk_accident_bicyclists['DATAccidentDate_accident'].dt.strftime('%j')\n",
    "wrk_accident_bicyclists['NUMYearOfAcc'] = wrk_accident_bicyclists['DATAccidentDate_accident'].dt.strftime('%Y')\n",
    "\n",
    "#Convert the time of accident to a string and clean up excess white space\n",
    "wrk_accident_bicyclists.TIMAccidentTime_accident = wrk_accident_bicyclists.TIMAccidentTime_accident.astype('string')\n",
    "wrk_accident_bicyclists.TIMAccidentTime_accident = wrk_accident_bicyclists.TIMAccidentTime_accident.str.rstrip()\n",
    "\n",
    "#Using the time of accident variable, create new features including accident hour, minute and second \n",
    "wrk_accident_bicyclists[['hour','minute','second']] = wrk_accident_bicyclists['TIMAccidentTime_accident'].astype(str).str.split(':', expand=True).astype(str)\n",
    "\n",
    "#Create a new feature to combine the week day name and hour of accident\n",
    "wrk_accident_bicyclists['CATWeekDayHour'] = wrk_accident_bicyclists[['CATDayOfWeek_accident', 'hour']].agg(' '.join, axis=1)\n",
    "\n",
    "#Set the time format for the time of accident variable\n",
    "wrk_accident_bicyclists['TIMAccidentTime_accident'] = pd.to_datetime(wrk_accident_bicyclists['TIMAccidentTime_accident'], format='%H:%M:%S').dt.time\n",
    "\n",
    "#Clean up the text white space in the DCA description variable\n",
    "wrk_accident_bicyclists.CATDCADesc_accident = wrk_accident_bicyclists.CATDCADesc_accident.str.rstrip()\n",
    "\n",
    "#Create and apply a group mapping for the hour of accident\n",
    "mapping = {'00': 'Early Morning', '01': 'Early Morning', '02': 'Early Morning', '03': 'Early Morning', '04': 'Early Morning', '05': 'Early Morning',\n",
    "           '06': 'Morning', '07': 'Morning', '08': 'Morning',  '09': 'Late Morning',  '10': 'Late Morning', '11': 'Late Morning',\n",
    "           '12': 'Early Afternoon', '13': 'Early Afternoon', '14':'Early Afternoon',  '15': 'Late Afternoon', '16': 'Late Afternoon',\n",
    "           '17': 'Evening', '18': 'Evening', '19': 'Evening', '20': 'Night', '21': 'Night', '22': 'Night', '23': 'Night' }\n",
    "wrk_accident_bicyclists['hourgroup'] = wrk_accident_bicyclists.hour.map(mapping)\n",
    "\n",
    "#Create a new feature which concatenates the week day name and accident hour group mapping\n",
    "wrk_accident_bicyclists['CATWeekDayHourGroup'] = wrk_accident_bicyclists[['CATDayOfWeek_accident', 'hourgroup']].agg(' '.join, axis=1)\n",
    "\n",
    "#Convert all categorical variables to strings\n",
    "wrk_accident_bicyclists.CATAccidentTypeDesc_accident = wrk_accident_bicyclists.CATAccidentTypeDesc_accident.astype('string')\n",
    "wrk_accident_bicyclists['CATDayOfWeek_accident'] = wrk_accident_bicyclists['CATDayOfWeek_accident'].astype('string')\n",
    "wrk_accident_bicyclists['CATDCADesc_accident'] = wrk_accident_bicyclists['CATDCADesc_accident'].astype('string')\n",
    "wrk_accident_bicyclists['CATMelwaysPage_accident'] = wrk_accident_bicyclists['CATMelwaysPage_accident'].astype('string')\n",
    "wrk_accident_bicyclists['CATMelwaysGridRef_X_accident'] = wrk_accident_bicyclists['CATMelwaysGridRef_X_accident'].astype('string')\n",
    "wrk_accident_bicyclists['CATMelwaysGridRef_Y_accident'] = wrk_accident_bicyclists['CATMelwaysGridRef_Y_accident'].astype('string')\n",
    "wrk_accident_bicyclists['CATLightConditionDesc_accident'] = wrk_accident_bicyclists['CATLightConditionDesc_accident'].astype('string')\n",
    "wrk_accident_bicyclists['CATRoadUserTypeDesc_person'] = wrk_accident_bicyclists['CATRoadUserTypeDesc_person'].astype('string')\n",
    "wrk_accident_bicyclists['CATTakenHospital_person'] = wrk_accident_bicyclists['CATTakenHospital_person'].astype('string')\n",
    "wrk_accident_bicyclists['CATInjuryLevelDesc_person'] = wrk_accident_bicyclists['CATInjuryLevelDesc_person'].astype('string')\n",
    "wrk_accident_bicyclists['CATAgeGroup_person'] = wrk_accident_bicyclists['CATAgeGroup_person'].astype('string')\n",
    "wrk_accident_bicyclists['CATPostcode_person'] = wrk_accident_bicyclists['CATPostcode_person'].astype('string')\n",
    "wrk_accident_bicyclists['CATGender_person'] = wrk_accident_bicyclists['CATGender_person'].astype('string')\n",
    "wrk_accident_bicyclists['CATLGAName_node'] = wrk_accident_bicyclists['CATLGAName_node'].astype('string')\n",
    "wrk_accident_bicyclists['CATDEGUrbanName_node'] = wrk_accident_bicyclists['CATDEGUrbanName_node'].astype('string')\n",
    "wrk_accident_bicyclists['CATPostcode_node'] = wrk_accident_bicyclists['CATPostcode_node'].astype('string')\n",
    "wrk_accident_bicyclists['CATSurfaceConditionDesc_surface'] = wrk_accident_bicyclists['CATSurfaceConditionDesc_surface'].astype('string')\n",
    "wrk_accident_bicyclists['CATSubDCACodeDesc_subdca'] = wrk_accident_bicyclists['CATSubDCACodeDesc_subdca'].astype('string')\n",
    "wrk_accident_bicyclists['CATAtmosphericConditionDesc_atmosphere'] = wrk_accident_bicyclists['CATAtmosphericConditionDesc_atmosphere'].astype('string')\n",
    "wrk_accident_bicyclists['CATRoadName_acclocation'] = wrk_accident_bicyclists['CATRoadName_acclocation'].astype('string')\n",
    "wrk_accident_bicyclists['CATRoadNameInt_acclocation'] = wrk_accident_bicyclists['CATRoadNameInt_acclocation'].astype('string')\n",
    "wrk_accident_bicyclists['CATRoadType_acclocation'] = wrk_accident_bicyclists['CATRoadType_acclocation'].astype('string')\n",
    "wrk_accident_bicyclists['CATRoadTypeInt_acclocation'] = wrk_accident_bicyclists['CATRoadTypeInt_acclocation'].astype('string')\n",
    "wrk_accident_bicyclists['CATEventTypeDesc_accevent'] = wrk_accident_bicyclists['CATEventTypeDesc_accevent'].astype('string')\n",
    "wrk_accident_bicyclists['CATObjectTypeDesc_accevent'] = wrk_accident_bicyclists['CATObjectTypeDesc_accevent'].astype('string')\n",
    "\n",
    "#Create a new feature which concatenates the accident road name and type variables\n",
    "wrk_accident_bicyclists['CATAccidentRoadGroup'] = wrk_accident_bicyclists['CATRoadName_acclocation'].fillna('') + ' ' + wrk_accident_bicyclists['CATRoadType_acclocation'].fillna('')\n",
    "\n",
    "#Convert all numerical variables to integer, except for longitude and latitude which will remain as a floating point.\n",
    "wrk_accident_bicyclists['NUMVehiclesInvolved_accident'] = wrk_accident_bicyclists['NUMVehiclesInvolved_accident'].astype(int)\n",
    "wrk_accident_bicyclists['NUMPersonsInvolved_accident'] = wrk_accident_bicyclists['NUMPersonsInvolved_accident'].astype(int)\n",
    "wrk_accident_bicyclists['NUMPersonsInjured_accident'] = wrk_accident_bicyclists['NUMPersonsInjured_accident'].astype(int)\n",
    "wrk_accident_bicyclists['NUMRecordCount'] = 1\n",
    "\n",
    "#Print the information summary for the working dataset\n",
    "wrk_accident_bicyclists.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting the value sets for each variable in the working dataset**\n",
    "\n",
    "Here we will broadly check the value sets for each variable. The information from this check will\n",
    "inform what types of values to expect for each column and cultivate thinking on what values constitute\n",
    "missing or invalid entries and how to deal with this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function to describe all columns with helpful summary statistics  \n",
    "def describe_all_columns(x):  \n",
    "    print('Column summary:')\n",
    "    #select the summary function based on the input data type\n",
    "    if x.dtypes == 'float64' or x.dtypes == 'int64': \n",
    "        print(x.describe())\n",
    "    else:\n",
    "        #select the summary function based on the input data type\n",
    "        print(x.describe(include=[object]))       \n",
    "        print(x.unique())\n",
    "\n",
    "for i in wrk_accident_bicyclists.columns: #for each column in the dataframe\n",
    "    #print out summary statistics results\n",
    "    print('Column %s is of type %s.' % (wrk_accident_bicyclists[i].name, wrk_accident_bicyclists[i].dtypes)) \n",
    "    describe_all_columns(wrk_accident_bicyclists[i])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting 'Accidents Per Year (All-Time)'**\n",
    "\n",
    "In this section we will explore and observe how many bicycle accidents have occurred each year.\n",
    "\n",
    "**Important Note:** The year 2020 is under-developed as an accident year as the last record date in the dataset is March 2020.\n",
    "\n",
    "We will use 'seaborn' and 'matplotlib' libraries for visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plots\n",
    "# Accidents per hour (all time)\n",
    "\n",
    "#Create a summary dataset to display results\n",
    "wrk_accident_bicyclists_yeargrp = wrk_accident_bicyclists.groupby('NUMYearOfAcc').agg(NUMAccidentsPerYear=('NUMYearOfAcc', 'count'))\n",
    "wrk_accident_bicyclists_yeargrp.reset_index(drop=False, inplace=True)\n",
    "print(wrk_accident_bicyclists_yeargrp)\n",
    "\n",
    "#Plot the summarised data\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.catplot(y=\"NUMYearOfAcc\", hue=\"CATInjuryLevelDesc_person\", \n",
    "            kind=\"count\",\n",
    "            palette='colorblind', \n",
    "            alpha=1,\n",
    "            height=8,\n",
    "            aspect=1,\n",
    "            data=wrk_accident_bicyclists.sort_values(by='NUMYearOfAcc'))\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"Count of Accidents\", \"Year of Accident\")\n",
    "g.legend.set_title(\"Injury Level\")\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Bicycle Accidents Per Year (all time)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting 'Accidents Per Hour (All-Time)'**\n",
    "\n",
    "In this section we will explore and observe how many bicycle accidents have occurred by accident hour.\n",
    "\n",
    "We will use 'seaborn' and 'matplotlib' libraries for visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plots\n",
    "# Accidents per hour (all time)\n",
    "\n",
    "#Create a summary dataset to display results\n",
    "wrk_accident_bicyclists_timegrp = wrk_accident_bicyclists.groupby('hour').agg(NUMAccidentsPerHour=('hour', 'count'))\n",
    "wrk_accident_bicyclists_timegrp.reset_index(drop=False, inplace=True)\n",
    "print(wrk_accident_bicyclists_timegrp)\n",
    "\n",
    "#Plot the summarised data\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.catplot(y=\"hour\", hue=\"CATInjuryLevelDesc_person\", \n",
    "            kind=\"count\",\n",
    "            palette='colorblind', \n",
    "            alpha=1,\n",
    "            height=8,\n",
    "            aspect=1,\n",
    "            data=wrk_accident_bicyclists.sort_values(by='hour'))\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"Count of Accidents\", \"Hour of Accident\")\n",
    "g.legend.set_title(\"Injury Level\")\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Bicycle Accidents Per Hour (all time)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting 'Accidents per Weekday (All-Time)'**\n",
    "\n",
    "In this section we will explore and observe how many bicycle accidents have occurred by weekday.\n",
    "\n",
    "We will use 'seaborn' and 'matplotlib' libraries for visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plots\n",
    "# Accidents per week-day (all time)\n",
    "\n",
    "#Create a summary dataset to display results\n",
    "wrk_accident_bicyclists_weekdaygrp = wrk_accident_bicyclists.loc[:,'CATDayOfWeek_accident'].value_counts().to_frame()\n",
    "wrk_accident_bicyclists_weekdaygrp.reset_index(drop=False, inplace=True)\n",
    "print(wrk_accident_bicyclists_weekdaygrp)\n",
    "\n",
    "#Plot the summarised data\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.catplot(x=\"CATDayOfWeek_accident\", y=\"NUMRecordCount\", hue=\"CATInjuryLevelDesc_person\", \n",
    "            kind=\"bar\",\n",
    "            palette='colorblind', \n",
    "            alpha=1,\n",
    "            height=8,\n",
    "            aspect=2,\n",
    "            data=wrk_accident_bicyclists.sort_values(by='NUMDayOfWeek'),\n",
    "            estimator=sum)\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"Weekday of Accident\", \"Count of Accidents\",)\n",
    "g.legend.set_title(\"Injury Level\")\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Bicycle Accidents Per Weekday (all time)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting 'Accidents per Day (All-Days, Detailed)'**\n",
    "\n",
    "In this section we will explore and observe how many bicycle accidents\n",
    "have occurred each day since the earliest date recorded in the dataset.\n",
    "\n",
    "We will use 'seaborn' and 'matplotlib' libraries for visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plots\n",
    "# Accidents per day (all-time)\n",
    "\n",
    "#Create a summary dataset to display results\n",
    "wrk_accident_bicyclists_daygrp = wrk_accident_bicyclists.loc[:,'DATAccidentDate_accident'].value_counts().to_frame()\n",
    "wrk_accident_bicyclists_daygrp.reset_index(drop=False, inplace=True)\n",
    "print(wrk_accident_bicyclists_daygrp)\n",
    "\n",
    "#Plot the summarised data\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,8))\n",
    "g = sns.lineplot(x=\"DATAccidentDate_accident\", y=\"NUMRecordCount\", \n",
    "            palette='colorblind', \n",
    "            alpha=1,\n",
    "            data=wrk_accident_bicyclists.sort_values(by='DATAccidentDate_accident'),\n",
    "            estimator=sum)\n",
    "plt.xticks(rotation=15)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Bicycle Accidents Per Day (all time)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting 'Accidents per Weekday and Hour grouping (All-Time)'**\n",
    "\n",
    "In this section we will explore and observe how many bicycle accidents have occurred each weekday and hour grouping.\n",
    "\n",
    "We will use 'seaborn' and 'matplotlib' libraries for visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plots\n",
    "# Accidents per Weekday and Hour Grouping (all time)\n",
    "\n",
    "#Create a summary dataset to display results\n",
    "wrk_accident_bicyclists_weekdayhrgrp = wrk_accident_bicyclists.loc[:,'CATWeekDayHourGroup'].value_counts().to_frame()\n",
    "wrk_accident_bicyclists_weekdayhrgrp.reset_index(drop=False, inplace=True)\n",
    "print(wrk_accident_bicyclists_weekdayhrgrp)\n",
    "\n",
    "#Plot the summarised data\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.catplot(x=\"CATWeekDayHourGroup\", y=\"NUMRecordCount\",\n",
    "            kind=\"bar\",\n",
    "            palette=\"colorblind\", \n",
    "            alpha=1,\n",
    "            height=8,\n",
    "            aspect=2,\n",
    "            data=wrk_accident_bicyclists.sort_values(by=['NUMDayOfWeek']),\n",
    "            estimator=sum)\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"Weekday Hour of Accident\", \"Count of Accidents\",)\n",
    "plt.xticks(rotation=90)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Bicycle Accidents Per Weekday and Hour Grouping (all time)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting the 'Geography of Bicycle Accident Occurrences'**\n",
    "\n",
    "In this section we will explore and observe the frequency of bicycle accidents by geographical locations.\n",
    "\n",
    "We will use 'seaborn' and 'matplotlib' libraries for visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographical analysis. Streets with most accidents\n",
    "# Which roads have the most frequent accidents?\n",
    "\n",
    "#Create a summary dataset to display results\n",
    "wrk_accident_bicyclists_roadsgrp = wrk_accident_bicyclists.loc[:,'CATAccidentRoadGroup'].value_counts().to_frame()\n",
    "wrk_accident_bicyclists_roadsgrp.reset_index(drop=False, inplace=True)\n",
    "wrk_accident_bicyclists_roadsgrp = wrk_accident_bicyclists_roadsgrp.head(50)\n",
    "print(wrk_accident_bicyclists_roadsgrp)\n",
    "\n",
    "#Plot the summarised data\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.catplot(x=\"CATAccidentRoadGroup\", y=\"NUMRecordCount\", hue=\"CATInjuryLevelDesc_person\", \n",
    "            kind=\"bar\",\n",
    "            palette='colorblind', \n",
    "            alpha=1,\n",
    "            height=8,\n",
    "            aspect=2,\n",
    "            order=wrk_accident_bicyclists.CATAccidentRoadGroup.value_counts().iloc[:50].index,\n",
    "            data=wrk_accident_bicyclists.sort_values(by=['CATAccidentRoadGroup']),\n",
    "            estimator=sum)\n",
    "g.despine(left=True)\n",
    "plt.xticks(rotation=90)\n",
    "g.set_axis_labels(\"Road Name\", \"Count of Accidents\",)\n",
    "g.legend.set_title(\"Injury Level\")\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Bicycle Accident Location - Roads Names (all time)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Visualising the Bicycle Accident Data on a Map</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the first map visual to observe where bicycle accidents are occurring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "def map_visualization(data):\n",
    "    locations = []\n",
    "    for i in range(len(data)):\n",
    "        row =data.iloc[i]\n",
    "        location = [(row.NUMLatitude_node,row.NUMLongitude_node)]*int(row.NUMRecordCount)\n",
    "        locations += location\n",
    "      \n",
    "    marker_cluster  = MarkerCluster(\n",
    "      locations=locations,\n",
    "      overlay=True,\n",
    "      control=True,\n",
    "      )\n",
    "    m = folium.Map(location=[-37.81368709240999, 144.95738102347036], tiles=\"Cartodb Positron\", zoom_start=13)\n",
    "    marker_cluster.add_to(m)\n",
    "\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    m\n",
    "    return m\n",
    "map_visualization(wrk_accident_bicyclists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Visualising the Melbourne Bicycle Route Network and Bicycle Accident Data</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an Alternative Map Visual to Distinguish Accidents by Year and Injury Type**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To observe the Melbourne Bicycle Route geoJSON map overlayed with the Bicycle Accident Data we can use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change the marker color\n",
    "# according to the injury level\n",
    "def color(CATInjuryLevelDesc_person):\n",
    "    if CATInjuryLevelDesc_person == \"Not injured\":\n",
    "        col = 'green'\n",
    "    elif CATInjuryLevelDesc_person == \"Other injury\":\n",
    "        col = 'blue'\n",
    "    elif CATInjuryLevelDesc_person == \"Serious injury\":\n",
    "        col = 'orange'\n",
    "    elif CATInjuryLevelDesc_person == \"Fatality\":\n",
    "        col = 'red'\n",
    "    else:\n",
    "        col='black'\n",
    "    return col\n",
    "\n",
    "# Creating a map object using Map() function.\n",
    "# Location parameter takes latitudes and\n",
    "# longitudes as starting location.\n",
    "# (Map will be centered at those co-ordinates)\n",
    "m = folium.Map(location=[-37.81368709240999, 144.95738102347036],\n",
    "                zoom_start=14, \n",
    "                tiles=\"cartodbpositron\",\n",
    "                control_scale=True,\n",
    "                prefer_canvas=True, \n",
    "                width=800, \n",
    "                height=580) \n",
    "\n",
    "#Create a feature group by accident year\n",
    "Year2017 = folium.FeatureGroup(name = 'Accident Year 2017')\n",
    "Year2018 = folium.FeatureGroup(name = 'Accident Year 2018')\n",
    "Year2019 = folium.FeatureGroup(name = 'Accident Year 2019')\n",
    "Year2020 = folium.FeatureGroup(name = 'Accident Year 2020')\n",
    "\n",
    "#Loop through each row of the working dataset\n",
    "for i, v in wrk_accident_bicyclists.iterrows():\n",
    "    \n",
    "    accyear = int(v['NUMYearOfAcc'])    \n",
    "    popup = \"\"\"\n",
    "    Accident ID : <b>%s</b><br>\n",
    "    Year : <b>%s</b><br>\n",
    "    Injury : <b>%s</b><br>\n",
    "    Long : <b>%s</b><br> \n",
    "    Lat: <b>%s</b><br>\n",
    "    \"\"\" % (v['KEYAccidentNumber'], v['NUMYearOfAcc'], \n",
    "           v['CATInjuryLevelDesc_person'], v['NUMLongitude_node'], \n",
    "           v['NUMLatitude_node'])\n",
    "    \n",
    "    # For each accident year in the dataset determine \n",
    "    # all marker points and add as separate layers so we can control the display for them\n",
    "    if accyear == 2017:\n",
    "        folium.Marker(location = [v['NUMLatitude_node'],v['NUMLongitude_node']],                       \n",
    "                           tooltip = popup,\n",
    "                           icon=folium.Icon(color=color(v['CATInjuryLevelDesc_person']),\n",
    "                           icon_color='yellow',icon = 'bicycle', prefix='fa')).add_to(Year2017)       \n",
    "        \n",
    "    if accyear == 2018:\n",
    "        folium.Marker(location = [v['NUMLatitude_node'],v['NUMLongitude_node']],\n",
    "                           tooltip = popup,\n",
    "                           icon=folium.Icon(color=color(v['CATInjuryLevelDesc_person']),\n",
    "                           icon_color='yellow',icon = 'bicycle', prefix='fa')).add_to(Year2018)\n",
    "    \n",
    "    if accyear == 2019:\n",
    "        folium.Marker(location = [v['NUMLatitude_node'], \n",
    "                                  v['NUMLongitude_node']],                           \n",
    "                           tooltip = popup,\n",
    "                           icon=folium.Icon(color=color(v['CATInjuryLevelDesc_person']),\n",
    "                           icon_color='yellow',icon = 'bicycle', prefix='fa')).add_to(Year2019)\n",
    "\n",
    "    if accyear == 2020:\n",
    "        folium.Marker(location = [v['NUMLatitude_node'], \n",
    "                                 v['NUMLongitude_node']],\n",
    "                           tooltip = popup,\n",
    "                           icon=folium.Icon(color=color(v['CATInjuryLevelDesc_person']),\n",
    "                           icon_color='yellow',icon = 'bicycle', prefix='fa')).add_to(Year2020)\n",
    "        \n",
    "#Add the layers to the base map        \n",
    "Year2017.add_to(m)\n",
    "Year2018.add_to(m)\n",
    "Year2019.add_to(m)\n",
    "Year2020.add_to(m)\n",
    "\n",
    "# iterate through the features in the bicyclepath DataFrame column\n",
    "for i in range(bicyclepath.shape[0]):\n",
    "    feature = bicyclepath[\"features\"].loc[i]\n",
    "    \n",
    "    # get the coordinates of the feature\n",
    "    coords = feature[\"geometry\"][\"coordinates\"]\n",
    "    coords = [[y, x] for x,y in coords[0]]\n",
    "\n",
    "    # create a PolyLine object from the coordinates\n",
    "    line = folium.PolyLine(coords, color='blue', weight=2).add_to(m)\n",
    "    lon, lat = bicyclepath['geo_point_2d'].loc[i].values()\n",
    "    \n",
    "    name,direction,b_type,info,status,notes= bicyclepath.loc[i][['name','direction','type','info','status','notes']]\n",
    "\n",
    "    iframe = folium.IFrame(f'<h4>{name}</h4><br>Directions: {direction}<br>Notes: {notes}<br>Info: {info}<br>Status: {status}')\n",
    "    popup = folium.Popup(iframe, min_width=300, max_width=300)\n",
    "    marker = folium.Marker(location=[lat,lon], icon=folium.Icon(icon='map-marker', prefix='fa'), popup=popup).add_to(m)\n",
    "\n",
    "#Add the map control\n",
    "folium.LayerControl(collapsed = False).add_to(m)\n",
    "\n",
    "#Show the map\n",
    "m\n",
    "\n",
    "#Save the map\n",
    "#m.save('geoJSON_bicycleaccidents_map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Findings and Opportunities</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis has provided a comprehensive starting point for inspecting the Melbourne Open Data Bicycle Network dataset and Traffic Accidents (Bicyclists) data.\n",
    "\n",
    "**We achieved in this analysis:**\n",
    "\n",
    "- A series of visualisations which illustrate the frequency, timing and basic characteristics of bicycle accidents occurring in Melbourne between the years 2017 and 2020\n",
    "- A series of map visualisations which illustrate the precise location of where bicycle accidents have occurred and a means to visually compare the locations to the bicycle path network\n",
    "\n",
    "\n",
    "**We learned from this analysis:**\n",
    "\n",
    "- How to interpret, analyse and visualise geoJSON files\n",
    "- How to create geographical maps with geoJSON files and dataframes to display geographical features\n",
    "- As a preliminary view, we observed that a majority of bicycle accidents did occur on designated bicycle network routes\n",
    "\n",
    "    At a broad level:\n",
    "    \n",
    "    The total number of bicycle accidents where cyclists have been seriously of fatally injured has been reducing over time (excluding the year 2020 as it was under-developed with only 3 months of data). More than 50 cyclists in 2017 to less than 25 in 2019. This appears to be a positive and optimistic trend.\n",
    "\n",
    "    The week days of Tuesdays and Thursdays appear to have the highest numbers of seriously injured cyclists. Separate to this, the hours of 8am-10am and 4pm-6pm have the highest numbers of seriously injured cyclists.\n",
    "\n",
    "    The top three roads with the highest number of seriously injured cyclists include Elizabeth Street, La Trobe Street and St Kilda Road.\n",
    "\n",
    "**Observations for further opportunities**\n",
    "\n",
    "- What are the traffic accident circumstances? Are cyclists colliding with open car doors an increasing or decreasing problem?\n",
    "- Do accidents co-occur with road-works, weather events or other disruptive events?\n",
    "- Report on sections of roadway where higher accident rates are observed\n",
    "- Part 2 of the Bicycle Network and Road Safety exploratory data analysis will dive deeper into the timing, geography, circumstance and 'hotspots' of bicycle accidents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">References</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Thompson Road North Geelong Road Safety Improvements https://regionalroads.vic.gov.au/map/barwon-south-west-improvements/thompson-road-safety-improvements\n",
    "\n",
    "[2] Victorian 'Crash-Stat's dataset https://discover.data.vic.gov.au/dataset/crash-stats-data-extract/resource/392b88c0-f010-491f-ac92-531c293de2e9\n",
    "\n",
    "[3] Bicycle Routes Dataset https://data.melbourne.vic.gov.au/Transport/Bicycle-routes-including-informal-on-road-and-off-/24aw-nd3i![image-3.png](attachment:image-3.png)\n",
    "\n",
    "\n",
    "**Technical References**\n",
    "\n",
    "[4] Accessing geoJSON data https://stackoverflow.com/questions/48263802/finding-location-using-geojson-file-using-python\n",
    "\n",
    "[5] Accessing geoJSON data https://medium.com/analytics-vidhya/measure-driving-distance-time-and-plot-routes-between-two-geographical-locations-using-python-39995dfea7e\n",
    "\n",
    "[6] Visualising a geoJSON dataset https://python-visualization.github.io/folium/quickstart.html#GeoJSON/TopoJSON-Overlays\n",
    "\n",
    "[7] Visualising categorised data on a map https://www.geeksforgeeks.org/python-adding-markers-to-volcano-locations-using-folium-package/\n",
    "\n",
    "[8] Creating point plot group layers with folium https://towardsdatascience.com/creating-an-interactive-map-of-wildfire-data-using-folium-in-python-7d6373b6334a\n",
    "\n",
    "[9] Ideas for further opportunities - Time Series Analysis https://geohackweek.github.io/ghw2018_web_portal_inlandwater_co2/InteractiveTimeSeries.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html usecase-bicyclenetworkroadsafety-part1.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
