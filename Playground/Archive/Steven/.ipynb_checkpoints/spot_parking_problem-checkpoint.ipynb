{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-title\">Spotting areas for public transportation planning in City of Melbourne</div>\n",
    "\n",
    "<div class=\"usecase-authors\"><b>Authored by: </b> Tithra Chap</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-duration\"><b>Duration:</b> 120 mins</div>\n",
    "\n",
    "<div class=\"usecase-level-skill\">\n",
    "    <div class=\"usecase-level\"><b>Level: </b>Intermediate</div>\n",
    "    <div class=\"usecase-skill\"><b>Pre-requisite Skills: </b>Python</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Scenario</div>\n",
    "\n",
    "The City of Melbourne has always evolved, and so have the numbers of its residential dwellings and employment population (based on data available on Melbourne Open Data). Without a consistent or parallel increase of off-street parking, the city will face the difficulty in providing enough spaces for parking of private transportation. To resolve this problem, the city planner needs to locate the potential areas where extension of public transportation should be implemented to replace the need for off-street parking. CLUE datasets contain information of employment, residential dwellings and parking spots of the city blocks. By tracking down the number of employments and residential dwellings in the city blocks and analyze their consistent trends with number of off-street parkings, we can identify the potential blocks that a city planner should pay more attention and ensure that public transportation are sufficient to handle the daily commuting traffic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">What this use case will teach you</div>\n",
    "\n",
    "This case study is intended to provide educational instructions of how to use CLUE datasets (Employment by blocks, Residential dwellings by blocks, and Off-street parking by blocks) to resolve the above analytical problem.\n",
    "\n",
    "The key learnings are:\n",
    "\n",
    "- How to explore the CLUE datasets using *pandas profiling*\n",
    "- How to clean those CLUE datasets\n",
    "- How to build linear regression model for this use case\n",
    "- How to use *ipywidgets* & *bninteract* to implement interactivity\n",
    "- How to link visualization with *ipywidgets*\n",
    "\n",
    "NOTE: This use case provides interactive tools so that user can experience the interaction with the data, as well as learning how to use the data.\n",
    "\n",
    "<div class=\"usecase-section-header\">Walkthrough steps:</div>\n",
    "\n",
    "1. Explore the THREE datasets\n",
    "2. Clean and merge them\n",
    "3. Build analysis model\n",
    "4. Visualize the analytical results\n",
    "5. Develop interactivity\n",
    "\n",
    "<div class=\"usecase-section-header\">A brief introduction to CLUE data</div>\n",
    "\n",
    "The City of Melbourne conducts a comprehensive bi-annual survey of its residents and businesses called the \"Census of Land Use and Employment (CLUE)\". CLUE captures key information on land use, employment, and economic activity across the City of Melbourne.\n",
    "\n",
    "CLUE data assists the City of Melbourne's business planning, policy development and strategic decision making. Investors, consultants, students, urban researchers, property analysts, businesses and developers can take advantage of CLUE to understand customers, the marketplace and the changing form and nature of the city.\n",
    "\n",
    "Among many CLUE datasets, this use case employs THREE datasets available at Melbourne Open Data website:\n",
    "\n",
    "- [Residential Dwellings Dataset 2002-2020](https://data.melbourne.vic.gov.au/Property/Residential-dwellings/44kh-ty54)\n",
    "- [Employment by city blocks 2002-2020](https://data.melbourne.vic.gov.au/Business/Employment-by-block-by-CLUE-industry/b36j-kiy4)\n",
    "- [Off-street car parking 2002-2020](https://data.melbourne.vic.gov.au/Transport/Off-street-car-parks-with-capacity-and-type/krh5-hhjn)\n",
    "\n",
    "[CLUE blocks](https://data.melbourne.vic.gov.au/Business/Blocks-for-Census-of-Land-Use-and-Employment-CLUE-/aia8-ryiq) json map is also used for location visualization.\n",
    "\n",
    "NOTE: we suggest scanning through data dictionaries of the above datasets at Melbourne Open Data to familiarize yourself beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Detail Walkthrough:</div>\n",
    "\n",
    "<div class=\"usecase-section-header\">1. Explore the datasets</div>\n",
    "\n",
    "Datasets containing missing values, duplications, inconsistency, extreme outliers are common problems in real world data. One of the most convenient way to identify these issues is to profile the data using python package ***pandas-profiling***. An example below shows how to read a .csv dataset and generate an html file containing deep profiling detail of ***Residential Dwelling.csv*** of CLUE dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Residential dwellings data\n",
    "resident = pd.read_csv('https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/residential-dwellings/exports/csv?delimiter=%3B&list_separator=%2C&quote_all=false&with_bom=true',on_bad_lines='skip',delimiter=\";\")\n",
    "resident = resident[resident[\"census_year\"] != 2021]\n",
    "resident.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">2. Clean and merge the datasets</div>\n",
    "\n",
    "\n",
    "CLUE datasets are mainly clean, although there are some issues with missing values and duplicated records. The process below is done to eliminate these problems, and drop unnecessary columns.\n",
    "\n",
    "\n",
    "### Residential Dwellings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total records before cleaning\n",
    "print('Total records before cleaning is',len(resident))\n",
    "#Data cleaning (remove duplicated values)\n",
    "resident.drop_duplicates(inplace = True)\n",
    "#Total records after cleaning\n",
    "print('Total records after cleaning is',len(resident))\n",
    "#Select only necessary columns\n",
    "selected_columns =['census_year','block_id','clue_small_area','dwelling_number']\n",
    "resident = resident[selected_columns]\n",
    "#Sum the [Dwelling number] based on [Block ID] and [Census Year], but keep one [CLUE small area] for each Block ID\n",
    "resident_by_block = resident.groupby(['census_year','block_id']).agg({'clue_small_area':'max','dwelling_number':'sum'})\n",
    "print('Total records after grouping (by Block ID) is',len(resident_by_block))\n",
    "#Detail of the residential dwellings by block\n",
    "resident_by_block.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result, we obtain ***resident_by_block*** pandas-series containing 2 columns: \"CLUE small area\" and \"Dwelling number\", with \"Census year\" and \"Block ID\" as multiple index.\n",
    "\n",
    "We repeat similar codes to work on *Employment by city blocks* and *Off-street car parking* datasets below:\n",
    "\n",
    "### Employment by city blocks datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment = pd.read_csv(\"https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/employment-by-block-by-anzsic/exports/csv?delimiter=%3B&list_separator=%2C&quote_all=false&with_bom=true\",delimiter=\";\")\n",
    "#Total records before cleaning\n",
    "print('Total records before cleaning is',len(employment))\n",
    "#Cleaning the data (remove missing values at [Total employment in block])\n",
    "employment.dropna(subset=['total_jobs_in_block'],inplace=True)\n",
    "#Total records after cleaning\n",
    "print('Total records after cleaning is',len(employment))\n",
    "#Select only necessary columns\n",
    "selected_columns =['census_year','block_id','total_jobs_in_block']\n",
    "employment = employment[selected_columns]\n",
    "#Sum the employment based on Block ID and Year\n",
    "employment_by_block = employment.groupby(['census_year','block_id']).sum()\n",
    "print('Total records after grouping (by Block ID) is',len(employment_by_block))\n",
    "#Detail of the employment_by_block\n",
    "employment_by_block.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Off-street car parking datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Off-street parking data\n",
    "parking = pd.read_csv('https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/off-street-car-parks-with-capacity-and-type/exports/csv?delimiter=%3B&list_separator=%2C&quote_all=false&with_bom=true',delimiter=\";\")\n",
    "#Total records before cleaning\n",
    "print('Total records before cleaning is',len(parking))\n",
    "#Data cleaning (remove duplicate values)\n",
    "parking.drop_duplicates(inplace=True)\n",
    "#Total records after cleaning\n",
    "print('Total records after cleaning is',len(parking))\n",
    "#Select only necessary columns\n",
    "selected_columns =['census_year','block_id','parking_spaces']\n",
    "parking = parking[selected_columns]\n",
    "#Sum the parking based on Block ID and Year\n",
    "parking_by_block = parking.groupby(['census_year','block_id']).sum()\n",
    "print('Total records after grouping (by Block ID) is',len(parking_by_block))\n",
    "#Detail of the employment_by_block\n",
    "parking_by_block.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the clean datasets and plot the scattered distributions\n",
    "\n",
    "The scatter plots provide insight of linear relationship between dependent variable (Off-street car park) and independent variables (Residential Dwellings , Employment by city block). Learning from this relationship, we can notice whether there is unhealthy distribution that could imply insufficient off-street car parking in the city blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(color_codes=True)\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "#Combine the datasets (only take the blocks that match between three datasets)\n",
    "data = resident_by_block.merge(employment_by_block, left_index= True, right_index=True)\n",
    "data = data.merge(parking_by_block,left_index=True,right_index=True)\n",
    "print(data.head())\n",
    "#Prepare data for scatter plots\n",
    "x1 = data['total_jobs_in_block']\n",
    "x2 = data['dwelling_number']\n",
    "y = data['parking_spaces']\n",
    "#Plot the data points (Parking Spaces vs. Total Employment) and regression line\n",
    "plt.plot(x1,y,'x')\n",
    "a, b = np.polyfit(x1,y,1)\n",
    "plt.plot(x1, a*x1 + b)\n",
    "plt.title('Parking Spaces vs. Total Employment')\n",
    "plt.ylabel('Parking Spaces')\n",
    "plt.xlabel('Total Employment')\n",
    "plt.show()\n",
    "#Plot the data points (Parking Spaces vs. Dwelling Number) and regression line\n",
    "plt.plot(x2,y,'+')\n",
    "a, b = np.polyfit(x2,y,1)\n",
    "plt.plot(x2, a*x2 + b)\n",
    "plt.title('Parking Spaces vs. Dwelling Number')\n",
    "plt.ylabel('Parking Spaces')\n",
    "plt.xlabel('Dwelling Number')\n",
    "plt.show()\n",
    "\n",
    "#NOTE: This dataset here ('data') need to be exported to GitHub and named as \"merged_data.csv\" to allow interactive (function) to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice the distributions below the orange lines (regression lines) are likely to have insufficient car parking.\n",
    "\n",
    "<div class=\"usecase-section-header\">3. Build analysis model</div>\n",
    "\n",
    "This model uses multiple-variable linear regression. The model has dependent variable ***Y*** as \"Off-street car park\" and ***X1***, ***X2*** as \"Residential Dwellings\" and \"Employment by city block\" respectively.\n",
    "\n",
    "### Prepare the data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare X and Y data for model training\n",
    "def Get_data(Data, Year_to_include,Employment,Resident_dwellings):\n",
    "  import numpy as np\n",
    "  features = np.array(['total_jobs_in_block', 'dwelling_number'])\n",
    "  features_to_include = features[[Employment,Resident_dwellings]] #Define the data features for the study\n",
    "  data_to_include = Data.loc[min(Year_to_include):max(Year_to_include)] #Get the wanted rows\n",
    "  X = np.array(data_to_include[features_to_include]) #Get the independent variable(s) based on the selected features\n",
    "  Y = np.array(data_to_include['parking_spaces']) #Get the dependent variable\n",
    "  return X, Y\n",
    "#print('The study period is between: %d and %d'%(min(years_to_include),max(years_to_include)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_model(X, Y):\n",
    "  import sklearn\n",
    "  from sklearn import linear_model\n",
    "  from sklearn.ensemble import IsolationForest\n",
    "  iso = IsolationForest(contamination=0.1)#use outliers detector\n",
    "  yhat = iso.fit_predict(X) #Search for outliers\n",
    "  lm = linear_model.LinearRegression() #linear regression model\n",
    "  lm.fit(X[yhat!=-1],Y[yhat!=-1]) # Train the model excluding outliers\n",
    "  return lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the parking problem based on the latest year (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict parking issue in 2020\n",
    "def Get_predict_result(Data, Model, Employment, Residential_dwellings):\n",
    "  import numpy as np\n",
    "  data_latest = Data.loc[years.max] # Get data of 2020\n",
    "  features = np.array(['Total employment in block', 'Dwelling number'])\n",
    "  features_to_include = features[[Employment,Residential_dwellings]] #Define the data features for the study\n",
    "  result = np.round(Model.predict(np.array(data_latest[features_to_include]))) #Predict based on the selected features\n",
    "  data_latest['Predict_parking'] = result.astype(int) #Add result to the data\n",
    "  impact = result - data_latest['Parking spaces']\n",
    "  impact[impact>=0] = 100*(impact[impact>=0]/(max(impact[impact>=0]))) # Normalize the impact index (0-100)\n",
    "  data_latest['Impact_index'] = impact.astype(int) #Add impact index to the data\n",
    "  return data_latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">4. Visualize the analytical results</div>\n",
    "\n",
    "### Plot barchart of the predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the impacted city blocks\n",
    "def bar_plot(Data, Impact_level):\n",
    "  import matplotlib.pyplot as plt\n",
    "  import numpy as np\n",
    "  import seaborn as sns\n",
    "  sns.set_theme(color_codes=True)\n",
    "  #Only visualize the blocks greater than the impact level\n",
    "  plot_data = Data['Impact_index']#Get only the data records with higher impact level\n",
    "  plt.figure(figsize=(13,len(plot_data)/3))\n",
    "  plt.xlabel('Impact Index (Higher index indicates serious shortage of off-street parking)')\n",
    "  plt.ylabel('Block ID of Melbourne city')\n",
    "  plt.title('Impacted Blocks vs. Impact Index\\n Shows impact index from '+str(Impact_level)+' to 100')\n",
    "  plt.barh (plot_data.index.astype(str),plot_data.values)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the map using Folium Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(clue_data):\n",
    "  import json\n",
    "  import folium\n",
    "  #Load the csv and json data for map plotting\n",
    "  json_file = open('interactive_dependencies/clue_blocks.geojson') \n",
    "  clue_geo = json.load(json_file)\n",
    "\n",
    "  clue_data.reset_index(inplace=True) #turn the index (Block_ID) into a column in the dataframe (clue_data)\n",
    "  clue_data['Block ID'] = clue_data['Block ID'].astype(str) # conver [Block ID] to str, so that it is compatible with json content\n",
    "\n",
    "  #Create the initial map\n",
    "  fmap = folium.Map(location=[-37.811600, 144.964610],\n",
    "            tiles = 'Stamen Toner',\n",
    "            width = '70%',\n",
    "            height = '100%',\n",
    "            zoom_start=13)\n",
    "\n",
    "  #create the choropleth layer and add to the map above\n",
    "  choropleth = folium.Choropleth(\n",
    "      geo_data=clue_geo,\n",
    "      name='choropleth',\n",
    "      data=clue_data,\n",
    "      columns=['Block ID','Impact_index'],\n",
    "      key_on='feature.properties.block_id',\n",
    "      fill_color='YlOrRd',\n",
    "      fill_opacity=1,\n",
    "      line_opacity=0.5,\n",
    "      nan_fill_color='cloud',\n",
    "      nan_fill_opacity = 0.2,\n",
    "      highlight=True,\n",
    "      legend_name='Impact index'\n",
    "  ).add_to(fmap)\n",
    "\n",
    "  #Add more layers and tooltips\n",
    "  choropleth.geojson.add_child(folium.features.GeoJsonTooltip(['block_id','clue_area'],labels=True))\n",
    "  return fmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">5. Develop interactivity</div>\n",
    "\n",
    "To have interactivity on Python notebook online, we need third party server to compile the Python notebook codes. In the replacement of local Jupyter notebook engine (used for locally run the Python notebook), Binder server provides that free service for Jupiter notebook community. What you need to do is:\n",
    "1. Create a public GitHub account\n",
    "2. Store your Python notebook file there\n",
    "3. Install nbinteract in your Jupyter notebook environment (pip install nbinteract)\n",
    "4. On Jupyter notebook commandline, change drive to GitHub clone folder (where your Python notebook located)\n",
    "5. run \"nbinteract init\" to create \"requirements.txt\" to tell Binder server the dependencies your Python notebook needs\n",
    "6. run \"nbinteract YourNotebookFile.ipynb\" to create \"YourNoteFile.html\"\n",
    "\n",
    "This [demonstration tutorial](https://www.youtube.com/watch?v=jln6h-dE2-0) provides more insight of the *nbinteract*.\n",
    "\n",
    "### Build interactive widgets using ipywidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a widget to select the range of study years\n",
    "import ipywidgets as widgets\n",
    "style = {'description_width': 'initial'} #for long label of the widgets\n",
    "#Year-to-include slider\n",
    "years = widgets.IntRangeSlider(value=[2002, 2020], min=2002, max=2020, step=1, description='Years to include:', style=style)\n",
    "#Display option: impact level\n",
    "show_impact = widgets.IntSlider(value=15, min=10, max=100, step=1, description='Impact index from:',style=style)\n",
    "#Employment checkbox\n",
    "chk_employment = widgets.Checkbox(value=True, description='Employment', indent=False)\n",
    "#Residential Dwellings checkbox\n",
    "chk_resident = widgets.Checkbox(value=True, description='Residential Dwellings', indent=False )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function for interactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to execute when using interactive tools\n",
    "def show_interaction(Year_to_include,Employment,Residential_dwellings, Impact_level):\n",
    "    from IPython.display import display\n",
    "    #Must import libraries and datasets for a self-contain function\n",
    "    import pandas as pd\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\") #suppress dataframe warning\n",
    "\n",
    "    data = pd.read_csv('interactive_dependencies/merged_data.csv') #the dataset that contains all the THREE features (employment, resident & parking)\n",
    "    data.set_index(['Census year','Block ID'],inplace=True) #Turn the data to pandas series\n",
    "    print('='*23)\n",
    "    print('|DATA ANALYSIS RESULTS|')\n",
    "    print('='*23)\n",
    "    print('(NOTE: The city blocks without parking information available are ignored by our analyzing model.)\\n\\n')\n",
    "    if (not(Employment)) & (not(Residential_dwellings)):\n",
    "        Employment = True  #Prevent both data features are unticked ==> Error\n",
    "    #Get the filtered data for analysis\n",
    "    X, Y = Get_data(data,Year_to_include,Employment,Residential_dwellings)\n",
    "    #Build regression model\n",
    "    lm = lm_model(X,Y)\n",
    "    #Get the predicted results\n",
    "    predict_results = Get_predict_result(data,lm, Employment, Residential_dwellings)\n",
    "    predict_results = predict_results[predict_results['Impact_index']>=Impact_level] #only plot city block that have higher impact level\n",
    "\n",
    "    #Plot the barchart of the predicted results\n",
    "    bar_plot(predict_results, Impact_level);\n",
    "    #Show table of the impacted blocks in detail table\n",
    "    print('\\n\\n The table below shows the impacted blocks (limited parking) by the order of the impact index.\\n')\n",
    "    display(predict_results.sort_values('Impact_index',ascending = False))\n",
    "    #Plot the folium choropleth map\n",
    "    print('The impacted city blocks can be seen via the map here:')\n",
    "    display(plot_map(predict_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Demo use case</div>\n",
    "\n",
    "With interactivity, a city planner can try to spot the city blocks that are likely to have insufficient parking but having high density of employments and residential dwellings. Underneath the code block below, there are interactivity options that can be selected to analyze the data.\n",
    "\n",
    ">Interactivity options:\n",
    "- ***Years to include*** - Determines the census data (in year) to be included in the analysis\n",
    "- ***Employment check*** - Ticked to include \"Employment by city block\" dataset in the analysis\n",
    "- ***Residential Dwellings check*** - Ticked to include \"Residential Dwellings\" dataset in the analysis\n",
    "- ***Impact index from*** - Filter out the block areas that have minor parking insufficient problem (lower than the selected ***Impact index***)\n",
    "\n",
    "Once all options have been selected, please click on \"Start Analysis...\" button to analysis the data.\n",
    "\n",
    "NOTE: If both ***Employment*** and ***Residential Dwellings*** are unchecked, ***Employment*** will be automatically used for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the interactive tools\n",
    "from ipywidgets import interact_manual\n",
    "interact_manual.opts['manual_name'] = 'Start Analyzing'\n",
    "interact_manual(show_interaction, Year_to_include=years, Employment=chk_employment, Residential_dwellings = chk_resident, Impact_level = show_impact);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "00bd831c53de52cee16e552ea13cca9c838ef1c874ebe408d7c288ec76d7b8ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
