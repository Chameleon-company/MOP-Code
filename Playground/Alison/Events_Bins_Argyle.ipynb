{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-title\">{Bins for events Argyle Squrae}</div>\n",
    "\n",
    "<div class=\"usecase-authors\"><b>Authored by: </b> {Alison Collins}</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-duration\"><b>Duration:</b> {60} mins</div>\n",
    "\n",
    "<div class=\"usecase-level-skill\">\n",
    "    <div class=\"usecase-level\"><b>Level: </b>{Intermediate}</div>\n",
    "    <div class=\"usecase-skill\"><b>Pre-requisite Skills: </b>{Python}</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">Scenario</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{If you are planning an event at Argyle Square you will need to know if you need to hire additional bins. This use case seeks to determine th ebin capacity during events and make recommendations on the need for more bins based on event attendee numbers.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">What this use case will teach you</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this use case you will:\n",
    "- {list the skills demonstrated in your use case}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"usecase-section-header\">{Heading for introduction or background relating to problem}</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{Write your introduction here. Keep it concise. We're not after \"War and Peace\" but enough background information to inform the reader on the rationale for solving this problem or background non-technical information that helps explain the approach. You may also wish to give information on the datasets, particularly how to source those not being imported from the client's open data portal.}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import required modules\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import datasets using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "# Function to collect datasets using API\n",
    "def datasetcollect(dataset_id):\n",
    "    base_url = 'https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/'\n",
    "    #apikey = \" \"\n",
    "    dataset_id = dataset_id\n",
    "    format = 'csv'\n",
    "\n",
    "    url = f'{base_url}{dataset_id}/exports/{format}'\n",
    "    params = {\n",
    "        'select': '*',\n",
    "        'limit': -1,  # all records\n",
    "        'lang': 'en',\n",
    "        'timezone': 'UTC',\n",
    "        #'api_key': apikey\n",
    "    }\n",
    "\n",
    "    # GET request\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # StringIO to read the CSV data\n",
    "        url_content = response.content.decode('utf-8')\n",
    "        dataset = pd.read_csv(StringIO(url_content), delimiter=';')\n",
    "        return dataset\n",
    "    else:\n",
    "        print(f'Request failed with status code {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dev_id</th>\n",
       "      <th>sensor_name</th>\n",
       "      <th>time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>light</th>\n",
       "      <th>motion</th>\n",
       "      <th>visit</th>\n",
       "      <th>vdd</th>\n",
       "      <th>lat_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ers-55eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-13T20:09:42+00:00</td>\n",
       "      <td>10.5</td>\n",
       "      <td>89</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3638</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ers-55ea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-13T20:26:03+00:00</td>\n",
       "      <td>10.6</td>\n",
       "      <td>88</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3635</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ers-55eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-13T20:34:47+00:00</td>\n",
       "      <td>10.8</td>\n",
       "      <td>89</td>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3638</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dev_id  sensor_name                       time  temperature  humidity  \\\n",
       "0  ers-55eb          NaN  2022-12-13T20:09:42+00:00         10.5        89   \n",
       "1  ers-55ea          NaN  2022-12-13T20:26:03+00:00         10.6        88   \n",
       "2  ers-55eb          NaN  2022-12-13T20:34:47+00:00         10.8        89   \n",
       "\n",
       "   light  motion  visit   vdd  lat_long  \n",
       "0    297       0      0  3638       NaN  \n",
       "1    136       0      0  3635       NaN  \n",
       "2    698       0      0  3638       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import stage activity dataset\n",
    "dataset_id = 'meshed-sensor-type-3'\n",
    "stage_activity_all = datasetcollect(dataset_id)\n",
    "print(len(stage_activity_all))\n",
    "stage_activity_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561783\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dev_id</th>\n",
       "      <th>time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>distance</th>\n",
       "      <th>filllevel</th>\n",
       "      <th>battery</th>\n",
       "      <th>lat_long</th>\n",
       "      <th>sensor_name</th>\n",
       "      <th>fill_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r718x-6778</td>\n",
       "      <td>2023-02-26T08:16:47+00:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-37.8025943, 144.9658434</td>\n",
       "      <td>r718x-bin sensor 8</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r718x-6f16</td>\n",
       "      <td>2023-02-26T08:18:10+00:00</td>\n",
       "      <td>19.9</td>\n",
       "      <td>202.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-37.8028794, 144.9662728</td>\n",
       "      <td>r718x-bin sensor 17</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r718x-677d</td>\n",
       "      <td>2023-02-26T08:18:02+00:00</td>\n",
       "      <td>20.7</td>\n",
       "      <td>200.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-37.8021051, 144.9654523</td>\n",
       "      <td>r718x-bin sensor 11</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dev_id                       time  temperature  distance  filllevel  \\\n",
       "0  r718x-6778  2023-02-26T08:16:47+00:00         19.0     209.0       73.0   \n",
       "1  r718x-6f16  2023-02-26T08:18:10+00:00         19.9     202.0       74.0   \n",
       "2  r718x-677d  2023-02-26T08:18:02+00:00         20.7     200.0       74.0   \n",
       "\n",
       "   battery                  lat_long          sensor_name  fill_level  \n",
       "0      3.6  -37.8025943, 144.9658434   r718x-bin sensor 8        71.0  \n",
       "1      3.6  -37.8028794, 144.9662728  r718x-bin sensor 17        72.0  \n",
       "2      3.6  -37.8021051, 144.9654523  r718x-bin sensor 11        72.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import bin sensor dataset\n",
    "dataset_id = 'netvox-r718x-bin-sensor'\n",
    "bin_sensor_all = datasetcollect(dataset_id)\n",
    "print(len(bin_sensor_all))\n",
    "bin_sensor_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109175\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>keys1</th>\n",
       "      <th>total</th>\n",
       "      <th>dwell</th>\n",
       "      <th>sensor_name</th>\n",
       "      <th>sensor_type</th>\n",
       "      <th>lat_long</th>\n",
       "      <th>avg_dwell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-25T22:00:00+00:00</td>\n",
       "      <td>8171</td>\n",
       "      <td>27</td>\n",
       "      <td>5697</td>\n",
       "      <td>Pedestrian Sensor-Birrarung Marr</td>\n",
       "      <td>Mobile phone counting</td>\n",
       "      <td>-37.8209898, 144.9759397</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-26T08:00:00+00:00</td>\n",
       "      <td>8171</td>\n",
       "      <td>115</td>\n",
       "      <td>42090</td>\n",
       "      <td>Pedestrian Sensor-Birrarung Marr</td>\n",
       "      <td>Mobile phone counting</td>\n",
       "      <td>-37.8209898, 144.9759397</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-26T02:00:00+00:00</td>\n",
       "      <td>7780</td>\n",
       "      <td>228</td>\n",
       "      <td>94848</td>\n",
       "      <td>Pedestrian Sensor-Argyle Sq</td>\n",
       "      <td>Mobile phone counting</td>\n",
       "      <td>-37.8025805, 144.9656012</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime  keys1  total  dwell  \\\n",
       "0  2022-08-25T22:00:00+00:00   8171     27   5697   \n",
       "1  2022-08-26T08:00:00+00:00   8171    115  42090   \n",
       "2  2022-08-26T02:00:00+00:00   7780    228  94848   \n",
       "\n",
       "                        sensor_name            sensor_type  \\\n",
       "0  Pedestrian Sensor-Birrarung Marr  Mobile phone counting   \n",
       "1  Pedestrian Sensor-Birrarung Marr  Mobile phone counting   \n",
       "2       Pedestrian Sensor-Argyle Sq  Mobile phone counting   \n",
       "\n",
       "                   lat_long  avg_dwell  \n",
       "0  -37.8209898, 144.9759397        3.0  \n",
       "1  -37.8209898, 144.9759397        6.0  \n",
       "2  -37.8025805, 144.9656012        6.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import blix mobile phone counter dataset\n",
    "dataset_id = 'blix-visits'\n",
    "blix_phones_all = datasetcollect(dataset_id)\n",
    "print(len(blix_phones_all))\n",
    "blix_phones_all.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unwanted columns from datasets\n",
    "\n",
    "# Drop columns from stage_activity dataframe\n",
    "stage_activity = stage_activity_all[['dev_id','time','motion','visit']]\n",
    "# Drop columns from stage_activity dataframe\n",
    "bin_sensor_cols = bin_sensor_all[['dev_id','time','filllevel']]\n",
    "# Drop columns from stage_activity dataframe\n",
    "blix_phones = blix_phones_all[['datetime','total','dwell','avg_dwell']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in Stage activity\n",
      "dev_id    object\n",
      "time      object\n",
      "motion     int64\n",
      "visit      int64\n",
      "dtype: object\n",
      "Data types in Bin Sensor\n",
      "dev_id        object\n",
      "time          object\n",
      "filllevel    float64\n",
      "dtype: object\n",
      "Data types in Blix Phones\n",
      "datetime      object\n",
      "total          int64\n",
      "dwell          int64\n",
      "avg_dwell    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check data types in columns\n",
    "\n",
    "print(\"Data types in Stage activity\")\n",
    "print(stage_activity.dtypes)\n",
    "\n",
    "print(\"Data types in Bin Sensor\")\n",
    "print(bin_sensor_cols.dtypes)\n",
    "\n",
    "print(\"Data types in Blix Phones\")\n",
    "print(blix_phones.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date time columns to date time type\n",
    "\n",
    "stage_activity['date_time'] = pd.to_datetime(stage_activity['time'])\n",
    "stage_activity = stage_activity.drop(['time'], axis=1)\n",
    "\n",
    "bin_sensor_cols['date_time'] = pd.to_datetime(bin_sensor_cols['time'])\n",
    "bin_sensor_cols = bin_sensor_cols.drop(['time'], axis=1)\n",
    "\n",
    "blix_phones['date_time'] = pd.to_datetime(blix_phones['datetime'])\n",
    "blix_phones = blix_phones.drop(['datetime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range in stage activity\n",
      "2022-11-29 06:05:16+00:00\n",
      "2024-03-27 07:28:36+00:00\n",
      "Date range in bin sensor\n",
      "2023-02-26 08:16:37+00:00\n",
      "2024-03-27 07:29:17+00:00\n",
      "Date range in blix phones\n",
      "2021-12-31 13:00:00+00:00\n",
      "2024-03-26 12:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "#Check oldest and most recent dates in datasets\n",
    "\n",
    "print(\"Date range in stage activity\")\n",
    "print(stage_activity[\"date_time\"].min())\n",
    "print(stage_activity[\"date_time\"].max())\n",
    "\n",
    "print(\"Date range in bin sensor\")\n",
    "print(bin_sensor_cols[\"date_time\"].min())\n",
    "print(bin_sensor_cols[\"date_time\"].max())\n",
    "\n",
    "print(\"Date range in blix phones\")\n",
    "print(blix_phones[\"date_time\"].min())\n",
    "print(blix_phones[\"date_time\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows so that all datasets have the same date range\n",
    "\n",
    "stage_activity= stage_activity[(stage_activity['date_time'] > '2023-2-26') & (stage_activity['date_time'] <= '2024-3-26')]\n",
    "\n",
    "bin_sensor= bin_sensor_cols[(bin_sensor_cols['date_time'] > '2023-2-26') & (bin_sensor_cols['date_time'] <= '2024-3-26')]\n",
    "\n",
    "blix_phones= blix_phones[(blix_phones['date_time'] > '2023-2-26') & (blix_phones['date_time'] <= '2024-3-26')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min      0.0\n",
      "max    255.0\n",
      "Name: filllevel, dtype: float64\n",
      "133765\n",
      "0.0004560236235188577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133704"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BIN DATASET PREPROCESSING\n",
    "# Filter unwanted values from bin dataset \n",
    "\n",
    "# Keep only rows with bin sensors in the stage area\n",
    "filtered_bin_sensor = bin_sensor_cols[bin_sensor_cols[\"dev_id\"].isin([\"r718x-6778\", \"r718x-6775\",\"r718x-6f25\",\"r718x-677e\",\"r718x-6f31\"])]\n",
    "filtered_bin_sensor.head(3)\n",
    "\n",
    "# Check max and min values in bin fill levels\n",
    "# Max and min of filllevel column\n",
    "print(filtered_bin_sensor['filllevel'].agg(['min', 'max']))\n",
    "\n",
    "# Count the number of values greater than 100 in the bin fill coumns\n",
    "more = len(filtered_bin_sensor[filtered_bin_sensor['filllevel']>100])\n",
    "\n",
    "# Fnd percentage of values impacted  by value >100 in fill level\n",
    "# Count the number of rows in the dataframe\n",
    "total = len(filtered_bin_sensor)\n",
    "#check the length of the dataframe\n",
    "print(len(filtered_bin_sensor))\n",
    "# Calculate the percentage of data that has values greater than 100\n",
    "print(more/total)\n",
    "\n",
    "# As only 0.0456% of data is impacted by data inaccuracies, make the decision to drop these rows from the table.\n",
    "\n",
    "# Drop rows where bin fill column is greater than 100\n",
    "filtered_bin_sensor = filtered_bin_sensor.drop(filtered_bin_sensor[filtered_bin_sensor['filllevel'] > 100].index)\n",
    "# Check the length of the dataframe\n",
    "len(filtered_bin_sensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dev_id</th>\n",
       "      <th>filllevel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">r718x-6775</th>\n",
       "      <th>2023-02-26 08:00:00+00:00</th>\n",
       "      <td>r718x-6775</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-26 08:30:00+00:00</th>\n",
       "      <td>r718x-6775</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-26 09:00:00+00:00</th>\n",
       "      <td>r718x-6775</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-26 09:30:00+00:00</th>\n",
       "      <td>r718x-6775</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-26 10:00:00+00:00</th>\n",
       "      <td>r718x-6775</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">r718x-6f31</th>\n",
       "      <th>2023-10-09 17:00:00+00:00</th>\n",
       "      <td>r718x-6f31</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09 17:30:00+00:00</th>\n",
       "      <td>r718x-6f31</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09 18:00:00+00:00</th>\n",
       "      <td>r718x-6f31</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09 18:30:00+00:00</th>\n",
       "      <td>r718x-6f31</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09 19:00:00+00:00</th>\n",
       "      <td>r718x-6f31</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84054 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          dev_id  filllevel\n",
       "dev_id     date_time                                       \n",
       "r718x-6775 2023-02-26 08:00:00+00:00  r718x-6775       61.0\n",
       "           2023-02-26 08:30:00+00:00  r718x-6775       61.0\n",
       "           2023-02-26 09:00:00+00:00  r718x-6775       63.0\n",
       "           2023-02-26 09:30:00+00:00  r718x-6775       62.0\n",
       "           2023-02-26 10:00:00+00:00  r718x-6775       52.0\n",
       "...                                          ...        ...\n",
       "r718x-6f31 2023-10-09 17:00:00+00:00  r718x-6f31       71.0\n",
       "           2023-10-09 17:30:00+00:00  r718x-6f31       71.0\n",
       "           2023-10-09 18:00:00+00:00  r718x-6f31       74.0\n",
       "           2023-10-09 18:30:00+00:00  r718x-6f31       74.0\n",
       "           2023-10-09 19:00:00+00:00  r718x-6f31       74.0\n",
       "\n",
       "[84054 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BIN DATASET PREPROCESSING: GROUP BY BIN THEN RESAMPLE\n",
    "\n",
    "# Set index to datetime column\n",
    "filtered_bin_sensor.set_index('date_time', inplace=True)\n",
    "\n",
    "# Resample the data by hour\n",
    "grouped_bin_sensor = filtered_bin_sensor.groupby('dev_id').resample('30min').max()\n",
    "grouped_bin_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2023-02-26 08:00:00+00:00    74.0\n",
       "2023-02-26 08:30:00+00:00    74.0\n",
       "2023-02-26 09:00:00+00:00    74.0\n",
       "2023-02-26 09:30:00+00:00    74.0\n",
       "2023-02-26 10:00:00+00:00    74.0\n",
       "                             ... \n",
       "2024-03-27 05:00:00+00:00    82.0\n",
       "2024-03-27 05:30:00+00:00    81.0\n",
       "2024-03-27 06:00:00+00:00    81.0\n",
       "2024-03-27 06:30:00+00:00    83.0\n",
       "2024-03-27 07:00:00+00:00    83.0\n",
       "Freq: 30T, Name: filllevel, Length: 18959, dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BIN DATASET PREPROCESSING: RESAMPLE WITHOUT GROUPING BY BIN\n",
    "\n",
    "# Set index to datetime column\n",
    "filtered_bin_sensor.set_index('date_time', inplace=True)\n",
    "\n",
    "# Resample the data by hour\n",
    "grouped_bin_sensor1 = filtered_bin_sensor.resample('30min').filllevel.max()\n",
    "grouped_bin_sensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2023-02-26 00:00:00+00:00    0.0\n",
       "2023-02-26 00:30:00+00:00    0.0\n",
       "2023-02-26 01:00:00+00:00    0.0\n",
       "2023-02-26 01:30:00+00:00    1.0\n",
       "2023-02-26 02:00:00+00:00    0.0\n",
       "                            ... \n",
       "2024-03-25 21:30:00+00:00    1.0\n",
       "2024-03-25 22:00:00+00:00    0.0\n",
       "2024-03-25 22:30:00+00:00    0.0\n",
       "2024-03-25 23:00:00+00:00    0.0\n",
       "2024-03-25 23:30:00+00:00    0.0\n",
       "Freq: 30T, Name: motion, Length: 18912, dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STAGE ACTIVITY DATASET PREPROCESSING: RESAMPLE WITHOUT GROUPING BY SENSOR\n",
    "\n",
    "# Set index to datetime column\n",
    "stage_a = stage_activity\n",
    "stage_a.set_index('date_time', inplace=True)\n",
    "\n",
    "# Resample the data by hour\n",
    "grouped_stage_activity = stage_a.resample('30min').motion.max()\n",
    "grouped_stage_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "right keys must be sorted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[165], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merged_dataframe_A \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_asof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrouped_bin_sensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTimedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2ms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m merged_dataframe_A\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:705\u001b[0m, in \u001b[0;36mmerge_asof\u001b[1;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03mPerform a merge by key distance.\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;124;03m4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    688\u001b[0m op \u001b[38;5;241m=\u001b[39m _AsOfMerge(\n\u001b[0;32m    689\u001b[0m     left,\n\u001b[0;32m    690\u001b[0m     right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    703\u001b[0m     direction\u001b[38;5;241m=\u001b[39mdirection,\n\u001b[0;32m    704\u001b[0m )\n\u001b[1;32m--> 705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1852\u001b[0m, in \u001b[0;36m_OrderedMerge.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 1852\u001b[0m     join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1854\u001b[0m     left_join_indexer: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     right_join_indexer: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1133\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1130\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1131\u001b[0m     )\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2176\u001b[0m, in \u001b[0;36m_AsOfMerge._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2174\u001b[0m \u001b[38;5;66;03m# initial type conversion as needed\u001b[39;00m\n\u001b[0;32m   2175\u001b[0m left_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_values_for_libjoin(left_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2176\u001b[0m right_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_values_for_libjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mright\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[38;5;66;03m# a \"by\" parameter requires special handling\u001b[39;00m\n\u001b[0;32m   2179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2180\u001b[0m     \u001b[38;5;66;03m# remove 'on' parameter from values if one existed\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2097\u001b[0m, in \u001b[0;36m_AsOfMerge._convert_values_for_libjoin\u001b[1;34m(self, values, side)\u001b[0m\n\u001b[0;32m   2095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isna(values)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   2096\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys contain null values on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mside\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m side\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2097\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mside\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m keys must be sorted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ArrowExtensionArray):\n\u001b[0;32m   2100\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39m_maybe_convert_datelike_array()\n",
      "\u001b[1;31mValueError\u001b[0m: right keys must be sorted"
     ]
    }
   ],
   "source": [
    "merged_dataframe_A = pd.merge_asof(grouped_bin_sensor1, stage_a, on=\"date_time\",tolerance=pd.Timedelta(\"2ms\"))\n",
    "merged_dataframe_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next steps \n",
    "##### learn time series\n",
    "# How to deal with data to have it all in same time intervals (10 miuntes? Hour? half hour?)\n",
    "# or maybe user interactive option????\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application is used to convert notebook files (*.ipynb)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'usecase_TEMPLATE_COPY.ipynb' matched no files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        to various other formats.\n",
      "\n",
      "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
      "\n",
      "Options\n",
      "=======\n",
      "The options below are convenience aliases to configurable class-options,\n",
      "as listed in the \"Equivalent to\" description-line of the aliases.\n",
      "To see all configurable class-options for some <cmd>, use:\n",
      "    <cmd> --help-all\n",
      "\n",
      "--debug\n",
      "    set log level to logging.DEBUG (maximize logging output)\n",
      "    Equivalent to: [--Application.log_level=10]\n",
      "--show-config\n",
      "    Show the application's configuration (human-readable format)\n",
      "    Equivalent to: [--Application.show_config=True]\n",
      "--show-config-json\n",
      "    Show the application's configuration (json format)\n",
      "    Equivalent to: [--Application.show_config_json=True]\n",
      "--generate-config\n",
      "    generate default config file\n",
      "    Equivalent to: [--JupyterApp.generate_config=True]\n",
      "-y\n",
      "    Answer yes to any questions instead of prompting.\n",
      "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
      "--execute\n",
      "    Execute the notebook prior to export.\n",
      "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
      "--allow-errors\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
      "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
      "--stdin\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
      "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
      "--stdout\n",
      "    Write notebook output to stdout instead of files.\n",
      "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
      "--inplace\n",
      "    Run nbconvert in place, overwriting the existing notebook (only\n",
      "            relevant when converting to notebook format)\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
      "--clear-output\n",
      "    Clear output of current file and save in place,\n",
      "            overwriting the existing notebook.\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
      "--no-prompt\n",
      "    Exclude input and output prompts from converted document.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
      "--no-input\n",
      "    Exclude input cells and output prompts from converted document.\n",
      "            This mode is ideal for generating code-free reports.\n",
      "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
      "--allow-chromium-download\n",
      "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
      "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
      "--disable-chromium-sandbox\n",
      "    Disable chromium security sandbox when converting to PDF..\n",
      "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
      "--show-input\n",
      "    Shows code input. This flag is only useful for dejavu users.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
      "--embed-images\n",
      "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
      "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
      "--sanitize-html\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
      "--log-level=<Enum>\n",
      "    Set the log level by value or name.\n",
      "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
      "    Default: 30\n",
      "    Equivalent to: [--Application.log_level]\n",
      "--config=<Unicode>\n",
      "    Full path of a config file.\n",
      "    Default: ''\n",
      "    Equivalent to: [--JupyterApp.config_file]\n",
      "--to=<Unicode>\n",
      "    The export format to be used, either one of the built-in formats\n",
      "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf']\n",
      "            or a dotted object name that represents the import path for an\n",
      "            ``Exporter`` class\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.export_format]\n",
      "--template=<Unicode>\n",
      "    Name of the template to use\n",
      "    Default: ''\n",
      "    Equivalent to: [--TemplateExporter.template_name]\n",
      "--template-file=<Unicode>\n",
      "    Name of the template file to use\n",
      "    Default: None\n",
      "    Equivalent to: [--TemplateExporter.template_file]\n",
      "--theme=<Unicode>\n",
      "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
      "    as prebuilt extension for the lab template)\n",
      "    Default: 'light'\n",
      "    Equivalent to: [--HTMLExporter.theme]\n",
      "--sanitize_html=<Bool>\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
      "    should be set to True by nbviewer or similar tools.\n",
      "    Default: False\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
      "--writer=<DottedObjectName>\n",
      "    Writer class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: 'FilesWriter'\n",
      "    Equivalent to: [--NbConvertApp.writer_class]\n",
      "--post=<DottedOrNone>\n",
      "    PostProcessor class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
      "--output=<Unicode>\n",
      "    overwrite base name use for output files.\n",
      "                can only be used when converting one notebook at a time.\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.output_base]\n",
      "--output-dir=<Unicode>\n",
      "    Directory to write output(s) to. Defaults\n",
      "                                  to output to the directory of each notebook. To recover\n",
      "                                  previous default behaviour (outputting to the current\n",
      "                                  working directory) use . as the flag value.\n",
      "    Default: ''\n",
      "    Equivalent to: [--FilesWriter.build_directory]\n",
      "--reveal-prefix=<Unicode>\n",
      "    The URL prefix for reveal.js (version 3.x).\n",
      "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
      "            of reveal.js.\n",
      "            For speaker notes to work, this must be a relative path to a local\n",
      "            copy of reveal.js: e.g., \"reveal.js\".\n",
      "            If a relative path is given, it must be a subdirectory of the\n",
      "            current directory (from which the server is run).\n",
      "            See the usage documentation\n",
      "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
      "            for more details.\n",
      "    Default: ''\n",
      "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
      "--nbformat=<Enum>\n",
      "    The nbformat version to write.\n",
      "            Use this to downgrade notebooks.\n",
      "    Choices: any of [1, 2, 3, 4]\n",
      "    Default: 4\n",
      "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "    The simplest way to use nbconvert is\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to html\n",
      "\n",
      "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf'].\n",
      "\n",
      "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
      "\n",
      "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
      "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
      "            'classic'. You can specify the flavor of the format used.\n",
      "\n",
      "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
      "\n",
      "            You can also pipe the output to stdout, rather than a file\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
      "\n",
      "            PDF is generated via latex\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
      "\n",
      "            You can get (and serve) a Reveal.js-powered slideshow\n",
      "\n",
      "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
      "\n",
      "            Multiple notebooks can be given at the command line in a couple of\n",
      "            different ways:\n",
      "\n",
      "            > jupyter nbconvert notebook*.ipynb\n",
      "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
      "\n",
      "            or you can specify the notebooks list in a config file, containing::\n",
      "\n",
      "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
      "\n",
      "            > jupyter nbconvert --config mycfg.py\n",
      "\n",
      "To see all available configurables, use `--help-all`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html usecase_TEMPLATE_COPY.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
