# EEG Stress Detection (CNN & LSTM)

This repo contains my sprint-based work on EEG stress-level classification using PyTorch
(CNN & LSTM), a Streamlit demo for inference + dashboards, and a minimal FastAPI
“cloud feasibility” prototype.

## What’s here 
- **Sprint 1 **: Setup & Dataset, Preprocessing, Model Prototyping
- **Sprint 2 **: Training Setup, Model Development
- **Sprint 3 **: Structured evaluation for CNN/LSTM, multiple seeds/splits,
  confusion matrices, reproducible data pipeline.
- **Sprint 4 **: Optimization trials (quantization, pruning), latency profiling,
  prototype dashboard.
- **Sprint 4/5 **: Streamlit dashboard integration (accuracy–latency, F1–size),
  cloud feasibility test (FastAPI endpoint exposed via tunnel).
- **Sprint 5 (Week 10)**: Final stress testing (noise/jitter/channel-drop), baseline
  summary CSVs/PNGs + short markdown report.

## Suggested structure
project-root/
├─ notebooks/
│  ├─ cnn_model-v4.ipynb
│  ├─ lstm_model-v1.ipynb
│  ├─ cnn_model_eval_final.ipynb
│  ├─ lstm_model_eval_final.ipynb
│  ├─ CNN_Sprint4_optimization_final.ipynb
│  ├─ LSTM_Sprint4_optimization_final.ipynb
│  ├─ Transformer.ipynb
│  └─ FinalTesting.ipynb
├─ streamlit_app/
│  ├─ app.py
│  └─ Streamlit_final.ipynb
├─ models/
│  ├─ cnn_model.pth
│  └─ lstm_model.pth
├─ README.md
└─ requirements.txt

>  Do **not** commit full datasets. Keep only tiny demo samples in `EEG_Samples/`.

## Data & assumptions

- Input sample shape: **(14, T)** (channels × timesteps).  
- Common evaluation window used: **T = 256**.  
- **Normalization**: per-sample, per-channel (z-score over the time axis).  
- Labels: **binary** (0 = Low stress, 1 = High stress).

## Models (PyTorch)

- **CNN**: 2×Conv1d → AdaptiveAvgPool1d → FC(64→32) → FC(32→2).
- **LSTM**: LSTM(input_size=14, hidden_size=64, num_layers=2) → FC(64→32) → FC(32→2).
- Trained checkpoints saved as:
  - cnn_model.pth`
  - lstm_model.pth`


## ▶️ How to run (Colab or local)

1) Install deps

pip install -r requirements.txt

2) Streamlit demo

Edit paths in streamlit_app/app.py if your checkpoints live in Drive.

Run: streamlit run streamlit_app/app.py
     streamlit run streamlit_app/app.py & npx localtunnel --port 8501
In the app:

Pick CNN or LSTM, enter checkpoint path (e.g., /content/drive/MyDrive/cnn_model.pth).

Upload a .npy EEG sample shaped (14, T).

See prediction (Low/High stress) and confidence.

Scroll to Model Optimization Dashboard and point to week9_results_all.csv
(generated by the optimization notebook) to view:

Accuracy vs Latency

F1 vs Model Size

3) Final stress testing (Week 10)

Run notebooks/FinalTesting.ipynb:

Generates:

week10_eval_baselines.csv

week10_stress_results.csv

confusion matrices (PNGs)

Week10_System_Report.md

**Results (typical)

CNN: ~81–82% test accuracy (with T=256 window).

LSTM: ~85% test accuracy when trained longer (e.g., 50 epochs).

Optimized variants show lower latency / size with small accuracy deltas.

**Repro notes

Fixed seeds used where appropriate (e.g., 42).

Consistent normalization (per-sample, per-channel z-score).

Clear Google Drive paths for data/model loading in notebooks.




