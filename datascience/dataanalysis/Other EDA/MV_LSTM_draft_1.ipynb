{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17402e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from matplotlib import pyplot\n",
    "from sodapy import Socrata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0698cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the below to open data source, download sensor data, and store it as a csv locally.\n",
    "\n",
    "# #Function to get Sensor count history data\n",
    "# def sensor_count():\n",
    "#     client = Socrata('data.melbourne.vic.gov.au', 'nlPM0PQJSjzCsbVqntjPvjB1f', None)\n",
    "#     sensor_data_id = \"b2ak-trbp\"\n",
    "#     results = client.get(sensor_data_id, limit=5000000)\n",
    "#     df = pd.DataFrame.from_records(results)\n",
    "#     df = df[['date_time', 'year', 'month', 'mdate', 'day', 'time', 'sensor_id', 'sensor_name', 'hourly_counts']]\n",
    "#     return df\n",
    "\n",
    "# sensor_history = sensor_count()\n",
    "\n",
    "# sensor_history.to_csv('sensor_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2ec307",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_history = pd.read_csv('sensor_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc533f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sensor = sensor_history[sensor_history.sensor_id == 4].copy()\n",
    "single_sensor.sort_values('date_time', inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b191deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sensor counts range from 0 to 1.\n",
    "maximum = single_sensor.hourly_counts.max()\n",
    "single_sensor['hourly_counts'] = single_sensor['hourly_counts']/maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695273bf",
   "metadata": {},
   "source": [
    "Now, it is important to understand that a model that attempts to make predictions on a time series can have reasonably good success by simply copying the value of the previous time step. In most cases, this value will be close to the next value in the sequence - and this can give the appearance of predictive ability where there is actually none.\n",
    "\n",
    "So before building models and evaluating them, it is worthwhile setting up a baseline. This is the performance attained by simply copying the hourly count from the previous time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fb1fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline R-squared score is: 0.8835439180056677\n"
     ]
    }
   ],
   "source": [
    "true_count = single_sensor.hourly_counts.to_numpy()\n",
    "prev_count = true_count[1:true_count.shape[0]]\n",
    "r2_baseline = r2_score(prev_count, true_count[0:true_count.shape[0]-1])   \n",
    "print(\"The baseline R-squared score is:\", r2_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d6ee5d",
   "metadata": {},
   "source": [
    "From this example we can see a fairly convincing score (at the time of writing this comment, it was around 0.884). However, we know that the model we just made is useless for our purposes.\n",
    "We need to improve on this score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0226a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_seq = []\n",
    "for i in range(0, len(single_sensor)):\n",
    "    sensor_seq.append(single_sensor.hourly_counts.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8a16e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 392\n",
    "# split into samples\n",
    "X, y = split_sequence(sensor_seq, n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37f71f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88d05ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[10001:80000]\n",
    "X_val = X[80001:]\n",
    "X_test = X[:10000]\n",
    "Y_train = y[10001:80000]\n",
    "Y_val = y[80001:]\n",
    "Y_test = y[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49d65fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.00001\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(48, return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(96, return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(120, return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(196, input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(48, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=opt, loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8008907c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "1094/1094 [==============================] - 164s 145ms/step - loss: 0.0440 - val_loss: 0.0227\n",
      "Epoch 2/45\n",
      "1094/1094 [==============================] - 114s 104ms/step - loss: 0.0260 - val_loss: 0.0223\n",
      "Epoch 3/45\n",
      "1094/1094 [==============================] - 111s 101ms/step - loss: 0.0257 - val_loss: 0.0241\n",
      "Epoch 4/45\n",
      "1094/1094 [==============================] - 107s 98ms/step - loss: 0.0154 - val_loss: 0.0043\n",
      "Epoch 5/45\n",
      "1094/1094 [==============================] - 105s 96ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 6/45\n",
      "1094/1094 [==============================] - 105s 96ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 7/45\n",
      "1094/1094 [==============================] - 104s 95ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 8/45\n",
      "1094/1094 [==============================] - 104s 95ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 9/45\n",
      "1094/1094 [==============================] - 105s 96ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 10/45\n",
      "1094/1094 [==============================] - 121s 111ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 11/45\n",
      "1094/1094 [==============================] - 107s 98ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 12/45\n",
      "1094/1094 [==============================] - 111s 101ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 13/45\n",
      "1094/1094 [==============================] - 101s 92ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 14/45\n",
      "1094/1094 [==============================] - 100s 91ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 15/45\n",
      "1094/1094 [==============================] - 160s 146ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 16/45\n",
      "1094/1094 [==============================] - 139s 126ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 17/45\n",
      "1094/1094 [==============================] - 98s 90ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 18/45\n",
      "1094/1094 [==============================] - 100s 91ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 19/45\n",
      "1094/1094 [==============================] - 112s 103ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 20/45\n",
      "1094/1094 [==============================] - 107s 98ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 21/45\n",
      "1094/1094 [==============================] - 104s 95ms/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 22/45\n",
      "1094/1094 [==============================] - 99s 90ms/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 23/45\n",
      "1094/1094 [==============================] - 103s 94ms/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 24/45\n",
      "1094/1094 [==============================] - 101s 92ms/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 25/45\n",
      "1094/1094 [==============================] - 104s 95ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 26/45\n",
      "1094/1094 [==============================] - 103s 94ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 27/45\n",
      "1094/1094 [==============================] - 102s 93ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 28/45\n",
      "1094/1094 [==============================] - 118s 108ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 29/45\n",
      "1094/1094 [==============================] - 98s 90ms/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 30/45\n",
      "1094/1094 [==============================] - 101s 93ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 31/45\n",
      "1094/1094 [==============================] - 102s 94ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 32/45\n",
      "1094/1094 [==============================] - 109s 100ms/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 33/45\n",
      "1094/1094 [==============================] - 110s 101ms/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 34/45\n",
      "1094/1094 [==============================] - 104s 95ms/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 35/45\n",
      "1094/1094 [==============================] - 103s 94ms/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 36/45\n",
      "1094/1094 [==============================] - 103s 94ms/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 37/45\n",
      "1094/1094 [==============================] - 103s 94ms/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 38/45\n",
      "1094/1094 [==============================] - 103s 94ms/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 39/45\n",
      "1094/1094 [==============================] - 103s 94ms/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 40/45\n",
      "1094/1094 [==============================] - 102s 93ms/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 41/45\n",
      "1094/1094 [==============================] - 101s 93ms/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 42/45\n",
      "1094/1094 [==============================] - 101s 92ms/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 43/45\n",
      "1094/1094 [==============================] - 101s 93ms/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 44/45\n",
      "1094/1094 [==============================] - 100s 92ms/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 45/45\n",
      "1094/1094 [==============================] - 101s 92ms/step - loss: 0.0021 - val_loss: 0.0053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fad4a388b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X_train, Y_train, validation_data =(X_val, Y_val), epochs=45, verbose=1, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "612be277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted next value:  [[127.42242]]\n",
      "actual next value:  69.0\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = array(sensor_seq[10001:10393])\n",
    "# x_input = x_input/maximum\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(\"predicted next value: \", yhat * maximum)\n",
    "print(\"actual next value: \", sensor_seq[10393] * maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d11a2b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted next value:  [[1327.6808]]\n",
      "actual next value:  1470.0\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_input = array(sensor_seq[10021:10413])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(\"predicted next value: \", yhat * maximum)\n",
    "print(\"actual next value: \", sensor_seq[10413] * maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dcc31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6be64d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337978519191391"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b5b4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fb7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function to get Sensor count history data\n",
    "# def micro_count():\n",
    "#     client = Socrata('data.melbourne.vic.gov.au', 'nlPM0PQJSjzCsbVqntjPvjB1f', None)\n",
    "#     micro_data_id = \"u4vh-84j8\"\n",
    "#     results = client.get(micro_data_id, limit=4000000)\n",
    "#     if results:\n",
    "#         df = pd.DataFrame.from_records(results)\n",
    "#     return df\n",
    "\n",
    "# micro_history = micro_count()\n",
    "\n",
    "# micro_history.to_csv('micro_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc19c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_history = pd.read_csv('micro_history.csv')\n",
    "\n",
    "micro_history = micro_history[(micro_history.sensor_id == '5a') | (micro_history.sensor_id == '5b') |\n",
    "                             (micro_history.sensor_id == '5c') | (micro_history.sensor_id == '0a') |\n",
    "                             (micro_history.sensor_id == '0b') | (micro_history.sensor_id == '6')]\n",
    "\n",
    "micro_history = micro_history[(micro_history.site_id == 1003) | (micro_history.site_id == 1009)]\n",
    "\n",
    "micro_history = micro_history.drop(['id', 'gateway_hub_id', 'type', 'units'], axis=1)\n",
    "\n",
    "micro_history.loc[micro_history.sensor_id == '5a', 'temp'] = micro_history.value\n",
    "micro_history.loc[micro_history.sensor_id == '5b', 'humidity'] = micro_history.value\n",
    "micro_history.loc[micro_history.sensor_id == '5c', 'pressure'] = micro_history.value\n",
    "micro_history.loc[micro_history.sensor_id == '0a', 'part_2p5'] = micro_history.value\n",
    "micro_history.loc[micro_history.sensor_id == '0b', 'part_10'] = micro_history.value\n",
    "micro_history.loc[micro_history.sensor_id == '6', 'wind'] = micro_history.value\n",
    "\n",
    "micro_history.local_time = pd.to_datetime(micro_history.local_time, format='%Y-%m-%d')\n",
    "micro_history['year'] = micro_history.local_time.dt.year\n",
    "micro_history['month'] = micro_history.local_time.dt.month_name()\n",
    "micro_history['mdate'] = micro_history.local_time.dt.day\n",
    "micro_history['time'] = micro_history.local_time.dt.hour\n",
    "\n",
    "micro_history = micro_history.drop(['site_id', 'sensor_id', 'value', 'local_time'], axis=1)\n",
    "micro_history = micro_history.groupby(by=['year', 'month', 'mdate', 'time']).max()\n",
    "\n",
    "ped_climate = sensor_history.merge(micro_history, on=('year', 'month', 'mdate', 'time'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dbd5ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sensor_climate = ped_climate.loc[ped_climate.sensor_name == 'Town Hall (West)'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a39449bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sensor_climate.fillna(method='ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7fb3ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>mdate</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>sensor_name</th>\n",
       "      <th>hourly_counts</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>part_2p5</th>\n",
       "      <th>part_10</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>2019-11-15T09:00:00.000</td>\n",
       "      <td>2019</td>\n",
       "      <td>November</td>\n",
       "      <td>15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Town Hall (West)</td>\n",
       "      <td>1430</td>\n",
       "      <td>15.41</td>\n",
       "      <td>66.14</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>18.4</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2019-11-15T10:00:00.000</td>\n",
       "      <td>2019</td>\n",
       "      <td>November</td>\n",
       "      <td>15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>Town Hall (West)</td>\n",
       "      <td>2101</td>\n",
       "      <td>16.12</td>\n",
       "      <td>59.41</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>2019-11-15T11:00:00.000</td>\n",
       "      <td>2019</td>\n",
       "      <td>November</td>\n",
       "      <td>15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>Town Hall (West)</td>\n",
       "      <td>2577</td>\n",
       "      <td>16.90</td>\n",
       "      <td>57.53</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.1</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2019-11-15T12:00:00.000</td>\n",
       "      <td>2019</td>\n",
       "      <td>November</td>\n",
       "      <td>15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Town Hall (West)</td>\n",
       "      <td>3439</td>\n",
       "      <td>18.73</td>\n",
       "      <td>54.64</td>\n",
       "      <td>1007.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>9.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>2019-11-15T13:00:00.000</td>\n",
       "      <td>2019</td>\n",
       "      <td>November</td>\n",
       "      <td>15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>Town Hall (West)</td>\n",
       "      <td>4043</td>\n",
       "      <td>18.78</td>\n",
       "      <td>51.06</td>\n",
       "      <td>1006.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>10.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date_time  year     month  mdate     day  time  sensor_id  \\\n",
       "512  2019-11-15T09:00:00.000  2019  November     15  Friday     9          4   \n",
       "567  2019-11-15T10:00:00.000  2019  November     15  Friday    10          4   \n",
       "622  2019-11-15T11:00:00.000  2019  November     15  Friday    11          4   \n",
       "677  2019-11-15T12:00:00.000  2019  November     15  Friday    12          4   \n",
       "732  2019-11-15T13:00:00.000  2019  November     15  Friday    13          4   \n",
       "\n",
       "          sensor_name  hourly_counts   temp  humidity  pressure  part_2p5  \\\n",
       "512  Town Hall (West)           1430  15.41     66.14    1008.0       4.5   \n",
       "567  Town Hall (West)           2101  16.12     59.41    1008.0       4.2   \n",
       "622  Town Hall (West)           2577  16.90     57.53    1007.9       4.1   \n",
       "677  Town Hall (West)           3439  18.73     54.64    1007.5       4.5   \n",
       "732  Town Hall (West)           4043  18.78     51.06    1006.7       4.1   \n",
       "\n",
       "     part_10   wind  \n",
       "512     18.4   7.92  \n",
       "567     20.0   7.88  \n",
       "622     20.1   7.92  \n",
       "677     23.1   9.68  \n",
       "732     18.7  10.44  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_sensor_climate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c02f7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sensor_climate.drop(['date_time', 'year', 'sensor_id', 'sensor_name', 'mdate'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "952ac916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>hourly_counts</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>part_2p5</th>\n",
       "      <th>part_10</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>November</td>\n",
       "      <td>Friday</td>\n",
       "      <td>9</td>\n",
       "      <td>1430</td>\n",
       "      <td>15.41</td>\n",
       "      <td>66.14</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>18.4</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>November</td>\n",
       "      <td>Friday</td>\n",
       "      <td>10</td>\n",
       "      <td>2101</td>\n",
       "      <td>16.12</td>\n",
       "      <td>59.41</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>November</td>\n",
       "      <td>Friday</td>\n",
       "      <td>11</td>\n",
       "      <td>2577</td>\n",
       "      <td>16.90</td>\n",
       "      <td>57.53</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.1</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>November</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12</td>\n",
       "      <td>3439</td>\n",
       "      <td>18.73</td>\n",
       "      <td>54.64</td>\n",
       "      <td>1007.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>9.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>November</td>\n",
       "      <td>Friday</td>\n",
       "      <td>13</td>\n",
       "      <td>4043</td>\n",
       "      <td>18.78</td>\n",
       "      <td>51.06</td>\n",
       "      <td>1006.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>10.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month     day  time  hourly_counts   temp  humidity  pressure  \\\n",
       "512  November  Friday     9           1430  15.41     66.14    1008.0   \n",
       "567  November  Friday    10           2101  16.12     59.41    1008.0   \n",
       "622  November  Friday    11           2577  16.90     57.53    1007.9   \n",
       "677  November  Friday    12           3439  18.73     54.64    1007.5   \n",
       "732  November  Friday    13           4043  18.78     51.06    1006.7   \n",
       "\n",
       "     part_2p5  part_10   wind  \n",
       "512       4.5     18.4   7.92  \n",
       "567       4.2     20.0   7.88  \n",
       "622       4.1     20.1   7.92  \n",
       "677       4.5     23.1   9.68  \n",
       "732       4.1     18.7  10.44  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_sensor_climate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e29c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {'January' : 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, 'July': 7,\n",
    "              'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "day_dict = {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, 'Friday': 5, 'Saturday': 6, 'Sunday': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8f33840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sensor_climate.replace({'month': month_dict, 'day': day_dict}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16873aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7aeefe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "74869965",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = scaler.fit_transform(single_sensor_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e39073d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sequence = np.zeros((scaled.shape[0], scaled.shape[1]+1), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1face35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, scaled.shape[0]-1):\n",
    "    new_sequence[i][0:9] = scaled[i][0:9]\n",
    "    new_sequence[i][10] = scaled[i+1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ae487721",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = new_sequence[0:12000, :]\n",
    "test = new_sequence[12000:15000, :]\n",
    "val = new_sequence[15000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "506a4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train[:, :-1], train[:, -1]\n",
    "test_x, test_y = test[:, :-1], test[:, -1]\n",
    "val_x, val_y = val[:, :-1], val[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e22fbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
    "test_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))\n",
    "val_x = val_x.reshape((val_x.shape[0], 1, val_x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4bf27410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "167/167 - 1s - loss: 0.1047 - val_loss: 0.0792\n",
      "Epoch 2/50\n",
      "167/167 - 0s - loss: 0.0790 - val_loss: 0.0584\n",
      "Epoch 3/50\n",
      "167/167 - 0s - loss: 0.0508 - val_loss: 0.0444\n",
      "Epoch 4/50\n",
      "167/167 - 0s - loss: 0.0356 - val_loss: 0.0412\n",
      "Epoch 5/50\n",
      "167/167 - 0s - loss: 0.0324 - val_loss: 0.0397\n",
      "Epoch 6/50\n",
      "167/167 - 0s - loss: 0.0317 - val_loss: 0.0392\n",
      "Epoch 7/50\n",
      "167/167 - 0s - loss: 0.0311 - val_loss: 0.0387\n",
      "Epoch 8/50\n",
      "167/167 - 0s - loss: 0.0305 - val_loss: 0.0382\n",
      "Epoch 9/50\n",
      "167/167 - 0s - loss: 0.0299 - val_loss: 0.0379\n",
      "Epoch 10/50\n",
      "167/167 - 0s - loss: 0.0292 - val_loss: 0.0375\n",
      "Epoch 11/50\n",
      "167/167 - 0s - loss: 0.0282 - val_loss: 0.0366\n",
      "Epoch 12/50\n",
      "167/167 - 0s - loss: 0.0274 - val_loss: 0.0360\n",
      "Epoch 13/50\n",
      "167/167 - 0s - loss: 0.0269 - val_loss: 0.0353\n",
      "Epoch 14/50\n",
      "167/167 - 0s - loss: 0.0265 - val_loss: 0.0350\n",
      "Epoch 15/50\n",
      "167/167 - 0s - loss: 0.0260 - val_loss: 0.0349\n",
      "Epoch 16/50\n",
      "167/167 - 0s - loss: 0.0258 - val_loss: 0.0346\n",
      "Epoch 17/50\n",
      "167/167 - 0s - loss: 0.0257 - val_loss: 0.0342\n",
      "Epoch 18/50\n",
      "167/167 - 0s - loss: 0.0256 - val_loss: 0.0340\n",
      "Epoch 19/50\n",
      "167/167 - 0s - loss: 0.0254 - val_loss: 0.0340\n",
      "Epoch 20/50\n",
      "167/167 - 0s - loss: 0.0253 - val_loss: 0.0340\n",
      "Epoch 21/50\n",
      "167/167 - 0s - loss: 0.0253 - val_loss: 0.0339\n",
      "Epoch 22/50\n",
      "167/167 - 0s - loss: 0.0252 - val_loss: 0.0339\n",
      "Epoch 23/50\n",
      "167/167 - 0s - loss: 0.0253 - val_loss: 0.0338\n",
      "Epoch 24/50\n",
      "167/167 - 0s - loss: 0.0251 - val_loss: 0.0339\n",
      "Epoch 25/50\n",
      "167/167 - 0s - loss: 0.0254 - val_loss: 0.0338\n",
      "Epoch 26/50\n",
      "167/167 - 0s - loss: 0.0250 - val_loss: 0.0340\n",
      "Epoch 27/50\n",
      "167/167 - 0s - loss: 0.0250 - val_loss: 0.0338\n",
      "Epoch 28/50\n",
      "167/167 - 0s - loss: 0.0250 - val_loss: 0.0339\n",
      "Epoch 29/50\n",
      "167/167 - 0s - loss: 0.0251 - val_loss: 0.0338\n",
      "Epoch 30/50\n",
      "167/167 - 0s - loss: 0.0251 - val_loss: 0.0338\n",
      "Epoch 31/50\n",
      "167/167 - 0s - loss: 0.0250 - val_loss: 0.0338\n",
      "Epoch 32/50\n",
      "167/167 - 0s - loss: 0.0250 - val_loss: 0.0338\n",
      "Epoch 33/50\n",
      "167/167 - 0s - loss: 0.0248 - val_loss: 0.0338\n",
      "Epoch 34/50\n",
      "167/167 - 0s - loss: 0.0248 - val_loss: 0.0338\n",
      "Epoch 35/50\n",
      "167/167 - 0s - loss: 0.0247 - val_loss: 0.0339\n",
      "Epoch 36/50\n",
      "167/167 - 0s - loss: 0.0245 - val_loss: 0.0339\n",
      "Epoch 37/50\n",
      "167/167 - 0s - loss: 0.0245 - val_loss: 0.0339\n",
      "Epoch 38/50\n",
      "167/167 - 0s - loss: 0.0244 - val_loss: 0.0339\n",
      "Epoch 39/50\n",
      "167/167 - 0s - loss: 0.0245 - val_loss: 0.0339\n",
      "Epoch 40/50\n",
      "167/167 - 0s - loss: 0.0243 - val_loss: 0.0339\n",
      "Epoch 41/50\n",
      "167/167 - 0s - loss: 0.0244 - val_loss: 0.0338\n",
      "Epoch 42/50\n",
      "167/167 - 0s - loss: 0.0243 - val_loss: 0.0340\n",
      "Epoch 43/50\n",
      "167/167 - 0s - loss: 0.0244 - val_loss: 0.0339\n",
      "Epoch 44/50\n",
      "167/167 - 0s - loss: 0.0243 - val_loss: 0.0339\n",
      "Epoch 45/50\n",
      "167/167 - 0s - loss: 0.0244 - val_loss: 0.0340\n",
      "Epoch 46/50\n",
      "167/167 - 0s - loss: 0.0242 - val_loss: 0.0340\n",
      "Epoch 47/50\n",
      "167/167 - 0s - loss: 0.0244 - val_loss: 0.0340\n",
      "Epoch 48/50\n",
      "167/167 - 0s - loss: 0.0243 - val_loss: 0.0341\n",
      "Epoch 49/50\n",
      "167/167 - 0s - loss: 0.0244 - val_loss: 0.0340\n",
      "Epoch 50/50\n",
      "167/167 - 0s - loss: 0.0243 - val_loss: 0.0340\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(50, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mae', optimizer='adam')\n",
    "# # fit network\n",
    "# history = model.fit(train_x, train_y, epochs=50, batch_size=72, validation_data=(test_x, test_y), verbose=2, shuffle=False)\n",
    "# # plot history\n",
    "# pyplot.plot(history.history['loss'], label='train')\n",
    "# pyplot.plot(history.history['val_loss'], label='test')\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a30e8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.00001\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(48, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(96, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(120, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(196, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(48, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6454cd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 2/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 3/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 4/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 5/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 6/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 7/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 8/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 9/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 10/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 11/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 12/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 13/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 14/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 15/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 16/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 17/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 18/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 19/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 20/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 21/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 22/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 23/200\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 24/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 25/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 26/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 27/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 28/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 29/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 30/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 31/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 32/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 33/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 34/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 35/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 36/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 37/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 38/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 39/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 40/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 41/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 42/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 43/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 44/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 45/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 46/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 47/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 48/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 49/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 50/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 51/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 52/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 53/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 54/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 55/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 56/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 57/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 58/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 59/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 60/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 61/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 62/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 63/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 64/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 65/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 66/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 67/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 68/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 69/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 70/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 71/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 72/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 73/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 74/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 75/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 76/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 77/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 78/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 79/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 80/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 81/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 82/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 83/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 84/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 85/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 86/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 87/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 88/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 89/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 90/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 91/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 92/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 93/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 94/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 95/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 96/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 97/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 98/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 99/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 100/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 101/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 102/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 103/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 104/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 105/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 106/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 107/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 108/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 109/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 110/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 111/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 112/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 113/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 114/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 115/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 116/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 117/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 118/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 119/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 120/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 121/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 122/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 123/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 124/200\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 125/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 126/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 127/200\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 128/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 129/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 130/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 131/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 132/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 133/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 134/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 135/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 136/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 137/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 138/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 139/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 140/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 141/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 142/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 143/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 144/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 145/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 146/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 147/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 148/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 149/200\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 150/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 151/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 152/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 153/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 154/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 155/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 156/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 157/200\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 158/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 159/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 160/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 162/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 163/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 164/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 165/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 166/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 167/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 168/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 169/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 170/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 171/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 172/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 173/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 174/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 175/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 176/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 177/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 178/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 179/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 180/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 181/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 182/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 183/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 184/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 185/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 186/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 187/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 188/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 189/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 190/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 191/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 192/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047ss: 0.00\n",
      "Epoch 193/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 194/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 195/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 196/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 197/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 198/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 199/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 200/200\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23235b6c460>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data =(test_x, test_y), epochs=1000, verbose=1, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d19d6944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score: 0.938\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(val_x)\n",
    "val_x = val_x.reshape((val_x.shape[0], val_x.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, val_x[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "val_y = val_y.reshape((len(val_y), 1))\n",
    "inv_y = concatenate((val_y, val_x[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "\n",
    "r2 = r2_score(inv_y, inv_yhat)\n",
    "print('R-squared score: %.3f' % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742bb65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "377f285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef6c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af2f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001cfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03579d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567fa9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cbcfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ffbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIT782_TF",
   "language": "python",
   "name": "sit782_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
