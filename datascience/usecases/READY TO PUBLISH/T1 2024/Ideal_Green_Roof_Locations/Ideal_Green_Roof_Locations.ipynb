{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hZs3_aDeM0P"
      },
      "source": [
        "<div class=\"usecase-title\">Ideal Green Roof Locations: Melbourne</div>\n",
        "\n",
        "<div class=\"usecase-authors\"><b>Authored by: </b> Ryan Waites, Hannah Smith, Ruofeng QIU</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5NFycOzeM0Q"
      },
      "source": [
        "<div class=\"usecase-duration\"><b>Duration:</b> 120 mins</div>\n",
        "\n",
        "<div class=\"usecase-level-skill\">\n",
        "    <div class=\"usecase-level\"><b>Level: </b>Beginner</div>\n",
        "    <div class=\"usecase-skill\"><b>Pre-requisite Skills: </b>Python</div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI5XEpUkeM0Q"
      },
      "source": [
        "<div class=\"usecase-section-header\">Scenario</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YTPuy1eeM0Q"
      },
      "source": [
        "**1. As a city planner, I want to identify the locations which could most benefit from retrofitting with a green roof.**\n",
        "\n",
        "**2. As a building manager or owner of a residence, I want to visualise the potential of retrofitting my building for energy efficiency and greening.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_8omN_2eM0Q"
      },
      "source": [
        "<div class=\"usecase-section-header\">Learning objectives</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yELV_ideM0Q"
      },
      "source": [
        "At the end of this use case you will be able to:\n",
        "\n",
        "- work with spatial databases using Geopandas\n",
        "\n",
        "- visualise spatial data on an interactive map\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3_SMmekeM0Q"
      },
      "source": [
        "<div class=\"usecase-section-header\">Why the interest in green roofs?</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_Vil9HZeM0Q"
      },
      "source": [
        "##### **What is a green roof?**\n",
        "\n",
        "<fn id=\"fn-14\">Green roofs are rooftops systems with plants in a growing medium, which are usually irrigated in drier climates. They can be:</fn>\n",
        "\n",
        "- _Extensive_: growing in a shallower medium, generally low growing plants like succulents or grasses\n",
        "- _Intensive_: growing in a deeper medium, with taller vegetation including shrubs or trees\n",
        "- _Semi-intensive_: partway between\n",
        "\n",
        "In Melbourne's climate even extensive green roofs may need to be irrigated.\n",
        "\n",
        "##### **How is this relevant to Melbourne?**\n",
        "\n",
        "Roofs make up about 23% of the total space in the City of Melbourne <a href=\"#fn-1\">[1]</a>, and over 90% of rooftops which are suitable for extensive roofs are also suitable for intensive. Therefore, there is a significant potential for green roofs to contribute to the urban forest target the council has set for 2040 <a href=\"#fn-2\">[2]</a>.\n",
        "\n",
        "Building turnover in the centre of Melbourne is slow, therefore the best approach is to identify retrofitting opportunities in the suitable existing buildings <a href=\"#fn-2\">[2]</a>.\n",
        "\n",
        "Urban areas with an elevated temperature relative to the rural surroundings is known as the urban heat island (UHI) effect <a href=\"#fn-3\">[3]</a>. It can refer to both the urban surface temperatures on roads, footpaths, and building envelopes as well as the ambient temperature. There is evidence of the UHI in Melbourne with an average annual intensity of approximately 1.5 degrees Celsius <a href=\"#fn-4\">[4]</a>.\n",
        "\n",
        "The UHI threatens the economy by reducing productivity, increases the need for cooling and thus impacts energy consumption, and is associated with poorer air quality and a number of health risks <a href=\"#fn-5\">[5]</a>. In Melbourne, simulations of thermal environments for residential buildings indicate that doubling the amount of vegetation is estimated to reduce heat-related deaths by 5-28%. <a href=\"#fn-6\">[6]</a>.\n",
        "\n",
        "##### **What are the benefits of green roofs?**\n",
        "\n",
        "Green roofs and walls mitigate the UHI by providing shade which blocks solar radiation from reaching urban surfaces, and by the vegetation absorbing and dissipating the radiation. This provides energy savings to the building owner, as well as cooling and comfort to the building users. For private businesses, this can improve productivity due to the improved interior comfort, and due to the psychological benefits of viewing vegetation <a href=\"#fn-7\">[7]</a>.\n",
        "\n",
        "In Melbourne, extensive green roofs were shown to reduce building energy use by 28% in summer <a href=\"#fn-7\">[7]</a>. Urban vegetation also increases urban ecology and biodiversity and provides amenity to the people using the urban spaces <a href=\"#fn-8\">[8]</a>. Green roofs make buildings cooler in summer and warmer in winter, provide barriers against noise pollution by reflecting sound as well as produce oxygen whilst capturing CO2 and other pollutants <a href=\"#fn-9\">[9]</a>. Ideally, trees should be used in combination with grasses, shrubs and planters for the optimum cooling effect <a href=\"#fn-10\">[10]</a>, and it is more effective to use multiple UHI mitigation strategies at the same time (cool materials, green roofs, green walls, and urban greenery) <a href=\"#fn-4\">[4]</a>.\n",
        "\n",
        "In addition, green roofs are an effective and sustainable tool to assist with the management of stormwater quality and quantity. The rainwater is initially stored in the soil and then the vegetation, often reducing peak runoff and volume in contrast to conventional roofs. A study conducted in the highly urbanized city of Seoul, South Korea, found the green roof to have an average runoff retention ranging from 10% to 60% <a href=\"#fn-11\">[11]</a> whilst a study simulating Melbourne's rainfall patterns, commonly frequent and small, found they had the potential to retain up to 90% each rainfall <a href=\"#fn-12\">[12]</a>. These effects, in combination with the delaying of runoff, can greatly reduce the chances of flash flooding in highly urbanized areas and the load on urban drainage <a href=\"#fn-13\">[13]</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oHnwr9MeM0R"
      },
      "source": [
        "<div class=\"usecase-section-header\">Relevant datasets</div>\n",
        "<h2 id=\"relevant-datasets\">Relevant Datasets</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6Av-jo4eM0R"
      },
      "source": [
        "##### **The Rooftop Project**\n",
        "\n",
        "This dataset uses a spatial multi-criteria analysis to classify buildings based on the possibility of adapting their rooftops for either intensive or extensive greenroofs. The buildings are located in the City of Melbourne.\n",
        "\n",
        "- [Rooftops with environmental retrofitting opportunities (\"Rooftop Project\")](https://data.melbourne.vic.gov.au/explore/dataset/rooftops-with-environmental-retrofitting-opportunities-rooftop-project/information/)\n",
        "\n",
        "****\n",
        "\n",
        "##### **Building Energy Consumption**\n",
        "\n",
        "This dataset outlines a model of energy consumption in megawatt hours in the City of Melbourne based on building attributes (age, floor area, etc) and is presented at property level scale. This model was developed by the CSIRO based on a baseline from 2011 to compare a potential reduction in energy consumption available in retrofitting is done. This retrofitting could be done demand-side (improving energy efficiency) or supply-side (by generating electricity on-site). The supply side considered roof size for placement of solar panels, but only considered 10% of that space to be potentially available for solar panels. The \"business as usual\" projections are property-level, but the retrofit scenario only is at block level due to privacy reasons.\n",
        "\n",
        "- [Property level energy consumption (modelled on building attributes) - baseline 2011 and business as usual projections 2016-2026](https://data.melbourne.vic.gov.au/explore/dataset/property-level-energy-consumption-modelled-on-building-attributes-baseline-2011-/information/)\n",
        "- [Block level energy consumption (modelled on building attributes) - 2026 projection - business-as-usual scenario](https://data.melbourne.vic.gov.au/explore/dataset/block-level-energy-consumption-modelled-on-building-attributes-2026-projection-b/information/)\n",
        "\n",
        "****\n",
        "\n",
        "##### **Urban Heat and Heat Vulnerability Index (HVI)**\n",
        "\n",
        "These datasets come from the Cooling and Greening Melbourne Interactive map made available by the state government. The urban heat dataset shows how many degrees Celsius the average temperature is above the baseline, when measuring within urban parts of a boundary area and using a non-urban baseline. The HVI refers to how vulnerable specific populations are to extreme heat events as indicated by heat exposure, sensitivity to heat, and adaptive capability.\n",
        "\n",
        "- [Access the Cooling and Greening Melbourne Interactive Map to download the data](https://www.planning.vic.gov.au/policy-and-strategy/planning-for-melbourne/plan-melbourne/cooling-greening-melbourne/cooling-and-greening-melbourne-interactive-map)\n",
        "\n",
        "****\n",
        "\n",
        "The rooftop and urban heat/HVI datasets are not accessible via the Socrata API, they need to be downloaded from the links above onto your local machine. Please note that the Urban Heat and HVI datasets are only downloadable over a mixed security connection which will be automatically blocked by any Chromium browser.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dsBoXh1eM0R"
      },
      "outputs": [],
      "source": [
        "# Working with the data\n",
        "import requests\n",
        "import io\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Polygon\n",
        "from shapely.geometry import MultiPolygon\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import tempfile\n",
        "import json\n",
        "from google.colab import drive\n",
        "from io import StringIO\n",
        "import requests\n",
        "import sys\n",
        "\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib.pylab as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import folium\n",
        "from folium import plugins\n",
        "import seaborn as sns\n",
        "import branca.colormap as cm\n",
        "from branca.colormap import StepColormap\n",
        "from shapely.geometry import Point\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTSSOI2LeM0R"
      },
      "source": [
        "<div class=\"usecase-section-header\">Accessing and loading the datasets</div>\n",
        "\n",
        "**Loading the energy consumption datasets**\n",
        "\n",
        "The building energy consumption datasets are available by API, available in the 'Export' tab at the website linked above. Since for this analysis the 2026 business as usual data will act as a baseline, it will be referred to as the baseline data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing datasets with API\n",
        "Using an API offers benefits like real-time data access, structured data retrieval, enhanced security, scalability, versioning support, cross-platform compatibility, and features like rate limiting. These advantages make APIs preferable over direct file access for accessing data in various applications.\n",
        "\n",
        "API keys can be generated throught the City of Melbourne Open Data Platform by creating an account and generating a key.\n",
        "https://data.melbourne.vic.gov.au/account/api-keys/\n",
        "\n",
        "For security reasons we use google drive to call our API Key as we don't want everyone to know what our key is."
      ],
      "metadata": {
        "id": "qxKJlloOMVqG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57dkRtM0eM0S"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Define a function to download and read a CSV file.\n",
        "#def download_and_load_csv(url):\n",
        "#    response = requests.get(url)\n",
        "#    csv_string = response.content.decode('utf-8')\n",
        "#    df = pd.read_csv(io.StringIO(csv_string))\n",
        "#    return df\n",
        "#\n",
        "## API Link\n",
        "#download_link = 'https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/property-level-energy-consumption-modelled-on-building-attributes-baseline-2011-/exports/csv?lang=en&timezone=Australia%2FSydney&use_labels=true&delimiter=%2C'\n",
        "#download_link_model = 'https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/block-level-energy-consumption-modelled-on-building-attributes-2026-projection-b/exports/csv?lang=en&timezone=Australia%2FSydney&use_labels=true&delimiter=%2C'\n",
        "#\n",
        "## Use functions to download and load data\n",
        "#baseline_df = download_and_load_csv(download_link)\n",
        "#model_df = download_and_load_csv(download_link_model)\n",
        "#\n",
        "#baseline_df = baseline_df[['Geo Shape', 'property_id', 'total_2026', 'floor_area']]\n",
        "#model_df = model_df[['Geo Shape', 'comm', 'num_b_prop', 'resi', 'total']]\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount our drive and give access to our Google Drive files\n",
        "#drive.mount('/content/drive')\n",
        "#with open('/content/drive/My Drive/API_KEY.txt', 'r') as file:\n",
        "#    api_key = file.read().strip()\n",
        "\n",
        "#api_key = os.getenv(api_key)"
      ],
      "metadata": {
        "id": "PtluPVtFZqcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we define the City of Melbourne Open Data base URL where we will be getting our datasets\n",
        "base_url = 'https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/'\n",
        "#apikey = api_key"
      ],
      "metadata": {
        "id": "m23kYs18Z46g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = 'property-level-energy-consumption-modelled-on-building-attributes-baseline-2011-'\n",
        "\n",
        "dataset_id1 = data1\n",
        "format = 'csv'\n",
        "\n",
        "url = f'{base_url}{dataset_id1}/exports/{format}'\n",
        "params = {\n",
        "    'select': '*',\n",
        "    'limit': -1,  # all records\n",
        "    'lang': 'en',\n",
        "    'timezone': 'UTC',\n",
        "    #'api_key': apikey\n",
        "}\n",
        "\n",
        "# GET request\n",
        "response = requests.get(url, params=params)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    # StringIO to read the CSV data\n",
        "    url_content = response.content.decode('utf-8')\n",
        "    baseline_df = pd.read_csv(StringIO(url_content), delimiter=';')\n",
        "    print(baseline_df.sample(10, random_state=999)) # Test\n",
        "else:\n",
        "    print(f'Request failed with status code {response.status_code}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkXlUVFQaqmY",
        "outputId": "755b96a2-b731-4bdd-ea62-62756705b412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  geo_point_2d  \\\n",
            "5951   -37.812878775966354, 144.95159085759175   \n",
            "8556     -37.7940431424463, 144.93220169589878   \n",
            "8493    -37.79052523446854, 144.93104709749272   \n",
            "5614    -37.81315500058192, 144.98540106735547   \n",
            "7730     -37.80391591810114, 144.9500909643986   \n",
            "12854   -37.796505867977935, 144.9574143686479   \n",
            "10109   -37.78925232661283, 144.92436935183676   \n",
            "4068    -37.79616919109746, 144.92892148507357   \n",
            "5885    -37.796551252465655, 144.9667591122433   \n",
            "12075  -37.814919661938426, 144.95594209579426   \n",
            "\n",
            "                                               geo_shape   total_2011  \\\n",
            "5951   {\"coordinates\": [[[[144.95172240926814, -37.81...  3210.979575   \n",
            "8556   {\"coordinates\": [[[[144.93235698727145, -37.79...     3.408451   \n",
            "8493   {\"coordinates\": [[[[144.93101249477107, -37.79...     4.231243   \n",
            "5614   {\"coordinates\": [[[[144.98545452154264, -37.81...     1.766663   \n",
            "7730   {\"coordinates\": [[[[144.9501908404918, -37.803...   128.736058   \n",
            "12854  {\"coordinates\": [[[[144.95722148527165, -37.79...     2.402328   \n",
            "10109  {\"coordinates\": [[[[144.92422537616062, -37.78...     6.576794   \n",
            "4068   {\"coordinates\": [[[[144.92871569249147, -37.79...     5.545171   \n",
            "5885   {\"coordinates\": [[[[144.9668734534323, -37.796...     3.419570   \n",
            "12075  {\"coordinates\": [[[[144.95622966212528, -37.81...    65.792567   \n",
            "\n",
            "        p_com_2011  p_res_2026    p_com_2026    total_2026    p_com_2021  \\\n",
            "5951   3196.591330   72.575772  22845.357230  22917.933002  16595.892190   \n",
            "8556      0.000000   22.697749      0.000000     22.697749      0.000000   \n",
            "8493      0.000000   24.228466      0.000000     24.228466      0.000000   \n",
            "5614      0.000000   11.605533      0.000000     11.605533      0.000000   \n",
            "7730    128.736051    0.000000    141.671789    141.671789    137.594733   \n",
            "12854     0.000000   14.830200      0.000000     14.830200      0.000000   \n",
            "10109     0.000000   36.919252      0.000000     36.919252      0.000000   \n",
            "4068      0.000000   35.032756      0.000000     35.032756      0.000000   \n",
            "5885      0.000000   18.429725      0.000000     18.429725      0.000000   \n",
            "12075    65.792534    0.000000     73.280293     73.280293     71.004694   \n",
            "\n",
            "       property_id  p_res_2011    total_2016    total_2021  p_res_2021  \\\n",
            "5951      105464.0   14.388245  10171.869193  16659.040474   63.148284   \n",
            "8556      615563.0    3.408451     17.167339     19.867883   19.867883   \n",
            "8493      615229.0    4.231243     18.302871     21.141121   21.141121   \n",
            "5614      104334.0    1.766663      8.853840     10.229686   10.229686   \n",
            "7730      111306.0    0.000000    133.370064    137.594733    0.000000   \n",
            "12854     108450.0    2.402328     11.470891     13.044432   13.044432   \n",
            "10109     618030.0    6.576794     28.425031     32.592008   32.592008   \n",
            "4068      110221.0    5.545171     26.606323     30.688371   30.688371   \n",
            "5885      105271.0    3.419570     14.206003     16.261546   16.261546   \n",
            "12075     105861.0    0.000000     68.605012     71.004694    0.000000   \n",
            "\n",
            "       floor_area  p_res_2016    p_com_2016  \n",
            "5951       340.10   54.236442  10117.632750  \n",
            "8556       103.69   17.167339      0.000000  \n",
            "8493       100.34   18.302871      0.000000  \n",
            "5614       155.40    8.853840      0.000000  \n",
            "7730         0.00    0.000000    133.370064  \n",
            "12854      159.10   11.470891      0.000000  \n",
            "10109      198.00   28.425031      0.000000  \n",
            "4068       224.00   26.606323      0.000000  \n",
            "5885       117.20   14.206003      0.000000  \n",
            "12075        0.00    0.000000     68.605012  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://data.melbourne.vic.gov.au/explore/dataset/live-music-venues/information/\n",
        "data1 = 'block-level-energy-consumption-modelled-on-building-attributes-2026-projection-b'\n",
        "\n",
        "dataset_id1 = data1\n",
        "format = 'csv'\n",
        "\n",
        "url = f'{base_url}{dataset_id1}/exports/{format}'\n",
        "params = {\n",
        "    'select': '*',\n",
        "    'limit': -1,  # all records\n",
        "    'lang': 'en',\n",
        "    'timezone': 'UTC',\n",
        "    #'api_key': apikey\n",
        "}\n",
        "\n",
        "# GET request\n",
        "response = requests.get(url, params=params)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    # StringIO to read the CSV data\n",
        "    url_content = response.content.decode('utf-8')\n",
        "    model_df = pd.read_csv(StringIO(url_content), delimiter=';')\n",
        "    print(model_df.sample(10, random_state=999)) # Test\n",
        "else:\n",
        "    print(f'Request failed with status code {response.status_code}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIVwCBV7bJDy",
        "outputId": "11b121ba-7a0a-4723-99dc-45cb38888d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                geo_point_2d  \\\n",
            "568     -37.7972605401462, 144.9739853653862   \n",
            "86    -37.80857230932849, 144.97239253658583   \n",
            "478  -37.813762433864675, 144.94156398242436   \n",
            "57    -37.81485927743677, 144.98677347160654   \n",
            "184   -37.794179783973085, 144.9240129390504   \n",
            "301  -37.810672905718754, 144.96571855733472   \n",
            "411   -37.835698748278276, 144.9798610731678   \n",
            "204   -37.78851479845848, 144.93945706527373   \n",
            "273    -37.81564892879715, 144.9839885616115   \n",
            "458  -37.818003552318466, 144.96348332674432   \n",
            "\n",
            "                                             geo_shape          comm  \\\n",
            "568  {\"coordinates\": [[[[144.97488893318013, -37.79...      0.000000   \n",
            "86   {\"coordinates\": [[[[144.97231148479653, -37.80...    895.729214   \n",
            "478  {\"coordinates\": [[[[144.94204765543608, -37.81...   1814.237879   \n",
            "57   {\"coordinates\": [[[[144.98786539601343, -37.81...      0.000000   \n",
            "184  {\"coordinates\": [[[[144.92365428618362, -37.79...      0.000000   \n",
            "301  {\"coordinates\": [[[[144.96660652706223, -37.80...  30741.587748   \n",
            "411  {\"coordinates\": [[[[144.98011196825615, -37.83...   1172.558427   \n",
            "204  {\"coordinates\": [[[[144.9399765715354, -37.788...   1489.835230   \n",
            "273  {\"coordinates\": [[[[144.98508074444095, -37.81...  16005.268544   \n",
            "458  {\"coordinates\": [[[[144.96441999096209, -37.81...  37843.856053   \n",
            "\n",
            "     num_b_prop         resi         total  \n",
            "568           1  1810.657254   1810.657254  \n",
            "86            1     0.000010    895.729224  \n",
            "478           1     0.000000   1814.237879  \n",
            "57           47   271.595430    271.595430  \n",
            "184         124   558.523028    558.523028  \n",
            "301           2  2093.682630  32835.270378  \n",
            "411          68   595.038985   1767.597412  \n",
            "204           5   651.064706   2140.899936  \n",
            "273          20   966.046859  16971.315403  \n",
            "458          30   332.497072  38176.353125  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rryudveleM0S"
      },
      "source": [
        "When downloaded from the API endpoint, these two datasets have their shapefiles stored as nested lists within a dictionary. To manipulate these datasets in Geopandas, we will need to convert these entries into a polygon.\n",
        "\n",
        "Geopandas geometry columns are typically named 'geometry', so we will also rename the column. This avoids having to specify the column name when passing the shapefiles to Geopandas methods."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_df = baseline_df[['geo_shape', 'property_id', 'total_2026', 'floor_area']]\n",
        "model_df = model_df[['geo_shape', 'comm', 'num_b_prop', 'resi', 'total']]"
      ],
      "metadata": {
        "id": "XxoE5ZJBcA8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_twmmlNueM0S"
      },
      "outputs": [],
      "source": [
        "# Methods for preparing the energy consumption datasets\n",
        "\n",
        "def get_coords(row):\n",
        "    # Parse the 'Geo Shape' data from a JSON string to a Python dictionary\n",
        "    geo_shape = json.loads(row['geometry'])\n",
        "\n",
        "    # Check if the geometry type is 'MultiPolygon'\n",
        "    if geo_shape['type'] == 'MultiPolygon':\n",
        "        # Extract coordinates for MultiPolygon\n",
        "        coordinates = geo_shape['coordinates']\n",
        "        polygons = [Polygon(p[0]) for p in coordinates]  # Extract each polygon\n",
        "        row[\"geometry\"] = MultiPolygon(polygons)\n",
        "    else:\n",
        "        row[\"geometry\"] = None  # Handle other types or malformed data\n",
        "    return row\n",
        "\n",
        "def prepare_dataset(dataframe, baseline=False):\n",
        "    # Create a new DataFrame to store the modified data\n",
        "    new_dataframe = dataframe.copy()\n",
        "\n",
        "    # Rename columns as needed\n",
        "    new_dataframe = new_dataframe.rename(columns={\"geo_shape\" : \"geometry\"})\n",
        "\n",
        "    # Apply the get_coords function and update the 'geometry' column\n",
        "    new_dataframe['geometry'] = new_dataframe.apply(get_coords, axis=1)['geometry']\n",
        "\n",
        "    # Convert numeric columns if needed\n",
        "    if baseline:\n",
        "        new_dataframe[\"total_2026\"] = pd.to_numeric(new_dataframe['total_2026'], errors='coerce')\n",
        "        new_dataframe[\"floor_area\"] = pd.to_numeric(new_dataframe['floor_area'], errors='coerce')\n",
        "    else:\n",
        "        new_dataframe[\"total\"] = pd.to_numeric(new_dataframe['total'], errors='coerce')\n",
        "\n",
        "    # Convert the DataFrame to a GeoDataFrame\n",
        "    return gpd.GeoDataFrame(new_dataframe, geometry='geometry', crs=4326)\n",
        "\n",
        "model_gdf = prepare_dataset(model_df)\n",
        "baseline_gdf = prepare_dataset(baseline_df, baseline=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BEhjblPeM0S"
      },
      "outputs": [],
      "source": [
        "# Preparing the dataset\n",
        "model_gdf = prepare_dataset(model_df)\n",
        "baseline_gdf = prepare_dataset(baseline_df, baseline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X4RG4MTeM0S"
      },
      "source": [
        "**Loading the rooftop datasets**\n",
        "\n",
        "Although the rooftop dataset is available as a zip over the API, this will not unpack to a shapefile. The shapefile data is only available by navigating to the link in the <a href=\"#relevant-datasets\">Relevant Datasets</a> section and downloading the zipped file from there directly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWR_lYCreM0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "1ab2ad62-3aa3-4ca9-babd-39e2f47f43dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:fiona._env:`/vsicurl/https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda94_green_roof_extensive.shp' not recognized as a supported file format.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DriverError",
          "evalue": "'/vsicurl/https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda94_green_roof_extensive.shp' not recognized as a supported file format.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: '/vsicurl/https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda94_green_roof_extensive.shp' not recognized as a supported file format.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-12b8e091b996>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extensive green roof dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrooftop_ext_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda94_green_roof_extensive.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Intensive green roof dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrooftop_int_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda94_green_roof_intensive.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Solar roof dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mpath_or_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         return _read_file_fiona(\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs_wkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;31m# attempt to get EPSG code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             colxn = Collection(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mDriverError\u001b[0m: '/vsicurl/https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda94_green_roof_extensive.shp' not recognized as a supported file format."
          ]
        }
      ],
      "source": [
        "# Extensive green roof dataset\n",
        "rooftop_ext_df = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda94_green_roof_extensive.shp\")\n",
        "# Intensive green roof dataset\n",
        "rooftop_int_df = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda94_green_roof_intensive.shp\")\n",
        "# Solar roof dataset\n",
        "rooftop_solar = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda95_green_roof_solar.shp\")\n",
        "# Cool roof dataset\n",
        "rooftop_cool = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/mga55_gda94_green_roof_cool.shp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcdLZlrQeM0S"
      },
      "source": [
        "**Loading from the Cooling and Greening map**\n",
        "\n",
        "The urban heat dataset and the HVI dataset are downloaded by searching on the interactive map, which only allows downloading 1000 results at once. Four files are required to capture the entire area of the City of Melbourne.\n",
        "\n",
        "Since the result selection on the interactive map is done with a rectangular selection, some of the data in the urban heat and HVI shape files will be irrelevant, so a shapefile of the City of Melbourne local government area (LGA) will be imported to trim the data to the correct areas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcX6bjEYeM0S"
      },
      "outputs": [],
      "source": [
        "# Heat vulnerability index dataset\n",
        "hvi_df = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/Heat Vulnerability Index (2018)(SA1).shp\")\n",
        "\n",
        "# The urban heat dataset\n",
        "df_part1 = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/Urban Heat (2018)(MB).shp\")\n",
        "df_part2 = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/Urban Heat (2018)(MB)2.shp\")\n",
        "df_part3 = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/Urban Heat (2018)(MB)3.shp\")\n",
        "df_part4 = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/Urban Heat (2018)(MB)4.shp\")\n",
        "# Collating the three files\n",
        "urbanheat_df = pd.concat([df_part1, df_part2, df_part3, df_part4]).drop_duplicates()\n",
        "\n",
        "# The City of Melbourne LGA file\n",
        "LGA_shape = gpd.read_file(\"https://github.com/Chameleon-company/MOP-Code/blob/master/datascience/usecases/DEPENDENCIES/greenroofs/Local Government Area Solid.shp\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "injvv2JleM0S"
      },
      "outputs": [],
      "source": [
        "# Converting the datasets to the same coordinate system\n",
        "rooftop_ext_gdf = rooftop_ext_df.to_crs(epsg=4326)\n",
        "rooftop_int_gdf = rooftop_int_df.to_crs(epsg=4326)\n",
        "rooftop_solar_gdf = rooftop_solar.to_crs(epsg=4326)\n",
        "rooftop_cool_gdf = rooftop_cool.to_crs(epsg=4326)\n",
        "hvi_gdf = hvi_df.to_crs(epsg=4326)\n",
        "urbanheat_gdf = urbanheat_df.to_crs(epsg=4326)\n",
        "LGA_shape_gdf = LGA_shape.to_crs(epsg=4326)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnt85ZE8eM0S"
      },
      "source": [
        "<div class=\"usecase-section-header\">Filtering the data</div>\n",
        "\n",
        "This use case seeks to find which buildings in Melbourne City could most benefit from installing either an intensive or extensive green roof.\n",
        "\n",
        "**Filtering for the most suitable roofs**\n",
        "\n",
        "First, let's narrow down the green rooftop datasets to filter out any properties that aren't suitable. The <code>RATING</code> column uses categorical data, which can be encoded as numerical data to make it easier to work with. This converts the system from \"Excellent\" to \"Very Poor\" into 0-4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjZN9A6WeM0S"
      },
      "outputs": [],
      "source": [
        "# Converting categorical ratings to numerical form\n",
        "le = LabelEncoder()\n",
        "\n",
        "def label_encoded(column):\n",
        "    # Encodes the data for the given column with labels between 0 and n_classes-1\n",
        "    le.fit(column)\n",
        "    le.classes_ = np.flip(le.classes_)\n",
        "    return le.transform(column)\n",
        "\n",
        "# Converting the columns in the dataset\n",
        "# We don't need to make a copy of the data since this process is reversible using the .inverse_transform method\n",
        "rooftop_ext_gdf[\"RATING\"] = label_encoded(rooftop_ext_gdf[\"RATING\"])\n",
        "rooftop_int_gdf[\"RATING\"] = label_encoded(rooftop_int_gdf[\"RATING\"])\n",
        "rooftop_solar_gdf[\"RATING\"] = label_encoded(rooftop_solar_gdf[\"RATING\"])\n",
        "rooftop_cool_gdf[\"RATING\"] = label_encoded(rooftop_cool_gdf[\"RATING\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQF95f_5eM0S"
      },
      "source": [
        "We need to visualise the spread of data across the rating categories to know how to filter. Below are bar charts which function as histograms showing the counts of each rating (ranging from \"Very Poor\" up to \"Excellent\") for both the intensive and extensive datasets.\n",
        "\n",
        "Predicatably, the overall suitability for the intensive dataset is lower as this type of green roof requires more things, like suitability for irrigation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0bh_p2TeM0S"
      },
      "outputs": [],
      "source": [
        "# Setting styles\n",
        "sns.set_theme(style=\"whitegrid\", font_scale=1.2, palette=\"YlGn\")\n",
        "\n",
        "# Creating Subgraphs\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=(10, 8))\n",
        "axes = [ax1, ax2, ax3, ax4]\n",
        "datasets = [rooftop_ext_gdf, rooftop_int_gdf, rooftop_solar_gdf, rooftop_cool_gdf]\n",
        "titles = [\"Extensive green roof suitability\", \"Intensive green roof suitability\",\n",
        "          \"Solar roof suitability\", \"Cool roof suitability\"]\n",
        "\n",
        "# Plotting each subgraph\n",
        "for ax, data, title in zip(axes, datasets, titles):\n",
        "    sns.countplot(data=data, x=\"RATING\", ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks([4, 3, 2, 1, 0])\n",
        "    ax.set_xticklabels(['Excellent', 'Good', 'Moderate', 'Poor', 'Very Poor'])\n",
        "    ax.set_xlabel(\"\")\n",
        "    ax.set_ylabel(\"Count by rating category\" if ax in [ax1, ax3] else \"\")\n",
        "\n",
        "# Restructuring of the layout\n",
        "fig.tight_layout(pad=2.0)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf6vKT39eM0T"
      },
      "source": [
        "There are several thousand properties which have an \"excellent\" suitability in each dataset, which is enough for the first pass of filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktt8XdExeM0T"
      },
      "outputs": [],
      "source": [
        "# \"Excellent\" was encoded as 4 by the label encoder\n",
        "# Define the datasets to be filtered and their naming\n",
        "datasets = {\n",
        "    \"rooftop_ext_gdf\": rooftop_ext_gdf,\n",
        "    \"rooftop_int_gdf\": rooftop_int_gdf,\n",
        "    \"rooftop_solar_gdf\": rooftop_solar_gdf,\n",
        "    \"rooftop_cool_gdf\": rooftop_cool_gdf\n",
        "}\n",
        "\n",
        "# Use a loop to filter out records rated \"Excellent\" in each dataset.\n",
        "best_datasets = {}\n",
        "for name, dataset in datasets.items():\n",
        "    best_datasets[f\"{name}_best\"] = dataset[dataset[\"RATING\"] == 4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ui2AmN4eM0T"
      },
      "source": [
        "These datasets have some very small polygons which might clutter up the map, so the final filtering for this dataset is to remove the very small shapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ-8WE-meM0T"
      },
      "outputs": [],
      "source": [
        "# Removing polygons with a small area\n",
        "# Define the minimum area\n",
        "minimum_area = 100\n",
        "\n",
        "# Update the previously created best_datasets dictionary to remove polygons with an area smaller than the minimum threshold\n",
        "for name, dataset in best_datasets.items():\n",
        "    best_datasets[name] = dataset[dataset['Shape_Area'] > minimum_area]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1MLBGl_eM0T"
      },
      "source": [
        "**Filtering the energy consumption datasets**\n",
        "\n",
        "Next, let's identify which buildings are modelled to have the _smallest_ improvement in their energy efficiency.\n",
        "\n",
        "To do this, we need to deal with the fact that the baseline dataset is property level, whereas the model dataset is block level.\n",
        "\n",
        "Doing a spatial join on the datasets means that properties that share a block (as determined by the <code>geometry</code> column) will also share a right index. Since the <code>total</code> column is unique in the <code>model_gdf</code> dataset, that can be used to lookup the relevant row.\n",
        "\n",
        "There are also zero values in both <code>baseline_gdf</code> and <code>model_gdf</code> for that need to be filtered out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6u8awR7ceM0T"
      },
      "outputs": [],
      "source": [
        "# Filtering the properties with totals of 0 mwh/s of energy consumption\n",
        "model_gdf_filtered = model_gdf[model_gdf[\"total\"] != 0]\n",
        "baseline_gdf_filtered = baseline_gdf[baseline_gdf[\"total_2026\"] != 0]\n",
        "\n",
        "# Spatial joining the datasets\n",
        "energy_consumption_diff = gpd.sjoin(baseline_gdf_filtered, model_gdf_filtered, how=\"inner\", op='intersects')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51KygQ8DeM0T"
      },
      "source": [
        "We can visualise this by choosing a block to lookup, here I used block <code>359</code>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV9XYGjoeM0T"
      },
      "outputs": [],
      "source": [
        "# Method to visualise the properties located on a given block in the energy consumption join\n",
        "\n",
        "def visualise_properties(block_index):\n",
        "    \"\"\"\n",
        "    Produces a plot visualising the properties located on a given block.\n",
        "    block_index: the index_right of the block in energy_consumption_diff dataset\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, figsize=(5, 5))\n",
        "\n",
        "    # Check if block_index exists in the dataset\n",
        "    if block_index not in energy_consumption_diff['index_right'].unique():\n",
        "        print(f\"Block index {block_index} not found.\")\n",
        "        return\n",
        "\n",
        "    # Display the properties (baseline data)\n",
        "    properties = energy_consumption_diff[energy_consumption_diff['index_right'] == block_index]\n",
        "\n",
        "    # Display the block (model_gdf_filtered data)\n",
        "    # Assuming 'total' field is unique for each block\n",
        "    block_total = properties['total'].iloc[0]\n",
        "    block = model_gdf_filtered[model_gdf_filtered['total'] == block_total]\n",
        "\n",
        "    if block.empty:\n",
        "        print(f\"No matching block found in model_gdf_filtered for the total value of {block_total}.\")\n",
        "        return\n",
        "\n",
        "    block.plot(ax=ax, color=\"#78c679\")\n",
        "    properties.plot(ax=ax, color=\"#31a354\", lw=0.8)\n",
        "    plt.yticks([])\n",
        "    plt.xticks([])\n",
        "    plt.title(\"Properties on block index \" + str(block_index))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cT5TYfqeM0T"
      },
      "outputs": [],
      "source": [
        "visualise_properties(359)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3tkNPhQeM0T"
      },
      "source": [
        "To find the difference between the projected business as usual condition for 2026 versus the modelled retrofitting scenario, we can create a new column and populate it with the percentage difference in energy consumption (increase or decrease). A positive number will represent the modelling situation having a greater energy consumption in megawatts per hour, and a negative number indicates a lower energy consumption.\n",
        "\n",
        "We can then sort the dataset by the difference column.\n",
        "\n",
        "To avoid redoing the summing operation for all the properties on a block, first sort the dataframe by the right index to ensure all properties in a block are clustered together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBAiiTRIeM0T"
      },
      "outputs": [],
      "source": [
        "# Adding a % difference between the baseline and model for 2026\n",
        "\n",
        "# Sort by 'index_right'\n",
        "energy_consumption_diff = energy_consumption_diff.sort_values('index_right')\n",
        "\n",
        "# Sum the baseline energy consumption for each property for this entire index\n",
        "baseline_sum = energy_consumption_diff.groupby('index_right')['total_2026'].transform('sum')\n",
        "\n",
        "# Select the relevant total from the model total\n",
        "model = energy_consumption_diff.groupby('index_right')['total'].transform('first')\n",
        "\n",
        "# Add new column\n",
        "energy_consumption_diff['difference'] = round((baseline_sum - model) / baseline_sum * -100, 2)\n",
        "\n",
        "# Sort in descending order\n",
        "energy_consumption_diff = energy_consumption_diff.sort_values('difference', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2paOuxEeM0T"
      },
      "source": [
        "Inspecting the first few values of this data shows an unexpectedly large increase for some properties, given the difference column is a percentage. Block 63 has an increase of nearly 40000%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAPDbd1ueM0T"
      },
      "source": [
        "Manual inspection of the blocks with unusually large increases reveals many of them have a floor area of 0, or few properties per block, which could be why the modelling total energy consumption is dramatically higher.\n",
        "\n",
        "Filtering can remove the extraneously large increases in energy consumption.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dc1ToOzYePK"
      },
      "outputs": [],
      "source": [
        "energy_consumption_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gchvryAeeM0V"
      },
      "outputs": [],
      "source": [
        "visualise_properties(63)\n",
        "visualise_properties(329)\n",
        "visualise_properties(256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm7Fh4HZbptn"
      },
      "outputs": [],
      "source": [
        "# Defining thresholds for abnormal growth\n",
        "max_difference = 100  # Adjustment as required\n",
        "\n",
        "# Filtering out records whose energy consumption increases above a threshold value\n",
        "energy_consumption_diff_filtered = energy_consumption_diff[energy_consumption_diff['difference'] < max_difference]\n",
        "\n",
        "# Filter out records with a floor area of 0\n",
        "energy_consumption_diff_filtered = energy_consumption_diff_filtered[energy_consumption_diff_filtered['floor_area'] != 0]\n",
        "\n",
        "# Filter out blocks with a low number of properties\n",
        "threshold = 5  # Adjustment as required\n",
        "energy_consumption_diff_filtered = energy_consumption_diff_filtered[energy_consumption_diff_filtered['num_b_prop'] >= threshold]\n",
        "\n",
        "# Select the records with difference value less than 100 and take the first 1200 records.\n",
        "n_properties = 1200\n",
        "if len(energy_consumption_diff_filtered) < n_properties:\n",
        "  print(f\"Warning: The dataset contains only {len(energy_consumption_diff_filtered)} records, which is less than {n_properties}.\")\n",
        "else:\n",
        "  energy_consumption_diff_filtered = energy_consumption_diff_filtered.iloc[:n_properties]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c42BEuJ8eM0W"
      },
      "outputs": [],
      "source": [
        "# Boxplot and histogram highlighting the distribution of values.\n",
        "fig, ax = plt.subplots(1, 2, figsize = (16, 8))\n",
        "\n",
        "energy_consumption_diff_filtered.boxplot(\n",
        "    ax = ax[0],\n",
        "    column = 'difference',\n",
        "    patch_artist = True,\n",
        "    boxprops=dict(facecolor = '#78c679',\n",
        "    color = 'black'))\n",
        "\n",
        "\n",
        "ax[0].set_title(\"Energy Consumption Differential Percentage\")\n",
        "ax[0].set_ylabel('Percentage')\n",
        "\n",
        "energy_consumption_diff_filtered.hist(\n",
        "    ax = ax[1],\n",
        "    column = 'difference',\n",
        "    color = '#78c679',\n",
        "    edgecolor = 'black')\n",
        "\n",
        "ax[1].set_title(\"Energy Consumption Differential Percentage\")\n",
        "ax[1].set_ylabel('Count')\n",
        "ax[1].set_xlabel('Percentage')\n",
        "ax[1].set_axisbelow(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaoIk_AkeM0W"
      },
      "outputs": [],
      "source": [
        "# Show specific columns\n",
        "columns_to_display = ['geometry', 'property_id', 'total_2026', 'floor_area', 'index_right', 'total', 'difference']\n",
        "energy_consumption_diff_filtered[columns_to_display]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgCv_eD6eM0W"
      },
      "source": [
        "**Filter the urban heat and HVI to the City of Melbourne LGA**\n",
        "\n",
        "The final filtering step concerns the urban heat difference and heat vulnerability index (HVI) datasets. Because the data was was selected by a rectangular area selection tool and we are only interested in the data that lies in the boundaries of the LGA, we need to filter out the values that don't relate to our area of interest - the City of Melbourne.\n",
        "\n",
        "An intersection overlay with a Shapefile of the LGA boundaries will allow us to fit the datasets to the area we are interested in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEec-mefeM0W"
      },
      "outputs": [],
      "source": [
        "# Creating the overlays\n",
        "HVI_overlay = gpd.overlay(hvi_gdf, LGA_shape_gdf, how=\"intersection\")\n",
        "urbanheat_overlay = gpd.overlay(urbanheat_gdf, LGA_shape_gdf, how=\"intersection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kLdjiIzeM0W"
      },
      "outputs": [],
      "source": [
        "# Visualising the overlay\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# Urban Heat Overlay\n",
        "urbanheat_overlay.plot(ax=ax1, color=\"#31a354\", lw=0.5)\n",
        "ax1.set_title(\"Urban Heat Overlay\")\n",
        "ax1.set_axis_off()\n",
        "\n",
        "# HVI Overlay\n",
        "HVI_overlay.plot(ax=ax2, color=\"#31a354\", lw=0.5)\n",
        "ax2.set_title(\"HVI Overlay\")\n",
        "ax2.set_axis_off()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR8JxN4OeM0W"
      },
      "outputs": [],
      "source": [
        "# After filtering, examine the basic distribution of the dataset.\n",
        "display(urbanheat_overlay['UHI18_M'].describe())\n",
        "\n",
        "# Highlighting the distribution of values.\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# Boxplot\n",
        "urbanheat_overlay.boxplot(\n",
        "    ax=ax[0],\n",
        "    column='UHI18_M',\n",
        "    patch_artist=True,\n",
        "    boxprops=dict(facecolor='#78c679', color='black')\n",
        ")\n",
        "ax[0].set_title(\"Urban Heat Index - Boxplot\")\n",
        "ax[0].set_ylabel('UHI18_M Values')\n",
        "\n",
        "# Histogram\n",
        "urbanheat_overlay.hist(\n",
        "    ax=ax[1],\n",
        "    column='UHI18_M',\n",
        "    color='#78c679',\n",
        "    edgecolor='black'\n",
        ")\n",
        "\n",
        "\n",
        "n, bins, patches = ax[1].hist(urbanheat_overlay['UHI18_M'], color='#78c679', edgecolor='black')\n",
        "\n",
        "for i in range(len(patches)):\n",
        "    ax[1].text(patches[i].get_x() + patches[i].get_width() / 2, patches[i].get_height(),\n",
        "               str(int(n[i])), ha='center', va='bottom')\n",
        "\n",
        "ax[1].set_title(\"Urban Heat Index - Histogram\")\n",
        "ax[1].set_ylabel('Frequency')\n",
        "ax[1].set_xlabel('UHI18_M Values')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1wr0vnYeM0W",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Sort the dataset from highest to lowest and examine the negative outliers\n",
        "urbanheat_overlay.sort_values(by=['UHI18_M'], ascending=False, inplace=True)\n",
        "display(urbanheat_overlay[\"UHI18_M\"].tail(6))\n",
        "\n",
        "# Map the lowest values against the rest of the area of interest\n",
        "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
        "\n",
        "# Plotting negative outliers\n",
        "urbanheat_overlay.tail(6).plot(color='red', ax=ax)\n",
        "\n",
        "# Plotting data for the entire region\n",
        "model_gdf.plot(color='#78c679', ax=ax)\n",
        "\n",
        "\n",
        "ax.set_axis_off()\n",
        "ax.set_title(\"Spatial Distribution of Lowest Values\")\n",
        "\n",
        "# Creating Custom Legends\n",
        "red_patch = mpatches.Patch(color='red', label='Lowest Values')\n",
        "green_patch = mpatches.Patch(color='#78c679', label='Urban Heat Model')\n",
        "ax.legend(handles=[red_patch, green_patch])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW0xjHeheM0W"
      },
      "source": [
        "After a brief look at the distribution of values in the UHI for the Melbourne area, it's clear that the Urban Heat Island effect has a significant impact on temperatures in the city with an average increase of 8 degrees seen across all readings. Among all 1500+ readings, only 6 of manage to reach negative values and as to be expected, all occur in areas almost, if not entirely, covered by the river."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46j-5RrpeM0W"
      },
      "source": [
        "<div class=\"usecase-section-header\">Visualisation</div>\n",
        "\n",
        "Finally, let's create a visualisation with our filtered data that allows us to locate buildings suitable for a green roof.\n",
        "\n",
        "Since our rooftop datasets both have entirely \"Excellent\" properties, these can be visualised with a single colour. The other datasets will vary in colour based on a column's values.\n",
        "\n",
        "The user will be able to interact with the map with each dataset appearing as a layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB8ZiHxLz3RN"
      },
      "outputs": [],
      "source": [
        "# Maps the rooftops datasets\n",
        "\n",
        "def enhanced_mapping(dataFrame, columns, labels, description, subgroup):\n",
        "    \"\"\"\n",
        "    dataFrame: the dataframe to add\n",
        "    columns: list of the columns to be included in the map, with the most important column at index 0, 'geometry' must be last.\n",
        "    labels: list of labels/aliases to use in place of provided column names for the tooltip (don't include one for 'geometry').\n",
        "    description: a short description visible in map layers,\n",
        "    foliumMap: the map to add the feature to\n",
        "    \"\"\"\n",
        "\n",
        "    # Verify that 'Geometry' is in the column\n",
        "    if 'geometry' not in columns:\n",
        "        raise ValueError(\"The 'geometry' column must be included in the columns list\")\n",
        "\n",
        "    # Creating Data Copies\n",
        "    geo_data = dataFrame[columns].copy()\n",
        "    geo_data['dataset'] = description\n",
        "    columns_with_dataset = ['dataset'] + columns\n",
        "    labels_with_dataset = ['Dataset'] + labels\n",
        "\n",
        "    # Transform spatial data into a geoJson.\n",
        "    geo_json = geo_data.to_json()\n",
        "\n",
        "    # Add the features to the group\n",
        "    folium.GeoJson(\n",
        "        geo_json,\n",
        "        style_function=lambda feature: {\n",
        "            'color': 'black',\n",
        "            'fillOpacity': 0.2,\n",
        "            'opacity': 0.3,\n",
        "            'weight': 1\n",
        "        },\n",
        "        highlight_function=lambda feature: {\n",
        "            'fillOpacity': 0.4,\n",
        "            'opacity': 0.5\n",
        "        },\n",
        "        tooltip=folium.GeoJsonTooltip(fields=columns_with_dataset[:-1], aliases=labels_with_dataset)\n",
        "    ).add_to(subgroup)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6OL_3M0eM0W"
      },
      "outputs": [],
      "source": [
        "# Mapping the data where the colours will vary based on a value\n",
        "\n",
        "def mapping_overlay(dataFrame, columns, labels, description, foliumMap, colorMap, overlay):\n",
        "    \"\"\"\n",
        "    dataFrame: the dataframe to add\n",
        "    columns: list of the columns to be included in the map, with the most important column at index 0, 'geometry' must be last.\n",
        "    labels: list of labels/aliases to use in place of provided column names for the tooltip (don't include one for 'geometry').\n",
        "    description: a short description visible in map layers,\n",
        "    foliumMap: the map to add the feature to\n",
        "    colorMap: the colormap for this dataframe\n",
        "    overlay: True or False value, sets as an overlay (Radio Button).\n",
        "    \"\"\"\n",
        "    # Verify that 'Geometry' is in the column\n",
        "    if 'geometry' not in columns:\n",
        "        raise ValueError(\"The 'geometry' column must be included in the columns list\")\n",
        "\n",
        "    # Creating Data Copies\n",
        "    geo_data = dataFrame[columns].copy()\n",
        "\n",
        "    # Add the dataset name to json properties for use in tooltip.\n",
        "    geo_data['dataset'] = description\n",
        "    columns_with_dataset = ['dataset'] + columns\n",
        "    labels_with_dataset = ['Dataset'] + labels\n",
        "\n",
        "    # Transform geo data into geoJson.\n",
        "    geo_json = geo_data.to_json()\n",
        "\n",
        "    # Feature group creation and adds the dataset to the map\n",
        "    feature_group = folium.FeatureGroup(name=description, overlay=overlay).add_to(foliumMap)\n",
        "\n",
        "    # Add the features to Feature Group\n",
        "    folium.GeoJson(\n",
        "        geo_json,\n",
        "        style_function=lambda feature: {\n",
        "            'fillColor': colorMap(feature['properties'][columns_with_dataset[1]]),\n",
        "            'fillOpacity': 0.5,\n",
        "            'weight': 0.5,\n",
        "            'opacity': 0.5,\n",
        "            'color': 'black'\n",
        "        },\n",
        "        highlight_function=lambda feature: {\n",
        "            'fillOpacity': 0.7,\n",
        "            'opacity': 0.7\n",
        "        },\n",
        "        tooltip=folium.GeoJsonTooltip(fields=columns_with_dataset[:-1], aliases=labels_with_dataset)\n",
        "    ).add_to(feature_group)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6NB3MpUeM0X"
      },
      "outputs": [],
      "source": [
        "# Create step color map for Urban Heat Index\n",
        "heat_cmap = StepColormap(\n",
        "    colors=['gray', 'yellow', 'orange', 'orangered'],\n",
        "    vmin = 0,\n",
        "    vmax = 13,\n",
        "    index = [0, 3, 6, 9, 12.2],\n",
        "    caption = 'Urban Heat Index')\n",
        "\n",
        "# Create step color map for Heat Vulnerability Index\n",
        "vuln_cmap = StepColormap(\n",
        "    colors=['LightBlue', 'Plum', 'Orchid', 'MediumOrchid', 'DarkOrchid'],\n",
        "    vmin = 0,\n",
        "    vmax = 5,\n",
        "    index =[0, 1, 2, 3, 4, 5],\n",
        "    caption = 'Heat Vulnerability Index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0Jx20KweM0X",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Initial map settings\n",
        "initial_location = [-37.81368709240999, 144.95738102347036]\n",
        "initial_zoom_start = 13\n",
        "map_dimensions = {'width': 1000, 'height': 600}\n",
        "min_map_zoom = 10\n",
        "\n",
        "# Getting the best data set\n",
        "extensive_gdf_best = best_datasets[\"rooftop_ext_gdf_best\"]\n",
        "intensive_gdf_best = best_datasets[\"rooftop_int_gdf_best\"]\n",
        "solar_gdf_best = best_datasets[\"rooftop_solar_gdf_best\"]\n",
        "cool_gdf_best = best_datasets[\"rooftop_cool_gdf_best\"]\n",
        "\n",
        "m = folium.Map(\n",
        "    location=initial_location,\n",
        "    zoom_start=initial_zoom_start,\n",
        "    width=map_dimensions['width'],\n",
        "    height=map_dimensions['height'],\n",
        "    min_zoom=min_map_zoom,\n",
        "    tiles=None\n",
        "    )\n",
        "\n",
        "# Adding the base 'always on' tile map (control on/off disabled to allow UHI/HVI overlay selection with base map still).\n",
        "# folium.TileLayer('Cartodb Positron', min_zoom=10, overlay=False, control=False).add_to(m)\n",
        "folium.TileLayer('Cartodb Positron', min_zoom=min_map_zoom, overlay=False, control=False).add_to(m)\n",
        "\n",
        "# Add same as selectable layer to turn off all other tile layers.\n",
        "# folium.TileLayer('Cartodb Positron', min_zoom=10, overlay=False, name=\"No Overlay\",).add_to(m)\n",
        "folium.TileLayer('Cartodb Positron', min_zoom=min_map_zoom, overlay=False, name=\"No Overlay\").add_to(m)\n",
        "\n",
        "# Urban Heat Index\n",
        "mapping_overlay(\n",
        "    urbanheat_overlay,\n",
        "    # Can pass more columns, as long as the first column passed is the value to show in the color mapping\n",
        "    [\"UHI18_M\", \"geometry\"],\n",
        "    # Ensure a label for each column to be shown in the hover tool tip, except for 'geometry' which wont be listed.\n",
        "    [\"UHI in C\"],\n",
        "    \"Urban heat difference\",\n",
        "    m,\n",
        "    heat_cmap,\n",
        "    False\n",
        "    )\n",
        "\n",
        "# Heat Vulnerability Index\n",
        "mapping_overlay(\n",
        "    HVI_overlay,\n",
        "    [\"HVI_INDEX\", \"geometry\"],\n",
        "    [\"HVI\"],\n",
        "    \"Heat Vulnerability Index\",\n",
        "    m,\n",
        "    vuln_cmap,\n",
        "    False\n",
        "    )\n",
        "\n",
        "# Energy Consumption Difference\n",
        "mapping_overlay(\n",
        "    energy_consumption_diff_filtered,\n",
        "    [\"difference\", \"floor_area\", \"geometry\"],\n",
        "    [\"Difference %\", \"Total Floor Area\"],\n",
        "    \"Modelled versus business as usual energy consumption\",\n",
        "    m,\n",
        "    cm.linear.YlGn_09.scale(-100, 100),\n",
        "    True\n",
        "    )\n",
        "\n",
        "# Create feature group to encompass all rooftop data (Enables show/hide all selection. Brings rooftops back above overlays.).\n",
        "rooftops_fg = folium.FeatureGroup(name='Show/Hide Rooftops')\n",
        "rooftops_fg.add_to(m)\n",
        "\n",
        "# Create subgroup and add to rooftops_fg\n",
        "extensive_subgroup = plugins.FeatureGroupSubGroup(rooftops_fg, name=\"Extensive Rooftop: Excellent\")\n",
        "extensive_subgroup.add_to(m)\n",
        "\n",
        "intensive_subgroup = plugins.FeatureGroupSubGroup(rooftops_fg, name=\"Intensive Rooftop: Excellent\")\n",
        "intensive_subgroup.add_to(m)\n",
        "\n",
        "solar_subgroup = plugins.FeatureGroupSubGroup(rooftops_fg, name=\"Solar Rooftop: Excellent\")\n",
        "solar_subgroup.add_to(m)\n",
        "\n",
        "cool_subgroup = plugins.FeatureGroupSubGroup(rooftops_fg, name=\"Cool Rooftop: Excellent\")\n",
        "cool_subgroup.add_to(m)\n",
        "\n",
        "# Call enhanced_mapping with newly created subgroups\n",
        "enhanced_mapping(extensive_gdf_best, [\"RATING\", \"geometry\"], [\"Rating\"], \"Extensive Rooftop: Excellent\", extensive_subgroup)\n",
        "enhanced_mapping(intensive_gdf_best, [\"RATING\", \"geometry\"], [\"Rating\"], \"Intensive Rooftop: Excellent\", intensive_subgroup)\n",
        "enhanced_mapping(solar_gdf_best, [\"RATING\", \"geometry\"], [\"Rating\"], \"Solar Rooftop: Excellent\", solar_subgroup)\n",
        "enhanced_mapping(cool_gdf_best, [\"RATING\", \"geometry\"], [\"Rating\"], \"Cool Rooftop: Excellent\", cool_subgroup)\n",
        "\n",
        "\n",
        "# Add the layer control to switch layers\n",
        "folium.LayerControl().add_to(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzM_kydleM0X"
      },
      "source": [
        "Finally, we output the map. Using the layer control button the overlays can be shown or hidden and the user can choose which of the filtered rooftop datasets to show at any one time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3StrIXjeM0X"
      },
      "outputs": [],
      "source": [
        "# Displays the map\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tju5hzaleM0X"
      },
      "source": [
        "<div class=\"usecase-subsection-blurb\">References</div>\n",
        "\n",
        "<fn id=\"fn-1\">[1] GHD (2015) _Rooftop Adaptation Study: Green Roofs, Cool Roofs and Solar Panels Final Report_, City of Melbourne, Melbourne.</fn>\n",
        "\n",
        "<fn id=\"fn-2\">[2] Jones, R (2018) _Valuing Green Guide. Green Roofs, Walls And Faades Project Report_, City of Melbourne, Melbourne, Australia.</fn>\n",
        "\n",
        "<fn id=\"fn-3\">[3]: Howard L (1818) _The Climate of London: Deduced from Metereological Observations, Made at Different Places in the Neighbourhood of the Metropolis_, Howard W. Phillips, London, UK.</fn>\n",
        "\n",
        "<fn id=\"fn-4\">[4] Yenneti K, Ding L, Prasad D, Ulpiani G, Paolini R, Haddad S and Santamouris M (2020) 'Urban Overheating and Cooling Potential in Australia: An Evidence-Based Review'. _Climate_, 8(11):126. https://doi.org/10.3390/cli8110126</fn>\n",
        "\n",
        "<fn id=\"fn-5\">[5] Price A, Jones EC and Jefferson F (2015) 'Vertical Greenery Systems as a Strategy in Urban Heat Island Mitigation'. _Water Air Soil Pollut_ 226, 247. https://doi.org/10.1007/s11270-015-2464-9</fn>\n",
        "\n",
        "<fn id=\"fn-6\">[6] Chen D, Wang X, Thatcher M, Barnett G, Kachenko A and Prince R (2014) 'Urban vegetation for reducing heat related mortality', _Environmental Pollution_ 192:275-284.</fn>\n",
        "\n",
        "<fn id=\"fn-7\">[7] Williams N, Rayner J, Lee K, Fletcher T, Chen D, Szota C and Farrell C (2016) 'Developing Australian green roofs: Overview of a 5-year research program'. _Acta Horticulturae_. 1108:345-352. 10.17660/ActaHortic.2016.1108.46.</fn>\n",
        "\n",
        "<fn id=\"fn-8\">[8]: Hayes AT, Jandaghian Z, Lacasse MA, Gaur A, Lu H, Laouadi A, Ge H and Wang L (2022) 'Nature-based solutions (NBSs) to mitigate urban heat island (UHI) effects in Canadian cities', _Buildings_ 12(925). https://doi.org/10.3390/buildings12070925</fn>\n",
        "\n",
        "<fn id=\"fn-9\">[9] Guattari C, Evangelisti L, Asdrubali F and De Lieto Vollaro R (2020) 'Experimental evaluation and numerical simulation of the thermal performance of a green roof', _Applied Sciences_ 10(1767), https://doi.org/10.3390/app10051767</fn>\n",
        "\n",
        "<fn id=\"fn-10\">[10] Fu J, Dupre K, Tavares S, King, D and Banhalmi-Zakar Z (2022) 'Optimized greenery configuration to mitigate urban heat: A decade systematic review', _Frontiers of Architectural Research_ 11:466-491.</fn>\n",
        "\n",
        "<fn id=\"fn-11\">[11] Jusi S, Hadi E and Milii H (2019) 'Stormwater Management by Green Roof', _Acta Scientific: Agriculture_, 3(7):57-62, DOI: 10.31080/ASAG.2019.03.0516</fn>\n",
        "\n",
        "<fn id=\"fn-12\">[12] Zhang Z, Szota C, Fletcher TD, Williams NSG and Farrell C (2019) 'Green roof storage capacity can be more important than evapotranspiration for retention performance', _Journal of Environmental Management_, 232:404-412, DOI: 10.1016/j.jenvman.2018.11.070</fn>\n",
        "\n",
        "<fn id=\"fn-13\">[13] Shafique M, Kim R and Kyung-Ho K (2018) 'Green Roof for Stormwater Management in a Highly Urbanized Area: The Case of Seoul, Korea', _Sustainability_, 10(3):584, DOI: 10.3390/su10030584</fn>\n",
        "\n",
        "<a href=\"#fn-14\">Return to top</a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}